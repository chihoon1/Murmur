{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f804ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.discriminant_analysis as DA\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "#import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make directory for visualization\n",
    "import os\n",
    "if not os.path.exists('visualization'):\n",
    "    os.makedirs('visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69668bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c86ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cases from case features folder\n",
    "Ent_Case = pd.read_csv('case_features/Window_Entropy_Case.csv', header=None)\n",
    "Slope_Case = pd.read_csv('case_features/Window_Slope_Case.csv', header=None)\n",
    "Mf_Case = pd.read_csv('case_features/Window_Mf_Case.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991d1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load controls from control features folder\n",
    "Ent_Control = pd.read_csv('control_features/Window_Entropy_Control.csv', header=None)\n",
    "Slope_Control = pd.read_csv('control_features/Window_Slope_Control.csv', header=None)\n",
    "Mf_Control = pd.read_csv('control_features/Window_Mf_Control.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f51e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Entropy \", \"Slope \", \"ID\", \"Hurst Exponent \",\n",
    "    \"Left Slope \", \"Right Slope \",\"Left Tangent \",\n",
    "    \"Right Tangent\", \"Broadness\", \"Left Tangent Point\", \"Right Tangent Point\"]\n",
    "# combine Ent_Case and Slope_Case and Mfcc_Case\n",
    "Case = pd.concat([ Ent_Case.T, Slope_Case.T, Mf_Case ], axis=1)\n",
    "Case.columns = col_names\n",
    "Control = pd.concat([ Ent_Control.T, Slope_Control.T, Mf_Control ], axis=1)\n",
    "Control.columns = col_names\n",
    "Case['Case'] = 1\n",
    "Control['Case'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f887cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entropy                156\n",
       "Slope                  156\n",
       "ID                       0\n",
       "Hurst Exponent           0\n",
       "Left Slope               0\n",
       "Right Slope              0\n",
       "Left Tangent             0\n",
       "Right Tangent            0\n",
       "Broadness                0\n",
       "Left Tangent Point       0\n",
       "Right Tangent Point      0\n",
       "Case                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine Case and Control data\n",
    "data = pd.concat([Case, Control], axis=0)\n",
    "\n",
    "# check if any missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4d5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffle data\n",
    "data = data.sample(frac=1, random_state= 42).reset_index(drop=True);\n",
    "# replace NaN values with mean of the column\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "X = data.iloc[:, [0,1,9]]\n",
    "\n",
    "# replace NaN values with mean of the column\n",
    "y = data.iloc[:, 11]\n",
    "\n",
    "# split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773db390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (2024,)\n",
      "Validation labels shape: (506,)\n",
      "Test labels shape: (633,)\n",
      "Training features shape: (2024, 3)\n",
      "Validation features shape: (506, 3)\n",
      "Test features shape: (633, 3)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Validation labels shape:', y_val.shape)\n",
    "print('Test labels shape:', y_test.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2c81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 3163\n",
      "    Positive: 616 (19.48% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(data['Case'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875f3e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 01:38:19.057662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 01:38:21.627429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d02847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  # build a NN model and return it\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(10, activation='relu',input_shape=(train_features.shape[-1],)),\n",
    "      keras.layers.Dense(8, activation='relu'),\n",
    "      keras.layers.Dense(4, activation='relu'),\n",
    "      keras.layers.Dense(2, activation='relu'),\n",
    "      #keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid',bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c381134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model training set up\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=50,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5ea0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41942451])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "babe32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model using three features: entorpy, slope, and left tangent point\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [data.columns[0], data.columns[1], data.columns[9]]  # predictor features name\n",
    "num_repeat=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac59fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "726bda78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5024447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measures_dict = {\n",
    "        'training_accuracy': np.zeros(num_repeat),\n",
    "        'testing_accuracy': np.zeros(num_repeat),\n",
    "        'sensitivity': np.zeros(num_repeat),\n",
    "        'specificity': np.zeros(num_repeat),\n",
    "        'case_precision': np.zeros(num_repeat),\n",
    "        'control_precision': np.zeros(num_repeat),\n",
    "        'case_F1_score': np.zeros(num_repeat),\n",
    "        'control_F1_score': np.zeros(num_repeat),\n",
    "        'AUC_score': np.zeros(num_repeat)\n",
    "    }\n",
    "max_test_acc, max_cm = 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd81158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_792 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_793 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_794 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_795 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 458us/step\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 557us/step\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_796 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_797 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_798 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_799 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 470us/step\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "8/8 [==============================] - 0s 649us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_800 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_801 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_802 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_803 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 468us/step\n",
      "31/31 [==============================] - 0s 447us/step\n",
      "8/8 [==============================] - 0s 695us/step\n",
      "8/8 [==============================] - 0s 617us/step\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_804 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_805 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_806 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_807 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "31/31 [==============================] - 0s 503us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_808 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_809 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_810 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_811 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 466us/step\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_812 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_813 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_814 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_815 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 440us/step\n",
      "31/31 [==============================] - 0s 492us/step\n",
      "8/8 [==============================] - 0s 617us/step\n",
      "8/8 [==============================] - 0s 668us/step\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_816 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_817 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_818 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_819 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 496us/step\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_820 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_821 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_822 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_823 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 453us/step\n",
      "31/31 [==============================] - 0s 574us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "8/8 [==============================] - 0s 585us/step\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_824 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_825 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_826 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_827 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 503us/step\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "8/8 [==============================] - 0s 632us/step\n",
      "8/8 [==============================] - 0s 587us/step\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_828 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_829 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_830 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_831 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "31/31 [==============================] - 0s 452us/step\n",
      "8/8 [==============================] - 0s 621us/step\n",
      "8/8 [==============================] - 0s 597us/step\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_832 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_833 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_834 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_835 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "31/31 [==============================] - 0s 468us/step\n",
      "8/8 [==============================] - 0s 569us/step\n",
      "8/8 [==============================] - 0s 530us/step\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_836 (Dense)           (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_837 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_838 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_839 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 468us/step\n",
      "31/31 [==============================] - 0s 451us/step\n",
      "8/8 [==============================] - 0s 533us/step\n",
      "8/8 [==============================] - 0s 562us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# repeat training and testing models where downsampling is used to mitigate the data imbalance\n",
    "for i in range(num_repeat):\n",
    "    # select a  from Conrols of size a without replacement\n",
    "    Control_new = Control.sample(n=Case.shape[0], replace=False, random_state=42)\n",
    "\n",
    "    # combine Case and Control data\n",
    "    data = pd.concat([Case, Control_new], axis=0)\n",
    "\n",
    "    # # create feature matrix and target vector\n",
    "    X = data.loc[:, features]\n",
    "\n",
    "    # replace NaN values with mean of the column\n",
    "    X = X.fillna(X.mean())\n",
    "    y = data.loc[:, target]\n",
    "\n",
    "    # split data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train); X_test = scaler.transform(X_test)\n",
    "    input_shape = X.shape[1]\n",
    "    # Add a fully connected layer with 64 units and a sigmoid activation function\n",
    "    model = Sequential();\n",
    "    model.add(Dense(5, input_shape=(X.shape[1],),activation='relu')) # Add an input shape! (features,)\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    # Define the learning rate\n",
    "    ep = 500; bs = 50;\n",
    "    \n",
    "    \n",
    "    # Define the optimizer\n",
    "    from keras.optimizers import Adam,SGD\n",
    "    optimizer = Adam(learning_rate=.001, decay= 1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor= tf.keras.metrics.AUC(),\n",
    "                                       mode='max',\n",
    "                                       patience=200,\n",
    "                                       restore_best_weights=True)\n",
    "    # now we just update our model fit call\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        #callbacks=[es],\n",
    "                        epochs=ep, # you can set this to a big number!\n",
    "                        batch_size= bs,\n",
    "                        validation_split=0.2,\n",
    "                        shuffle= True,\n",
    "                        verbose= 0)\n",
    "\n",
    "    ## Training performance\n",
    "    model.predict(X_train) # prob of successes (survival)\n",
    "    # 1 and 0 (survival or not) so need to round to a whole number (0 or 1)\n",
    "    train_pred = np.round(model.predict(X_train),0)\n",
    "    test_pred = np.round(model.predict(X_test),0)\n",
    "    \n",
    "    # store performance metrics for each iteration\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    performance_measures_dict['training_accuracy'][i] = accuracy_score(y_train, train_pred)\n",
    "    performance_measures_dict['testing_accuracy'][i] = test_acc\n",
    "    performance_measures_dict['sensitivity'][i] = recall_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['specificity'][i] = recall_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_precision'][i] = precision_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_precision'][i] = precision_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_F1_score'][i] = f1_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_F1_score'][i] = f1_score(y_test, test_pred, pos_label=0)\n",
    "    y_prob = model.predict(X_test)\n",
    "    performance_measures_dict['AUC_score'][i] = roc_auc_score(y_test, y_prob)\n",
    "    if test_acc > max_test_acc:\n",
    "        max_test_acc = test_acc\n",
    "        max_cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "max_cm = pd.DataFrame({\"Predicted Negative(Absent)\": max_cm[:, 0], \"Predicted Positive(Present)\": max_cm[:, 1]})\n",
    "max_cm.index = [\"Actual Negative(Absent)\", \"Actual positive(Present)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "708de138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Training Accuracy: 0.6687817258883247\n",
      "Mean of Testing Accuracy: 0.6224696356275304\n",
      "Standard deviation of Testing Accuracy: 0.033267636198595726\n",
      "Mean of Sensitivity: 0.5981912144702842\n",
      "Standard deviation of Sensitivity: 0.12345770820055385\n",
      "Mean of Speicificity: 0.6490112994350283\n",
      "Standard deviation of Speicificity: 0.20020034293615951\n",
      "Mean of Case Precision: 0.6663632962489122\n",
      "Standard deviation of Case Precision: 0.050785150190414144\n",
      "Mean of Control Precision: 0.5465535538374705\n",
      "Standard deviation of Control Precision: 0.16510426637170847\n",
      "Mean of Case F1: 0.6201371412147276\n",
      "Standard deviation of Case F1: 0.023334573226217712\n",
      "Mean of Control F1: 0.5929269394117578\n",
      "Standard deviation of Control F1: 0.1800243882776128\n",
      "Mean of AUC: 0.6887892523978453\n",
      "Standard deviation of AUC: 0.057946398426397386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative(Absent)</th>\n",
       "      <th>Predicted Positive(Present)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative(Absent)</th>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual positive(Present)</th>\n",
       "      <td>61</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Negative(Absent)  \\\n",
       "Actual Negative(Absent)                           94   \n",
       "Actual positive(Present)                          61   \n",
       "\n",
       "                          Predicted Positive(Present)  \n",
       "Actual Negative(Absent)                            24  \n",
       "Actual positive(Present)                           68  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Mean of Training Accuracy: {performance_measures_dict['training_accuracy'].mean()}\")\n",
    "print(f\"Mean of Testing Accuracy: {performance_measures_dict['testing_accuracy'].mean()}\")\n",
    "print(f\"Standard deviation of Testing Accuracy: {performance_measures_dict['testing_accuracy'].std()}\")\n",
    "print(f\"Mean of Sensitivity: {performance_measures_dict['sensitivity'].mean()}\")\n",
    "print(f\"Standard deviation of Sensitivity: {performance_measures_dict['sensitivity'].std()}\")\n",
    "print(f\"Mean of Speicificity: {performance_measures_dict['specificity'].mean()}\")\n",
    "print(f\"Standard deviation of Speicificity: {performance_measures_dict['specificity'].std()}\")\n",
    "print(f\"Mean of Case Precision: {performance_measures_dict['case_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Case Precision: {performance_measures_dict['case_precision'].std()}\")\n",
    "print(f\"Mean of Control Precision: {performance_measures_dict['control_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Control Precision: {performance_measures_dict['control_precision'].std()}\")\n",
    "print(f\"Mean of Case F1: {performance_measures_dict['case_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Case F1: {performance_measures_dict['case_F1_score'].std()}\")\n",
    "print(f\"Mean of Control F1: {performance_measures_dict['control_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Control F1: {performance_measures_dict['control_F1_score'].std()}\")\n",
    "print(f\"Mean of AUC: {performance_measures_dict['AUC_score'].mean()}\")\n",
    "print(f\"Standard deviation of AUC: {performance_measures_dict['AUC_score'].std()}\")\n",
    "max_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdce6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Slope ',\n",
       " 'Hurst Exponent ',\n",
       " 'Left Slope ',\n",
       " 'Right Slope ',\n",
       " 'Left Tangent ',\n",
       " 'Left Tangent Point',\n",
       " 'Right Tangent Point']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using all features in the data\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [col_name for col_name in data.columns[1:11]]  # predictor features name\n",
    "features.pop(features.index('ID'))  # remove patient ID from feature names list\n",
    "features.pop(features.index('Broadness'))\n",
    "features.pop(features.index('Right Tangent'))\n",
    "num_repeat = 100\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8b5006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb4d86dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(train_features[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7afa8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measures_dict = {\n",
    "        'training_accuracy': np.zeros(num_repeat),\n",
    "        'testing_accuracy': np.zeros(num_repeat),\n",
    "        'sensitivity': np.zeros(num_repeat),\n",
    "        'specificity': np.zeros(num_repeat),\n",
    "        'case_precision': np.zeros(num_repeat),\n",
    "        'control_precision': np.zeros(num_repeat),\n",
    "        'case_F1_score': np.zeros(num_repeat),\n",
    "        'control_F1_score': np.zeros(num_repeat),\n",
    "        'AUC_score': np.zeros(num_repeat)\n",
    "    }\n",
    "max_test_acc, max_cm = 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df6d9d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_845 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_846 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_847 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_848 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 454us/step\n",
      "31/31 [==============================] - 0s 451us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 573us/step\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_849 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_850 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_851 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_852 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 532us/step\n",
      "31/31 [==============================] - 0s 498us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_853 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_854 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_855 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_856 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 447us/step\n",
      "31/31 [==============================] - 0s 499us/step\n",
      "8/8 [==============================] - 0s 744us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_857 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_858 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_859 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_860 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 527us/step\n",
      "31/31 [==============================] - 0s 508us/step\n",
      "8/8 [==============================] - 0s 594us/step\n",
      "8/8 [==============================] - 0s 658us/step\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_861 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_862 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_863 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_864 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 464us/step\n",
      "31/31 [==============================] - 0s 538us/step\n",
      "8/8 [==============================] - 0s 644us/step\n",
      "8/8 [==============================] - 0s 606us/step\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_865 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_866 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_867 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_868 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 437us/step\n",
      "31/31 [==============================] - 0s 511us/step\n",
      "8/8 [==============================] - 0s 623us/step\n",
      "8/8 [==============================] - 0s 820us/step\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_869 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_870 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_871 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_872 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 494us/step\n",
      "31/31 [==============================] - 0s 545us/step\n",
      "8/8 [==============================] - 0s 595us/step\n",
      "8/8 [==============================] - 0s 626us/step\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_873 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_874 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_875 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_876 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 504us/step\n",
      "31/31 [==============================] - 0s 581us/step\n",
      "8/8 [==============================] - 0s 590us/step\n",
      "8/8 [==============================] - 0s 605us/step\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_877 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_878 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_879 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_880 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 495us/step\n",
      "31/31 [==============================] - 0s 464us/step\n",
      "8/8 [==============================] - 0s 562us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_881 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_882 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_883 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_884 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 498us/step\n",
      "31/31 [==============================] - 0s 495us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "8/8 [==============================] - 0s 684us/step\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_885 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_886 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_887 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_888 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 474us/step\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "8/8 [==============================] - 0s 569us/step\n",
      "Model: \"sequential_189\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_889 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_890 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_891 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_892 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 512us/step\n",
      "31/31 [==============================] - 0s 507us/step\n",
      "8/8 [==============================] - 0s 602us/step\n",
      "8/8 [==============================] - 0s 612us/step\n",
      "Model: \"sequential_190\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_893 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_894 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_895 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_896 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 485us/step\n",
      "31/31 [==============================] - 0s 507us/step\n",
      "8/8 [==============================] - 0s 588us/step\n",
      "8/8 [==============================] - 0s 556us/step\n",
      "Model: \"sequential_191\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_897 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_898 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_899 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_900 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 510us/step\n",
      "31/31 [==============================] - 0s 494us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "8/8 [==============================] - 0s 580us/step\n",
      "Model: \"sequential_192\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_901 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_902 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_903 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_904 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 515us/step\n",
      "31/31 [==============================] - 0s 494us/step\n",
      "8/8 [==============================] - 0s 564us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_905 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_906 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_907 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_908 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "31/31 [==============================] - 0s 485us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_909 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_910 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_911 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_912 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "8/8 [==============================] - 0s 595us/step\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_913 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_914 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_915 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_916 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 510us/step\n",
      "31/31 [==============================] - 0s 544us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 750us/step\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_917 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_918 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_919 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_920 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "8/8 [==============================] - 0s 552us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_921 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_922 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_923 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_924 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 1s 485us/step\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "8/8 [==============================] - 0s 544us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_925 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_926 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_927 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_928 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 476us/step\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "8/8 [==============================] - 0s 650us/step\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_929 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_930 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_931 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_932 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 501us/step\n",
      "31/31 [==============================] - 0s 467us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 576us/step\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_933 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_934 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_935 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_936 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "31/31 [==============================] - 0s 458us/step\n",
      "8/8 [==============================] - 0s 560us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_937 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_938 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_939 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_940 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "31/31 [==============================] - 0s 501us/step\n",
      "8/8 [==============================] - 0s 535us/step\n",
      "8/8 [==============================] - 0s 574us/step\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_941 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_942 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_943 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_944 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 507us/step\n",
      "31/31 [==============================] - 0s 482us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_945 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_946 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_947 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_948 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 496us/step\n",
      "31/31 [==============================] - 0s 458us/step\n",
      "8/8 [==============================] - 0s 584us/step\n",
      "8/8 [==============================] - 0s 579us/step\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_949 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_950 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_951 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_952 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "31/31 [==============================] - 0s 518us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 599us/step\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_953 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_954 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_955 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_956 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "8/8 [==============================] - 0s 539us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_957 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_958 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_959 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_960 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 546us/step\n",
      "31/31 [==============================] - 0s 542us/step\n",
      "8/8 [==============================] - 0s 661us/step\n",
      "8/8 [==============================] - 0s 719us/step\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_961 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_962 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_963 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_964 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 502us/step\n",
      "31/31 [==============================] - 0s 520us/step\n",
      "8/8 [==============================] - 0s 582us/step\n",
      "8/8 [==============================] - 0s 649us/step\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_965 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_966 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_967 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_968 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "31/31 [==============================] - 0s 519us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_969 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_970 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_971 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_972 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 497us/step\n",
      "31/31 [==============================] - 0s 495us/step\n",
      "8/8 [==============================] - 0s 641us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_973 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_974 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_975 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_976 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 492us/step\n",
      "31/31 [==============================] - 0s 494us/step\n",
      "8/8 [==============================] - 0s 607us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_977 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_978 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_979 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_980 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 482us/step\n",
      "31/31 [==============================] - 0s 500us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 633us/step\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_981 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_982 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_983 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_984 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 494us/step\n",
      "31/31 [==============================] - 0s 522us/step\n",
      "8/8 [==============================] - 0s 692us/step\n",
      "8/8 [==============================] - 0s 663us/step\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_985 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_986 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_987 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_988 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 529us/step\n",
      "31/31 [==============================] - 0s 457us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_989 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_990 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_991 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_992 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 599us/step\n",
      "31/31 [==============================] - 0s 583us/step\n",
      "8/8 [==============================] - 0s 680us/step\n",
      "8/8 [==============================] - 0s 638us/step\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_993 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_994 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_995 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_996 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 528us/step\n",
      "31/31 [==============================] - 0s 503us/step\n",
      "8/8 [==============================] - 0s 632us/step\n",
      "8/8 [==============================] - 0s 631us/step\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_997 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_998 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_999 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1000 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 498us/step\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "8/8 [==============================] - 0s 664us/step\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1001 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1002 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1003 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1004 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 503us/step\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 635us/step\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1005 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1006 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1007 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1008 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "31/31 [==============================] - 0s 516us/step\n",
      "8/8 [==============================] - 0s 552us/step\n",
      "8/8 [==============================] - 0s 599us/step\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1009 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1010 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1011 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1012 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 475us/step\n",
      "31/31 [==============================] - 0s 513us/step\n",
      "8/8 [==============================] - 0s 557us/step\n",
      "8/8 [==============================] - 0s 606us/step\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1013 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1014 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1015 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1016 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 502us/step\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1017 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1018 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1019 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1020 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 528us/step\n",
      "31/31 [==============================] - 0s 497us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 610us/step\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1021 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1022 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1023 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1024 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 470us/step\n",
      "31/31 [==============================] - 0s 485us/step\n",
      "8/8 [==============================] - 0s 587us/step\n",
      "8/8 [==============================] - 0s 587us/step\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1025 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1026 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1027 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1028 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 514us/step\n",
      "31/31 [==============================] - 0s 528us/step\n",
      "8/8 [==============================] - 0s 582us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1029 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1030 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1031 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1032 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 555us/step\n",
      "31/31 [==============================] - 0s 582us/step\n",
      "8/8 [==============================] - 0s 633us/step\n",
      "8/8 [==============================] - 0s 584us/step\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1033 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1034 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1035 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1036 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "31/31 [==============================] - 0s 507us/step\n",
      "8/8 [==============================] - 0s 576us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1037 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1038 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1039 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1040 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 515us/step\n",
      "8/8 [==============================] - 0s 636us/step\n",
      "8/8 [==============================] - 0s 632us/step\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1041 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1042 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1043 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1044 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 524us/step\n",
      "31/31 [==============================] - 0s 452us/step\n",
      "8/8 [==============================] - 0s 641us/step\n",
      "8/8 [==============================] - 0s 695us/step\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1045 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1046 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1047 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1048 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "31/31 [==============================] - 0s 450us/step\n",
      "8/8 [==============================] - 0s 546us/step\n",
      "8/8 [==============================] - 0s 564us/step\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1049 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1050 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1051 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1052 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 467us/step\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "8/8 [==============================] - 0s 537us/step\n",
      "8/8 [==============================] - 0s 549us/step\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1053 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1054 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1055 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1056 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "8/8 [==============================] - 0s 560us/step\n",
      "8/8 [==============================] - 0s 582us/step\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1057 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1058 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1059 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1060 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "31/31 [==============================] - 0s 456us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 535us/step\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1061 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1062 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1063 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1064 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 530us/step\n",
      "31/31 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 621us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1065 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1066 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1067 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1068 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 502us/step\n",
      "31/31 [==============================] - 0s 475us/step\n",
      "8/8 [==============================] - 0s 527us/step\n",
      "8/8 [==============================] - 0s 589us/step\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1069 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1070 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1071 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1072 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 501us/step\n",
      "31/31 [==============================] - 0s 476us/step\n",
      "8/8 [==============================] - 0s 622us/step\n",
      "8/8 [==============================] - 0s 725us/step\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1073 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1074 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1075 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1076 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 480us/step\n",
      "31/31 [==============================] - 0s 514us/step\n",
      "8/8 [==============================] - 0s 623us/step\n",
      "8/8 [==============================] - 0s 780us/step\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1077 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1078 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1079 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1080 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 474us/step\n",
      "31/31 [==============================] - 0s 444us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "8/8 [==============================] - 0s 554us/step\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1081 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1082 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1083 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1084 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 504us/step\n",
      "31/31 [==============================] - 0s 451us/step\n",
      "8/8 [==============================] - 0s 541us/step\n",
      "8/8 [==============================] - 0s 569us/step\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1085 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1086 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1087 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1088 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 534us/step\n",
      "31/31 [==============================] - 0s 598us/step\n",
      "8/8 [==============================] - 0s 837us/step\n",
      "8/8 [==============================] - 0s 789us/step\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1089 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1090 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1091 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1092 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 451us/step\n",
      "31/31 [==============================] - 0s 533us/step\n",
      "8/8 [==============================] - 0s 651us/step\n",
      "8/8 [==============================] - 0s 638us/step\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1093 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1094 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1095 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1096 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 501us/step\n",
      "31/31 [==============================] - 0s 472us/step\n",
      "8/8 [==============================] - 0s 642us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1097 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1098 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1099 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1100 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 462us/step\n",
      "31/31 [==============================] - 0s 524us/step\n",
      "8/8 [==============================] - 0s 599us/step\n",
      "8/8 [==============================] - 0s 651us/step\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1101 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1102 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1103 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1104 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 511us/step\n",
      "31/31 [==============================] - 0s 524us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "8/8 [==============================] - 0s 714us/step\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1105 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1106 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1107 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1108 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 532us/step\n",
      "31/31 [==============================] - 0s 517us/step\n",
      "8/8 [==============================] - 0s 752us/step\n",
      "8/8 [==============================] - 0s 726us/step\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1109 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1110 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1111 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1112 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 538us/step\n",
      "31/31 [==============================] - 0s 519us/step\n",
      "8/8 [==============================] - 0s 607us/step\n",
      "8/8 [==============================] - 0s 598us/step\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1113 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1114 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1115 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1116 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "8/8 [==============================] - 0s 601us/step\n",
      "8/8 [==============================] - 0s 639us/step\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1117 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1118 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1119 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1120 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "31/31 [==============================] - 0s 535us/step\n",
      "8/8 [==============================] - 0s 584us/step\n",
      "8/8 [==============================] - 0s 648us/step\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1121 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1122 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1123 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1124 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 542us/step\n",
      "31/31 [==============================] - 0s 524us/step\n",
      "8/8 [==============================] - 0s 669us/step\n",
      "8/8 [==============================] - 0s 688us/step\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1125 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1126 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1127 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1128 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 455us/step\n",
      "31/31 [==============================] - 0s 444us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 582us/step\n",
      "8/8 [==============================] - 0s 554us/step\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1129 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1130 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1131 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1132 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 508us/step\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "8/8 [==============================] - 0s 656us/step\n",
      "8/8 [==============================] - 0s 687us/step\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1133 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1134 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1135 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1136 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "8/8 [==============================] - 0s 601us/step\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1137 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1138 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1139 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1140 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "31/31 [==============================] - 0s 525us/step\n",
      "8/8 [==============================] - 0s 610us/step\n",
      "8/8 [==============================] - 0s 612us/step\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1141 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1142 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1143 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1144 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 492us/step\n",
      "31/31 [==============================] - 0s 470us/step\n",
      "8/8 [==============================] - 0s 640us/step\n",
      "8/8 [==============================] - 0s 593us/step\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1145 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1146 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1147 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1148 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1149 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1150 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1151 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1152 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 486us/step\n",
      "31/31 [==============================] - 0s 505us/step\n",
      "8/8 [==============================] - 0s 581us/step\n",
      "8/8 [==============================] - 0s 615us/step\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1153 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1154 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1155 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1156 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 467us/step\n",
      "31/31 [==============================] - 0s 450us/step\n",
      "8/8 [==============================] - 0s 547us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1157 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1158 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1159 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1160 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 451us/step\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 634us/step\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1161 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1162 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1163 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1164 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "31/31 [==============================] - 0s 480us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "8/8 [==============================] - 0s 628us/step\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1165 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1166 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1167 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1168 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 495us/step\n",
      "31/31 [==============================] - 0s 472us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "8/8 [==============================] - 0s 592us/step\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1169 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1170 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1171 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1172 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "8/8 [==============================] - 0s 598us/step\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1173 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1174 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1175 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1176 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 453us/step\n",
      "31/31 [==============================] - 0s 486us/step\n",
      "8/8 [==============================] - 0s 576us/step\n",
      "8/8 [==============================] - 0s 591us/step\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1177 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1178 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1179 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1180 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 474us/step\n",
      "31/31 [==============================] - 0s 530us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "8/8 [==============================] - 0s 610us/step\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1181 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1182 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1183 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1184 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 466us/step\n",
      "31/31 [==============================] - 0s 470us/step\n",
      "8/8 [==============================] - 0s 587us/step\n",
      "8/8 [==============================] - 0s 562us/step\n",
      "Model: \"sequential_263\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1185 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1186 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1187 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1188 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 511us/step\n",
      "31/31 [==============================] - 0s 472us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1189 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1190 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1191 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1192 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 509us/step\n",
      "31/31 [==============================] - 0s 503us/step\n",
      "8/8 [==============================] - 0s 663us/step\n",
      "8/8 [==============================] - 0s 598us/step\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1193 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1194 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1195 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1196 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "31/31 [==============================] - 0s 467us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "8/8 [==============================] - 0s 676us/step\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1197 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1198 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1199 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1200 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 497us/step\n",
      "8/8 [==============================] - 0s 643us/step\n",
      "8/8 [==============================] - 0s 633us/step\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1201 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1202 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1203 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1204 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 490us/step\n",
      "31/31 [==============================] - 0s 492us/step\n",
      "8/8 [==============================] - 0s 574us/step\n",
      "8/8 [==============================] - 0s 605us/step\n",
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1205 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1206 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1207 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1208 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 513us/step\n",
      "31/31 [==============================] - 0s 518us/step\n",
      "8/8 [==============================] - 0s 666us/step\n",
      "8/8 [==============================] - 0s 667us/step\n",
      "Model: \"sequential_269\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1209 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1210 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1211 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1212 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "31/31 [==============================] - 0s 500us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 589us/step\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " dense_1213 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1214 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1215 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1216 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "31/31 [==============================] - 0s 534us/step\n",
      "8/8 [==============================] - 0s 613us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_271\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1217 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1218 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1219 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1220 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "31/31 [==============================] - 0s 506us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 574us/step\n",
      "Model: \"sequential_272\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1221 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1222 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1223 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1224 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 483us/step\n",
      "31/31 [==============================] - 0s 498us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 587us/step\n",
      "Model: \"sequential_273\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1225 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1226 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1227 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1228 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "31/31 [==============================] - 0s 502us/step\n",
      "8/8 [==============================] - 0s 631us/step\n",
      "8/8 [==============================] - 0s 614us/step\n",
      "Model: \"sequential_274\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1229 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1230 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1231 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1232 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 480us/step\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "8/8 [==============================] - 0s 534us/step\n",
      "8/8 [==============================] - 0s 626us/step\n",
      "Model: \"sequential_275\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1233 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1234 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1235 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1236 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "31/31 [==============================] - 0s 482us/step\n",
      "8/8 [==============================] - 0s 573us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_276\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1237 (Dense)          (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_1238 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1239 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1240 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 468us/step\n",
      "31/31 [==============================] - 0s 476us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 604us/step\n",
      "Model: \"sequential_277\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1241 (Dense)          (None, 5)                 40        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_1242 (Dense)          (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_1243 (Dense)          (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_1244 (Dense)          (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "31/31 [==============================] - 0s 464us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 575us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# repeat training and testing models where downsampling is used to mitigate the data imbalance\n",
    "for i in range(num_repeat):\n",
    "    # select a  from Conrols of size a without replacement\n",
    "    Control_new = Control.sample(n=Case.shape[0], replace=False, random_state=42)\n",
    "\n",
    "    # combine Case and Control data\n",
    "    data = pd.concat([Case, Control_new], axis=0)\n",
    "\n",
    "    # # create feature matrix and target vector\n",
    "    X = data.loc[:, features]\n",
    "\n",
    "    # replace NaN values with mean of the column\n",
    "    X = X.fillna(X.mean())\n",
    "    y = data.loc[:, target]\n",
    "\n",
    "    # split data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train); X_test = scaler.transform(X_test)\n",
    "    input_shape = X.shape[1]\n",
    "    # Add a fully connected layer with 64 units and a sigmoid activation function\n",
    "    model = Sequential();\n",
    "    model.add(Dense(5, input_shape=(X.shape[1],),activation='relu')) # Add an input shape! (features,)\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    # Define the learning rate\n",
    "    ep = 500; bs = 50;\n",
    "    \n",
    "    \n",
    "    # Define the optimizer\n",
    "    from keras.optimizers import Adam,SGD\n",
    "    optimizer = Adam(learning_rate=.001, decay= 1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor= tf.keras.metrics.AUC(),\n",
    "                                       mode='max',\n",
    "                                       patience=200,\n",
    "                                       restore_best_weights=True)\n",
    "    # now we just update our model fit call\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=ep, # you can set this to a big number!\n",
    "                        batch_size= bs,\n",
    "                        validation_split=0.2,\n",
    "                        shuffle= True,\n",
    "                        verbose= 0)\n",
    "\n",
    "    ## Training performance\n",
    "    model.predict(X_train) # prob of successes (survival)\n",
    "    # 1 and 0 (survival or not) so need to round to a whole number (0 or 1)\n",
    "    train_pred = np.round(model.predict(X_train),0)\n",
    "    test_pred = np.round(model.predict(X_test),0)\n",
    "    \n",
    "    # store performance metrics for each iteration\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    performance_measures_dict['training_accuracy'][i] = accuracy_score(y_train, train_pred)\n",
    "    performance_measures_dict['testing_accuracy'][i] = test_acc\n",
    "    performance_measures_dict['sensitivity'][i] = recall_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['specificity'][i] = recall_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_precision'][i] = precision_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_precision'][i] = precision_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_F1_score'][i] = f1_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_F1_score'][i] = f1_score(y_test, test_pred, pos_label=0)\n",
    "    y_prob = model.predict(X_test)\n",
    "    performance_measures_dict['AUC_score'][i] = roc_auc_score(y_test, y_prob)\n",
    "    if test_acc > max_test_acc:\n",
    "        max_test_acc = test_acc\n",
    "        max_cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "max_cm = pd.DataFrame({\"Predicted Negative(Absent)\": max_cm[:, 0], \"Predicted Positive(Present)\": max_cm[:, 1]})\n",
    "max_cm.index = [\"Actual Negative(Absent)\", \"Actual positive(Present)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "956a880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Training Accuracy: 0.6673908629441624\n",
      "Mean of Testing Accuracy: 0.6570445344129555\n",
      "Standard deviation of Testing Accuracy: 0.03997366324695109\n",
      "Mean of Sensitivity: 0.6161240310077521\n",
      "Standard deviation of Sensitivity: 0.11151199839349124\n",
      "Mean of Speicificity: 0.7017796610169491\n",
      "Standard deviation of Speicificity: 0.15336264858885632\n",
      "Mean of Case Precision: 0.7010108069219214\n",
      "Standard deviation of Case Precision: 0.05390073267182253\n",
      "Mean of Control Precision: 0.6050418533621129\n",
      "Standard deviation of Control Precision: 0.12182010620761738\n",
      "Mean of Case F1: 0.6477884949863798\n",
      "Standard deviation of Case F1: 0.06876874472916732\n",
      "Mean of Control F1: 0.6473191379412132\n",
      "Standard deviation of Control F1: 0.1330233214724814\n",
      "Mean of AUC: 0.7123784653790566\n",
      "Standard deviation of AUC: 0.05396413696171723\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative(Absent)</th>\n",
       "      <th>Predicted Positive(Present)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative(Absent)</th>\n",
       "      <td>84</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual positive(Present)</th>\n",
       "      <td>35</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Negative(Absent)  \\\n",
       "Actual Negative(Absent)                           84   \n",
       "Actual positive(Present)                          35   \n",
       "\n",
       "                          Predicted Positive(Present)  \n",
       "Actual Negative(Absent)                            34  \n",
       "Actual positive(Present)                           94  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Mean of Training Accuracy: {performance_measures_dict['training_accuracy'].mean()}\")\n",
    "print(f\"Mean of Testing Accuracy: {performance_measures_dict['testing_accuracy'].mean()}\")\n",
    "print(f\"Standard deviation of Testing Accuracy: {performance_measures_dict['testing_accuracy'].std()}\")\n",
    "print(f\"Mean of Sensitivity: {performance_measures_dict['sensitivity'].mean()}\")\n",
    "print(f\"Standard deviation of Sensitivity: {performance_measures_dict['sensitivity'].std()}\")\n",
    "print(f\"Mean of Speicificity: {performance_measures_dict['specificity'].mean()}\")\n",
    "print(f\"Standard deviation of Speicificity: {performance_measures_dict['specificity'].std()}\")\n",
    "print(f\"Mean of Case Precision: {performance_measures_dict['case_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Case Precision: {performance_measures_dict['case_precision'].std()}\")\n",
    "print(f\"Mean of Control Precision: {performance_measures_dict['control_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Control Precision: {performance_measures_dict['control_precision'].std()}\")\n",
    "print(f\"Mean of Case F1: {performance_measures_dict['case_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Case F1: {performance_measures_dict['case_F1_score'].std()}\")\n",
    "print(f\"Mean of Control F1: {performance_measures_dict['control_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Control F1: {performance_measures_dict['control_F1_score'].std()}\")\n",
    "print(f\"Mean of AUC: {performance_measures_dict['AUC_score'].mean()}\")\n",
    "print(f\"Standard deviation of AUC: {performance_measures_dict['AUC_score'].std()}\")\n",
    "max_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6817df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color='r', label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color='b', label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d6ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    # plot each individual performance metric\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color='b', label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color='g', linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fabaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "# report confusion matrix\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba82ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae238e5",
   "metadata": {},
   "source": [
    "Applying class weights without balancing the dataset to mitigate data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94712aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model using three features: entorpy, slope, and left tangent point\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [data.columns[0], data.columns[1], data.columns[9]]  # predictor features name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f26fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "'''\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(X_train[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d183aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.6542 - tp: 70.0000 - fp: 209.0000 - tn: 1832.0000 - fn: 419.0000 - accuracy: 0.7518 - precision: 0.2509 - recall: 0.1431 - auc: 0.5168 - prc: 0.2331 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6503 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4692 - prc: 0.1815 - val_loss: 0.4744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6475 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5065 - prc: 0.1995 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4785 - prc: 0.1880 - val_loss: 0.4774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6437 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4978 - prc: 0.1950 - val_loss: 0.4790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6424 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5108 - prc: 0.2113 - val_loss: 0.4804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6414 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4904 - prc: 0.1908 - val_loss: 0.4822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6407 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4940 - prc: 0.1908 - val_loss: 0.4836 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4923 - prc: 0.1941 - val_loss: 0.4845 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6397 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5086 - prc: 0.2009 - val_loss: 0.4858 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5030 - val_prc: 0.1807\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6383 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5235 - prc: 0.2047 - val_loss: 0.4861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5137 - val_prc: 0.1840\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6343 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5647 - prc: 0.2217 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5506 - val_prc: 0.1972\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6566 - prc: 0.3030 - val_loss: 0.4656 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6410 - val_prc: 0.2757\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6229 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6700 - prc: 0.3224 - val_loss: 0.4690 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6375 - val_prc: 0.2665\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6194 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6769 - prc: 0.3357 - val_loss: 0.4599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6522 - val_prc: 0.2956\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6179 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6717 - prc: 0.3229 - val_loss: 0.4588 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6540 - val_prc: 0.3012\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6719 - prc: 0.3314 - val_loss: 0.4657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6490 - val_prc: 0.2837\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6184 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6373 - prc: 0.2683 - val_loss: 0.4600 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6532 - val_prc: 0.2976\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6122 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6788 - prc: 0.3331 - val_loss: 0.4680 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6501 - val_prc: 0.2836\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6093 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6858 - prc: 0.3482 - val_loss: 0.4803 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6331 - val_prc: 0.2570\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6107 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6608 - prc: 0.2855 - val_loss: 0.4965 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5908 - val_prc: 0.2187\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6118 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6557 - prc: 0.2830 - val_loss: 0.4609 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.2980\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6039 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6928 - prc: 0.3527 - val_loss: 0.4621 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6589 - val_prc: 0.3005\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6037 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6860 - prc: 0.3392 - val_loss: 0.4739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6536 - val_prc: 0.2855\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6930 - prc: 0.3573 - val_loss: 0.4674 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6577 - val_prc: 0.2962\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6002 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6904 - prc: 0.3449 - val_loss: 0.4684 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6567 - val_prc: 0.2942\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6969 - prc: 0.3644 - val_loss: 0.4616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6624 - val_prc: 0.3140\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6936 - prc: 0.3628 - val_loss: 0.4773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6569 - val_prc: 0.2886\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6976 - prc: 0.3694 - val_loss: 0.4653 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6609 - val_prc: 0.3073\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5949 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6984 - prc: 0.3635 - val_loss: 0.4627 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6635 - val_prc: 0.3133\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5963 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6915 - prc: 0.3514 - val_loss: 0.4665 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6628 - val_prc: 0.3088\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5934 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6966 - prc: 0.3493 - val_loss: 0.4498 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6693 - val_prc: 0.3471\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6986 - prc: 0.3622 - val_loss: 0.4523 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6684 - val_prc: 0.3394\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5905 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7038 - prc: 0.3701 - val_loss: 0.4672 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6657 - val_prc: 0.3147\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5897 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7008 - prc: 0.3573 - val_loss: 0.4681 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6642 - val_prc: 0.3110\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5889 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7023 - prc: 0.3682 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6614 - val_prc: 0.3010\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7030 - prc: 0.3732 - val_loss: 0.4621 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6678 - val_prc: 0.3223\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7054 - prc: 0.3813 - val_loss: 0.4597 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6688 - val_prc: 0.3226\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5843 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7105 - prc: 0.3611 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6648 - val_prc: 0.3070\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5866 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7039 - prc: 0.3690 - val_loss: 0.4611 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6697 - val_prc: 0.3260\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5859 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7050 - prc: 0.3712 - val_loss: 0.4533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6722 - val_prc: 0.3386\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5849 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7045 - prc: 0.3657 - val_loss: 0.4523 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6731 - val_prc: 0.3409\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7086 - prc: 0.3663 - val_loss: 0.4463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6748 - val_prc: 0.3513\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5870 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6988 - prc: 0.3585 - val_loss: 0.4532 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6723 - val_prc: 0.3388\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7077 - prc: 0.3867 - val_loss: 0.4670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6697 - val_prc: 0.3265\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5816 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7093 - prc: 0.3834 - val_loss: 0.4610 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6715 - val_prc: 0.3271\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7054 - prc: 0.3868 - val_loss: 0.4616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6718 - val_prc: 0.3294\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5832 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7047 - prc: 0.3707 - val_loss: 0.4497 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6753 - val_prc: 0.3464\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5801 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7097 - prc: 0.3798 - val_loss: 0.4667 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6729 - val_prc: 0.3283\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5819 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7075 - prc: 0.3777 - val_loss: 0.4651 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6730 - val_prc: 0.3322\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5791 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7137 - prc: 0.3876 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6712 - val_prc: 0.3216\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5796 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7082 - prc: 0.3648 - val_loss: 0.4461 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6779 - val_prc: 0.3621\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5784 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7126 - prc: 0.3823 - val_loss: 0.4834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6700 - val_prc: 0.3153\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7109 - prc: 0.3948 - val_loss: 0.4802 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6731 - val_prc: 0.3283\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7110 - prc: 0.3859 - val_loss: 0.4558 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6785 - val_prc: 0.3508\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5787 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7111 - prc: 0.3827 - val_loss: 0.4753 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6738 - val_prc: 0.3289\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7094 - prc: 0.3967 - val_loss: 0.4572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6784 - val_prc: 0.3459\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5805 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7080 - prc: 0.3682 - val_loss: 0.4671 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6763 - val_prc: 0.3393\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5781 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7107 - prc: 0.3981 - val_loss: 0.4574 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6794 - val_prc: 0.3513\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5771 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7117 - prc: 0.3869 - val_loss: 0.4487 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6804 - val_prc: 0.3732\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5769 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7117 - prc: 0.3923 - val_loss: 0.4610 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6775 - val_prc: 0.3483\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5756 - tp: 8.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 390.0000 - accuracy: 0.8039 - precision: 0.5333 - recall: 0.0201 - auc: 0.7149 - prc: 0.3947 - val_loss: 0.4404 - val_tp: 6.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 85.0000 - val_accuracy: 0.8281 - val_precision: 0.7500 - val_recall: 0.0659 - val_auc: 0.6813 - val_prc: 0.3821\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5784 - tp: 87.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 311.0000 - accuracy: 0.8113 - precision: 0.5506 - recall: 0.2186 - auc: 0.7077 - prc: 0.3815 - val_loss: 0.4442 - val_tp: 10.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 81.0000 - val_accuracy: 0.8300 - val_precision: 0.6667 - val_recall: 0.1099 - val_auc: 0.6822 - val_prc: 0.3766\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5758 - tp: 87.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 311.0000 - accuracy: 0.8127 - precision: 0.5613 - recall: 0.2186 - auc: 0.7136 - prc: 0.3965 - val_loss: 0.4794 - val_tp: 30.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 61.0000 - val_accuracy: 0.8004 - val_precision: 0.4286 - val_recall: 0.3297 - val_auc: 0.6752 - val_prc: 0.3302\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5779 - tp: 92.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 306.0000 - accuracy: 0.8113 - precision: 0.5476 - recall: 0.2312 - auc: 0.7087 - prc: 0.3895 - val_loss: 0.4619 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6785 - val_prc: 0.3515\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5799 - tp: 97.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 301.0000 - accuracy: 0.8093 - precision: 0.5330 - recall: 0.2437 - auc: 0.7061 - prc: 0.3800 - val_loss: 0.4664 - val_tp: 24.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 67.0000 - val_accuracy: 0.8123 - val_precision: 0.4615 - val_recall: 0.2637 - val_auc: 0.6768 - val_prc: 0.3381\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5752 - tp: 94.0000 - fp: 94.0000 - tn: 1532.0000 - fn: 304.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2362 - auc: 0.7128 - prc: 0.3773 - val_loss: 0.4655 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6782 - val_prc: 0.3510\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5761 - tp: 94.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 304.0000 - accuracy: 0.8098 - precision: 0.5371 - recall: 0.2362 - auc: 0.7121 - prc: 0.3908 - val_loss: 0.4465 - val_tp: 13.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 78.0000 - val_accuracy: 0.8320 - val_precision: 0.6500 - val_recall: 0.1429 - val_auc: 0.6810 - val_prc: 0.3701\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5736 - tp: 94.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 304.0000 - accuracy: 0.8113 - precision: 0.5465 - recall: 0.2362 - auc: 0.7177 - prc: 0.3915 - val_loss: 0.4427 - val_tp: 10.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 81.0000 - val_accuracy: 0.8300 - val_precision: 0.6667 - val_recall: 0.1099 - val_auc: 0.6822 - val_prc: 0.3760\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5744 - tp: 90.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 308.0000 - accuracy: 0.8123 - precision: 0.5556 - recall: 0.2261 - auc: 0.7154 - prc: 0.3999 - val_loss: 0.4926 - val_tp: 36.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 55.0000 - val_accuracy: 0.7905 - val_precision: 0.4138 - val_recall: 0.3956 - val_auc: 0.6760 - val_prc: 0.3337\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5759 - tp: 99.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 299.0000 - accuracy: 0.8073 - precision: 0.5211 - recall: 0.2487 - auc: 0.7119 - prc: 0.3799 - val_loss: 0.4511 - val_tp: 15.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 76.0000 - val_accuracy: 0.8300 - val_precision: 0.6000 - val_recall: 0.1648 - val_auc: 0.6812 - val_prc: 0.3764\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5786 - tp: 85.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 313.0000 - accuracy: 0.8058 - precision: 0.5152 - recall: 0.2136 - auc: 0.7072 - prc: 0.3887 - val_loss: 0.4590 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6798 - val_prc: 0.3631\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5770 - tp: 88.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 310.0000 - accuracy: 0.8127 - precision: 0.5605 - recall: 0.2211 - auc: 0.7089 - prc: 0.3902 - val_loss: 0.4553 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 74.0000 - val_accuracy: 0.8241 - val_precision: 0.5312 - val_recall: 0.1868 - val_auc: 0.6822 - val_prc: 0.3763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5730 - tp: 88.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 310.0000 - accuracy: 0.8103 - precision: 0.5432 - recall: 0.2211 - auc: 0.7159 - prc: 0.4021 - val_loss: 0.4724 - val_tp: 26.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 65.0000 - val_accuracy: 0.8063 - val_precision: 0.4407 - val_recall: 0.2857 - val_auc: 0.6780 - val_prc: 0.3384\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5746 - tp: 91.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 307.0000 - accuracy: 0.8123 - precision: 0.5549 - recall: 0.2286 - auc: 0.7136 - prc: 0.3964 - val_loss: 0.4440 - val_tp: 11.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 80.0000 - val_accuracy: 0.8300 - val_precision: 0.6471 - val_recall: 0.1209 - val_auc: 0.6831 - val_prc: 0.3749\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5756 - tp: 93.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 305.0000 - accuracy: 0.8113 - precision: 0.5471 - recall: 0.2337 - auc: 0.7116 - prc: 0.3996 - val_loss: 0.4486 - val_tp: 14.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 77.0000 - val_accuracy: 0.8340 - val_precision: 0.6667 - val_recall: 0.1538 - val_auc: 0.6832 - val_prc: 0.3805\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5717 - tp: 95.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 303.0000 - accuracy: 0.8098 - precision: 0.5367 - recall: 0.2387 - auc: 0.7174 - prc: 0.3863 - val_loss: 0.4774 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6775 - val_prc: 0.3387\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5742 - tp: 94.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 304.0000 - accuracy: 0.8207 - precision: 0.6144 - recall: 0.2362 - auc: 0.7139 - prc: 0.4045 - val_loss: 0.4854 - val_tp: 35.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 56.0000 - val_accuracy: 0.8063 - val_precision: 0.4545 - val_recall: 0.3846 - val_auc: 0.6760 - val_prc: 0.3327\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5737 - tp: 103.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 295.0000 - accuracy: 0.8132 - precision: 0.5538 - recall: 0.2588 - auc: 0.7136 - prc: 0.4003 - val_loss: 0.4541 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 73.0000 - val_accuracy: 0.8300 - val_precision: 0.5806 - val_recall: 0.1978 - val_auc: 0.6823 - val_prc: 0.3783\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5729 - tp: 93.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 305.0000 - accuracy: 0.8123 - precision: 0.5536 - recall: 0.2337 - auc: 0.7179 - prc: 0.4138 - val_loss: 0.4636 - val_tp: 23.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 68.0000 - val_accuracy: 0.8182 - val_precision: 0.4894 - val_recall: 0.2527 - val_auc: 0.6813 - val_prc: 0.3757\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5731 - tp: 98.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 300.0000 - accuracy: 0.8043 - precision: 0.5052 - recall: 0.2462 - auc: 0.7178 - prc: 0.3891 - val_loss: 0.4403 - val_tp: 9.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 82.0000 - val_accuracy: 0.8300 - val_precision: 0.6923 - val_recall: 0.0989 - val_auc: 0.6831 - val_prc: 0.3870\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5722 - tp: 86.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 312.0000 - accuracy: 0.8123 - precision: 0.5584 - recall: 0.2161 - auc: 0.7173 - prc: 0.4041 - val_loss: 0.4785 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6793 - val_prc: 0.3517\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5737 - tp: 96.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 302.0000 - accuracy: 0.8132 - precision: 0.5581 - recall: 0.2412 - auc: 0.7139 - prc: 0.4030 - val_loss: 0.4536 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 73.0000 - val_accuracy: 0.8300 - val_precision: 0.5806 - val_recall: 0.1978 - val_auc: 0.6824 - val_prc: 0.3836\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5752 - tp: 82.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 316.0000 - accuracy: 0.8118 - precision: 0.5578 - recall: 0.2060 - auc: 0.7108 - prc: 0.4150 - val_loss: 0.4708 - val_tp: 26.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 65.0000 - val_accuracy: 0.8083 - val_precision: 0.4483 - val_recall: 0.2857 - val_auc: 0.6806 - val_prc: 0.3594\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5720 - tp: 97.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 301.0000 - accuracy: 0.8172 - precision: 0.5843 - recall: 0.2437 - auc: 0.7164 - prc: 0.4162 - val_loss: 0.4578 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6815 - val_prc: 0.3792\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5744 - tp: 94.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 304.0000 - accuracy: 0.8108 - precision: 0.5434 - recall: 0.2362 - auc: 0.7129 - prc: 0.4011 - val_loss: 0.4660 - val_tp: 24.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 67.0000 - val_accuracy: 0.8123 - val_precision: 0.4615 - val_recall: 0.2637 - val_auc: 0.6815 - val_prc: 0.3764\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5735 - tp: 84.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 314.0000 - accuracy: 0.8127 - precision: 0.5638 - recall: 0.2111 - auc: 0.7143 - prc: 0.4062 - val_loss: 0.4627 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6820 - val_prc: 0.3793\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5726 - tp: 96.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 302.0000 - accuracy: 0.8103 - precision: 0.5393 - recall: 0.2412 - auc: 0.7160 - prc: 0.4047 - val_loss: 0.4609 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6828 - val_prc: 0.3804\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5720 - tp: 90.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 308.0000 - accuracy: 0.8147 - precision: 0.5732 - recall: 0.2261 - auc: 0.7142 - prc: 0.4134 - val_loss: 0.4641 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6821 - val_prc: 0.3798\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5719 - tp: 99.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 299.0000 - accuracy: 0.8142 - precision: 0.5625 - recall: 0.2487 - auc: 0.7148 - prc: 0.4074 - val_loss: 0.4636 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6828 - val_prc: 0.3803\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5739 - tp: 83.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 315.0000 - accuracy: 0.8127 - precision: 0.5646 - recall: 0.2085 - auc: 0.7118 - prc: 0.3938 - val_loss: 0.4593 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6828 - val_prc: 0.3831\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5703 - tp: 86.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 312.0000 - accuracy: 0.8103 - precision: 0.5443 - recall: 0.2161 - auc: 0.7191 - prc: 0.3943 - val_loss: 0.4825 - val_tp: 32.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 59.0000 - val_accuracy: 0.8043 - val_precision: 0.4444 - val_recall: 0.3516 - val_auc: 0.6804 - val_prc: 0.3591\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5723 - tp: 89.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 309.0000 - accuracy: 0.8098 - precision: 0.5394 - recall: 0.2236 - auc: 0.7156 - prc: 0.4125 - val_loss: 0.4759 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6810 - val_prc: 0.3605\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5719 - tp: 97.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 301.0000 - accuracy: 0.8093 - precision: 0.5330 - recall: 0.2437 - auc: 0.7161 - prc: 0.4001 - val_loss: 0.4724 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6816 - val_prc: 0.3725\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5715 - tp: 103.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 295.0000 - accuracy: 0.8113 - precision: 0.5421 - recall: 0.2588 - auc: 0.7161 - prc: 0.3941 - val_loss: 0.4582 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6823 - val_prc: 0.3909\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5700 - tp: 98.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 300.0000 - accuracy: 0.8137 - precision: 0.5600 - recall: 0.2462 - auc: 0.7186 - prc: 0.4231 - val_loss: 0.4343 - val_tp: 5.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 86.0000 - val_accuracy: 0.8261 - val_precision: 0.7143 - val_recall: 0.0549 - val_auc: 0.6857 - val_prc: 0.4074\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5752 - tp: 97.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 301.0000 - accuracy: 0.8147 - precision: 0.5673 - recall: 0.2437 - auc: 0.7097 - prc: 0.3983 - val_loss: 0.4533 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 73.0000 - val_accuracy: 0.8300 - val_precision: 0.5806 - val_recall: 0.1978 - val_auc: 0.6838 - val_prc: 0.3902\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5702 - tp: 91.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 307.0000 - accuracy: 0.8147 - precision: 0.5723 - recall: 0.2286 - auc: 0.7189 - prc: 0.4153 - val_loss: 0.4615 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6833 - val_prc: 0.3855\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5733 - tp: 97.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 301.0000 - accuracy: 0.8103 - precision: 0.5389 - recall: 0.2437 - auc: 0.7136 - prc: 0.4041 - val_loss: 0.4556 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6833 - val_prc: 0.3899\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5703 - tp: 84.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 314.0000 - accuracy: 0.8142 - precision: 0.5753 - recall: 0.2111 - auc: 0.7181 - prc: 0.4203 - val_loss: 0.4784 - val_tp: 32.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 59.0000 - val_accuracy: 0.8083 - val_precision: 0.4571 - val_recall: 0.3516 - val_auc: 0.6814 - val_prc: 0.3644\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5746 - tp: 97.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 301.0000 - accuracy: 0.8073 - precision: 0.5215 - recall: 0.2437 - auc: 0.7105 - prc: 0.3950 - val_loss: 0.4554 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 72.0000 - val_accuracy: 0.8241 - val_precision: 0.5278 - val_recall: 0.2088 - val_auc: 0.6829 - val_prc: 0.3846\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5721 - tp: 92.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 306.0000 - accuracy: 0.8132 - precision: 0.5610 - recall: 0.2312 - auc: 0.7155 - prc: 0.4045 - val_loss: 0.4450 - val_tp: 13.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 78.0000 - val_accuracy: 0.8340 - val_precision: 0.6842 - val_recall: 0.1429 - val_auc: 0.6836 - val_prc: 0.3928\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5710 - tp: 91.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 307.0000 - accuracy: 0.8127 - precision: 0.5583 - recall: 0.2286 - auc: 0.7167 - prc: 0.4109 - val_loss: 0.4555 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6832 - val_prc: 0.3885\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5716 - tp: 84.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 314.0000 - accuracy: 0.8073 - precision: 0.5250 - recall: 0.2111 - auc: 0.7176 - prc: 0.4116 - val_loss: 0.4593 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6831 - val_prc: 0.3910\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5725 - tp: 88.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 310.0000 - accuracy: 0.8137 - precision: 0.5677 - recall: 0.2211 - auc: 0.7151 - prc: 0.4138 - val_loss: 0.4541 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6833 - val_prc: 0.3853\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5699 - tp: 94.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 304.0000 - accuracy: 0.8127 - precision: 0.5562 - recall: 0.2362 - auc: 0.7163 - prc: 0.4196 - val_loss: 0.4649 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6819 - val_prc: 0.3854\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5711 - tp: 89.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 309.0000 - accuracy: 0.8157 - precision: 0.5817 - recall: 0.2236 - auc: 0.7144 - prc: 0.4088 - val_loss: 0.4867 - val_tp: 33.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 58.0000 - val_accuracy: 0.7945 - val_precision: 0.4177 - val_recall: 0.3626 - val_auc: 0.6813 - val_prc: 0.3678\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5712 - tp: 98.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 300.0000 - accuracy: 0.8088 - precision: 0.5297 - recall: 0.2462 - auc: 0.7155 - prc: 0.4115 - val_loss: 0.4681 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6817 - val_prc: 0.3910\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5707 - tp: 89.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 309.0000 - accuracy: 0.8157 - precision: 0.5817 - recall: 0.2236 - auc: 0.7153 - prc: 0.4140 - val_loss: 0.4669 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6829 - val_prc: 0.3972\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5702 - tp: 94.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 304.0000 - accuracy: 0.8118 - precision: 0.5497 - recall: 0.2362 - auc: 0.7165 - prc: 0.4168 - val_loss: 0.4742 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6826 - val_prc: 0.3868\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5708 - tp: 98.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 300.0000 - accuracy: 0.8083 - precision: 0.5269 - recall: 0.2462 - auc: 0.7173 - prc: 0.4082 - val_loss: 0.4486 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 75.0000 - val_accuracy: 0.8340 - val_precision: 0.6400 - val_recall: 0.1758 - val_auc: 0.6841 - val_prc: 0.3931\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5702 - tp: 93.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 305.0000 - accuracy: 0.8202 - precision: 0.6118 - recall: 0.2337 - auc: 0.7143 - prc: 0.4273 - val_loss: 0.4705 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6814 - val_prc: 0.3851\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5691 - tp: 85.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 313.0000 - accuracy: 0.8142 - precision: 0.5743 - recall: 0.2136 - auc: 0.7170 - prc: 0.4240 - val_loss: 0.4625 - val_tp: 23.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 68.0000 - val_accuracy: 0.8162 - val_precision: 0.4792 - val_recall: 0.2527 - val_auc: 0.6831 - val_prc: 0.3904\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5722 - tp: 101.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 297.0000 - accuracy: 0.8142 - precision: 0.5611 - recall: 0.2538 - auc: 0.7128 - prc: 0.4229 - val_loss: 0.4486 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 75.0000 - val_accuracy: 0.8340 - val_precision: 0.6400 - val_recall: 0.1758 - val_auc: 0.6837 - val_prc: 0.3935\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5700 - tp: 91.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 307.0000 - accuracy: 0.8162 - precision: 0.5833 - recall: 0.2286 - auc: 0.7166 - prc: 0.4128 - val_loss: 0.4502 - val_tp: 17.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 74.0000 - val_accuracy: 0.8340 - val_precision: 0.6296 - val_recall: 0.1868 - val_auc: 0.6837 - val_prc: 0.3930\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5696 - tp: 102.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 296.0000 - accuracy: 0.8147 - precision: 0.5635 - recall: 0.2563 - auc: 0.7179 - prc: 0.4171 - val_loss: 0.4352 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 85.0000 - val_accuracy: 0.8241 - val_precision: 0.6000 - val_recall: 0.0659 - val_auc: 0.6840 - val_prc: 0.4080\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5706 - tp: 80.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 318.0000 - accuracy: 0.8137 - precision: 0.5755 - recall: 0.2010 - auc: 0.7149 - prc: 0.4245 - val_loss: 0.4861 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6819 - val_prc: 0.3751\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5700 - tp: 97.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 301.0000 - accuracy: 0.8108 - precision: 0.5419 - recall: 0.2437 - auc: 0.7164 - prc: 0.4193 - val_loss: 0.4590 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6836 - val_prc: 0.3894\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5699 - tp: 100.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 298.0000 - accuracy: 0.8182 - precision: 0.5882 - recall: 0.2513 - auc: 0.7154 - prc: 0.4214 - val_loss: 0.4441 - val_tp: 15.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 76.0000 - val_accuracy: 0.8379 - val_precision: 0.7143 - val_recall: 0.1648 - val_auc: 0.6846 - val_prc: 0.3995\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5723 - tp: 96.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 302.0000 - accuracy: 0.8137 - precision: 0.5614 - recall: 0.2412 - auc: 0.7121 - prc: 0.4206 - val_loss: 0.4425 - val_tp: 13.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 78.0000 - val_accuracy: 0.8360 - val_precision: 0.7222 - val_recall: 0.1429 - val_auc: 0.6847 - val_prc: 0.4074\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5708 - tp: 91.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 307.0000 - accuracy: 0.8137 - precision: 0.5652 - recall: 0.2286 - auc: 0.7158 - prc: 0.4232 - val_loss: 0.4665 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 63.0000 - val_accuracy: 0.8182 - val_precision: 0.4912 - val_recall: 0.3077 - val_auc: 0.6833 - val_prc: 0.3924\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5692 - tp: 92.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 306.0000 - accuracy: 0.8152 - precision: 0.5750 - recall: 0.2312 - auc: 0.7178 - prc: 0.4265 - val_loss: 0.4752 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6838 - val_prc: 0.3978\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5701 - tp: 93.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 305.0000 - accuracy: 0.8123 - precision: 0.5536 - recall: 0.2337 - auc: 0.7160 - prc: 0.4154 - val_loss: 0.4627 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6830 - val_prc: 0.3875\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5688 - tp: 96.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 302.0000 - accuracy: 0.8113 - precision: 0.5455 - recall: 0.2412 - auc: 0.7183 - prc: 0.4174 - val_loss: 0.4492 - val_tp: 17.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 74.0000 - val_accuracy: 0.8360 - val_precision: 0.6538 - val_recall: 0.1868 - val_auc: 0.6835 - val_prc: 0.3926\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5705 - tp: 87.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 311.0000 - accuracy: 0.8142 - precision: 0.5724 - recall: 0.2186 - auc: 0.7148 - prc: 0.4141 - val_loss: 0.4876 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6825 - val_prc: 0.3780\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5701 - tp: 99.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 299.0000 - accuracy: 0.8152 - precision: 0.5690 - recall: 0.2487 - auc: 0.7167 - prc: 0.4123 - val_loss: 0.4501 - val_tp: 17.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 74.0000 - val_accuracy: 0.8340 - val_precision: 0.6296 - val_recall: 0.1868 - val_auc: 0.6832 - val_prc: 0.3946\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5710 - tp: 96.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 302.0000 - accuracy: 0.8127 - precision: 0.5549 - recall: 0.2412 - auc: 0.7149 - prc: 0.4158 - val_loss: 0.4397 - val_tp: 11.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 80.0000 - val_accuracy: 0.8340 - val_precision: 0.7333 - val_recall: 0.1209 - val_auc: 0.6841 - val_prc: 0.4087\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5700 - tp: 91.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 307.0000 - accuracy: 0.8142 - precision: 0.5688 - recall: 0.2286 - auc: 0.7149 - prc: 0.4252 - val_loss: 0.4664 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6829 - val_prc: 0.3919\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5688 - tp: 101.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 297.0000 - accuracy: 0.8137 - precision: 0.5580 - recall: 0.2538 - auc: 0.7178 - prc: 0.4215 - val_loss: 0.4524 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6848 - val_prc: 0.3954\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5691 - tp: 93.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 305.0000 - accuracy: 0.8127 - precision: 0.5569 - recall: 0.2337 - auc: 0.7181 - prc: 0.4199 - val_loss: 0.4583 - val_tp: 22.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 69.0000 - val_accuracy: 0.8221 - val_precision: 0.5116 - val_recall: 0.2418 - val_auc: 0.6843 - val_prc: 0.3835\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5686 - tp: 97.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 301.0000 - accuracy: 0.8152 - precision: 0.5706 - recall: 0.2437 - auc: 0.7172 - prc: 0.4236 - val_loss: 0.4573 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6837 - val_prc: 0.3839\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5710 - tp: 97.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 301.0000 - accuracy: 0.8078 - precision: 0.5243 - recall: 0.2437 - auc: 0.7149 - prc: 0.4141 - val_loss: 0.4511 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 73.0000 - val_accuracy: 0.8300 - val_precision: 0.5806 - val_recall: 0.1978 - val_auc: 0.6841 - val_prc: 0.3931\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 95.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 303.0000 - accuracy: 0.8137 - precision: 0.5621 - recall: 0.2387 - auc: 0.7201 - prc: 0.4318 - val_loss: 0.4436 - val_tp: 15.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 76.0000 - val_accuracy: 0.8379 - val_precision: 0.7143 - val_recall: 0.1648 - val_auc: 0.6855 - val_prc: 0.4094\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5705 - tp: 100.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 298.0000 - accuracy: 0.8157 - precision: 0.5714 - recall: 0.2513 - auc: 0.7143 - prc: 0.4263 - val_loss: 0.4394 - val_tp: 11.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 80.0000 - val_accuracy: 0.8340 - val_precision: 0.7333 - val_recall: 0.1209 - val_auc: 0.6857 - val_prc: 0.4094\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5690 - tp: 92.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 306.0000 - accuracy: 0.8132 - precision: 0.5610 - recall: 0.2312 - auc: 0.7171 - prc: 0.4237 - val_loss: 0.4584 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 70.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2308 - val_auc: 0.6836 - val_prc: 0.3838\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5696 - tp: 87.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 311.0000 - accuracy: 0.8132 - precision: 0.5649 - recall: 0.2186 - auc: 0.7154 - prc: 0.4262 - val_loss: 0.4515 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 73.0000 - val_accuracy: 0.8300 - val_precision: 0.5806 - val_recall: 0.1978 - val_auc: 0.6845 - val_prc: 0.3932\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5705 - tp: 97.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 301.0000 - accuracy: 0.8147 - precision: 0.5673 - recall: 0.2437 - auc: 0.7137 - prc: 0.4145 - val_loss: 0.4459 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 75.0000 - val_accuracy: 0.8340 - val_precision: 0.6400 - val_recall: 0.1758 - val_auc: 0.6843 - val_prc: 0.4017\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5688 - tp: 89.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 309.0000 - accuracy: 0.8162 - precision: 0.5855 - recall: 0.2236 - auc: 0.7169 - prc: 0.4243 - val_loss: 0.4659 - val_tp: 28.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 63.0000 - val_accuracy: 0.8142 - val_precision: 0.4746 - val_recall: 0.3077 - val_auc: 0.6835 - val_prc: 0.3908\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 98.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 300.0000 - accuracy: 0.8132 - precision: 0.5568 - recall: 0.2462 - auc: 0.7196 - prc: 0.4251 - val_loss: 0.4423 - val_tp: 15.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 76.0000 - val_accuracy: 0.8399 - val_precision: 0.7500 - val_recall: 0.1648 - val_auc: 0.6857 - val_prc: 0.4100\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5683 - tp: 94.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 304.0000 - accuracy: 0.8127 - precision: 0.5562 - recall: 0.2362 - auc: 0.7184 - prc: 0.4271 - val_loss: 0.4540 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6850 - val_prc: 0.3954\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5701 - tp: 98.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 300.0000 - accuracy: 0.8123 - precision: 0.5506 - recall: 0.2462 - auc: 0.7135 - prc: 0.4273 - val_loss: 0.4487 - val_tp: 17.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 74.0000 - val_accuracy: 0.8360 - val_precision: 0.6538 - val_recall: 0.1868 - val_auc: 0.6855 - val_prc: 0.4015\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5675 - tp: 93.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 305.0000 - accuracy: 0.8172 - precision: 0.5886 - recall: 0.2337 - auc: 0.7178 - prc: 0.4315 - val_loss: 0.4640 - val_tp: 28.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 63.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3077 - val_auc: 0.6835 - val_prc: 0.3870\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5716 - tp: 92.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 306.0000 - accuracy: 0.8108 - precision: 0.5444 - recall: 0.2312 - auc: 0.7121 - prc: 0.4199 - val_loss: 0.4569 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6851 - val_prc: 0.3965\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5667 - tp: 97.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 301.0000 - accuracy: 0.8137 - precision: 0.5607 - recall: 0.2437 - auc: 0.7202 - prc: 0.4235 - val_loss: 0.4500 - val_tp: 18.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 73.0000 - val_accuracy: 0.8300 - val_precision: 0.5806 - val_recall: 0.1978 - val_auc: 0.6848 - val_prc: 0.4011\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 95.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 303.0000 - accuracy: 0.8152 - precision: 0.5723 - recall: 0.2387 - auc: 0.7196 - prc: 0.4331 - val_loss: 0.4633 - val_tp: 28.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 63.0000 - val_accuracy: 0.8221 - val_precision: 0.5091 - val_recall: 0.3077 - val_auc: 0.6840 - val_prc: 0.3878\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5674 - tp: 96.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 302.0000 - accuracy: 0.8132 - precision: 0.5581 - recall: 0.2412 - auc: 0.7180 - prc: 0.4322 - val_loss: 0.4473 - val_tp: 17.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 74.0000 - val_accuracy: 0.8360 - val_precision: 0.6538 - val_recall: 0.1868 - val_auc: 0.6853 - val_prc: 0.4098\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5686 - tp: 92.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 306.0000 - accuracy: 0.8127 - precision: 0.5576 - recall: 0.2312 - auc: 0.7168 - prc: 0.4253 - val_loss: 0.4420 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6857 - val_prc: 0.4092\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5696 - tp: 92.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 306.0000 - accuracy: 0.8127 - precision: 0.5576 - recall: 0.2312 - auc: 0.7142 - prc: 0.4236 - val_loss: 0.4582 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6834 - val_prc: 0.3908\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 106.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 292.0000 - accuracy: 0.8192 - precision: 0.5889 - recall: 0.2663 - auc: 0.7171 - prc: 0.4348 - val_loss: 0.4649 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 63.0000 - val_accuracy: 0.8182 - val_precision: 0.4912 - val_recall: 0.3077 - val_auc: 0.6839 - val_prc: 0.3892\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5704 - tp: 99.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 299.0000 - accuracy: 0.8113 - precision: 0.5440 - recall: 0.2487 - auc: 0.7126 - prc: 0.4211 - val_loss: 0.4808 - val_tp: 32.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 59.0000 - val_accuracy: 0.7964 - val_precision: 0.4211 - val_recall: 0.3516 - val_auc: 0.6844 - val_prc: 0.4004\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5693 - tp: 95.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 303.0000 - accuracy: 0.8132 - precision: 0.5588 - recall: 0.2387 - auc: 0.7151 - prc: 0.4251 - val_loss: 0.4544 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6861 - val_prc: 0.3961\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5683 - tp: 108.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 290.0000 - accuracy: 0.8207 - precision: 0.5967 - recall: 0.2714 - auc: 0.7149 - prc: 0.4213 - val_loss: 0.4557 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6856 - val_prc: 0.4010\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5669 - tp: 94.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 304.0000 - accuracy: 0.8142 - precision: 0.5663 - recall: 0.2362 - auc: 0.7178 - prc: 0.4313 - val_loss: 0.4540 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6842 - val_prc: 0.4013\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5668 - tp: 94.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 304.0000 - accuracy: 0.8182 - precision: 0.5949 - recall: 0.2362 - auc: 0.7185 - prc: 0.4404 - val_loss: 0.4388 - val_tp: 12.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 79.0000 - val_accuracy: 0.8360 - val_precision: 0.7500 - val_recall: 0.1319 - val_auc: 0.6849 - val_prc: 0.4092\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5704 - tp: 91.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 307.0000 - accuracy: 0.8088 - precision: 0.5322 - recall: 0.2286 - auc: 0.7167 - prc: 0.4112 - val_loss: 0.4871 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6841 - val_prc: 0.4021\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5704 - tp: 101.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 297.0000 - accuracy: 0.8152 - precision: 0.5674 - recall: 0.2538 - auc: 0.7124 - prc: 0.4248 - val_loss: 0.4578 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6852 - val_prc: 0.3950\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5679 - tp: 99.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 299.0000 - accuracy: 0.8152 - precision: 0.5690 - recall: 0.2487 - auc: 0.7156 - prc: 0.4209 - val_loss: 0.4719 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6844 - val_prc: 0.3916\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5667 - tp: 100.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 298.0000 - accuracy: 0.8123 - precision: 0.5495 - recall: 0.2513 - auc: 0.7196 - prc: 0.4294 - val_loss: 0.4521 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6851 - val_prc: 0.4021\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5708 - tp: 94.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 304.0000 - accuracy: 0.8098 - precision: 0.5371 - recall: 0.2362 - auc: 0.7141 - prc: 0.4175 - val_loss: 0.4597 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6856 - val_prc: 0.3955\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5660 - tp: 92.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 306.0000 - accuracy: 0.8152 - precision: 0.5750 - recall: 0.2312 - auc: 0.7193 - prc: 0.4343 - val_loss: 0.4873 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6842 - val_prc: 0.4020\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 105.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 293.0000 - accuracy: 0.8211 - precision: 0.6034 - recall: 0.2638 - auc: 0.7176 - prc: 0.4382 - val_loss: 0.4568 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6858 - val_prc: 0.4019\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5674 - tp: 94.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 304.0000 - accuracy: 0.8123 - precision: 0.5529 - recall: 0.2362 - auc: 0.7185 - prc: 0.4231 - val_loss: 0.4471 - val_tp: 17.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 74.0000 - val_accuracy: 0.8360 - val_precision: 0.6538 - val_recall: 0.1868 - val_auc: 0.6862 - val_prc: 0.4110\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5663 - tp: 93.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 305.0000 - accuracy: 0.8152 - precision: 0.5741 - recall: 0.2337 - auc: 0.7189 - prc: 0.4298 - val_loss: 0.4546 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6853 - val_prc: 0.4023\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - tp: 98.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 300.0000 - accuracy: 0.8137 - precision: 0.5600 - recall: 0.2462 - auc: 0.7195 - prc: 0.4326 - val_loss: 0.4513 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6855 - val_prc: 0.4022\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 93.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 305.0000 - accuracy: 0.8152 - precision: 0.5741 - recall: 0.2337 - auc: 0.7206 - prc: 0.4277 - val_loss: 0.4750 - val_tp: 30.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 61.0000 - val_accuracy: 0.8004 - val_precision: 0.4286 - val_recall: 0.3297 - val_auc: 0.6850 - val_prc: 0.3938\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5689 - tp: 106.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 292.0000 - accuracy: 0.8147 - precision: 0.5608 - recall: 0.2663 - auc: 0.7151 - prc: 0.4242 - val_loss: 0.4428 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 75.0000 - val_accuracy: 0.8379 - val_precision: 0.6957 - val_recall: 0.1758 - val_auc: 0.6862 - val_prc: 0.4104\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5745 - tp: 94.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 304.0000 - accuracy: 0.8103 - precision: 0.5402 - recall: 0.2362 - auc: 0.7072 - prc: 0.4021 - val_loss: 0.4360 - val_tp: 10.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 81.0000 - val_accuracy: 0.8320 - val_precision: 0.7143 - val_recall: 0.1099 - val_auc: 0.6873 - val_prc: 0.4118\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5683 - tp: 93.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 305.0000 - accuracy: 0.8123 - precision: 0.5536 - recall: 0.2337 - auc: 0.7180 - prc: 0.4232 - val_loss: 0.4560 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6860 - val_prc: 0.4018\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5677 - tp: 98.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 300.0000 - accuracy: 0.8142 - precision: 0.5632 - recall: 0.2462 - auc: 0.7166 - prc: 0.4245 - val_loss: 0.4573 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6866 - val_prc: 0.4026\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5685 - tp: 98.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 300.0000 - accuracy: 0.8142 - precision: 0.5632 - recall: 0.2462 - auc: 0.7164 - prc: 0.4294 - val_loss: 0.4379 - val_tp: 12.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 79.0000 - val_accuracy: 0.8360 - val_precision: 0.7500 - val_recall: 0.1319 - val_auc: 0.6869 - val_prc: 0.4105\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5676 - tp: 102.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 296.0000 - accuracy: 0.8137 - precision: 0.5574 - recall: 0.2563 - auc: 0.7180 - prc: 0.4267 - val_loss: 0.4404 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6863 - val_prc: 0.4106\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5680 - tp: 94.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 304.0000 - accuracy: 0.8192 - precision: 0.6026 - recall: 0.2362 - auc: 0.7162 - prc: 0.4257 - val_loss: 0.4765 - val_tp: 30.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 61.0000 - val_accuracy: 0.8004 - val_precision: 0.4286 - val_recall: 0.3297 - val_auc: 0.6843 - val_prc: 0.3929\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 97.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 301.0000 - accuracy: 0.8152 - precision: 0.5706 - recall: 0.2437 - auc: 0.7185 - prc: 0.4323 - val_loss: 0.4810 - val_tp: 34.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 57.0000 - val_accuracy: 0.7984 - val_precision: 0.4304 - val_recall: 0.3736 - val_auc: 0.6848 - val_prc: 0.3926\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5700 - tp: 105.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 293.0000 - accuracy: 0.8113 - precision: 0.5412 - recall: 0.2638 - auc: 0.7138 - prc: 0.4029 - val_loss: 0.4394 - val_tp: 15.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 76.0000 - val_accuracy: 0.8399 - val_precision: 0.7500 - val_recall: 0.1648 - val_auc: 0.6862 - val_prc: 0.4110\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5696 - tp: 94.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 304.0000 - accuracy: 0.8132 - precision: 0.5595 - recall: 0.2362 - auc: 0.7146 - prc: 0.4173 - val_loss: 0.4558 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6872 - val_prc: 0.4030\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5682 - tp: 99.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 299.0000 - accuracy: 0.8157 - precision: 0.5723 - recall: 0.2487 - auc: 0.7164 - prc: 0.4222 - val_loss: 0.4502 - val_tp: 20.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 71.0000 - val_accuracy: 0.8300 - val_precision: 0.5714 - val_recall: 0.2198 - val_auc: 0.6860 - val_prc: 0.4118\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5676 - tp: 100.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 298.0000 - accuracy: 0.8157 - precision: 0.5714 - recall: 0.2513 - auc: 0.7182 - prc: 0.4239 - val_loss: 0.4527 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6864 - val_prc: 0.4115\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5688 - tp: 95.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 303.0000 - accuracy: 0.8088 - precision: 0.5307 - recall: 0.2387 - auc: 0.7166 - prc: 0.4245 - val_loss: 0.4491 - val_tp: 20.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 71.0000 - val_accuracy: 0.8340 - val_precision: 0.6061 - val_recall: 0.2198 - val_auc: 0.6870 - val_prc: 0.4111\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5668 - tp: 96.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 302.0000 - accuracy: 0.8177 - precision: 0.5890 - recall: 0.2412 - auc: 0.7179 - prc: 0.4335 - val_loss: 0.4518 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6868 - val_prc: 0.4116\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5679 - tp: 96.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 302.0000 - accuracy: 0.8167 - precision: 0.5818 - recall: 0.2412 - auc: 0.7162 - prc: 0.4336 - val_loss: 0.4501 - val_tp: 21.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 70.0000 - val_accuracy: 0.8300 - val_precision: 0.5676 - val_recall: 0.2308 - val_auc: 0.6871 - val_prc: 0.4121\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5670 - tp: 95.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 303.0000 - accuracy: 0.8167 - precision: 0.5828 - recall: 0.2387 - auc: 0.7181 - prc: 0.4298 - val_loss: 0.4675 - val_tp: 28.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 63.0000 - val_accuracy: 0.8063 - val_precision: 0.4444 - val_recall: 0.3077 - val_auc: 0.6851 - val_prc: 0.3877\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5684 - tp: 101.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 297.0000 - accuracy: 0.8127 - precision: 0.5519 - recall: 0.2538 - auc: 0.7144 - prc: 0.4246 - val_loss: 0.4416 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 75.0000 - val_accuracy: 0.8379 - val_precision: 0.6957 - val_recall: 0.1758 - val_auc: 0.6860 - val_prc: 0.4106\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5686 - tp: 98.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 300.0000 - accuracy: 0.8182 - precision: 0.5904 - recall: 0.2462 - auc: 0.7172 - prc: 0.4208 - val_loss: 0.4674 - val_tp: 28.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 63.0000 - val_accuracy: 0.8063 - val_precision: 0.4444 - val_recall: 0.3077 - val_auc: 0.6845 - val_prc: 0.3898\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5668 - tp: 105.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 293.0000 - accuracy: 0.8127 - precision: 0.5497 - recall: 0.2638 - auc: 0.7192 - prc: 0.4318 - val_loss: 0.4480 - val_tp: 20.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 71.0000 - val_accuracy: 0.8340 - val_precision: 0.6061 - val_recall: 0.2198 - val_auc: 0.6877 - val_prc: 0.4115\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 91.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 307.0000 - accuracy: 0.8137 - precision: 0.5652 - recall: 0.2286 - auc: 0.7212 - prc: 0.4306 - val_loss: 0.4730 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6848 - val_prc: 0.3890\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 108.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 290.0000 - accuracy: 0.8127 - precision: 0.5482 - recall: 0.2714 - auc: 0.7209 - prc: 0.4304 - val_loss: 0.4358 - val_tp: 10.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 81.0000 - val_accuracy: 0.8320 - val_precision: 0.7143 - val_recall: 0.1099 - val_auc: 0.6873 - val_prc: 0.4133\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 91.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 307.0000 - accuracy: 0.8137 - precision: 0.5652 - recall: 0.2286 - auc: 0.7188 - prc: 0.4305 - val_loss: 0.4609 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6859 - val_prc: 0.4021\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5675 - tp: 91.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 307.0000 - accuracy: 0.8137 - precision: 0.5652 - recall: 0.2286 - auc: 0.7176 - prc: 0.4287 - val_loss: 0.4537 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6868 - val_prc: 0.4033\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5672 - tp: 99.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 299.0000 - accuracy: 0.8142 - precision: 0.5625 - recall: 0.2487 - auc: 0.7162 - prc: 0.4331 - val_loss: 0.4411 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6875 - val_prc: 0.4132\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5660 - tp: 90.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 308.0000 - accuracy: 0.8172 - precision: 0.5921 - recall: 0.2261 - auc: 0.7190 - prc: 0.4310 - val_loss: 0.4709 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6869 - val_prc: 0.3868\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5682 - tp: 96.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 302.0000 - accuracy: 0.8123 - precision: 0.5517 - recall: 0.2412 - auc: 0.7148 - prc: 0.4268 - val_loss: 0.4813 - val_tp: 34.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 57.0000 - val_accuracy: 0.7984 - val_precision: 0.4304 - val_recall: 0.3736 - val_auc: 0.6852 - val_prc: 0.3945\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5668 - tp: 99.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 299.0000 - accuracy: 0.8157 - precision: 0.5723 - recall: 0.2487 - auc: 0.7173 - prc: 0.4330 - val_loss: 0.4403 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6880 - val_prc: 0.4131\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5676 - tp: 97.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 301.0000 - accuracy: 0.8167 - precision: 0.5808 - recall: 0.2437 - auc: 0.7162 - prc: 0.4303 - val_loss: 0.4697 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6858 - val_prc: 0.3889\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 102.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 296.0000 - accuracy: 0.8147 - precision: 0.5635 - recall: 0.2563 - auc: 0.7179 - prc: 0.4267 - val_loss: 0.4509 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6864 - val_prc: 0.4121\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5645 - tp: 86.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 312.0000 - accuracy: 0.8152 - precision: 0.5811 - recall: 0.2161 - auc: 0.7230 - prc: 0.4385 - val_loss: 0.5188 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6845 - val_prc: 0.3792\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5693 - tp: 107.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 291.0000 - accuracy: 0.8068 - precision: 0.5169 - recall: 0.2688 - auc: 0.7170 - prc: 0.4070 - val_loss: 0.4453 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 72.0000 - val_accuracy: 0.8360 - val_precision: 0.6333 - val_recall: 0.2088 - val_auc: 0.6872 - val_prc: 0.4127\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5650 - tp: 96.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 302.0000 - accuracy: 0.8177 - precision: 0.5890 - recall: 0.2412 - auc: 0.7211 - prc: 0.4317 - val_loss: 0.4728 - val_tp: 29.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 62.0000 - val_accuracy: 0.7984 - val_precision: 0.4203 - val_recall: 0.3187 - val_auc: 0.6856 - val_prc: 0.3916\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 102.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 296.0000 - accuracy: 0.8172 - precision: 0.5795 - recall: 0.2563 - auc: 0.7137 - prc: 0.4243 - val_loss: 0.4886 - val_tp: 34.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 57.0000 - val_accuracy: 0.7866 - val_precision: 0.4000 - val_recall: 0.3736 - val_auc: 0.6842 - val_prc: 0.3905\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5723 - tp: 98.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 300.0000 - accuracy: 0.8142 - precision: 0.5632 - recall: 0.2462 - auc: 0.7113 - prc: 0.4228 - val_loss: 0.4594 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6856 - val_prc: 0.4006\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5659 - tp: 99.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 299.0000 - accuracy: 0.8172 - precision: 0.5824 - recall: 0.2487 - auc: 0.7201 - prc: 0.4297 - val_loss: 0.4519 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6867 - val_prc: 0.4105\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5668 - tp: 98.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 300.0000 - accuracy: 0.8162 - precision: 0.5765 - recall: 0.2462 - auc: 0.7180 - prc: 0.4271 - val_loss: 0.4429 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 75.0000 - val_accuracy: 0.8340 - val_precision: 0.6400 - val_recall: 0.1758 - val_auc: 0.6872 - val_prc: 0.4113\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5660 - tp: 98.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 300.0000 - accuracy: 0.8177 - precision: 0.5868 - recall: 0.2462 - auc: 0.7189 - prc: 0.4361 - val_loss: 0.4836 - val_tp: 34.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 57.0000 - val_accuracy: 0.7984 - val_precision: 0.4304 - val_recall: 0.3736 - val_auc: 0.6848 - val_prc: 0.3903\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 94.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 304.0000 - accuracy: 0.8123 - precision: 0.5529 - recall: 0.2362 - auc: 0.7166 - prc: 0.4337 - val_loss: 0.4609 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6858 - val_prc: 0.4017\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5670 - tp: 96.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 302.0000 - accuracy: 0.8113 - precision: 0.5455 - recall: 0.2412 - auc: 0.7185 - prc: 0.4257 - val_loss: 0.4400 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6875 - val_prc: 0.4124\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5679 - tp: 90.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 308.0000 - accuracy: 0.8113 - precision: 0.5488 - recall: 0.2261 - auc: 0.7171 - prc: 0.4282 - val_loss: 0.4780 - val_tp: 32.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 59.0000 - val_accuracy: 0.8004 - val_precision: 0.4324 - val_recall: 0.3516 - val_auc: 0.6852 - val_prc: 0.3882\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5668 - tp: 92.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 306.0000 - accuracy: 0.8088 - precision: 0.5318 - recall: 0.2312 - auc: 0.7174 - prc: 0.4299 - val_loss: 0.4568 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6865 - val_prc: 0.4107\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5667 - tp: 102.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 296.0000 - accuracy: 0.8147 - precision: 0.5635 - recall: 0.2563 - auc: 0.7187 - prc: 0.4301 - val_loss: 0.4483 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 71.0000 - val_accuracy: 0.8360 - val_precision: 0.6250 - val_recall: 0.2198 - val_auc: 0.6872 - val_prc: 0.4121\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5677 - tp: 90.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 308.0000 - accuracy: 0.8127 - precision: 0.5590 - recall: 0.2261 - auc: 0.7175 - prc: 0.4357 - val_loss: 0.4609 - val_tp: 26.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 65.0000 - val_accuracy: 0.8241 - val_precision: 0.5200 - val_recall: 0.2857 - val_auc: 0.6865 - val_prc: 0.4016\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5661 - tp: 97.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 301.0000 - accuracy: 0.8162 - precision: 0.5774 - recall: 0.2437 - auc: 0.7184 - prc: 0.4340 - val_loss: 0.4460 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 72.0000 - val_accuracy: 0.8360 - val_precision: 0.6333 - val_recall: 0.2088 - val_auc: 0.6867 - val_prc: 0.4122\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5669 - tp: 97.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 301.0000 - accuracy: 0.8167 - precision: 0.5808 - recall: 0.2437 - auc: 0.7180 - prc: 0.4312 - val_loss: 0.4601 - val_tp: 26.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 65.0000 - val_accuracy: 0.8241 - val_precision: 0.5200 - val_recall: 0.2857 - val_auc: 0.6859 - val_prc: 0.4016\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5663 - tp: 93.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 305.0000 - accuracy: 0.8147 - precision: 0.5706 - recall: 0.2337 - auc: 0.7183 - prc: 0.4345 - val_loss: 0.4729 - val_tp: 29.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 62.0000 - val_accuracy: 0.7984 - val_precision: 0.4203 - val_recall: 0.3187 - val_auc: 0.6856 - val_prc: 0.3949\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5677 - tp: 105.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 293.0000 - accuracy: 0.8142 - precision: 0.5585 - recall: 0.2638 - auc: 0.7149 - prc: 0.4354 - val_loss: 0.4682 - val_tp: 28.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 63.0000 - val_accuracy: 0.8083 - val_precision: 0.4516 - val_recall: 0.3077 - val_auc: 0.6854 - val_prc: 0.4006\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5696 - tp: 103.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 295.0000 - accuracy: 0.8182 - precision: 0.5852 - recall: 0.2588 - auc: 0.7127 - prc: 0.4265 - val_loss: 0.4702 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6865 - val_prc: 0.4013\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5668 - tp: 99.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 299.0000 - accuracy: 0.8132 - precision: 0.5562 - recall: 0.2487 - auc: 0.7165 - prc: 0.4353 - val_loss: 0.4568 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6873 - val_prc: 0.4130\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5697 - tp: 95.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 303.0000 - accuracy: 0.8132 - precision: 0.5588 - recall: 0.2387 - auc: 0.7132 - prc: 0.4266 - val_loss: 0.4556 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6869 - val_prc: 0.4129\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 101.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 297.0000 - accuracy: 0.8147 - precision: 0.5642 - recall: 0.2538 - auc: 0.7175 - prc: 0.4344 - val_loss: 0.4394 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6876 - val_prc: 0.4134\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 105.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 293.0000 - accuracy: 0.8187 - precision: 0.5866 - recall: 0.2638 - auc: 0.7153 - prc: 0.4371 - val_loss: 0.4634 - val_tp: 28.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 63.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3077 - val_auc: 0.6871 - val_prc: 0.4045\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5681 - tp: 100.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 298.0000 - accuracy: 0.8167 - precision: 0.5780 - recall: 0.2513 - auc: 0.7133 - prc: 0.4392 - val_loss: 0.4696 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6865 - val_prc: 0.3923\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5661 - tp: 98.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 300.0000 - accuracy: 0.8182 - precision: 0.5904 - recall: 0.2462 - auc: 0.7177 - prc: 0.4338 - val_loss: 0.4666 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6862 - val_prc: 0.4038\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - tp: 98.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 300.0000 - accuracy: 0.8147 - precision: 0.5665 - recall: 0.2462 - auc: 0.7169 - prc: 0.4353 - val_loss: 0.4575 - val_tp: 26.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 65.0000 - val_accuracy: 0.8281 - val_precision: 0.5417 - val_recall: 0.2857 - val_auc: 0.6871 - val_prc: 0.4133\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - tp: 100.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 298.0000 - accuracy: 0.8147 - precision: 0.5650 - recall: 0.2513 - auc: 0.7161 - prc: 0.4329 - val_loss: 0.4561 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6873 - val_prc: 0.4134\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5675 - tp: 105.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 293.0000 - accuracy: 0.8157 - precision: 0.5676 - recall: 0.2638 - auc: 0.7145 - prc: 0.4261 - val_loss: 0.4457 - val_tp: 19.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 72.0000 - val_accuracy: 0.8340 - val_precision: 0.6129 - val_recall: 0.2088 - val_auc: 0.6870 - val_prc: 0.4133\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5663 - tp: 103.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 295.0000 - accuracy: 0.8147 - precision: 0.5628 - recall: 0.2588 - auc: 0.7184 - prc: 0.4290 - val_loss: 0.4532 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6877 - val_prc: 0.4137\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 103.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 295.0000 - accuracy: 0.8152 - precision: 0.5659 - recall: 0.2588 - auc: 0.7188 - prc: 0.4318 - val_loss: 0.4584 - val_tp: 27.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 64.0000 - val_accuracy: 0.8261 - val_precision: 0.5294 - val_recall: 0.2967 - val_auc: 0.6861 - val_prc: 0.4128\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 102.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 296.0000 - accuracy: 0.8167 - precision: 0.5763 - recall: 0.2563 - auc: 0.7185 - prc: 0.4342 - val_loss: 0.4508 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6879 - val_prc: 0.4134\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5642 - tp: 99.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 299.0000 - accuracy: 0.8103 - precision: 0.5380 - recall: 0.2487 - auc: 0.7224 - prc: 0.4310 - val_loss: 0.4368 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 75.0000 - val_accuracy: 0.8419 - val_precision: 0.7619 - val_recall: 0.1758 - val_auc: 0.6879 - val_prc: 0.4135\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5669 - tp: 106.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 292.0000 - accuracy: 0.8152 - precision: 0.5638 - recall: 0.2663 - auc: 0.7173 - prc: 0.4304 - val_loss: 0.4375 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 75.0000 - val_accuracy: 0.8419 - val_precision: 0.7619 - val_recall: 0.1758 - val_auc: 0.6876 - val_prc: 0.4123\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5675 - tp: 95.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 303.0000 - accuracy: 0.8118 - precision: 0.5491 - recall: 0.2387 - auc: 0.7166 - prc: 0.4271 - val_loss: 0.4411 - val_tp: 16.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 75.0000 - val_accuracy: 0.8360 - val_precision: 0.6667 - val_recall: 0.1758 - val_auc: 0.6877 - val_prc: 0.4118\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5661 - tp: 97.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 301.0000 - accuracy: 0.8113 - precision: 0.5449 - recall: 0.2437 - auc: 0.7181 - prc: 0.4343 - val_loss: 0.4511 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6886 - val_prc: 0.4135\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5661 - tp: 96.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 302.0000 - accuracy: 0.8108 - precision: 0.5424 - recall: 0.2412 - auc: 0.7178 - prc: 0.4322 - val_loss: 0.4316 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 86.0000 - val_accuracy: 0.8221 - val_precision: 0.5556 - val_recall: 0.0549 - val_auc: 0.6893 - val_prc: 0.4147\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5672 - tp: 102.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 296.0000 - accuracy: 0.8187 - precision: 0.5896 - recall: 0.2563 - auc: 0.7164 - prc: 0.4273 - val_loss: 0.4354 - val_tp: 12.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 79.0000 - val_accuracy: 0.8360 - val_precision: 0.7500 - val_recall: 0.1319 - val_auc: 0.6887 - val_prc: 0.4145\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5666 - tp: 99.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 299.0000 - accuracy: 0.8187 - precision: 0.5928 - recall: 0.2487 - auc: 0.7148 - prc: 0.4385 - val_loss: 0.4409 - val_tp: 16.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 75.0000 - val_accuracy: 0.8360 - val_precision: 0.6667 - val_recall: 0.1758 - val_auc: 0.6883 - val_prc: 0.4131\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5657 - tp: 92.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 306.0000 - accuracy: 0.8177 - precision: 0.5935 - recall: 0.2312 - auc: 0.7199 - prc: 0.4315 - val_loss: 0.4636 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6864 - val_prc: 0.4035\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5672 - tp: 108.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 290.0000 - accuracy: 0.8142 - precision: 0.5567 - recall: 0.2714 - auc: 0.7162 - prc: 0.4300 - val_loss: 0.4620 - val_tp: 28.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 63.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3077 - val_auc: 0.6873 - val_prc: 0.4049\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5658 - tp: 94.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 304.0000 - accuracy: 0.8172 - precision: 0.5875 - recall: 0.2362 - auc: 0.7172 - prc: 0.4402 - val_loss: 0.4833 - val_tp: 34.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 57.0000 - val_accuracy: 0.7925 - val_precision: 0.4146 - val_recall: 0.3736 - val_auc: 0.6863 - val_prc: 0.3920\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 107.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 291.0000 - accuracy: 0.8152 - precision: 0.5632 - recall: 0.2688 - auc: 0.7157 - prc: 0.4302 - val_loss: 0.4408 - val_tp: 16.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 75.0000 - val_accuracy: 0.8379 - val_precision: 0.6957 - val_recall: 0.1758 - val_auc: 0.6884 - val_prc: 0.4148\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5666 - tp: 105.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 293.0000 - accuracy: 0.8142 - precision: 0.5585 - recall: 0.2638 - auc: 0.7164 - prc: 0.4299 - val_loss: 0.4422 - val_tp: 18.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 73.0000 - val_accuracy: 0.8360 - val_precision: 0.6429 - val_recall: 0.1978 - val_auc: 0.6871 - val_prc: 0.4141\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 102.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 296.0000 - accuracy: 0.8187 - precision: 0.5896 - recall: 0.2563 - auc: 0.7169 - prc: 0.4339 - val_loss: 0.4550 - val_tp: 26.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 65.0000 - val_accuracy: 0.8281 - val_precision: 0.5417 - val_recall: 0.2857 - val_auc: 0.6872 - val_prc: 0.4135\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 107.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 291.0000 - accuracy: 0.8177 - precision: 0.5784 - recall: 0.2688 - auc: 0.7195 - prc: 0.4353 - val_loss: 0.4359 - val_tp: 11.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 80.0000 - val_accuracy: 0.8340 - val_precision: 0.7333 - val_recall: 0.1209 - val_auc: 0.6867 - val_prc: 0.4130\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5653 - tp: 90.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 308.0000 - accuracy: 0.8142 - precision: 0.5696 - recall: 0.2261 - auc: 0.7199 - prc: 0.4315 - val_loss: 0.4548 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6869 - val_prc: 0.4141\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5651 - tp: 104.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 294.0000 - accuracy: 0.8132 - precision: 0.5532 - recall: 0.2613 - auc: 0.7198 - prc: 0.4329 - val_loss: 0.4534 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6881 - val_prc: 0.4131\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5663 - tp: 94.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 304.0000 - accuracy: 0.8192 - precision: 0.6026 - recall: 0.2362 - auc: 0.7174 - prc: 0.4353 - val_loss: 0.4706 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6860 - val_prc: 0.3913\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5641 - tp: 113.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 285.0000 - accuracy: 0.8162 - precision: 0.5650 - recall: 0.2839 - auc: 0.7217 - prc: 0.4383 - val_loss: 0.4337 - val_tp: 8.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 83.0000 - val_accuracy: 0.8281 - val_precision: 0.6667 - val_recall: 0.0879 - val_auc: 0.6883 - val_prc: 0.4132\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5670 - tp: 89.0000 - fp: 55.0000 - tn: 1571.0000 - fn: 309.0000 - accuracy: 0.8202 - precision: 0.6181 - recall: 0.2236 - auc: 0.7177 - prc: 0.4360 - val_loss: 0.4713 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6869 - val_prc: 0.3967\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - tp: 102.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 296.0000 - accuracy: 0.8118 - precision: 0.5455 - recall: 0.2563 - auc: 0.7163 - prc: 0.4376 - val_loss: 0.4495 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6882 - val_prc: 0.4144\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5645 - tp: 100.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 298.0000 - accuracy: 0.8167 - precision: 0.5780 - recall: 0.2513 - auc: 0.7206 - prc: 0.4390 - val_loss: 0.4437 - val_tp: 19.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 72.0000 - val_accuracy: 0.8340 - val_precision: 0.6129 - val_recall: 0.2088 - val_auc: 0.6880 - val_prc: 0.4153\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5649 - tp: 98.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 300.0000 - accuracy: 0.8177 - precision: 0.5868 - recall: 0.2462 - auc: 0.7191 - prc: 0.4380 - val_loss: 0.4495 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6881 - val_prc: 0.4149\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - tp: 96.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 302.0000 - accuracy: 0.8127 - precision: 0.5549 - recall: 0.2412 - auc: 0.7183 - prc: 0.4391 - val_loss: 0.4566 - val_tp: 27.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 64.0000 - val_accuracy: 0.8241 - val_precision: 0.5192 - val_recall: 0.2967 - val_auc: 0.6873 - val_prc: 0.4147\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5659 - tp: 106.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 292.0000 - accuracy: 0.8132 - precision: 0.5521 - recall: 0.2663 - auc: 0.7177 - prc: 0.4369 - val_loss: 0.4373 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 75.0000 - val_accuracy: 0.8419 - val_precision: 0.7619 - val_recall: 0.1758 - val_auc: 0.6872 - val_prc: 0.4125\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5676 - tp: 92.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 306.0000 - accuracy: 0.8103 - precision: 0.5412 - recall: 0.2312 - auc: 0.7151 - prc: 0.4394 - val_loss: 0.4333 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 85.0000 - val_accuracy: 0.8241 - val_precision: 0.6000 - val_recall: 0.0659 - val_auc: 0.6885 - val_prc: 0.4137\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5686 - tp: 89.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 309.0000 - accuracy: 0.8103 - precision: 0.5427 - recall: 0.2236 - auc: 0.7162 - prc: 0.4288 - val_loss: 0.4403 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6878 - val_prc: 0.4144\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5681 - tp: 100.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 298.0000 - accuracy: 0.8073 - precision: 0.5208 - recall: 0.2513 - auc: 0.7182 - prc: 0.4138 - val_loss: 0.4408 - val_tp: 19.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 72.0000 - val_accuracy: 0.8379 - val_precision: 0.6552 - val_recall: 0.2088 - val_auc: 0.6876 - val_prc: 0.4147\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5653 - tp: 99.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 299.0000 - accuracy: 0.8142 - precision: 0.5625 - recall: 0.2487 - auc: 0.7190 - prc: 0.4379 - val_loss: 0.4468 - val_tp: 20.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 71.0000 - val_accuracy: 0.8340 - val_precision: 0.6061 - val_recall: 0.2198 - val_auc: 0.6874 - val_prc: 0.4138\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5647 - tp: 105.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 293.0000 - accuracy: 0.8123 - precision: 0.5469 - recall: 0.2638 - auc: 0.7210 - prc: 0.4342 - val_loss: 0.4442 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 72.0000 - val_accuracy: 0.8360 - val_precision: 0.6333 - val_recall: 0.2088 - val_auc: 0.6877 - val_prc: 0.4138\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 100.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 298.0000 - accuracy: 0.8162 - precision: 0.5747 - recall: 0.2513 - auc: 0.7165 - prc: 0.4381 - val_loss: 0.4394 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6892 - val_prc: 0.4153\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5674 - tp: 98.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 300.0000 - accuracy: 0.8142 - precision: 0.5632 - recall: 0.2462 - auc: 0.7145 - prc: 0.4284 - val_loss: 0.4566 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6877 - val_prc: 0.4145\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - tp: 96.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 302.0000 - accuracy: 0.8157 - precision: 0.5749 - recall: 0.2412 - auc: 0.7178 - prc: 0.4397 - val_loss: 0.4770 - val_tp: 31.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 60.0000 - val_accuracy: 0.7984 - val_precision: 0.4247 - val_recall: 0.3407 - val_auc: 0.6857 - val_prc: 0.3917\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - tp: 99.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 299.0000 - accuracy: 0.8152 - precision: 0.5690 - recall: 0.2487 - auc: 0.7179 - prc: 0.4369 - val_loss: 0.4505 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6878 - val_prc: 0.4131\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5678 - tp: 101.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 297.0000 - accuracy: 0.8167 - precision: 0.5771 - recall: 0.2538 - auc: 0.7146 - prc: 0.4314 - val_loss: 0.4566 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6870 - val_prc: 0.4134\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 100.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 298.0000 - accuracy: 0.8167 - precision: 0.5780 - recall: 0.2513 - auc: 0.7179 - prc: 0.4299 - val_loss: 0.4531 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6880 - val_prc: 0.4139\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5647 - tp: 102.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 296.0000 - accuracy: 0.8132 - precision: 0.5543 - recall: 0.2563 - auc: 0.7187 - prc: 0.4279 - val_loss: 0.4677 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6877 - val_prc: 0.4041\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5655 - tp: 101.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 297.0000 - accuracy: 0.8137 - precision: 0.5580 - recall: 0.2538 - auc: 0.7174 - prc: 0.4363 - val_loss: 0.4474 - val_tp: 21.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 70.0000 - val_accuracy: 0.8360 - val_precision: 0.6176 - val_recall: 0.2308 - val_auc: 0.6885 - val_prc: 0.4157\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5649 - tp: 103.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 295.0000 - accuracy: 0.8152 - precision: 0.5659 - recall: 0.2588 - auc: 0.7183 - prc: 0.4411 - val_loss: 0.4405 - val_tp: 17.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 74.0000 - val_accuracy: 0.8379 - val_precision: 0.6800 - val_recall: 0.1868 - val_auc: 0.6887 - val_prc: 0.4154\n",
      "Epoch 264/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5657 - tp: 96.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 302.0000 - accuracy: 0.8132 - precision: 0.5581 - recall: 0.2412 - auc: 0.7175 - prc: 0.4350 - val_loss: 0.4464 - val_tp: 22.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 69.0000 - val_accuracy: 0.8320 - val_precision: 0.5789 - val_recall: 0.2418 - val_auc: 0.6878 - val_prc: 0.4147\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5650 - tp: 101.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 297.0000 - accuracy: 0.8162 - precision: 0.5739 - recall: 0.2538 - auc: 0.7181 - prc: 0.4403 - val_loss: 0.4509 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6886 - val_prc: 0.4155\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5646 - tp: 102.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 296.0000 - accuracy: 0.8147 - precision: 0.5635 - recall: 0.2563 - auc: 0.7194 - prc: 0.4353 - val_loss: 0.4481 - val_tp: 22.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 69.0000 - val_accuracy: 0.8360 - val_precision: 0.6111 - val_recall: 0.2418 - val_auc: 0.6888 - val_prc: 0.4160\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5638 - tp: 102.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 296.0000 - accuracy: 0.8162 - precision: 0.5730 - recall: 0.2563 - auc: 0.7216 - prc: 0.4442 - val_loss: 0.4405 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6886 - val_prc: 0.4136\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5666 - tp: 96.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 302.0000 - accuracy: 0.8157 - precision: 0.5749 - recall: 0.2412 - auc: 0.7171 - prc: 0.4291 - val_loss: 0.4730 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6869 - val_prc: 0.3983\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5667 - tp: 106.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 292.0000 - accuracy: 0.8221 - precision: 0.6092 - recall: 0.2663 - auc: 0.7143 - prc: 0.4365 - val_loss: 0.4694 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6869 - val_prc: 0.3922\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5636 - tp: 103.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 295.0000 - accuracy: 0.8167 - precision: 0.5754 - recall: 0.2588 - auc: 0.7213 - prc: 0.4418 - val_loss: 0.4424 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 72.0000 - val_accuracy: 0.8360 - val_precision: 0.6333 - val_recall: 0.2088 - val_auc: 0.6881 - val_prc: 0.4152\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5655 - tp: 101.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 297.0000 - accuracy: 0.8127 - precision: 0.5519 - recall: 0.2538 - auc: 0.7195 - prc: 0.4393 - val_loss: 0.4497 - val_tp: 21.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 70.0000 - val_accuracy: 0.8379 - val_precision: 0.6364 - val_recall: 0.2308 - val_auc: 0.6874 - val_prc: 0.4142\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5657 - tp: 97.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 301.0000 - accuracy: 0.8172 - precision: 0.5843 - recall: 0.2437 - auc: 0.7171 - prc: 0.4409 - val_loss: 0.4337 - val_tp: 7.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 84.0000 - val_accuracy: 0.8261 - val_precision: 0.6364 - val_recall: 0.0769 - val_auc: 0.6881 - val_prc: 0.4147\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 90.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 308.0000 - accuracy: 0.8162 - precision: 0.5844 - recall: 0.2261 - auc: 0.7188 - prc: 0.4332 - val_loss: 0.4587 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6871 - val_prc: 0.4141\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5641 - tp: 103.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 295.0000 - accuracy: 0.8137 - precision: 0.5568 - recall: 0.2588 - auc: 0.7211 - prc: 0.4419 - val_loss: 0.4397 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6881 - val_prc: 0.4138\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5647 - tp: 96.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 302.0000 - accuracy: 0.8187 - precision: 0.5963 - recall: 0.2412 - auc: 0.7203 - prc: 0.4431 - val_loss: 0.4637 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6872 - val_prc: 0.4134\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5641 - tp: 96.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 302.0000 - accuracy: 0.8123 - precision: 0.5517 - recall: 0.2412 - auc: 0.7203 - prc: 0.4382 - val_loss: 0.4682 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6869 - val_prc: 0.4135\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 110.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 288.0000 - accuracy: 0.8152 - precision: 0.5612 - recall: 0.2764 - auc: 0.7163 - prc: 0.4323 - val_loss: 0.4532 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6878 - val_prc: 0.4145\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5649 - tp: 99.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 299.0000 - accuracy: 0.8172 - precision: 0.5824 - recall: 0.2487 - auc: 0.7181 - prc: 0.4406 - val_loss: 0.4674 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6877 - val_prc: 0.4153\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - tp: 108.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 290.0000 - accuracy: 0.8167 - precision: 0.5714 - recall: 0.2714 - auc: 0.7175 - prc: 0.4354 - val_loss: 0.4607 - val_tp: 26.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 65.0000 - val_accuracy: 0.8261 - val_precision: 0.5306 - val_recall: 0.2857 - val_auc: 0.6878 - val_prc: 0.4135\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5640 - tp: 101.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 297.0000 - accuracy: 0.8142 - precision: 0.5611 - recall: 0.2538 - auc: 0.7193 - prc: 0.4397 - val_loss: 0.4501 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6864 - val_prc: 0.4141\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5636 - tp: 106.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 292.0000 - accuracy: 0.8113 - precision: 0.5408 - recall: 0.2663 - auc: 0.7218 - prc: 0.4299 - val_loss: 0.4574 - val_tp: 26.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 65.0000 - val_accuracy: 0.8241 - val_precision: 0.5200 - val_recall: 0.2857 - val_auc: 0.6873 - val_prc: 0.4144\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5670 - tp: 96.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 302.0000 - accuracy: 0.8142 - precision: 0.5647 - recall: 0.2412 - auc: 0.7167 - prc: 0.4324 - val_loss: 0.4686 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6865 - val_prc: 0.4136\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5681 - tp: 90.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 308.0000 - accuracy: 0.8118 - precision: 0.5521 - recall: 0.2261 - auc: 0.7131 - prc: 0.4291 - val_loss: 0.4437 - val_tp: 17.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 74.0000 - val_accuracy: 0.8399 - val_precision: 0.7083 - val_recall: 0.1868 - val_auc: 0.6885 - val_prc: 0.4143\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5650 - tp: 101.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 297.0000 - accuracy: 0.8132 - precision: 0.5549 - recall: 0.2538 - auc: 0.7180 - prc: 0.4332 - val_loss: 0.4660 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6865 - val_prc: 0.4143\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5647 - tp: 102.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 296.0000 - accuracy: 0.8167 - precision: 0.5763 - recall: 0.2563 - auc: 0.7186 - prc: 0.4360 - val_loss: 0.4504 - val_tp: 22.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 69.0000 - val_accuracy: 0.8360 - val_precision: 0.6111 - val_recall: 0.2418 - val_auc: 0.6877 - val_prc: 0.4151\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5651 - tp: 100.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 298.0000 - accuracy: 0.8202 - precision: 0.6024 - recall: 0.2513 - auc: 0.7184 - prc: 0.4401 - val_loss: 0.4522 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6879 - val_prc: 0.4150\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5663 - tp: 105.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 293.0000 - accuracy: 0.8182 - precision: 0.5833 - recall: 0.2638 - auc: 0.7168 - prc: 0.4347 - val_loss: 0.4852 - val_tp: 33.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 58.0000 - val_accuracy: 0.7866 - val_precision: 0.3976 - val_recall: 0.3626 - val_auc: 0.6861 - val_prc: 0.3955\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5683 - tp: 103.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 295.0000 - accuracy: 0.8048 - precision: 0.5074 - recall: 0.2588 - auc: 0.7169 - prc: 0.4255 - val_loss: 0.4346 - val_tp: 7.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 84.0000 - val_accuracy: 0.8261 - val_precision: 0.6364 - val_recall: 0.0769 - val_auc: 0.6881 - val_prc: 0.4147\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 95.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 303.0000 - accuracy: 0.8137 - precision: 0.5621 - recall: 0.2387 - auc: 0.7147 - prc: 0.4343 - val_loss: 0.4583 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6874 - val_prc: 0.4145\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5702 - tp: 102.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 296.0000 - accuracy: 0.8093 - precision: 0.5312 - recall: 0.2563 - auc: 0.7133 - prc: 0.4170 - val_loss: 0.4378 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 75.0000 - val_accuracy: 0.8419 - val_precision: 0.7619 - val_recall: 0.1758 - val_auc: 0.6895 - val_prc: 0.4145\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5639 - tp: 99.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 299.0000 - accuracy: 0.8172 - precision: 0.5824 - recall: 0.2487 - auc: 0.7198 - prc: 0.4367 - val_loss: 0.4523 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6886 - val_prc: 0.4154\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5665 - tp: 95.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 303.0000 - accuracy: 0.8152 - precision: 0.5723 - recall: 0.2387 - auc: 0.7160 - prc: 0.4298 - val_loss: 0.4559 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6875 - val_prc: 0.4136\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5643 - tp: 103.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 295.0000 - accuracy: 0.8177 - precision: 0.5819 - recall: 0.2588 - auc: 0.7200 - prc: 0.4407 - val_loss: 0.4582 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6869 - val_prc: 0.4143\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5653 - tp: 105.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 293.0000 - accuracy: 0.8167 - precision: 0.5738 - recall: 0.2638 - auc: 0.7176 - prc: 0.4359 - val_loss: 0.4523 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6880 - val_prc: 0.4149\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5637 - tp: 98.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 300.0000 - accuracy: 0.8162 - precision: 0.5765 - recall: 0.2462 - auc: 0.7200 - prc: 0.4401 - val_loss: 0.4346 - val_tp: 15.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 76.0000 - val_accuracy: 0.8399 - val_precision: 0.7500 - val_recall: 0.1648 - val_auc: 0.6892 - val_prc: 0.4162\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5645 - tp: 92.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 306.0000 - accuracy: 0.8177 - precision: 0.5935 - recall: 0.2312 - auc: 0.7170 - prc: 0.4509 - val_loss: 0.4656 - val_tp: 29.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 62.0000 - val_accuracy: 0.8083 - val_precision: 0.4531 - val_recall: 0.3187 - val_auc: 0.6870 - val_prc: 0.4142\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5675 - tp: 95.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 303.0000 - accuracy: 0.8147 - precision: 0.5689 - recall: 0.2387 - auc: 0.7165 - prc: 0.4315 - val_loss: 0.4487 - val_tp: 22.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 69.0000 - val_accuracy: 0.8379 - val_precision: 0.6286 - val_recall: 0.2418 - val_auc: 0.6881 - val_prc: 0.4143\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5634 - tp: 98.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 300.0000 - accuracy: 0.8162 - precision: 0.5765 - recall: 0.2462 - auc: 0.7212 - prc: 0.4431 - val_loss: 0.4648 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6875 - val_prc: 0.4142\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5655 - tp: 95.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 303.0000 - accuracy: 0.8187 - precision: 0.5975 - recall: 0.2387 - auc: 0.7173 - prc: 0.4407 - val_loss: 0.4547 - val_tp: 26.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 65.0000 - val_accuracy: 0.8261 - val_precision: 0.5306 - val_recall: 0.2857 - val_auc: 0.6873 - val_prc: 0.4141\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5647 - tp: 102.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 296.0000 - accuracy: 0.8127 - precision: 0.5514 - recall: 0.2563 - auc: 0.7184 - prc: 0.4380 - val_loss: 0.4581 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6877 - val_prc: 0.4145\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5649 - tp: 99.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 299.0000 - accuracy: 0.8187 - precision: 0.5928 - recall: 0.2487 - auc: 0.7177 - prc: 0.4401 - val_loss: 0.4439 - val_tp: 21.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 70.0000 - val_accuracy: 0.8379 - val_precision: 0.6364 - val_recall: 0.2308 - val_auc: 0.6881 - val_prc: 0.4154\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5638 - tp: 104.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 294.0000 - accuracy: 0.8152 - precision: 0.5652 - recall: 0.2613 - auc: 0.7203 - prc: 0.4368 - val_loss: 0.4638 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6868 - val_prc: 0.4140\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5653 - tp: 100.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 298.0000 - accuracy: 0.8157 - precision: 0.5714 - recall: 0.2513 - auc: 0.7162 - prc: 0.4397 - val_loss: 0.4510 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6880 - val_prc: 0.4152\n",
      "Epoch 304/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5650 - tp: 95.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 303.0000 - accuracy: 0.8152 - precision: 0.5723 - recall: 0.2387 - auc: 0.7184 - prc: 0.4376 - val_loss: 0.4502 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6873 - val_prc: 0.4144\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5672 - tp: 101.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 297.0000 - accuracy: 0.8157 - precision: 0.5706 - recall: 0.2538 - auc: 0.7138 - prc: 0.4329 - val_loss: 0.4419 - val_tp: 19.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 72.0000 - val_accuracy: 0.8360 - val_precision: 0.6333 - val_recall: 0.2088 - val_auc: 0.6887 - val_prc: 0.4155\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 102.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 296.0000 - accuracy: 0.8202 - precision: 0.6000 - recall: 0.2563 - auc: 0.7171 - prc: 0.4366 - val_loss: 0.4484 - val_tp: 21.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 70.0000 - val_accuracy: 0.8379 - val_precision: 0.6364 - val_recall: 0.2308 - val_auc: 0.6876 - val_prc: 0.4148\n",
      "Epoch 307/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5645 - tp: 99.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 299.0000 - accuracy: 0.8177 - precision: 0.5858 - recall: 0.2487 - auc: 0.7182 - prc: 0.4422 - val_loss: 0.4599 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6869 - val_prc: 0.4143\n",
      "Epoch 308/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 98.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 300.0000 - accuracy: 0.8142 - precision: 0.5632 - recall: 0.2462 - auc: 0.7184 - prc: 0.4314 - val_loss: 0.4535 - val_tp: 22.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 69.0000 - val_accuracy: 0.8360 - val_precision: 0.6111 - val_recall: 0.2418 - val_auc: 0.6888 - val_prc: 0.4145\n",
      "Epoch 309/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5638 - tp: 91.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 307.0000 - accuracy: 0.8192 - precision: 0.6067 - recall: 0.2286 - auc: 0.7189 - prc: 0.4447 - val_loss: 0.4478 - val_tp: 22.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 69.0000 - val_accuracy: 0.8360 - val_precision: 0.6111 - val_recall: 0.2418 - val_auc: 0.6884 - val_prc: 0.4154\n",
      "Epoch 310/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 100.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 298.0000 - accuracy: 0.8123 - precision: 0.5495 - recall: 0.2513 - auc: 0.7176 - prc: 0.4232 - val_loss: 0.4511 - val_tp: 23.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 68.0000 - val_accuracy: 0.8320 - val_precision: 0.5750 - val_recall: 0.2527 - val_auc: 0.6877 - val_prc: 0.4146\n",
      "Epoch 311/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - tp: 90.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 308.0000 - accuracy: 0.8142 - precision: 0.5696 - recall: 0.2261 - auc: 0.7175 - prc: 0.4410 - val_loss: 0.4647 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6877 - val_prc: 0.4150\n",
      "Epoch 312/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5639 - tp: 98.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 300.0000 - accuracy: 0.8207 - precision: 0.6087 - recall: 0.2462 - auc: 0.7195 - prc: 0.4454 - val_loss: 0.4702 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6880 - val_prc: 0.4147\n",
      "Epoch 313/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5644 - tp: 101.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 297.0000 - accuracy: 0.8187 - precision: 0.5906 - recall: 0.2538 - auc: 0.7194 - prc: 0.4392 - val_loss: 0.4466 - val_tp: 22.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 69.0000 - val_accuracy: 0.8360 - val_precision: 0.6111 - val_recall: 0.2418 - val_auc: 0.6877 - val_prc: 0.4153\n",
      "Epoch 314/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 98.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 300.0000 - accuracy: 0.8142 - precision: 0.5632 - recall: 0.2462 - auc: 0.7150 - prc: 0.4322 - val_loss: 0.4439 - val_tp: 18.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 73.0000 - val_accuracy: 0.8360 - val_precision: 0.6429 - val_recall: 0.1978 - val_auc: 0.6882 - val_prc: 0.4156\n",
      "Epoch 315/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5650 - tp: 96.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 302.0000 - accuracy: 0.8197 - precision: 0.6038 - recall: 0.2412 - auc: 0.7171 - prc: 0.4413 - val_loss: 0.4521 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6878 - val_prc: 0.4148\n",
      "Epoch 316/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5644 - tp: 106.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 292.0000 - accuracy: 0.8162 - precision: 0.5699 - recall: 0.2663 - auc: 0.7183 - prc: 0.4399 - val_loss: 0.4435 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 71.0000 - val_accuracy: 0.8360 - val_precision: 0.6250 - val_recall: 0.2198 - val_auc: 0.6878 - val_prc: 0.4146\n",
      "Epoch 317/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5643 - tp: 101.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 297.0000 - accuracy: 0.8142 - precision: 0.5611 - recall: 0.2538 - auc: 0.7194 - prc: 0.4416 - val_loss: 0.4500 - val_tp: 23.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 68.0000 - val_accuracy: 0.8300 - val_precision: 0.5610 - val_recall: 0.2527 - val_auc: 0.6879 - val_prc: 0.4143\n",
      "Epoch 318/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5650 - tp: 100.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 298.0000 - accuracy: 0.8142 - precision: 0.5618 - recall: 0.2513 - auc: 0.7177 - prc: 0.4400 - val_loss: 0.4553 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6877 - val_prc: 0.4139\n",
      "Epoch 319/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5639 - tp: 101.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 297.0000 - accuracy: 0.8147 - precision: 0.5642 - recall: 0.2538 - auc: 0.7192 - prc: 0.4475 - val_loss: 0.4464 - val_tp: 21.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 70.0000 - val_accuracy: 0.8379 - val_precision: 0.6364 - val_recall: 0.2308 - val_auc: 0.6888 - val_prc: 0.4154\n",
      "Epoch 320/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5635 - tp: 96.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 302.0000 - accuracy: 0.8123 - precision: 0.5517 - recall: 0.2412 - auc: 0.7210 - prc: 0.4417 - val_loss: 0.4421 - val_tp: 16.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 75.0000 - val_accuracy: 0.8399 - val_precision: 0.7273 - val_recall: 0.1758 - val_auc: 0.6887 - val_prc: 0.4156\n",
      "Epoch 321/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5645 - tp: 97.0000 - fp: 60.0000 - tn: 1566.0000 - fn: 301.0000 - accuracy: 0.8216 - precision: 0.6178 - recall: 0.2437 - auc: 0.7164 - prc: 0.4428 - val_loss: 0.4499 - val_tp: 23.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 68.0000 - val_accuracy: 0.8300 - val_precision: 0.5610 - val_recall: 0.2527 - val_auc: 0.6876 - val_prc: 0.4146\n",
      "Epoch 322/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 104.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 294.0000 - accuracy: 0.8118 - precision: 0.5445 - recall: 0.2613 - auc: 0.7170 - prc: 0.4350 - val_loss: 0.4452 - val_tp: 19.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 72.0000 - val_accuracy: 0.8379 - val_precision: 0.6552 - val_recall: 0.2088 - val_auc: 0.6884 - val_prc: 0.4147\n",
      "Epoch 323/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5671 - tp: 93.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 305.0000 - accuracy: 0.8157 - precision: 0.5776 - recall: 0.2337 - auc: 0.7150 - prc: 0.4299 - val_loss: 0.4500 - val_tp: 23.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 68.0000 - val_accuracy: 0.8320 - val_precision: 0.5750 - val_recall: 0.2527 - val_auc: 0.6883 - val_prc: 0.4151\n",
      "Epoch 324/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 106.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 292.0000 - accuracy: 0.8172 - precision: 0.5761 - recall: 0.2663 - auc: 0.7156 - prc: 0.4272 - val_loss: 0.4375 - val_tp: 17.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 74.0000 - val_accuracy: 0.8379 - val_precision: 0.6800 - val_recall: 0.1868 - val_auc: 0.6886 - val_prc: 0.4155\n",
      "Epoch 325/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5646 - tp: 86.0000 - fp: 50.0000 - tn: 1576.0000 - fn: 312.0000 - accuracy: 0.8211 - precision: 0.6324 - recall: 0.2161 - auc: 0.7190 - prc: 0.4423 - val_loss: 0.4685 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6879 - val_prc: 0.4147\n",
      "Epoch 326/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5664 - tp: 104.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 294.0000 - accuracy: 0.8137 - precision: 0.5561 - recall: 0.2613 - auc: 0.7152 - prc: 0.4327 - val_loss: 0.4704 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6873 - val_prc: 0.4139\n",
      "Epoch 327/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5645 - tp: 99.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 299.0000 - accuracy: 0.8162 - precision: 0.5756 - recall: 0.2487 - auc: 0.7191 - prc: 0.4408 - val_loss: 0.4609 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6876 - val_prc: 0.4147\n",
      "Epoch 328/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5658 - tp: 98.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 300.0000 - accuracy: 0.8167 - precision: 0.5799 - recall: 0.2462 - auc: 0.7154 - prc: 0.4373 - val_loss: 0.4465 - val_tp: 22.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 69.0000 - val_accuracy: 0.8379 - val_precision: 0.6286 - val_recall: 0.2418 - val_auc: 0.6883 - val_prc: 0.4154\n",
      "Epoch 329/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5643 - tp: 99.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 299.0000 - accuracy: 0.8167 - precision: 0.5789 - recall: 0.2487 - auc: 0.7190 - prc: 0.4395 - val_loss: 0.4350 - val_tp: 16.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 75.0000 - val_accuracy: 0.8419 - val_precision: 0.7619 - val_recall: 0.1758 - val_auc: 0.6894 - val_prc: 0.4160\n",
      "Epoch 330/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - tp: 103.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 295.0000 - accuracy: 0.8167 - precision: 0.5754 - recall: 0.2588 - auc: 0.7175 - prc: 0.4318 - val_loss: 0.4365 - val_tp: 15.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 76.0000 - val_accuracy: 0.8399 - val_precision: 0.7500 - val_recall: 0.1648 - val_auc: 0.6878 - val_prc: 0.4150\n",
      "Epoch 331/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5667 - tp: 95.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 303.0000 - accuracy: 0.8162 - precision: 0.5793 - recall: 0.2387 - auc: 0.7142 - prc: 0.4368 - val_loss: 0.4582 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6872 - val_prc: 0.4139\n",
      "Epoch 332/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5639 - tp: 92.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 306.0000 - accuracy: 0.8152 - precision: 0.5750 - recall: 0.2312 - auc: 0.7191 - prc: 0.4402 - val_loss: 0.4550 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6879 - val_prc: 0.4150\n",
      "Epoch 333/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5639 - tp: 94.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 304.0000 - accuracy: 0.8192 - precision: 0.6026 - recall: 0.2362 - auc: 0.7198 - prc: 0.4362 - val_loss: 0.4817 - val_tp: 33.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 58.0000 - val_accuracy: 0.7866 - val_precision: 0.3976 - val_recall: 0.3626 - val_auc: 0.6867 - val_prc: 0.3920\n",
      "Epoch 334/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5677 - tp: 105.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 293.0000 - accuracy: 0.8132 - precision: 0.5526 - recall: 0.2638 - auc: 0.7135 - prc: 0.4335 - val_loss: 0.4573 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6874 - val_prc: 0.4137\n",
      "Epoch 335/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5652 - tp: 100.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 298.0000 - accuracy: 0.8127 - precision: 0.5525 - recall: 0.2513 - auc: 0.7172 - prc: 0.4307 - val_loss: 0.4399 - val_tp: 18.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 73.0000 - val_accuracy: 0.8360 - val_precision: 0.6429 - val_recall: 0.1978 - val_auc: 0.6895 - val_prc: 0.4155\n",
      "Epoch 336/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5637 - tp: 97.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 301.0000 - accuracy: 0.8157 - precision: 0.5740 - recall: 0.2437 - auc: 0.7182 - prc: 0.4393 - val_loss: 0.4641 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6875 - val_prc: 0.4140\n",
      "Epoch 337/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 97.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 301.0000 - accuracy: 0.8157 - precision: 0.5740 - recall: 0.2437 - auc: 0.7149 - prc: 0.4388 - val_loss: 0.4614 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6875 - val_prc: 0.4141\n",
      "Epoch 338/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5649 - tp: 101.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 297.0000 - accuracy: 0.8211 - precision: 0.6084 - recall: 0.2538 - auc: 0.7176 - prc: 0.4392 - val_loss: 0.4605 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6879 - val_prc: 0.4140\n",
      "Epoch 339/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5654 - tp: 102.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 296.0000 - accuracy: 0.8182 - precision: 0.5862 - recall: 0.2563 - auc: 0.7165 - prc: 0.4390 - val_loss: 0.4461 - val_tp: 20.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 71.0000 - val_accuracy: 0.8340 - val_precision: 0.6061 - val_recall: 0.2198 - val_auc: 0.6884 - val_prc: 0.4144\n",
      "Epoch 340/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5632 - tp: 101.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 297.0000 - accuracy: 0.8157 - precision: 0.5706 - recall: 0.2538 - auc: 0.7198 - prc: 0.4411 - val_loss: 0.4470 - val_tp: 22.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 69.0000 - val_accuracy: 0.8379 - val_precision: 0.6286 - val_recall: 0.2418 - val_auc: 0.6879 - val_prc: 0.4155\n",
      "Epoch 341/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5653 - tp: 97.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 301.0000 - accuracy: 0.8162 - precision: 0.5774 - recall: 0.2437 - auc: 0.7176 - prc: 0.4404 - val_loss: 0.4556 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6881 - val_prc: 0.4145\n",
      "Epoch 342/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5641 - tp: 100.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 298.0000 - accuracy: 0.8152 - precision: 0.5682 - recall: 0.2513 - auc: 0.7179 - prc: 0.4413 - val_loss: 0.4415 - val_tp: 20.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 71.0000 - val_accuracy: 0.8379 - val_precision: 0.6452 - val_recall: 0.2198 - val_auc: 0.6891 - val_prc: 0.4155\n",
      "Epoch 343/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5629 - tp: 103.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 295.0000 - accuracy: 0.8172 - precision: 0.5787 - recall: 0.2588 - auc: 0.7207 - prc: 0.4405 - val_loss: 0.4585 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6876 - val_prc: 0.4141\n",
      "Epoch 344/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5678 - tp: 96.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 302.0000 - accuracy: 0.8147 - precision: 0.5680 - recall: 0.2412 - auc: 0.7104 - prc: 0.4406 - val_loss: 0.4450 - val_tp: 20.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 71.0000 - val_accuracy: 0.8340 - val_precision: 0.6061 - val_recall: 0.2198 - val_auc: 0.6875 - val_prc: 0.4145\n",
      "Epoch 345/500\n",
      " 53/102 [==============>...............] - ETA: 0s - loss: 0.5823 - tp: 52.0000 - fp: 35.0000 - tn: 804.0000 - fn: 169.0000 - accuracy: 0.8075 - precision: 0.5977 - recall: 0.2353 - auc: 0.7147 - prc: 0.4616           Restoring model weights from the end of the best epoch: 295.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5636 - tp: 94.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 304.0000 - accuracy: 0.8187 - precision: 0.5987 - recall: 0.2362 - auc: 0.7199 - prc: 0.4432 - val_loss: 0.4446 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 71.0000 - val_accuracy: 0.8360 - val_precision: 0.6250 - val_recall: 0.2198 - val_auc: 0.6876 - val_prc: 0.4145\n",
      "Epoch 345: early stopping\n",
      "26/26 [==============================] - 0s 566us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.8119 - tp: 20.0000 - fp: 12.0000 - tn: 2029.0000 - fn: 469.0000 - accuracy: 0.8099 - precision: 0.6250 - recall: 0.0409 - auc: 0.5397 - prc: 0.2464 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4873 - prc: 0.1889 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7934 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4852 - prc: 0.1959 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7865 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5013 - prc: 0.1976 - val_loss: 0.4808 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4991 - prc: 0.2006 - val_loss: 0.4839 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - prc: 0.1966 - val_loss: 0.4874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7715 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5171 - prc: 0.2040 - val_loss: 0.4909 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1958 - val_loss: 0.4947 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7658 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5168 - prc: 0.2065 - val_loss: 0.4977 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7638 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5109 - prc: 0.2014 - val_loss: 0.5007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7623 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5019 - prc: 0.1973 - val_loss: 0.5039 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7610 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5092 - prc: 0.1997 - val_loss: 0.5067 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7602 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4972 - prc: 0.1957 - val_loss: 0.5091 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7595 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4963 - prc: 0.1953 - val_loss: 0.5116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5023 - prc: 0.1978 - val_loss: 0.5132 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7585 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.5151 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7584 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4919 - prc: 0.1939 - val_loss: 0.5171 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7579 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.5181 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7578 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4926 - prc: 0.1941 - val_loss: 0.5192 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7576 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.5212 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7575 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4944 - prc: 0.1929 - val_loss: 0.5220 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1971 - val_loss: 0.5223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7566 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5124 - prc: 0.2007 - val_loss: 0.4962 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6294 - val_prc: 0.2558\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6468 - prc: 0.2855 - val_loss: 0.5121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5572 - val_prc: 0.2003\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7364 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6681 - prc: 0.3288 - val_loss: 0.4980 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6301 - val_prc: 0.2559\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6765 - prc: 0.3418 - val_loss: 0.4870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6527 - val_prc: 0.2902\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6832 - prc: 0.3246 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6611 - val_prc: 0.3171\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7222 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6906 - prc: 0.3451 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6624 - val_prc: 0.3149\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7257 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6677 - prc: 0.3012 - val_loss: 0.4971 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6511 - val_prc: 0.2840\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7195 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6894 - prc: 0.3433 - val_loss: 0.4738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6637 - val_prc: 0.3192\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7169 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6902 - prc: 0.3434 - val_loss: 0.4841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6607 - val_prc: 0.3084\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7159 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6870 - prc: 0.3334 - val_loss: 0.4578 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6669 - val_prc: 0.3561\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7140 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6910 - prc: 0.3457 - val_loss: 0.4830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6638 - val_prc: 0.3152\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6943 - prc: 0.3598 - val_loss: 0.4910 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6622 - val_prc: 0.3065\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6952 - prc: 0.3432 - val_loss: 0.4848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6635 - val_prc: 0.3105\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7080 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6956 - prc: 0.3597 - val_loss: 0.5078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6566 - val_prc: 0.2894\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7050 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6992 - prc: 0.3496 - val_loss: 0.4878 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6648 - val_prc: 0.3128\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7032 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7017 - prc: 0.3549 - val_loss: 0.4891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6648 - val_prc: 0.3100\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6977 - prc: 0.3373 - val_loss: 0.4608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6716 - val_prc: 0.3574\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7041 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7014 - prc: 0.3777 - val_loss: 0.4938 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6657 - val_prc: 0.3104\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7002 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7052 - prc: 0.3763 - val_loss: 0.4567 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6718 - val_prc: 0.3663\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6980 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7065 - prc: 0.3808 - val_loss: 0.4926 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6679 - val_prc: 0.3190\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7015 - prc: 0.3595 - val_loss: 0.4676 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6730 - val_prc: 0.3497\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7099 - prc: 0.3838 - val_loss: 0.4798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6722 - val_prc: 0.3328\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6952 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7047 - prc: 0.3597 - val_loss: 0.5001 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6677 - val_prc: 0.3135\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7033 - prc: 0.3716 - val_loss: 0.5597 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6415 - val_prc: 0.2637\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7033 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6869 - prc: 0.3365 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6735 - val_prc: 0.3479\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6931 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7087 - prc: 0.3843 - val_loss: 0.4742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6750 - val_prc: 0.3459\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7055 - prc: 0.3713 - val_loss: 0.4830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6741 - val_prc: 0.3387\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7065 - prc: 0.3650 - val_loss: 0.5450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6560 - val_prc: 0.2827\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7010 - prc: 0.3522 - val_loss: 0.4617 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6771 - val_prc: 0.3630\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6922 - tp: 45.0000 - fp: 53.0000 - tn: 1573.0000 - fn: 353.0000 - accuracy: 0.7994 - precision: 0.4592 - recall: 0.1131 - auc: 0.7054 - prc: 0.3731 - val_loss: 0.5004 - val_tp: 33.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 58.0000 - val_accuracy: 0.7964 - val_precision: 0.4231 - val_recall: 0.3626 - val_auc: 0.6721 - val_prc: 0.3258\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6892 - tp: 107.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 291.0000 - accuracy: 0.8088 - precision: 0.5271 - recall: 0.2688 - auc: 0.7088 - prc: 0.3802 - val_loss: 0.5206 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6680 - val_prc: 0.3105\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6899 - tp: 119.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 279.0000 - accuracy: 0.8058 - precision: 0.5107 - recall: 0.2990 - auc: 0.7077 - prc: 0.3812 - val_loss: 0.4975 - val_tp: 32.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 59.0000 - val_accuracy: 0.7964 - val_precision: 0.4211 - val_recall: 0.3516 - val_auc: 0.6725 - val_prc: 0.3245\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6876 - tp: 108.0000 - fp: 117.0000 - tn: 1509.0000 - fn: 290.0000 - accuracy: 0.7989 - precision: 0.4800 - recall: 0.2714 - auc: 0.7112 - prc: 0.3662 - val_loss: 0.4847 - val_tp: 26.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 65.0000 - val_accuracy: 0.8043 - val_precision: 0.4333 - val_recall: 0.2857 - val_auc: 0.6751 - val_prc: 0.3371\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6869 - tp: 107.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 291.0000 - accuracy: 0.8043 - precision: 0.5047 - recall: 0.2688 - auc: 0.7124 - prc: 0.3858 - val_loss: 0.5062 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 54.0000 - val_accuracy: 0.7905 - val_precision: 0.4157 - val_recall: 0.4066 - val_auc: 0.6731 - val_prc: 0.3268\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6873 - tp: 127.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 271.0000 - accuracy: 0.7979 - precision: 0.4792 - recall: 0.3191 - auc: 0.7114 - prc: 0.3976 - val_loss: 0.4593 - val_tp: 13.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 78.0000 - val_accuracy: 0.8300 - val_precision: 0.6190 - val_recall: 0.1429 - val_auc: 0.6804 - val_prc: 0.3640\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6876 - tp: 113.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 285.0000 - accuracy: 0.8029 - precision: 0.4978 - recall: 0.2839 - auc: 0.7095 - prc: 0.3784 - val_loss: 0.4690 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 73.0000 - val_accuracy: 0.8221 - val_precision: 0.5143 - val_recall: 0.1978 - val_auc: 0.6786 - val_prc: 0.3626\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6861 - tp: 115.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 283.0000 - accuracy: 0.8039 - precision: 0.5022 - recall: 0.2889 - auc: 0.7115 - prc: 0.3928 - val_loss: 0.4914 - val_tp: 30.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 61.0000 - val_accuracy: 0.8004 - val_precision: 0.4286 - val_recall: 0.3297 - val_auc: 0.6752 - val_prc: 0.3338\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6880 - tp: 128.0000 - fp: 160.0000 - tn: 1466.0000 - fn: 270.0000 - accuracy: 0.7875 - precision: 0.4444 - recall: 0.3216 - auc: 0.7061 - prc: 0.3695 - val_loss: 0.4782 - val_tp: 25.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 66.0000 - val_accuracy: 0.8142 - val_precision: 0.4717 - val_recall: 0.2747 - val_auc: 0.6779 - val_prc: 0.3507\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6857 - tp: 125.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 273.0000 - accuracy: 0.7950 - precision: 0.4682 - recall: 0.3141 - auc: 0.7099 - prc: 0.3723 - val_loss: 0.4746 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6784 - val_prc: 0.3550\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6908 - tp: 131.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 267.0000 - accuracy: 0.8088 - precision: 0.5219 - recall: 0.3291 - auc: 0.7007 - prc: 0.3844 - val_loss: 0.4774 - val_tp: 24.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 67.0000 - val_accuracy: 0.8123 - val_precision: 0.4615 - val_recall: 0.2637 - val_auc: 0.6792 - val_prc: 0.3518\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6864 - tp: 116.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 282.0000 - accuracy: 0.8048 - precision: 0.5066 - recall: 0.2915 - auc: 0.7100 - prc: 0.3940 - val_loss: 0.4803 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6791 - val_prc: 0.3520\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6838 - tp: 128.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 270.0000 - accuracy: 0.8004 - precision: 0.4885 - recall: 0.3216 - auc: 0.7112 - prc: 0.3661 - val_loss: 0.4560 - val_tp: 13.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 78.0000 - val_accuracy: 0.8320 - val_precision: 0.6500 - val_recall: 0.1429 - val_auc: 0.6816 - val_prc: 0.3822\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6861 - tp: 128.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 270.0000 - accuracy: 0.7969 - precision: 0.4758 - recall: 0.3216 - auc: 0.7052 - prc: 0.3760 - val_loss: 0.4705 - val_tp: 23.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 68.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2527 - val_auc: 0.6806 - val_prc: 0.3654\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6839 - tp: 125.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 273.0000 - accuracy: 0.7974 - precision: 0.4771 - recall: 0.3141 - auc: 0.7113 - prc: 0.3819 - val_loss: 0.4929 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6776 - val_prc: 0.3370\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6836 - tp: 110.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 288.0000 - accuracy: 0.7979 - precision: 0.4762 - recall: 0.2764 - auc: 0.7126 - prc: 0.3833 - val_loss: 0.5664 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6631 - val_prc: 0.2927\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6871 - tp: 132.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 266.0000 - accuracy: 0.7925 - precision: 0.4615 - recall: 0.3317 - auc: 0.7051 - prc: 0.3759 - val_loss: 0.4946 - val_tp: 35.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 56.0000 - val_accuracy: 0.8043 - val_precision: 0.4487 - val_recall: 0.3846 - val_auc: 0.6780 - val_prc: 0.3413\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6841 - tp: 123.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 275.0000 - accuracy: 0.7964 - precision: 0.4731 - recall: 0.3090 - auc: 0.7106 - prc: 0.3900 - val_loss: 0.4925 - val_tp: 34.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 57.0000 - val_accuracy: 0.8043 - val_precision: 0.4474 - val_recall: 0.3736 - val_auc: 0.6782 - val_prc: 0.3413\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6826 - tp: 116.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 282.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2915 - auc: 0.7139 - prc: 0.3946 - val_loss: 0.5108 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6761 - val_prc: 0.3321\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6843 - tp: 130.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 268.0000 - accuracy: 0.7910 - precision: 0.4561 - recall: 0.3266 - auc: 0.7088 - prc: 0.3814 - val_loss: 0.4928 - val_tp: 34.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 57.0000 - val_accuracy: 0.8043 - val_precision: 0.4474 - val_recall: 0.3736 - val_auc: 0.6787 - val_prc: 0.3439\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6891 - tp: 116.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 282.0000 - accuracy: 0.7935 - precision: 0.4603 - recall: 0.2915 - auc: 0.7034 - prc: 0.3865 - val_loss: 0.4798 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6818 - val_prc: 0.3610\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6798 - tp: 134.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 264.0000 - accuracy: 0.8009 - precision: 0.4908 - recall: 0.3367 - auc: 0.7149 - prc: 0.3934 - val_loss: 0.4946 - val_tp: 35.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 56.0000 - val_accuracy: 0.8043 - val_precision: 0.4487 - val_recall: 0.3846 - val_auc: 0.6788 - val_prc: 0.3414\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6810 - tp: 122.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 276.0000 - accuracy: 0.8019 - precision: 0.4939 - recall: 0.3065 - auc: 0.7139 - prc: 0.3979 - val_loss: 0.4641 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6828 - val_prc: 0.3778\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6852 - tp: 124.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 274.0000 - accuracy: 0.8024 - precision: 0.4960 - recall: 0.3116 - auc: 0.7070 - prc: 0.3786 - val_loss: 0.4880 - val_tp: 33.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 58.0000 - val_accuracy: 0.8063 - val_precision: 0.4521 - val_recall: 0.3626 - val_auc: 0.6811 - val_prc: 0.3629\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6840 - tp: 129.0000 - fp: 151.0000 - tn: 1475.0000 - fn: 269.0000 - accuracy: 0.7925 - precision: 0.4607 - recall: 0.3241 - auc: 0.7103 - prc: 0.3820 - val_loss: 0.4557 - val_tp: 14.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 77.0000 - val_accuracy: 0.8261 - val_precision: 0.5600 - val_recall: 0.1538 - val_auc: 0.6831 - val_prc: 0.3839\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6826 - tp: 124.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 274.0000 - accuracy: 0.8004 - precision: 0.4882 - recall: 0.3116 - auc: 0.7116 - prc: 0.3882 - val_loss: 0.4960 - val_tp: 35.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 56.0000 - val_accuracy: 0.7964 - val_precision: 0.4268 - val_recall: 0.3846 - val_auc: 0.6795 - val_prc: 0.3516\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6816 - tp: 123.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 275.0000 - accuracy: 0.7959 - precision: 0.4713 - recall: 0.3090 - auc: 0.7123 - prc: 0.3917 - val_loss: 0.5015 - val_tp: 36.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 55.0000 - val_accuracy: 0.7885 - val_precision: 0.4091 - val_recall: 0.3956 - val_auc: 0.6792 - val_prc: 0.3440\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6790 - tp: 122.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 276.0000 - accuracy: 0.7989 - precision: 0.4822 - recall: 0.3065 - auc: 0.7158 - prc: 0.4006 - val_loss: 0.4920 - val_tp: 34.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 57.0000 - val_accuracy: 0.8024 - val_precision: 0.4416 - val_recall: 0.3736 - val_auc: 0.6801 - val_prc: 0.3526\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6807 - tp: 131.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 267.0000 - accuracy: 0.8009 - precision: 0.4906 - recall: 0.3291 - auc: 0.7128 - prc: 0.4013 - val_loss: 0.4516 - val_tp: 13.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 78.0000 - val_accuracy: 0.8320 - val_precision: 0.6500 - val_recall: 0.1429 - val_auc: 0.6834 - val_prc: 0.3843\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6843 - tp: 126.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 272.0000 - accuracy: 0.7969 - precision: 0.4755 - recall: 0.3166 - auc: 0.7085 - prc: 0.3852 - val_loss: 0.4824 - val_tp: 33.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 58.0000 - val_accuracy: 0.8123 - val_precision: 0.4714 - val_recall: 0.3626 - val_auc: 0.6815 - val_prc: 0.3766\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6817 - tp: 121.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 277.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3040 - auc: 0.7111 - prc: 0.4066 - val_loss: 0.4969 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6790 - val_prc: 0.3548\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6774 - tp: 135.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 263.0000 - accuracy: 0.7984 - precision: 0.4821 - recall: 0.3392 - auc: 0.7182 - prc: 0.3946 - val_loss: 0.5342 - val_tp: 41.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 50.0000 - val_accuracy: 0.7411 - val_precision: 0.3361 - val_recall: 0.4505 - val_auc: 0.6777 - val_prc: 0.3380\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6794 - tp: 132.0000 - fp: 153.0000 - tn: 1473.0000 - fn: 266.0000 - accuracy: 0.7930 - precision: 0.4632 - recall: 0.3317 - auc: 0.7156 - prc: 0.4072 - val_loss: 0.4853 - val_tp: 33.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 58.0000 - val_accuracy: 0.8063 - val_precision: 0.4521 - val_recall: 0.3626 - val_auc: 0.6814 - val_prc: 0.3775\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6784 - tp: 124.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 274.0000 - accuracy: 0.8004 - precision: 0.4882 - recall: 0.3116 - auc: 0.7159 - prc: 0.4030 - val_loss: 0.4631 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6841 - val_prc: 0.3762\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6793 - tp: 118.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 280.0000 - accuracy: 0.7984 - precision: 0.4797 - recall: 0.2965 - auc: 0.7132 - prc: 0.4015 - val_loss: 0.4971 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6811 - val_prc: 0.3593\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6800 - tp: 133.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 265.0000 - accuracy: 0.7930 - precision: 0.4634 - recall: 0.3342 - auc: 0.7133 - prc: 0.3940 - val_loss: 0.4661 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6832 - val_prc: 0.3772\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6798 - tp: 126.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 272.0000 - accuracy: 0.7945 - precision: 0.4667 - recall: 0.3166 - auc: 0.7120 - prc: 0.3962 - val_loss: 0.4582 - val_tp: 17.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 74.0000 - val_accuracy: 0.8281 - val_precision: 0.5667 - val_recall: 0.1868 - val_auc: 0.6851 - val_prc: 0.3882\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6789 - tp: 123.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 275.0000 - accuracy: 0.8058 - precision: 0.5104 - recall: 0.3090 - auc: 0.7143 - prc: 0.4078 - val_loss: 0.4997 - val_tp: 36.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 55.0000 - val_accuracy: 0.7964 - val_precision: 0.4286 - val_recall: 0.3956 - val_auc: 0.6816 - val_prc: 0.3638\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6771 - tp: 132.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 266.0000 - accuracy: 0.7969 - precision: 0.4765 - recall: 0.3317 - auc: 0.7163 - prc: 0.3929 - val_loss: 0.4987 - val_tp: 36.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 55.0000 - val_accuracy: 0.7925 - val_precision: 0.4186 - val_recall: 0.3956 - val_auc: 0.6801 - val_prc: 0.3560\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6774 - tp: 129.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 269.0000 - accuracy: 0.8009 - precision: 0.4905 - recall: 0.3241 - auc: 0.7163 - prc: 0.4089 - val_loss: 0.4963 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6817 - val_prc: 0.3723\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6785 - tp: 126.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 272.0000 - accuracy: 0.7989 - precision: 0.4828 - recall: 0.3166 - auc: 0.7156 - prc: 0.4244 - val_loss: 0.4915 - val_tp: 34.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 57.0000 - val_accuracy: 0.8024 - val_precision: 0.4416 - val_recall: 0.3736 - val_auc: 0.6834 - val_prc: 0.3819\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6790 - tp: 123.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 275.0000 - accuracy: 0.8053 - precision: 0.5083 - recall: 0.3090 - auc: 0.7134 - prc: 0.4125 - val_loss: 0.4842 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6849 - val_prc: 0.3847\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6792 - tp: 129.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 269.0000 - accuracy: 0.8004 - precision: 0.4886 - recall: 0.3241 - auc: 0.7114 - prc: 0.4021 - val_loss: 0.4521 - val_tp: 15.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 76.0000 - val_accuracy: 0.8340 - val_precision: 0.6522 - val_recall: 0.1648 - val_auc: 0.6845 - val_prc: 0.3876\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6776 - tp: 125.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 273.0000 - accuracy: 0.8058 - precision: 0.5102 - recall: 0.3141 - auc: 0.7147 - prc: 0.4014 - val_loss: 0.4970 - val_tp: 36.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 55.0000 - val_accuracy: 0.7964 - val_precision: 0.4286 - val_recall: 0.3956 - val_auc: 0.6826 - val_prc: 0.3816\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6770 - tp: 131.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 267.0000 - accuracy: 0.8004 - precision: 0.4888 - recall: 0.3291 - auc: 0.7156 - prc: 0.4127 - val_loss: 0.4544 - val_tp: 17.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 74.0000 - val_accuracy: 0.8320 - val_precision: 0.6071 - val_recall: 0.1868 - val_auc: 0.6838 - val_prc: 0.3903\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6760 - tp: 124.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 274.0000 - accuracy: 0.8009 - precision: 0.4901 - recall: 0.3116 - auc: 0.7192 - prc: 0.3998 - val_loss: 0.5427 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6777 - val_prc: 0.3340\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6804 - tp: 127.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 271.0000 - accuracy: 0.7969 - precision: 0.4757 - recall: 0.3191 - auc: 0.7114 - prc: 0.4019 - val_loss: 0.4870 - val_tp: 32.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 59.0000 - val_accuracy: 0.8004 - val_precision: 0.4324 - val_recall: 0.3516 - val_auc: 0.6836 - val_prc: 0.3842\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6765 - tp: 127.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 271.0000 - accuracy: 0.7964 - precision: 0.4739 - recall: 0.3191 - auc: 0.7189 - prc: 0.4029 - val_loss: 0.4716 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6823 - val_prc: 0.3786\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6745 - tp: 134.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 264.0000 - accuracy: 0.8048 - precision: 0.5057 - recall: 0.3367 - auc: 0.7181 - prc: 0.4192 - val_loss: 0.4742 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6831 - val_prc: 0.3829\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6777 - tp: 127.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 271.0000 - accuracy: 0.7989 - precision: 0.4829 - recall: 0.3191 - auc: 0.7141 - prc: 0.4105 - val_loss: 0.4753 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6833 - val_prc: 0.3800\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6780 - tp: 122.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 276.0000 - accuracy: 0.8004 - precision: 0.4880 - recall: 0.3065 - auc: 0.7150 - prc: 0.4161 - val_loss: 0.4889 - val_tp: 33.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 58.0000 - val_accuracy: 0.8004 - val_precision: 0.4342 - val_recall: 0.3626 - val_auc: 0.6832 - val_prc: 0.3855\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6752 - tp: 125.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 273.0000 - accuracy: 0.8053 - precision: 0.5081 - recall: 0.3141 - auc: 0.7172 - prc: 0.4198 - val_loss: 0.5019 - val_tp: 36.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 55.0000 - val_accuracy: 0.7925 - val_precision: 0.4186 - val_recall: 0.3956 - val_auc: 0.6828 - val_prc: 0.3845\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6755 - tp: 129.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 269.0000 - accuracy: 0.7964 - precision: 0.4743 - recall: 0.3241 - auc: 0.7165 - prc: 0.4156 - val_loss: 0.4677 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6840 - val_prc: 0.3914\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6764 - tp: 123.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 275.0000 - accuracy: 0.8039 - precision: 0.5020 - recall: 0.3090 - auc: 0.7155 - prc: 0.4184 - val_loss: 0.4970 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6833 - val_prc: 0.3858\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6802 - tp: 136.0000 - fp: 172.0000 - tn: 1454.0000 - fn: 262.0000 - accuracy: 0.7856 - precision: 0.4416 - recall: 0.3417 - auc: 0.7114 - prc: 0.3978 - val_loss: 0.4394 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 85.0000 - val_accuracy: 0.8241 - val_precision: 0.6000 - val_recall: 0.0659 - val_auc: 0.6845 - val_prc: 0.4065\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6772 - tp: 122.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 276.0000 - accuracy: 0.8063 - precision: 0.5126 - recall: 0.3065 - auc: 0.7146 - prc: 0.4256 - val_loss: 0.4855 - val_tp: 32.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 59.0000 - val_accuracy: 0.8043 - val_precision: 0.4444 - val_recall: 0.3516 - val_auc: 0.6841 - val_prc: 0.3905\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6784 - tp: 133.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 265.0000 - accuracy: 0.7964 - precision: 0.4750 - recall: 0.3342 - auc: 0.7113 - prc: 0.4049 - val_loss: 0.4745 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6840 - val_prc: 0.3822\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6753 - tp: 129.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 269.0000 - accuracy: 0.8019 - precision: 0.4943 - recall: 0.3241 - auc: 0.7167 - prc: 0.4180 - val_loss: 0.4875 - val_tp: 32.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 59.0000 - val_accuracy: 0.8004 - val_precision: 0.4324 - val_recall: 0.3516 - val_auc: 0.6845 - val_prc: 0.3918\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6735 - tp: 130.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 268.0000 - accuracy: 0.7984 - precision: 0.4815 - recall: 0.3266 - auc: 0.7200 - prc: 0.4156 - val_loss: 0.4603 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6846 - val_prc: 0.3912\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6769 - tp: 121.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 277.0000 - accuracy: 0.7969 - precision: 0.4745 - recall: 0.3040 - auc: 0.7152 - prc: 0.4016 - val_loss: 0.4832 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6833 - val_prc: 0.3840\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6757 - tp: 120.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 278.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3015 - auc: 0.7157 - prc: 0.4160 - val_loss: 0.5120 - val_tp: 37.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 54.0000 - val_accuracy: 0.7787 - val_precision: 0.3895 - val_recall: 0.4066 - val_auc: 0.6825 - val_prc: 0.3826\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6754 - tp: 131.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 267.0000 - accuracy: 0.7989 - precision: 0.4834 - recall: 0.3291 - auc: 0.7155 - prc: 0.4129 - val_loss: 0.4820 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6836 - val_prc: 0.3843\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6756 - tp: 131.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 267.0000 - accuracy: 0.7974 - precision: 0.4781 - recall: 0.3291 - auc: 0.7161 - prc: 0.4104 - val_loss: 0.4954 - val_tp: 35.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 56.0000 - val_accuracy: 0.7945 - val_precision: 0.4217 - val_recall: 0.3846 - val_auc: 0.6836 - val_prc: 0.3964\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6751 - tp: 128.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 270.0000 - accuracy: 0.7999 - precision: 0.4867 - recall: 0.3216 - auc: 0.7156 - prc: 0.4080 - val_loss: 0.4755 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6840 - val_prc: 0.3828\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6773 - tp: 119.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 279.0000 - accuracy: 0.7979 - precision: 0.4779 - recall: 0.2990 - auc: 0.7133 - prc: 0.4136 - val_loss: 0.4775 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6838 - val_prc: 0.3815\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6759 - tp: 130.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 268.0000 - accuracy: 0.7984 - precision: 0.4815 - recall: 0.3266 - auc: 0.7155 - prc: 0.4166 - val_loss: 0.4732 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6836 - val_prc: 0.3834\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6793 - tp: 129.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 269.0000 - accuracy: 0.7895 - precision: 0.4510 - recall: 0.3241 - auc: 0.7109 - prc: 0.3935 - val_loss: 0.4745 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6845 - val_prc: 0.3847\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6771 - tp: 132.0000 - fp: 160.0000 - tn: 1466.0000 - fn: 266.0000 - accuracy: 0.7895 - precision: 0.4521 - recall: 0.3317 - auc: 0.7148 - prc: 0.4082 - val_loss: 0.4760 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6835 - val_prc: 0.3833\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6735 - tp: 132.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 266.0000 - accuracy: 0.8043 - precision: 0.5038 - recall: 0.3317 - auc: 0.7177 - prc: 0.4206 - val_loss: 0.4784 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6835 - val_prc: 0.3832\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6781 - tp: 126.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 272.0000 - accuracy: 0.7964 - precision: 0.4737 - recall: 0.3166 - auc: 0.7113 - prc: 0.4167 - val_loss: 0.4548 - val_tp: 18.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 73.0000 - val_accuracy: 0.8340 - val_precision: 0.6207 - val_recall: 0.1978 - val_auc: 0.6852 - val_prc: 0.4088\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6770 - tp: 132.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 266.0000 - accuracy: 0.7974 - precision: 0.4783 - recall: 0.3317 - auc: 0.7133 - prc: 0.4102 - val_loss: 0.4801 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6840 - val_prc: 0.3829\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6747 - tp: 131.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 267.0000 - accuracy: 0.8068 - precision: 0.5137 - recall: 0.3291 - auc: 0.7164 - prc: 0.4246 - val_loss: 0.4957 - val_tp: 35.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 56.0000 - val_accuracy: 0.7925 - val_precision: 0.4167 - val_recall: 0.3846 - val_auc: 0.6839 - val_prc: 0.3914\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6753 - tp: 134.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 264.0000 - accuracy: 0.8019 - precision: 0.4945 - recall: 0.3367 - auc: 0.7152 - prc: 0.4226 - val_loss: 0.4812 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6839 - val_prc: 0.3836\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6780 - tp: 123.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 275.0000 - accuracy: 0.7905 - precision: 0.4522 - recall: 0.3090 - auc: 0.7109 - prc: 0.4226 - val_loss: 0.4835 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6843 - val_prc: 0.3843\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6739 - tp: 120.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 278.0000 - accuracy: 0.8058 - precision: 0.5106 - recall: 0.3015 - auc: 0.7164 - prc: 0.4279 - val_loss: 0.5167 - val_tp: 38.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 53.0000 - val_accuracy: 0.7787 - val_precision: 0.3918 - val_recall: 0.4176 - val_auc: 0.6829 - val_prc: 0.3827\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6767 - tp: 134.0000 - fp: 148.0000 - tn: 1478.0000 - fn: 264.0000 - accuracy: 0.7964 - precision: 0.4752 - recall: 0.3367 - auc: 0.7137 - prc: 0.4143 - val_loss: 0.4929 - val_tp: 33.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 58.0000 - val_accuracy: 0.7945 - val_precision: 0.4177 - val_recall: 0.3626 - val_auc: 0.6840 - val_prc: 0.3860\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6727 - tp: 129.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 269.0000 - accuracy: 0.7999 - precision: 0.4868 - recall: 0.3241 - auc: 0.7187 - prc: 0.4233 - val_loss: 0.4876 - val_tp: 33.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 58.0000 - val_accuracy: 0.7984 - val_precision: 0.4286 - val_recall: 0.3626 - val_auc: 0.6830 - val_prc: 0.3831\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6734 - tp: 123.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 275.0000 - accuracy: 0.8004 - precision: 0.4881 - recall: 0.3090 - auc: 0.7171 - prc: 0.4209 - val_loss: 0.5102 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6841 - val_prc: 0.3985\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6743 - tp: 127.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 271.0000 - accuracy: 0.8004 - precision: 0.4885 - recall: 0.3191 - auc: 0.7167 - prc: 0.4226 - val_loss: 0.5007 - val_tp: 36.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 55.0000 - val_accuracy: 0.7905 - val_precision: 0.4138 - val_recall: 0.3956 - val_auc: 0.6840 - val_prc: 0.3945\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6729 - tp: 130.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 268.0000 - accuracy: 0.7979 - precision: 0.4797 - recall: 0.3266 - auc: 0.7195 - prc: 0.4272 - val_loss: 0.4720 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6839 - val_prc: 0.3927\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6759 - tp: 128.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 270.0000 - accuracy: 0.7979 - precision: 0.4794 - recall: 0.3216 - auc: 0.7144 - prc: 0.4099 - val_loss: 0.4787 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6841 - val_prc: 0.3948\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6723 - tp: 128.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 270.0000 - accuracy: 0.8043 - precision: 0.5039 - recall: 0.3216 - auc: 0.7186 - prc: 0.4229 - val_loss: 0.5244 - val_tp: 38.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 53.0000 - val_accuracy: 0.7589 - val_precision: 0.3551 - val_recall: 0.4176 - val_auc: 0.6832 - val_prc: 0.3821\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6763 - tp: 135.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 263.0000 - accuracy: 0.7974 - precision: 0.4787 - recall: 0.3392 - auc: 0.7147 - prc: 0.4149 - val_loss: 0.5151 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6831 - val_prc: 0.3827\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6741 - tp: 130.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 268.0000 - accuracy: 0.7999 - precision: 0.4869 - recall: 0.3266 - auc: 0.7150 - prc: 0.4134 - val_loss: 0.4617 - val_tp: 23.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.5476 - val_recall: 0.2527 - val_auc: 0.6846 - val_prc: 0.4091\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6755 - tp: 120.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 278.0000 - accuracy: 0.7979 - precision: 0.4781 - recall: 0.3015 - auc: 0.7154 - prc: 0.4162 - val_loss: 0.4581 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6853 - val_prc: 0.4090\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6732 - tp: 134.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 264.0000 - accuracy: 0.8048 - precision: 0.5057 - recall: 0.3367 - auc: 0.7166 - prc: 0.4244 - val_loss: 0.5011 - val_tp: 35.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 56.0000 - val_accuracy: 0.7866 - val_precision: 0.4023 - val_recall: 0.3846 - val_auc: 0.6839 - val_prc: 0.3915\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6777 - tp: 122.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 276.0000 - accuracy: 0.7999 - precision: 0.4861 - recall: 0.3065 - auc: 0.7103 - prc: 0.4233 - val_loss: 0.5007 - val_tp: 35.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 56.0000 - val_accuracy: 0.7905 - val_precision: 0.4118 - val_recall: 0.3846 - val_auc: 0.6842 - val_prc: 0.3899\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6778 - tp: 130.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 268.0000 - accuracy: 0.7950 - precision: 0.4693 - recall: 0.3266 - auc: 0.7130 - prc: 0.4084 - val_loss: 0.5439 - val_tp: 44.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 47.0000 - val_accuracy: 0.7490 - val_precision: 0.3548 - val_recall: 0.4835 - val_auc: 0.6830 - val_prc: 0.3762\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6775 - tp: 133.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 265.0000 - accuracy: 0.7955 - precision: 0.4716 - recall: 0.3342 - auc: 0.7132 - prc: 0.4194 - val_loss: 0.4706 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6853 - val_prc: 0.4006\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6735 - tp: 122.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 276.0000 - accuracy: 0.7994 - precision: 0.4841 - recall: 0.3065 - auc: 0.7167 - prc: 0.4256 - val_loss: 0.4704 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6848 - val_prc: 0.4013\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6721 - tp: 129.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 269.0000 - accuracy: 0.8048 - precision: 0.5059 - recall: 0.3241 - auc: 0.7187 - prc: 0.4310 - val_loss: 0.4927 - val_tp: 34.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 57.0000 - val_accuracy: 0.7964 - val_precision: 0.4250 - val_recall: 0.3736 - val_auc: 0.6838 - val_prc: 0.3850\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6723 - tp: 127.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 271.0000 - accuracy: 0.8019 - precision: 0.4942 - recall: 0.3191 - auc: 0.7192 - prc: 0.4262 - val_loss: 0.4720 - val_tp: 28.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 63.0000 - val_accuracy: 0.8142 - val_precision: 0.4746 - val_recall: 0.3077 - val_auc: 0.6844 - val_prc: 0.3999\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6719 - tp: 125.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 273.0000 - accuracy: 0.8024 - precision: 0.4960 - recall: 0.3141 - auc: 0.7196 - prc: 0.4192 - val_loss: 0.4968 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6840 - val_prc: 0.3869\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6722 - tp: 133.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 265.0000 - accuracy: 0.7974 - precision: 0.4784 - recall: 0.3342 - auc: 0.7175 - prc: 0.4266 - val_loss: 0.4853 - val_tp: 32.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 59.0000 - val_accuracy: 0.7945 - val_precision: 0.4156 - val_recall: 0.3516 - val_auc: 0.6844 - val_prc: 0.3894\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6720 - tp: 139.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 259.0000 - accuracy: 0.7984 - precision: 0.4826 - recall: 0.3492 - auc: 0.7195 - prc: 0.4227 - val_loss: 0.4615 - val_tp: 23.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.5476 - val_recall: 0.2527 - val_auc: 0.6855 - val_prc: 0.4090\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6733 - tp: 123.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 275.0000 - accuracy: 0.7989 - precision: 0.4824 - recall: 0.3090 - auc: 0.7184 - prc: 0.4189 - val_loss: 0.4957 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6831 - val_prc: 0.3874\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6708 - tp: 141.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 257.0000 - accuracy: 0.8019 - precision: 0.4947 - recall: 0.3543 - auc: 0.7212 - prc: 0.4241 - val_loss: 0.4529 - val_tp: 19.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 72.0000 - val_accuracy: 0.8300 - val_precision: 0.5758 - val_recall: 0.2088 - val_auc: 0.6856 - val_prc: 0.4095\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6735 - tp: 126.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 272.0000 - accuracy: 0.8019 - precision: 0.4941 - recall: 0.3166 - auc: 0.7171 - prc: 0.4210 - val_loss: 0.5289 - val_tp: 40.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 51.0000 - val_accuracy: 0.7569 - val_precision: 0.3571 - val_recall: 0.4396 - val_auc: 0.6833 - val_prc: 0.3885\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6730 - tp: 141.0000 - fp: 156.0000 - tn: 1470.0000 - fn: 257.0000 - accuracy: 0.7959 - precision: 0.4747 - recall: 0.3543 - auc: 0.7169 - prc: 0.4297 - val_loss: 0.4592 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6856 - val_prc: 0.4092\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6795 - tp: 129.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 269.0000 - accuracy: 0.7905 - precision: 0.4542 - recall: 0.3241 - auc: 0.7074 - prc: 0.4146 - val_loss: 0.4681 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6837 - val_prc: 0.4077\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6762 - tp: 126.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 272.0000 - accuracy: 0.8014 - precision: 0.4922 - recall: 0.3166 - auc: 0.7141 - prc: 0.4198 - val_loss: 0.4811 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6845 - val_prc: 0.3991\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6718 - tp: 135.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 263.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3392 - auc: 0.7177 - prc: 0.4340 - val_loss: 0.4772 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6846 - val_prc: 0.4103\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6712 - tp: 126.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 272.0000 - accuracy: 0.7989 - precision: 0.4828 - recall: 0.3166 - auc: 0.7185 - prc: 0.4318 - val_loss: 0.5040 - val_tp: 37.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 54.0000 - val_accuracy: 0.7846 - val_precision: 0.4022 - val_recall: 0.4066 - val_auc: 0.6836 - val_prc: 0.3901\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6719 - tp: 132.0000 - fp: 152.0000 - tn: 1474.0000 - fn: 266.0000 - accuracy: 0.7935 - precision: 0.4648 - recall: 0.3317 - auc: 0.7183 - prc: 0.4217 - val_loss: 0.4583 - val_tp: 22.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 69.0000 - val_accuracy: 0.8281 - val_precision: 0.5500 - val_recall: 0.2418 - val_auc: 0.6841 - val_prc: 0.4091\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6711 - tp: 132.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 266.0000 - accuracy: 0.8039 - precision: 0.5019 - recall: 0.3317 - auc: 0.7184 - prc: 0.4361 - val_loss: 0.4563 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6858 - val_prc: 0.4093\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6777 - tp: 131.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 267.0000 - accuracy: 0.7979 - precision: 0.4799 - recall: 0.3291 - auc: 0.7084 - prc: 0.4245 - val_loss: 0.4718 - val_tp: 28.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 63.0000 - val_accuracy: 0.8142 - val_precision: 0.4746 - val_recall: 0.3077 - val_auc: 0.6853 - val_prc: 0.4099\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6691 - tp: 127.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 271.0000 - accuracy: 0.7964 - precision: 0.4739 - recall: 0.3191 - auc: 0.7204 - prc: 0.4335 - val_loss: 0.4967 - val_tp: 34.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 57.0000 - val_accuracy: 0.7885 - val_precision: 0.4048 - val_recall: 0.3736 - val_auc: 0.6853 - val_prc: 0.3856\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6709 - tp: 129.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 269.0000 - accuracy: 0.8004 - precision: 0.4886 - recall: 0.3241 - auc: 0.7194 - prc: 0.4325 - val_loss: 0.5089 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6844 - val_prc: 0.3914\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6725 - tp: 127.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 271.0000 - accuracy: 0.7935 - precision: 0.4635 - recall: 0.3191 - auc: 0.7182 - prc: 0.4306 - val_loss: 0.4968 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6843 - val_prc: 0.3862\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6712 - tp: 133.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 265.0000 - accuracy: 0.8019 - precision: 0.4944 - recall: 0.3342 - auc: 0.7175 - prc: 0.4288 - val_loss: 0.4719 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6848 - val_prc: 0.4100\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6741 - tp: 136.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 262.0000 - accuracy: 0.7984 - precision: 0.4823 - recall: 0.3417 - auc: 0.7134 - prc: 0.4315 - val_loss: 0.5160 - val_tp: 37.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 54.0000 - val_accuracy: 0.7727 - val_precision: 0.3776 - val_recall: 0.4066 - val_auc: 0.6841 - val_prc: 0.3949\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6729 - tp: 137.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 261.0000 - accuracy: 0.8024 - precision: 0.4964 - recall: 0.3442 - auc: 0.7167 - prc: 0.4279 - val_loss: 0.4875 - val_tp: 33.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 58.0000 - val_accuracy: 0.7964 - val_precision: 0.4231 - val_recall: 0.3626 - val_auc: 0.6847 - val_prc: 0.4002\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6703 - tp: 130.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 268.0000 - accuracy: 0.7964 - precision: 0.4745 - recall: 0.3266 - auc: 0.7209 - prc: 0.4349 - val_loss: 0.4807 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6851 - val_prc: 0.4119\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6711 - tp: 137.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 261.0000 - accuracy: 0.8004 - precision: 0.4893 - recall: 0.3442 - auc: 0.7198 - prc: 0.4291 - val_loss: 0.4679 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6861 - val_prc: 0.4102\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6735 - tp: 132.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 266.0000 - accuracy: 0.7979 - precision: 0.4800 - recall: 0.3317 - auc: 0.7154 - prc: 0.4172 - val_loss: 0.4545 - val_tp: 21.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 70.0000 - val_accuracy: 0.8320 - val_precision: 0.5833 - val_recall: 0.2308 - val_auc: 0.6860 - val_prc: 0.4100\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6731 - tp: 127.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 271.0000 - accuracy: 0.8043 - precision: 0.5040 - recall: 0.3191 - auc: 0.7153 - prc: 0.4353 - val_loss: 0.4979 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6846 - val_prc: 0.3851\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6714 - tp: 130.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 268.0000 - accuracy: 0.8009 - precision: 0.4906 - recall: 0.3266 - auc: 0.7178 - prc: 0.4349 - val_loss: 0.5046 - val_tp: 36.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 55.0000 - val_accuracy: 0.7826 - val_precision: 0.3956 - val_recall: 0.3956 - val_auc: 0.6844 - val_prc: 0.3881\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6704 - tp: 130.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 268.0000 - accuracy: 0.7974 - precision: 0.4779 - recall: 0.3266 - auc: 0.7193 - prc: 0.4362 - val_loss: 0.4602 - val_tp: 24.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 67.0000 - val_accuracy: 0.8300 - val_precision: 0.5581 - val_recall: 0.2637 - val_auc: 0.6859 - val_prc: 0.4102\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6720 - tp: 136.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 262.0000 - accuracy: 0.8048 - precision: 0.5056 - recall: 0.3417 - auc: 0.7175 - prc: 0.4229 - val_loss: 0.5045 - val_tp: 36.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 55.0000 - val_accuracy: 0.7806 - val_precision: 0.3913 - val_recall: 0.3956 - val_auc: 0.6843 - val_prc: 0.3894\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6705 - tp: 131.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 267.0000 - accuracy: 0.7955 - precision: 0.4712 - recall: 0.3291 - auc: 0.7196 - prc: 0.4305 - val_loss: 0.5017 - val_tp: 34.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 57.0000 - val_accuracy: 0.7806 - val_precision: 0.3864 - val_recall: 0.3736 - val_auc: 0.6840 - val_prc: 0.3850\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6704 - tp: 131.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 267.0000 - accuracy: 0.8024 - precision: 0.4962 - recall: 0.3291 - auc: 0.7186 - prc: 0.4354 - val_loss: 0.4800 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6852 - val_prc: 0.4108\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6709 - tp: 133.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 265.0000 - accuracy: 0.8019 - precision: 0.4944 - recall: 0.3342 - auc: 0.7178 - prc: 0.4426 - val_loss: 0.5133 - val_tp: 37.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 54.0000 - val_accuracy: 0.7747 - val_precision: 0.3814 - val_recall: 0.4066 - val_auc: 0.6845 - val_prc: 0.3910\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6722 - tp: 137.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 261.0000 - accuracy: 0.7945 - precision: 0.4692 - recall: 0.3442 - auc: 0.7167 - prc: 0.4282 - val_loss: 0.5218 - val_tp: 38.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 53.0000 - val_accuracy: 0.7628 - val_precision: 0.3619 - val_recall: 0.4176 - val_auc: 0.6843 - val_prc: 0.3957\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6728 - tp: 133.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 265.0000 - accuracy: 0.7989 - precision: 0.4836 - recall: 0.3342 - auc: 0.7168 - prc: 0.4257 - val_loss: 0.4561 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6861 - val_prc: 0.4117\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6736 - tp: 133.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 265.0000 - accuracy: 0.8009 - precision: 0.4908 - recall: 0.3342 - auc: 0.7171 - prc: 0.4229 - val_loss: 0.4886 - val_tp: 33.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 58.0000 - val_accuracy: 0.7945 - val_precision: 0.4177 - val_recall: 0.3626 - val_auc: 0.6861 - val_prc: 0.4026\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6707 - tp: 135.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 263.0000 - accuracy: 0.8004 - precision: 0.4891 - recall: 0.3392 - auc: 0.7216 - prc: 0.4203 - val_loss: 0.4973 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6845 - val_prc: 0.3906\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6713 - tp: 131.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 267.0000 - accuracy: 0.8048 - precision: 0.5058 - recall: 0.3291 - auc: 0.7173 - prc: 0.4390 - val_loss: 0.4939 - val_tp: 34.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 57.0000 - val_accuracy: 0.7885 - val_precision: 0.4048 - val_recall: 0.3736 - val_auc: 0.6848 - val_prc: 0.3954\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6689 - tp: 137.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 261.0000 - accuracy: 0.8024 - precision: 0.4964 - recall: 0.3442 - auc: 0.7212 - prc: 0.4325 - val_loss: 0.4854 - val_tp: 32.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 59.0000 - val_accuracy: 0.7945 - val_precision: 0.4156 - val_recall: 0.3516 - val_auc: 0.6864 - val_prc: 0.4027\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6717 - tp: 131.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 267.0000 - accuracy: 0.7984 - precision: 0.4816 - recall: 0.3291 - auc: 0.7173 - prc: 0.4320 - val_loss: 0.4850 - val_tp: 32.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 59.0000 - val_accuracy: 0.7964 - val_precision: 0.4211 - val_recall: 0.3516 - val_auc: 0.6859 - val_prc: 0.4104\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6725 - tp: 134.0000 - fp: 150.0000 - tn: 1476.0000 - fn: 264.0000 - accuracy: 0.7955 - precision: 0.4718 - recall: 0.3367 - auc: 0.7154 - prc: 0.4390 - val_loss: 0.4948 - val_tp: 34.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 57.0000 - val_accuracy: 0.7885 - val_precision: 0.4048 - val_recall: 0.3736 - val_auc: 0.6856 - val_prc: 0.4022\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6712 - tp: 128.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 270.0000 - accuracy: 0.8058 - precision: 0.5100 - recall: 0.3216 - auc: 0.7176 - prc: 0.4390 - val_loss: 0.4774 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6865 - val_prc: 0.4123\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6709 - tp: 139.0000 - fp: 167.0000 - tn: 1459.0000 - fn: 259.0000 - accuracy: 0.7895 - precision: 0.4542 - recall: 0.3492 - auc: 0.7202 - prc: 0.4283 - val_loss: 0.4630 - val_tp: 26.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 65.0000 - val_accuracy: 0.8281 - val_precision: 0.5417 - val_recall: 0.2857 - val_auc: 0.6863 - val_prc: 0.4124\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6700 - tp: 132.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 266.0000 - accuracy: 0.8024 - precision: 0.4962 - recall: 0.3317 - auc: 0.7195 - prc: 0.4309 - val_loss: 0.5020 - val_tp: 34.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 57.0000 - val_accuracy: 0.7806 - val_precision: 0.3864 - val_recall: 0.3736 - val_auc: 0.6846 - val_prc: 0.3910\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6744 - tp: 143.0000 - fp: 167.0000 - tn: 1459.0000 - fn: 255.0000 - accuracy: 0.7915 - precision: 0.4613 - recall: 0.3593 - auc: 0.7159 - prc: 0.4243 - val_loss: 0.4684 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6865 - val_prc: 0.4127\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6774 - tp: 129.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 269.0000 - accuracy: 0.7910 - precision: 0.4558 - recall: 0.3241 - auc: 0.7102 - prc: 0.4210 - val_loss: 0.5202 - val_tp: 38.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 53.0000 - val_accuracy: 0.7648 - val_precision: 0.3654 - val_recall: 0.4176 - val_auc: 0.6849 - val_prc: 0.3932\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6709 - tp: 133.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 265.0000 - accuracy: 0.7984 - precision: 0.4819 - recall: 0.3342 - auc: 0.7169 - prc: 0.4448 - val_loss: 0.4891 - val_tp: 33.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 58.0000 - val_accuracy: 0.7905 - val_precision: 0.4074 - val_recall: 0.3626 - val_auc: 0.6857 - val_prc: 0.4129\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6711 - tp: 134.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 264.0000 - accuracy: 0.7999 - precision: 0.4873 - recall: 0.3367 - auc: 0.7195 - prc: 0.4294 - val_loss: 0.4631 - val_tp: 26.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 65.0000 - val_accuracy: 0.8281 - val_precision: 0.5417 - val_recall: 0.2857 - val_auc: 0.6867 - val_prc: 0.4130\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6742 - tp: 126.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 272.0000 - accuracy: 0.7994 - precision: 0.4846 - recall: 0.3166 - auc: 0.7135 - prc: 0.4272 - val_loss: 0.4736 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6856 - val_prc: 0.4129\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6695 - tp: 128.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 270.0000 - accuracy: 0.8093 - precision: 0.5246 - recall: 0.3216 - auc: 0.7197 - prc: 0.4372 - val_loss: 0.5244 - val_tp: 38.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 53.0000 - val_accuracy: 0.7589 - val_precision: 0.3551 - val_recall: 0.4176 - val_auc: 0.6853 - val_prc: 0.3948\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6698 - tp: 140.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 258.0000 - accuracy: 0.7950 - precision: 0.4714 - recall: 0.3518 - auc: 0.7221 - prc: 0.4322 - val_loss: 0.4471 - val_tp: 17.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 74.0000 - val_accuracy: 0.8379 - val_precision: 0.6800 - val_recall: 0.1868 - val_auc: 0.6872 - val_prc: 0.4133\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6730 - tp: 120.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 278.0000 - accuracy: 0.8083 - precision: 0.5217 - recall: 0.3015 - auc: 0.7162 - prc: 0.4331 - val_loss: 0.4942 - val_tp: 34.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 57.0000 - val_accuracy: 0.7846 - val_precision: 0.3953 - val_recall: 0.3736 - val_auc: 0.6874 - val_prc: 0.4025\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6725 - tp: 141.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 257.0000 - accuracy: 0.7950 - precision: 0.4716 - recall: 0.3543 - auc: 0.7177 - prc: 0.4240 - val_loss: 0.4853 - val_tp: 33.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 58.0000 - val_accuracy: 0.7984 - val_precision: 0.4286 - val_recall: 0.3626 - val_auc: 0.6873 - val_prc: 0.4114\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6699 - tp: 138.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 260.0000 - accuracy: 0.8058 - precision: 0.5092 - recall: 0.3467 - auc: 0.7190 - prc: 0.4350 - val_loss: 0.5260 - val_tp: 39.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 52.0000 - val_accuracy: 0.7589 - val_precision: 0.3578 - val_recall: 0.4286 - val_auc: 0.6857 - val_prc: 0.3926\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6697 - tp: 138.0000 - fp: 156.0000 - tn: 1470.0000 - fn: 260.0000 - accuracy: 0.7945 - precision: 0.4694 - recall: 0.3467 - auc: 0.7198 - prc: 0.4359 - val_loss: 0.4470 - val_tp: 17.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 74.0000 - val_accuracy: 0.8399 - val_precision: 0.7083 - val_recall: 0.1868 - val_auc: 0.6882 - val_prc: 0.4135\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6703 - tp: 128.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 270.0000 - accuracy: 0.8039 - precision: 0.5020 - recall: 0.3216 - auc: 0.7181 - prc: 0.4348 - val_loss: 0.4704 - val_tp: 29.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 62.0000 - val_accuracy: 0.8162 - val_precision: 0.4833 - val_recall: 0.3187 - val_auc: 0.6881 - val_prc: 0.4130\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6690 - tp: 127.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 271.0000 - accuracy: 0.8053 - precision: 0.5080 - recall: 0.3191 - auc: 0.7195 - prc: 0.4412 - val_loss: 0.4902 - val_tp: 34.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 57.0000 - val_accuracy: 0.7925 - val_precision: 0.4146 - val_recall: 0.3736 - val_auc: 0.6881 - val_prc: 0.4008\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6707 - tp: 140.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 258.0000 - accuracy: 0.7945 - precision: 0.4698 - recall: 0.3518 - auc: 0.7189 - prc: 0.4293 - val_loss: 0.5041 - val_tp: 36.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 55.0000 - val_accuracy: 0.7806 - val_precision: 0.3913 - val_recall: 0.3956 - val_auc: 0.6870 - val_prc: 0.3882\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6694 - tp: 125.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 273.0000 - accuracy: 0.8068 - precision: 0.5144 - recall: 0.3141 - auc: 0.7189 - prc: 0.4348 - val_loss: 0.5096 - val_tp: 36.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 55.0000 - val_accuracy: 0.7787 - val_precision: 0.3871 - val_recall: 0.3956 - val_auc: 0.6876 - val_prc: 0.3887\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6692 - tp: 135.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 263.0000 - accuracy: 0.8009 - precision: 0.4909 - recall: 0.3392 - auc: 0.7212 - prc: 0.4336 - val_loss: 0.4763 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6876 - val_prc: 0.4102\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6709 - tp: 151.0000 - fp: 182.0000 - tn: 1444.0000 - fn: 247.0000 - accuracy: 0.7880 - precision: 0.4535 - recall: 0.3794 - auc: 0.7186 - prc: 0.4235 - val_loss: 0.4568 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6879 - val_prc: 0.4101\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6698 - tp: 129.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 269.0000 - accuracy: 0.7989 - precision: 0.4831 - recall: 0.3241 - auc: 0.7190 - prc: 0.4281 - val_loss: 0.4759 - val_tp: 29.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 62.0000 - val_accuracy: 0.7984 - val_precision: 0.4203 - val_recall: 0.3187 - val_auc: 0.6877 - val_prc: 0.4105\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6687 - tp: 131.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 267.0000 - accuracy: 0.7984 - precision: 0.4816 - recall: 0.3291 - auc: 0.7206 - prc: 0.4331 - val_loss: 0.4836 - val_tp: 33.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 58.0000 - val_accuracy: 0.7984 - val_precision: 0.4286 - val_recall: 0.3626 - val_auc: 0.6880 - val_prc: 0.4019\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6700 - tp: 137.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 261.0000 - accuracy: 0.7989 - precision: 0.4841 - recall: 0.3442 - auc: 0.7197 - prc: 0.4269 - val_loss: 0.4979 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6874 - val_prc: 0.3946\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6690 - tp: 129.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 269.0000 - accuracy: 0.7935 - precision: 0.4640 - recall: 0.3241 - auc: 0.7202 - prc: 0.4271 - val_loss: 0.4930 - val_tp: 34.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 57.0000 - val_accuracy: 0.7846 - val_precision: 0.3953 - val_recall: 0.3736 - val_auc: 0.6874 - val_prc: 0.4007\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6688 - tp: 138.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 260.0000 - accuracy: 0.7999 - precision: 0.4876 - recall: 0.3467 - auc: 0.7199 - prc: 0.4322 - val_loss: 0.4674 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6881 - val_prc: 0.4106\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6678 - tp: 137.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 261.0000 - accuracy: 0.8024 - precision: 0.4964 - recall: 0.3442 - auc: 0.7206 - prc: 0.4431 - val_loss: 0.4935 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6871 - val_prc: 0.4025\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6706 - tp: 137.0000 - fp: 153.0000 - tn: 1473.0000 - fn: 261.0000 - accuracy: 0.7955 - precision: 0.4724 - recall: 0.3442 - auc: 0.7189 - prc: 0.4311 - val_loss: 0.4653 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6858 - val_prc: 0.4106\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6695 - tp: 131.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 267.0000 - accuracy: 0.8078 - precision: 0.5178 - recall: 0.3291 - auc: 0.7212 - prc: 0.4310 - val_loss: 0.5006 - val_tp: 34.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 57.0000 - val_accuracy: 0.7767 - val_precision: 0.3778 - val_recall: 0.3736 - val_auc: 0.6872 - val_prc: 0.3898\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6685 - tp: 131.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 267.0000 - accuracy: 0.8019 - precision: 0.4943 - recall: 0.3291 - auc: 0.7212 - prc: 0.4397 - val_loss: 0.4738 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6865 - val_prc: 0.4098\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6678 - tp: 132.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 266.0000 - accuracy: 0.8014 - precision: 0.4925 - recall: 0.3317 - auc: 0.7220 - prc: 0.4331 - val_loss: 0.4681 - val_tp: 28.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 63.0000 - val_accuracy: 0.8083 - val_precision: 0.4516 - val_recall: 0.3077 - val_auc: 0.6854 - val_prc: 0.4089\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6696 - tp: 131.0000 - fp: 148.0000 - tn: 1478.0000 - fn: 267.0000 - accuracy: 0.7950 - precision: 0.4695 - recall: 0.3291 - auc: 0.7210 - prc: 0.4238 - val_loss: 0.5300 - val_tp: 40.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 51.0000 - val_accuracy: 0.7569 - val_precision: 0.3571 - val_recall: 0.4396 - val_auc: 0.6859 - val_prc: 0.3933\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6698 - tp: 131.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 267.0000 - accuracy: 0.7945 - precision: 0.4679 - recall: 0.3291 - auc: 0.7200 - prc: 0.4291 - val_loss: 0.4751 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6857 - val_prc: 0.4104\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6713 - tp: 133.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 265.0000 - accuracy: 0.7925 - precision: 0.4618 - recall: 0.3342 - auc: 0.7198 - prc: 0.4228 - val_loss: 0.4720 - val_tp: 29.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 62.0000 - val_accuracy: 0.8083 - val_precision: 0.4531 - val_recall: 0.3187 - val_auc: 0.6850 - val_prc: 0.4098\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6684 - tp: 137.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 261.0000 - accuracy: 0.8019 - precision: 0.4946 - recall: 0.3442 - auc: 0.7210 - prc: 0.4325 - val_loss: 0.4880 - val_tp: 34.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 57.0000 - val_accuracy: 0.7964 - val_precision: 0.4250 - val_recall: 0.3736 - val_auc: 0.6841 - val_prc: 0.3996\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6708 - tp: 140.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 258.0000 - accuracy: 0.8103 - precision: 0.5263 - recall: 0.3518 - auc: 0.7149 - prc: 0.4340 - val_loss: 0.4691 - val_tp: 27.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 64.0000 - val_accuracy: 0.8063 - val_precision: 0.4426 - val_recall: 0.2967 - val_auc: 0.6846 - val_prc: 0.4086\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6719 - tp: 131.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 267.0000 - accuracy: 0.7999 - precision: 0.4870 - recall: 0.3291 - auc: 0.7160 - prc: 0.4252 - val_loss: 0.4767 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6842 - val_prc: 0.4100\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6693 - tp: 130.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 268.0000 - accuracy: 0.8029 - precision: 0.4981 - recall: 0.3266 - auc: 0.7191 - prc: 0.4384 - val_loss: 0.4810 - val_tp: 33.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 58.0000 - val_accuracy: 0.7984 - val_precision: 0.4286 - val_recall: 0.3626 - val_auc: 0.6856 - val_prc: 0.4096\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6693 - tp: 132.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 266.0000 - accuracy: 0.7964 - precision: 0.4748 - recall: 0.3317 - auc: 0.7213 - prc: 0.4355 - val_loss: 0.4762 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6854 - val_prc: 0.4099\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6700 - tp: 133.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 265.0000 - accuracy: 0.8004 - precision: 0.4890 - recall: 0.3342 - auc: 0.7197 - prc: 0.4261 - val_loss: 0.4551 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6854 - val_prc: 0.4116\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6666 - tp: 130.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 268.0000 - accuracy: 0.8029 - precision: 0.4981 - recall: 0.3266 - auc: 0.7221 - prc: 0.4355 - val_loss: 0.4607 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6840 - val_prc: 0.4089\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6664 - tp: 136.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 262.0000 - accuracy: 0.7969 - precision: 0.4772 - recall: 0.3417 - auc: 0.7217 - prc: 0.4325 - val_loss: 0.4680 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6845 - val_prc: 0.4106\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6706 - tp: 124.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 274.0000 - accuracy: 0.8019 - precision: 0.4940 - recall: 0.3116 - auc: 0.7172 - prc: 0.4317 - val_loss: 0.5113 - val_tp: 36.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 55.0000 - val_accuracy: 0.7727 - val_precision: 0.3750 - val_recall: 0.3956 - val_auc: 0.6840 - val_prc: 0.3971\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6693 - tp: 136.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 262.0000 - accuracy: 0.7984 - precision: 0.4823 - recall: 0.3417 - auc: 0.7219 - prc: 0.4280 - val_loss: 0.4878 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6861 - val_prc: 0.4008\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6682 - tp: 135.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 263.0000 - accuracy: 0.8019 - precision: 0.4945 - recall: 0.3392 - auc: 0.7225 - prc: 0.4383 - val_loss: 0.4771 - val_tp: 29.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 62.0000 - val_accuracy: 0.8004 - val_precision: 0.4265 - val_recall: 0.3187 - val_auc: 0.6852 - val_prc: 0.4097\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6704 - tp: 135.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 263.0000 - accuracy: 0.7935 - precision: 0.4655 - recall: 0.3392 - auc: 0.7173 - prc: 0.4337 - val_loss: 0.4519 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6847 - val_prc: 0.4094\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6706 - tp: 128.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 270.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3216 - auc: 0.7182 - prc: 0.4269 - val_loss: 0.5037 - val_tp: 34.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 57.0000 - val_accuracy: 0.7747 - val_precision: 0.3736 - val_recall: 0.3736 - val_auc: 0.6863 - val_prc: 0.3986\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6689 - tp: 132.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 266.0000 - accuracy: 0.7989 - precision: 0.4835 - recall: 0.3317 - auc: 0.7186 - prc: 0.4413 - val_loss: 0.4887 - val_tp: 34.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 57.0000 - val_accuracy: 0.7925 - val_precision: 0.4146 - val_recall: 0.3736 - val_auc: 0.6846 - val_prc: 0.4005\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6680 - tp: 134.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 264.0000 - accuracy: 0.8004 - precision: 0.4891 - recall: 0.3367 - auc: 0.7236 - prc: 0.4363 - val_loss: 0.5494 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6862 - val_prc: 0.4056\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6702 - tp: 142.0000 - fp: 160.0000 - tn: 1466.0000 - fn: 256.0000 - accuracy: 0.7945 - precision: 0.4702 - recall: 0.3568 - auc: 0.7201 - prc: 0.4286 - val_loss: 0.4870 - val_tp: 33.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 58.0000 - val_accuracy: 0.7945 - val_precision: 0.4177 - val_recall: 0.3626 - val_auc: 0.6853 - val_prc: 0.4105\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6677 - tp: 135.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 263.0000 - accuracy: 0.7994 - precision: 0.4856 - recall: 0.3392 - auc: 0.7217 - prc: 0.4347 - val_loss: 0.4701 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6876 - val_prc: 0.4115\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6678 - tp: 136.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 262.0000 - accuracy: 0.7984 - precision: 0.4823 - recall: 0.3417 - auc: 0.7201 - prc: 0.4367 - val_loss: 0.4482 - val_tp: 20.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 71.0000 - val_accuracy: 0.8360 - val_precision: 0.6250 - val_recall: 0.2198 - val_auc: 0.6851 - val_prc: 0.4108\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6688 - tp: 123.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 275.0000 - accuracy: 0.8029 - precision: 0.4980 - recall: 0.3090 - auc: 0.7198 - prc: 0.4343 - val_loss: 0.4775 - val_tp: 31.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 60.0000 - val_accuracy: 0.7984 - val_precision: 0.4247 - val_recall: 0.3407 - val_auc: 0.6859 - val_prc: 0.4094\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6691 - tp: 128.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 270.0000 - accuracy: 0.8058 - precision: 0.5100 - recall: 0.3216 - auc: 0.7177 - prc: 0.4402 - val_loss: 0.4632 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6841 - val_prc: 0.4081\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6663 - tp: 127.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 271.0000 - accuracy: 0.8113 - precision: 0.5336 - recall: 0.3191 - auc: 0.7208 - prc: 0.4463 - val_loss: 0.5179 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6861 - val_prc: 0.3923\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6704 - tp: 143.0000 - fp: 160.0000 - tn: 1466.0000 - fn: 255.0000 - accuracy: 0.7950 - precision: 0.4719 - recall: 0.3593 - auc: 0.7186 - prc: 0.4319 - val_loss: 0.4741 - val_tp: 31.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 60.0000 - val_accuracy: 0.8024 - val_precision: 0.4366 - val_recall: 0.3407 - val_auc: 0.6866 - val_prc: 0.4098\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6699 - tp: 129.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 269.0000 - accuracy: 0.8024 - precision: 0.4962 - recall: 0.3241 - auc: 0.7191 - prc: 0.4348 - val_loss: 0.4688 - val_tp: 26.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 65.0000 - val_accuracy: 0.8004 - val_precision: 0.4194 - val_recall: 0.2857 - val_auc: 0.6861 - val_prc: 0.4078\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6671 - tp: 145.0000 - fp: 162.0000 - tn: 1464.0000 - fn: 253.0000 - accuracy: 0.7950 - precision: 0.4723 - recall: 0.3643 - auc: 0.7205 - prc: 0.4362 - val_loss: 0.4538 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6851 - val_prc: 0.4100\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6696 - tp: 122.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 276.0000 - accuracy: 0.7984 - precision: 0.4803 - recall: 0.3065 - auc: 0.7192 - prc: 0.4382 - val_loss: 0.4876 - val_tp: 34.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 57.0000 - val_accuracy: 0.7925 - val_precision: 0.4146 - val_recall: 0.3736 - val_auc: 0.6855 - val_prc: 0.4098\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6662 - tp: 134.0000 - fp: 153.0000 - tn: 1473.0000 - fn: 264.0000 - accuracy: 0.7940 - precision: 0.4669 - recall: 0.3367 - auc: 0.7235 - prc: 0.4423 - val_loss: 0.4992 - val_tp: 35.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 56.0000 - val_accuracy: 0.7787 - val_precision: 0.3846 - val_recall: 0.3846 - val_auc: 0.6865 - val_prc: 0.4010\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6679 - tp: 135.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 263.0000 - accuracy: 0.7964 - precision: 0.4754 - recall: 0.3392 - auc: 0.7214 - prc: 0.4307 - val_loss: 0.4992 - val_tp: 34.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 57.0000 - val_accuracy: 0.7747 - val_precision: 0.3736 - val_recall: 0.3736 - val_auc: 0.6865 - val_prc: 0.3948\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6677 - tp: 135.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 263.0000 - accuracy: 0.7984 - precision: 0.4821 - recall: 0.3392 - auc: 0.7210 - prc: 0.4340 - val_loss: 0.4657 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6853 - val_prc: 0.4081\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6674 - tp: 136.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 262.0000 - accuracy: 0.7984 - precision: 0.4823 - recall: 0.3417 - auc: 0.7218 - prc: 0.4355 - val_loss: 0.4868 - val_tp: 34.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 57.0000 - val_accuracy: 0.7846 - val_precision: 0.3953 - val_recall: 0.3736 - val_auc: 0.6878 - val_prc: 0.4026\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6682 - tp: 139.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 259.0000 - accuracy: 0.8073 - precision: 0.5148 - recall: 0.3492 - auc: 0.7178 - prc: 0.4433 - val_loss: 0.5106 - val_tp: 36.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 55.0000 - val_accuracy: 0.7668 - val_precision: 0.3636 - val_recall: 0.3956 - val_auc: 0.6865 - val_prc: 0.3958\n",
      "Epoch 245/500\n",
      "100/102 [============================>.] - ETA: 0s - loss: 0.6678 - tp: 141.0000 - fp: 143.0000 - tn: 1462.0000 - fn: 254.0000 - accuracy: 0.8015 - precision: 0.4965 - recall: 0.3570 - auc: 0.7237 - prc: 0.4377Restoring model weights from the end of the best epoch: 195.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6670 - tp: 142.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 256.0000 - accuracy: 0.8009 - precision: 0.4913 - recall: 0.3568 - auc: 0.7227 - prc: 0.4367 - val_loss: 0.5380 - val_tp: 44.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 47.0000 - val_accuracy: 0.7569 - val_precision: 0.3667 - val_recall: 0.4835 - val_auc: 0.6869 - val_prc: 0.3995\n",
      "Epoch 245: early stopping\n",
      "26/26 [==============================] - 0s 537us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.9700 - tp: 44.0000 - fp: 76.0000 - tn: 1965.0000 - fn: 445.0000 - accuracy: 0.7941 - precision: 0.3667 - recall: 0.0900 - auc: 0.5076 - prc: 0.2321 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9536 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4592 - prc: 0.1782 - val_loss: 0.4757 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9388 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5079 - prc: 0.1994 - val_loss: 0.4787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9255 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5206 - prc: 0.2093 - val_loss: 0.4824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9137 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4963 - prc: 0.1941 - val_loss: 0.4869 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9039 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4863 - prc: 0.1915 - val_loss: 0.4915 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8955 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5053 - prc: 0.1973 - val_loss: 0.4967 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8886 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5314 - prc: 0.2068 - val_loss: 0.5019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8826 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4705 - prc: 0.1817 - val_loss: 0.5072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8779 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5140 - prc: 0.2037 - val_loss: 0.5120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5034 - prc: 0.1973 - val_loss: 0.5170 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8708 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5205 - prc: 0.2064 - val_loss: 0.5216 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4895 - prc: 0.1925 - val_loss: 0.5266 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5109 - prc: 0.2013 - val_loss: 0.5311 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8645 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4819 - prc: 0.1905 - val_loss: 0.5349 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8632 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4925 - prc: 0.1941 - val_loss: 0.5384 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8623 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5080 - prc: 0.1996 - val_loss: 0.5419 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8616 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4897 - prc: 0.1927 - val_loss: 0.5448 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8610 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4768 - prc: 0.1865 - val_loss: 0.5475 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8606 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.5497 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8603 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4951 - prc: 0.1943 - val_loss: 0.5516 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8600 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.5533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8598 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1965 - val_loss: 0.5551 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8598 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5566 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8595 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.5578 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8548 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5690 - prc: 0.2588 - val_loss: 0.5104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6512 - val_prc: 0.2962\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8477 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5839 - prc: 0.2500 - val_loss: 0.5060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6436 - val_prc: 0.2809\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8370 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6282 - prc: 0.2468 - val_loss: 0.5614 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5525 - val_prc: 0.1975\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8396 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6039 - prc: 0.2421 - val_loss: 0.5429 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5785 - val_prc: 0.2111\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6601 - prc: 0.3009 - val_loss: 0.5381 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6080 - val_prc: 0.2324\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8251 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6781 - prc: 0.3315 - val_loss: 0.5208 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6432 - val_prc: 0.2729\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8218 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6830 - prc: 0.3372 - val_loss: 0.4889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6577 - val_prc: 0.3117\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8247 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6534 - prc: 0.2844 - val_loss: 0.4878 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6589 - val_prc: 0.3144\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8195 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6766 - prc: 0.3274 - val_loss: 0.5110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6563 - val_prc: 0.2972\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6845 - prc: 0.3469 - val_loss: 0.5078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6592 - val_prc: 0.3017\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8130 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6849 - prc: 0.3473 - val_loss: 0.5336 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6548 - val_prc: 0.2880\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6935 - prc: 0.3527 - val_loss: 0.5118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6603 - val_prc: 0.3046\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8072 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6929 - prc: 0.3457 - val_loss: 0.5229 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6605 - val_prc: 0.3007\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8079 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6853 - prc: 0.3353 - val_loss: 0.4992 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6653 - val_prc: 0.3217\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8058 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6920 - prc: 0.3564 - val_loss: 0.5191 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6621 - val_prc: 0.3043\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7996 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7001 - prc: 0.3535 - val_loss: 0.4951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6673 - val_prc: 0.3264\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7001 - prc: 0.3681 - val_loss: 0.4864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6689 - val_prc: 0.3504\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7978 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7005 - prc: 0.3606 - val_loss: 0.5003 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6675 - val_prc: 0.3213\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7960 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7030 - prc: 0.3821 - val_loss: 0.5542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6594 - val_prc: 0.2925\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7961 - tp: 71.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 327.0000 - accuracy: 0.7875 - precision: 0.4080 - recall: 0.1784 - auc: 0.6966 - prc: 0.3496 - val_loss: 0.5176 - val_tp: 29.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 62.0000 - val_accuracy: 0.7945 - val_precision: 0.4085 - val_recall: 0.3187 - val_auc: 0.6673 - val_prc: 0.3198\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7921 - tp: 111.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 287.0000 - accuracy: 0.7979 - precision: 0.4764 - recall: 0.2789 - auc: 0.7051 - prc: 0.3716 - val_loss: 0.5453 - val_tp: 40.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 51.0000 - val_accuracy: 0.7569 - val_precision: 0.3571 - val_recall: 0.4396 - val_auc: 0.6627 - val_prc: 0.3002\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7946 - tp: 130.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 268.0000 - accuracy: 0.7964 - precision: 0.4745 - recall: 0.3266 - auc: 0.6983 - prc: 0.3679 - val_loss: 0.5387 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6651 - val_prc: 0.3079\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7899 - tp: 132.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 266.0000 - accuracy: 0.7974 - precision: 0.4783 - recall: 0.3317 - auc: 0.7045 - prc: 0.3663 - val_loss: 0.5452 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6651 - val_prc: 0.3068\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7911 - tp: 117.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 281.0000 - accuracy: 0.7959 - precision: 0.4699 - recall: 0.2940 - auc: 0.7028 - prc: 0.3812 - val_loss: 0.5309 - val_tp: 36.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 55.0000 - val_accuracy: 0.7767 - val_precision: 0.3830 - val_recall: 0.3956 - val_auc: 0.6690 - val_prc: 0.3238\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7883 - tp: 135.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 263.0000 - accuracy: 0.7984 - precision: 0.4821 - recall: 0.3392 - auc: 0.7068 - prc: 0.3757 - val_loss: 0.5286 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6699 - val_prc: 0.3265\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7883 - tp: 131.0000 - fp: 159.0000 - tn: 1467.0000 - fn: 267.0000 - accuracy: 0.7895 - precision: 0.4517 - recall: 0.3291 - auc: 0.7049 - prc: 0.3675 - val_loss: 0.5237 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6703 - val_prc: 0.3245\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7881 - tp: 133.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 265.0000 - accuracy: 0.7930 - precision: 0.4634 - recall: 0.3342 - auc: 0.7031 - prc: 0.3684 - val_loss: 0.5322 - val_tp: 39.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 52.0000 - val_accuracy: 0.7767 - val_precision: 0.3900 - val_recall: 0.4286 - val_auc: 0.6702 - val_prc: 0.3244\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7854 - tp: 139.0000 - fp: 169.0000 - tn: 1457.0000 - fn: 259.0000 - accuracy: 0.7885 - precision: 0.4513 - recall: 0.3492 - auc: 0.7067 - prc: 0.3731 - val_loss: 0.4956 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 65.0000 - val_accuracy: 0.8103 - val_precision: 0.4561 - val_recall: 0.2857 - val_auc: 0.6747 - val_prc: 0.3457\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7844 - tp: 133.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 265.0000 - accuracy: 0.8009 - precision: 0.4908 - recall: 0.3342 - auc: 0.7086 - prc: 0.3887 - val_loss: 0.5154 - val_tp: 34.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 57.0000 - val_accuracy: 0.7964 - val_precision: 0.4250 - val_recall: 0.3736 - val_auc: 0.6721 - val_prc: 0.3317\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7831 - tp: 130.0000 - fp: 151.0000 - tn: 1475.0000 - fn: 268.0000 - accuracy: 0.7930 - precision: 0.4626 - recall: 0.3266 - auc: 0.7092 - prc: 0.3830 - val_loss: 0.5430 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6704 - val_prc: 0.3195\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7828 - tp: 142.0000 - fp: 172.0000 - tn: 1454.0000 - fn: 256.0000 - accuracy: 0.7885 - precision: 0.4522 - recall: 0.3568 - auc: 0.7091 - prc: 0.3780 - val_loss: 0.5037 - val_tp: 30.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 61.0000 - val_accuracy: 0.7964 - val_precision: 0.4167 - val_recall: 0.3297 - val_auc: 0.6746 - val_prc: 0.3472\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7812 - tp: 134.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 264.0000 - accuracy: 0.7836 - precision: 0.4351 - recall: 0.3367 - auc: 0.7095 - prc: 0.3630 - val_loss: 0.5423 - val_tp: 40.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 51.0000 - val_accuracy: 0.7549 - val_precision: 0.3540 - val_recall: 0.4396 - val_auc: 0.6716 - val_prc: 0.3256\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7805 - tp: 142.0000 - fp: 159.0000 - tn: 1467.0000 - fn: 256.0000 - accuracy: 0.7950 - precision: 0.4718 - recall: 0.3568 - auc: 0.7102 - prc: 0.3917 - val_loss: 0.4983 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6763 - val_prc: 0.3480\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7805 - tp: 146.0000 - fp: 168.0000 - tn: 1458.0000 - fn: 252.0000 - accuracy: 0.7925 - precision: 0.4650 - recall: 0.3668 - auc: 0.7089 - prc: 0.3874 - val_loss: 0.4967 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6769 - val_prc: 0.3505\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7821 - tp: 160.0000 - fp: 219.0000 - tn: 1407.0000 - fn: 238.0000 - accuracy: 0.7742 - precision: 0.4222 - recall: 0.4020 - auc: 0.7058 - prc: 0.3736 - val_loss: 0.4977 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6789 - val_prc: 0.3598\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7821 - tp: 147.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 251.0000 - accuracy: 0.7806 - precision: 0.4324 - recall: 0.3693 - auc: 0.7049 - prc: 0.3719 - val_loss: 0.5415 - val_tp: 40.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 51.0000 - val_accuracy: 0.7510 - val_precision: 0.3478 - val_recall: 0.4396 - val_auc: 0.6718 - val_prc: 0.3253\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7812 - tp: 151.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 247.0000 - accuracy: 0.7787 - precision: 0.4290 - recall: 0.3794 - auc: 0.7053 - prc: 0.3763 - val_loss: 0.5112 - val_tp: 37.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 54.0000 - val_accuracy: 0.7945 - val_precision: 0.4253 - val_recall: 0.4066 - val_auc: 0.6770 - val_prc: 0.3511\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7774 - tp: 144.0000 - fp: 168.0000 - tn: 1458.0000 - fn: 254.0000 - accuracy: 0.7915 - precision: 0.4615 - recall: 0.3618 - auc: 0.7114 - prc: 0.3803 - val_loss: 0.5669 - val_tp: 44.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 47.0000 - val_accuracy: 0.7095 - val_precision: 0.3056 - val_recall: 0.4835 - val_auc: 0.6696 - val_prc: 0.3148\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7796 - tp: 155.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 243.0000 - accuracy: 0.7727 - precision: 0.4167 - recall: 0.3894 - auc: 0.7069 - prc: 0.3804 - val_loss: 0.5312 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6750 - val_prc: 0.3329\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7788 - tp: 151.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 247.0000 - accuracy: 0.7747 - precision: 0.4194 - recall: 0.3794 - auc: 0.7095 - prc: 0.3779 - val_loss: 0.5337 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6748 - val_prc: 0.3334\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7756 - tp: 151.0000 - fp: 199.0000 - tn: 1427.0000 - fn: 247.0000 - accuracy: 0.7796 - precision: 0.4314 - recall: 0.3794 - auc: 0.7119 - prc: 0.3831 - val_loss: 0.5464 - val_tp: 42.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 49.0000 - val_accuracy: 0.7372 - val_precision: 0.3333 - val_recall: 0.4615 - val_auc: 0.6738 - val_prc: 0.3288\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7783 - tp: 152.0000 - fp: 187.0000 - tn: 1439.0000 - fn: 246.0000 - accuracy: 0.7861 - precision: 0.4484 - recall: 0.3819 - auc: 0.7079 - prc: 0.3823 - val_loss: 0.5228 - val_tp: 39.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 52.0000 - val_accuracy: 0.7747 - val_precision: 0.3861 - val_recall: 0.4286 - val_auc: 0.6771 - val_prc: 0.3511\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7769 - tp: 154.0000 - fp: 190.0000 - tn: 1436.0000 - fn: 244.0000 - accuracy: 0.7856 - precision: 0.4477 - recall: 0.3869 - auc: 0.7111 - prc: 0.3920 - val_loss: 0.5050 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6790 - val_prc: 0.3592\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7765 - tp: 156.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 242.0000 - accuracy: 0.7831 - precision: 0.4419 - recall: 0.3920 - auc: 0.7100 - prc: 0.3838 - val_loss: 0.4789 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6808 - val_prc: 0.3832\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7745 - tp: 158.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 240.0000 - accuracy: 0.7861 - precision: 0.4501 - recall: 0.3970 - auc: 0.7117 - prc: 0.3976 - val_loss: 0.5339 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6755 - val_prc: 0.3360\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7740 - tp: 167.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 231.0000 - accuracy: 0.7762 - precision: 0.4293 - recall: 0.4196 - auc: 0.7125 - prc: 0.3871 - val_loss: 0.5164 - val_tp: 38.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 53.0000 - val_accuracy: 0.7767 - val_precision: 0.3878 - val_recall: 0.4176 - val_auc: 0.6785 - val_prc: 0.3511\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7722 - tp: 162.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 236.0000 - accuracy: 0.7861 - precision: 0.4513 - recall: 0.4070 - auc: 0.7141 - prc: 0.3789 - val_loss: 0.5205 - val_tp: 39.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 52.0000 - val_accuracy: 0.7747 - val_precision: 0.3861 - val_recall: 0.4286 - val_auc: 0.6782 - val_prc: 0.3494\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7750 - tp: 158.0000 - fp: 210.0000 - tn: 1416.0000 - fn: 240.0000 - accuracy: 0.7777 - precision: 0.4293 - recall: 0.3970 - auc: 0.7112 - prc: 0.3888 - val_loss: 0.4859 - val_tp: 31.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8123 - val_precision: 0.4697 - val_recall: 0.3407 - val_auc: 0.6799 - val_prc: 0.3713\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7741 - tp: 149.0000 - fp: 207.0000 - tn: 1419.0000 - fn: 249.0000 - accuracy: 0.7747 - precision: 0.4185 - recall: 0.3744 - auc: 0.7131 - prc: 0.4018 - val_loss: 0.5079 - val_tp: 37.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 54.0000 - val_accuracy: 0.7925 - val_precision: 0.4205 - val_recall: 0.4066 - val_auc: 0.6803 - val_prc: 0.3689\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7788 - tp: 165.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 233.0000 - accuracy: 0.7663 - precision: 0.4074 - recall: 0.4146 - auc: 0.7065 - prc: 0.3801 - val_loss: 0.5363 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6782 - val_prc: 0.3418\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7716 - tp: 156.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 242.0000 - accuracy: 0.7792 - precision: 0.4321 - recall: 0.3920 - auc: 0.7146 - prc: 0.3985 - val_loss: 0.5066 - val_tp: 36.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 55.0000 - val_accuracy: 0.7925 - val_precision: 0.4186 - val_recall: 0.3956 - val_auc: 0.6814 - val_prc: 0.3765\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7751 - tp: 160.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 238.0000 - accuracy: 0.7762 - precision: 0.4267 - recall: 0.4020 - auc: 0.7091 - prc: 0.3890 - val_loss: 0.5240 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6788 - val_prc: 0.3523\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7723 - tp: 156.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 242.0000 - accuracy: 0.7861 - precision: 0.4496 - recall: 0.3920 - auc: 0.7124 - prc: 0.3968 - val_loss: 0.4863 - val_tp: 31.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8123 - val_precision: 0.4697 - val_recall: 0.3407 - val_auc: 0.6814 - val_prc: 0.3769\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7739 - tp: 153.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 245.0000 - accuracy: 0.7742 - precision: 0.4192 - recall: 0.3844 - auc: 0.7117 - prc: 0.3961 - val_loss: 0.5348 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6798 - val_prc: 0.3494\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7726 - tp: 148.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 250.0000 - accuracy: 0.7806 - precision: 0.4327 - recall: 0.3719 - auc: 0.7121 - prc: 0.3946 - val_loss: 0.5501 - val_tp: 42.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 49.0000 - val_accuracy: 0.7372 - val_precision: 0.3333 - val_recall: 0.4615 - val_auc: 0.6781 - val_prc: 0.3398\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7723 - tp: 151.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 247.0000 - accuracy: 0.7811 - precision: 0.4352 - recall: 0.3794 - auc: 0.7130 - prc: 0.3959 - val_loss: 0.5314 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6800 - val_prc: 0.3530\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7723 - tp: 156.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 242.0000 - accuracy: 0.7772 - precision: 0.4274 - recall: 0.3920 - auc: 0.7128 - prc: 0.3945 - val_loss: 0.5834 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6775 - val_prc: 0.3380\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7704 - tp: 160.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 238.0000 - accuracy: 0.7851 - precision: 0.4482 - recall: 0.4020 - auc: 0.7143 - prc: 0.4053 - val_loss: 0.5067 - val_tp: 35.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 56.0000 - val_accuracy: 0.7945 - val_precision: 0.4217 - val_recall: 0.3846 - val_auc: 0.6811 - val_prc: 0.3824\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7700 - tp: 165.0000 - fp: 218.0000 - tn: 1408.0000 - fn: 233.0000 - accuracy: 0.7772 - precision: 0.4308 - recall: 0.4146 - auc: 0.7143 - prc: 0.3860 - val_loss: 0.5272 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6797 - val_prc: 0.3600\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7701 - tp: 157.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 241.0000 - accuracy: 0.7880 - precision: 0.4551 - recall: 0.3945 - auc: 0.7150 - prc: 0.4039 - val_loss: 0.5247 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6807 - val_prc: 0.3668\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7694 - tp: 146.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 252.0000 - accuracy: 0.7841 - precision: 0.4411 - recall: 0.3668 - auc: 0.7154 - prc: 0.4148 - val_loss: 0.5502 - val_tp: 42.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 49.0000 - val_accuracy: 0.7352 - val_precision: 0.3307 - val_recall: 0.4615 - val_auc: 0.6779 - val_prc: 0.3392\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7714 - tp: 174.0000 - fp: 257.0000 - tn: 1369.0000 - fn: 224.0000 - accuracy: 0.7624 - precision: 0.4037 - recall: 0.4372 - auc: 0.7145 - prc: 0.3953 - val_loss: 0.4874 - val_tp: 31.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 60.0000 - val_accuracy: 0.8083 - val_precision: 0.4559 - val_recall: 0.3407 - val_auc: 0.6817 - val_prc: 0.3764\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7706 - tp: 150.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 248.0000 - accuracy: 0.7732 - precision: 0.4155 - recall: 0.3769 - auc: 0.7131 - prc: 0.3962 - val_loss: 0.4926 - val_tp: 34.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 57.0000 - val_accuracy: 0.8024 - val_precision: 0.4416 - val_recall: 0.3736 - val_auc: 0.6817 - val_prc: 0.3817\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7689 - tp: 159.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 239.0000 - accuracy: 0.7772 - precision: 0.4286 - recall: 0.3995 - auc: 0.7152 - prc: 0.3961 - val_loss: 0.4974 - val_tp: 35.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 56.0000 - val_accuracy: 0.8024 - val_precision: 0.4430 - val_recall: 0.3846 - val_auc: 0.6826 - val_prc: 0.3862\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7686 - tp: 155.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 243.0000 - accuracy: 0.7836 - precision: 0.4429 - recall: 0.3894 - auc: 0.7138 - prc: 0.4082 - val_loss: 0.5082 - val_tp: 37.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 54.0000 - val_accuracy: 0.7885 - val_precision: 0.4111 - val_recall: 0.4066 - val_auc: 0.6820 - val_prc: 0.3803\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7696 - tp: 165.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 233.0000 - accuracy: 0.7777 - precision: 0.4319 - recall: 0.4146 - auc: 0.7140 - prc: 0.3979 - val_loss: 0.5621 - val_tp: 44.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 47.0000 - val_accuracy: 0.7194 - val_precision: 0.3165 - val_recall: 0.4835 - val_auc: 0.6786 - val_prc: 0.3428\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7713 - tp: 160.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 238.0000 - accuracy: 0.7722 - precision: 0.4178 - recall: 0.4020 - auc: 0.7116 - prc: 0.3946 - val_loss: 0.5276 - val_tp: 38.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 53.0000 - val_accuracy: 0.7609 - val_precision: 0.3585 - val_recall: 0.4176 - val_auc: 0.6818 - val_prc: 0.3765\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7694 - tp: 156.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 242.0000 - accuracy: 0.7772 - precision: 0.4274 - recall: 0.3920 - auc: 0.7134 - prc: 0.4038 - val_loss: 0.5209 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6818 - val_prc: 0.3812\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7687 - tp: 155.0000 - fp: 189.0000 - tn: 1437.0000 - fn: 243.0000 - accuracy: 0.7866 - precision: 0.4506 - recall: 0.3894 - auc: 0.7147 - prc: 0.4163 - val_loss: 0.5559 - val_tp: 43.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 48.0000 - val_accuracy: 0.7332 - val_precision: 0.3308 - val_recall: 0.4725 - val_auc: 0.6794 - val_prc: 0.3493\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7688 - tp: 163.0000 - fp: 219.0000 - tn: 1407.0000 - fn: 235.0000 - accuracy: 0.7757 - precision: 0.4267 - recall: 0.4095 - auc: 0.7144 - prc: 0.4155 - val_loss: 0.5068 - val_tp: 36.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 55.0000 - val_accuracy: 0.7905 - val_precision: 0.4138 - val_recall: 0.3956 - val_auc: 0.6821 - val_prc: 0.3903\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7666 - tp: 165.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 233.0000 - accuracy: 0.7816 - precision: 0.4412 - recall: 0.4146 - auc: 0.7160 - prc: 0.4107 - val_loss: 0.5025 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6824 - val_prc: 0.3875\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7687 - tp: 151.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 247.0000 - accuracy: 0.7782 - precision: 0.4278 - recall: 0.3794 - auc: 0.7139 - prc: 0.4241 - val_loss: 0.5255 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6823 - val_prc: 0.3792\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7660 - tp: 168.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 230.0000 - accuracy: 0.7737 - precision: 0.4242 - recall: 0.4221 - auc: 0.7168 - prc: 0.4066 - val_loss: 0.5161 - val_tp: 38.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 53.0000 - val_accuracy: 0.7806 - val_precision: 0.3958 - val_recall: 0.4176 - val_auc: 0.6816 - val_prc: 0.3841\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7685 - tp: 164.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 234.0000 - accuracy: 0.7722 - precision: 0.4194 - recall: 0.4121 - auc: 0.7155 - prc: 0.4089 - val_loss: 0.4696 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6840 - val_prc: 0.3948\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7678 - tp: 154.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 244.0000 - accuracy: 0.7836 - precision: 0.4425 - recall: 0.3869 - auc: 0.7145 - prc: 0.4081 - val_loss: 0.5407 - val_tp: 41.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 50.0000 - val_accuracy: 0.7510 - val_precision: 0.3504 - val_recall: 0.4505 - val_auc: 0.6821 - val_prc: 0.3725\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7679 - tp: 159.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 239.0000 - accuracy: 0.7727 - precision: 0.4184 - recall: 0.3995 - auc: 0.7163 - prc: 0.4048 - val_loss: 0.5675 - val_tp: 45.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 46.0000 - val_accuracy: 0.7115 - val_precision: 0.3103 - val_recall: 0.4945 - val_auc: 0.6792 - val_prc: 0.3463\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7667 - tp: 163.0000 - fp: 219.0000 - tn: 1407.0000 - fn: 235.0000 - accuracy: 0.7757 - precision: 0.4267 - recall: 0.4095 - auc: 0.7163 - prc: 0.4157 - val_loss: 0.4751 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6841 - val_prc: 0.3890\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7693 - tp: 161.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 237.0000 - accuracy: 0.7712 - precision: 0.4160 - recall: 0.4045 - auc: 0.7135 - prc: 0.3987 - val_loss: 0.5129 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6829 - val_prc: 0.3913\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7656 - tp: 168.0000 - fp: 236.0000 - tn: 1390.0000 - fn: 230.0000 - accuracy: 0.7698 - precision: 0.4158 - recall: 0.4221 - auc: 0.7181 - prc: 0.4079 - val_loss: 0.5034 - val_tp: 35.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 56.0000 - val_accuracy: 0.7945 - val_precision: 0.4217 - val_recall: 0.3846 - val_auc: 0.6828 - val_prc: 0.3802\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7652 - tp: 159.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 239.0000 - accuracy: 0.7777 - precision: 0.4297 - recall: 0.3995 - auc: 0.7193 - prc: 0.4068 - val_loss: 0.5062 - val_tp: 37.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 54.0000 - val_accuracy: 0.7925 - val_precision: 0.4205 - val_recall: 0.4066 - val_auc: 0.6831 - val_prc: 0.3833\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7655 - tp: 164.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 234.0000 - accuracy: 0.7757 - precision: 0.4271 - recall: 0.4121 - auc: 0.7189 - prc: 0.3937 - val_loss: 0.4925 - val_tp: 34.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 57.0000 - val_accuracy: 0.8004 - val_precision: 0.4359 - val_recall: 0.3736 - val_auc: 0.6829 - val_prc: 0.3804\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7661 - tp: 165.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 233.0000 - accuracy: 0.7747 - precision: 0.4253 - recall: 0.4146 - auc: 0.7173 - prc: 0.4105 - val_loss: 0.5013 - val_tp: 35.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 56.0000 - val_accuracy: 0.7945 - val_precision: 0.4217 - val_recall: 0.3846 - val_auc: 0.6834 - val_prc: 0.3809\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7662 - tp: 171.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 227.0000 - accuracy: 0.7811 - precision: 0.4419 - recall: 0.4296 - auc: 0.7156 - prc: 0.4055 - val_loss: 0.5377 - val_tp: 41.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 50.0000 - val_accuracy: 0.7549 - val_precision: 0.3565 - val_recall: 0.4505 - val_auc: 0.6823 - val_prc: 0.3823\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7660 - tp: 164.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 234.0000 - accuracy: 0.7752 - precision: 0.4260 - recall: 0.4121 - auc: 0.7156 - prc: 0.4154 - val_loss: 0.5180 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6820 - val_prc: 0.3912\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7656 - tp: 154.0000 - fp: 210.0000 - tn: 1416.0000 - fn: 244.0000 - accuracy: 0.7757 - precision: 0.4231 - recall: 0.3869 - auc: 0.7175 - prc: 0.4149 - val_loss: 0.5668 - val_tp: 45.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 46.0000 - val_accuracy: 0.7115 - val_precision: 0.3103 - val_recall: 0.4945 - val_auc: 0.6806 - val_prc: 0.3532\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7705 - tp: 160.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 238.0000 - accuracy: 0.7727 - precision: 0.4188 - recall: 0.4020 - auc: 0.7098 - prc: 0.4148 - val_loss: 0.5425 - val_tp: 41.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 50.0000 - val_accuracy: 0.7470 - val_precision: 0.3445 - val_recall: 0.4505 - val_auc: 0.6825 - val_prc: 0.3870\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7662 - tp: 156.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 242.0000 - accuracy: 0.7732 - precision: 0.4182 - recall: 0.3920 - auc: 0.7157 - prc: 0.4206 - val_loss: 0.5002 - val_tp: 35.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 56.0000 - val_accuracy: 0.7964 - val_precision: 0.4268 - val_recall: 0.3846 - val_auc: 0.6838 - val_prc: 0.3821\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7636 - tp: 163.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 235.0000 - accuracy: 0.7831 - precision: 0.4441 - recall: 0.4095 - auc: 0.7189 - prc: 0.4126 - val_loss: 0.5281 - val_tp: 39.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 52.0000 - val_accuracy: 0.7609 - val_precision: 0.3611 - val_recall: 0.4286 - val_auc: 0.6828 - val_prc: 0.3946\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7654 - tp: 163.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 235.0000 - accuracy: 0.7846 - precision: 0.4478 - recall: 0.4095 - auc: 0.7171 - prc: 0.4117 - val_loss: 0.5564 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6820 - val_prc: 0.3726\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7670 - tp: 152.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 246.0000 - accuracy: 0.7777 - precision: 0.4270 - recall: 0.3819 - auc: 0.7153 - prc: 0.4146 - val_loss: 0.5351 - val_tp: 40.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 51.0000 - val_accuracy: 0.7549 - val_precision: 0.3540 - val_recall: 0.4396 - val_auc: 0.6823 - val_prc: 0.3853\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7689 - tp: 161.0000 - fp: 244.0000 - tn: 1382.0000 - fn: 237.0000 - accuracy: 0.7624 - precision: 0.3975 - recall: 0.4045 - auc: 0.7117 - prc: 0.4047 - val_loss: 0.5108 - val_tp: 37.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 54.0000 - val_accuracy: 0.7846 - val_precision: 0.4022 - val_recall: 0.4066 - val_auc: 0.6833 - val_prc: 0.3829\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7641 - tp: 162.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 236.0000 - accuracy: 0.7792 - precision: 0.4343 - recall: 0.4070 - auc: 0.7177 - prc: 0.4178 - val_loss: 0.4984 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6839 - val_prc: 0.3875\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7634 - tp: 166.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 232.0000 - accuracy: 0.7792 - precision: 0.4357 - recall: 0.4171 - auc: 0.7184 - prc: 0.4099 - val_loss: 0.5138 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6831 - val_prc: 0.3845\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7652 - tp: 157.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 241.0000 - accuracy: 0.7708 - precision: 0.4132 - recall: 0.3945 - auc: 0.7183 - prc: 0.4060 - val_loss: 0.5888 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6801 - val_prc: 0.3489\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7658 - tp: 162.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 236.0000 - accuracy: 0.7806 - precision: 0.4378 - recall: 0.4070 - auc: 0.7149 - prc: 0.4145 - val_loss: 0.5299 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6834 - val_prc: 0.3973\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7667 - tp: 176.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 222.0000 - accuracy: 0.7653 - precision: 0.4103 - recall: 0.4422 - auc: 0.7146 - prc: 0.4094 - val_loss: 0.5070 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 54.0000 - val_accuracy: 0.7905 - val_precision: 0.4157 - val_recall: 0.4066 - val_auc: 0.6831 - val_prc: 0.3821\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7656 - tp: 160.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 238.0000 - accuracy: 0.7811 - precision: 0.4384 - recall: 0.4020 - auc: 0.7150 - prc: 0.4277 - val_loss: 0.4951 - val_tp: 33.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 58.0000 - val_accuracy: 0.7964 - val_precision: 0.4231 - val_recall: 0.3626 - val_auc: 0.6834 - val_prc: 0.3931\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7674 - tp: 156.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 242.0000 - accuracy: 0.7742 - precision: 0.4205 - recall: 0.3920 - auc: 0.7144 - prc: 0.4125 - val_loss: 0.5553 - val_tp: 44.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 47.0000 - val_accuracy: 0.7391 - val_precision: 0.3411 - val_recall: 0.4835 - val_auc: 0.6819 - val_prc: 0.3778\n",
      "Epoch 124/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7663 - tp: 167.0000 - fp: 225.0000 - tn: 1401.0000 - fn: 231.0000 - accuracy: 0.7747 - precision: 0.4260 - recall: 0.4196 - auc: 0.7144 - prc: 0.4046 - val_loss: 0.5288 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6835 - val_prc: 0.3917\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7648 - tp: 155.0000 - fp: 203.0000 - tn: 1423.0000 - fn: 243.0000 - accuracy: 0.7796 - precision: 0.4330 - recall: 0.3894 - auc: 0.7161 - prc: 0.4138 - val_loss: 0.5681 - val_tp: 46.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 45.0000 - val_accuracy: 0.7154 - val_precision: 0.3172 - val_recall: 0.5055 - val_auc: 0.6824 - val_prc: 0.3764\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7622 - tp: 166.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 232.0000 - accuracy: 0.7811 - precision: 0.4403 - recall: 0.4171 - auc: 0.7177 - prc: 0.4279 - val_loss: 0.5118 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6841 - val_prc: 0.3840\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7616 - tp: 184.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 214.0000 - accuracy: 0.7747 - precision: 0.4319 - recall: 0.4623 - auc: 0.7207 - prc: 0.4156 - val_loss: 0.4634 - val_tp: 23.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 68.0000 - val_accuracy: 0.8300 - val_precision: 0.5610 - val_recall: 0.2527 - val_auc: 0.6851 - val_prc: 0.4077\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7677 - tp: 155.0000 - fp: 203.0000 - tn: 1423.0000 - fn: 243.0000 - accuracy: 0.7796 - precision: 0.4330 - recall: 0.3894 - auc: 0.7127 - prc: 0.4181 - val_loss: 0.5206 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6834 - val_prc: 0.3905\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7632 - tp: 166.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 232.0000 - accuracy: 0.7752 - precision: 0.4267 - recall: 0.4171 - auc: 0.7180 - prc: 0.4096 - val_loss: 0.4970 - val_tp: 33.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 58.0000 - val_accuracy: 0.7925 - val_precision: 0.4125 - val_recall: 0.3626 - val_auc: 0.6838 - val_prc: 0.3925\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7666 - tp: 157.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 241.0000 - accuracy: 0.7767 - precision: 0.4266 - recall: 0.3945 - auc: 0.7142 - prc: 0.4082 - val_loss: 0.5164 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6832 - val_prc: 0.3862\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7659 - tp: 166.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 232.0000 - accuracy: 0.7703 - precision: 0.4160 - recall: 0.4171 - auc: 0.7154 - prc: 0.4101 - val_loss: 0.5201 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6838 - val_prc: 0.3859\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7627 - tp: 163.0000 - fp: 229.0000 - tn: 1397.0000 - fn: 235.0000 - accuracy: 0.7708 - precision: 0.4158 - recall: 0.4095 - auc: 0.7195 - prc: 0.4143 - val_loss: 0.5085 - val_tp: 37.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 54.0000 - val_accuracy: 0.7846 - val_precision: 0.4022 - val_recall: 0.4066 - val_auc: 0.6846 - val_prc: 0.3848\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7613 - tp: 164.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 234.0000 - accuracy: 0.7737 - precision: 0.4227 - recall: 0.4121 - auc: 0.7205 - prc: 0.4280 - val_loss: 0.4840 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6851 - val_prc: 0.4086\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7635 - tp: 160.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 238.0000 - accuracy: 0.7752 - precision: 0.4244 - recall: 0.4020 - auc: 0.7177 - prc: 0.4202 - val_loss: 0.5019 - val_tp: 35.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 56.0000 - val_accuracy: 0.7925 - val_precision: 0.4167 - val_recall: 0.3846 - val_auc: 0.6842 - val_prc: 0.3922\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7629 - tp: 157.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 241.0000 - accuracy: 0.7762 - precision: 0.4255 - recall: 0.3945 - auc: 0.7179 - prc: 0.4253 - val_loss: 0.4835 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6845 - val_prc: 0.4072\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7651 - tp: 174.0000 - fp: 231.0000 - tn: 1395.0000 - fn: 224.0000 - accuracy: 0.7752 - precision: 0.4296 - recall: 0.4372 - auc: 0.7156 - prc: 0.4135 - val_loss: 0.5300 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6834 - val_prc: 0.3935\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7635 - tp: 154.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 244.0000 - accuracy: 0.7727 - precision: 0.4162 - recall: 0.3869 - auc: 0.7177 - prc: 0.4158 - val_loss: 0.5706 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6828 - val_prc: 0.3777\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7635 - tp: 165.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 233.0000 - accuracy: 0.7792 - precision: 0.4354 - recall: 0.4146 - auc: 0.7168 - prc: 0.4259 - val_loss: 0.5063 - val_tp: 37.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 54.0000 - val_accuracy: 0.7885 - val_precision: 0.4111 - val_recall: 0.4066 - val_auc: 0.6844 - val_prc: 0.3949\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7662 - tp: 157.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 241.0000 - accuracy: 0.7712 - precision: 0.4142 - recall: 0.3945 - auc: 0.7131 - prc: 0.4167 - val_loss: 0.5030 - val_tp: 36.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 55.0000 - val_accuracy: 0.7905 - val_precision: 0.4138 - val_recall: 0.3956 - val_auc: 0.6842 - val_prc: 0.3951\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7613 - tp: 164.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 234.0000 - accuracy: 0.7796 - precision: 0.4362 - recall: 0.4121 - auc: 0.7202 - prc: 0.4303 - val_loss: 0.5209 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6835 - val_prc: 0.3862\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7639 - tp: 165.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 233.0000 - accuracy: 0.7742 - precision: 0.4242 - recall: 0.4146 - auc: 0.7165 - prc: 0.4199 - val_loss: 0.4830 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6847 - val_prc: 0.4078\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7627 - tp: 160.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 238.0000 - accuracy: 0.7732 - precision: 0.4199 - recall: 0.4020 - auc: 0.7176 - prc: 0.4292 - val_loss: 0.4969 - val_tp: 33.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 58.0000 - val_accuracy: 0.7905 - val_precision: 0.4074 - val_recall: 0.3626 - val_auc: 0.6843 - val_prc: 0.4001\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7623 - tp: 162.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 236.0000 - accuracy: 0.7806 - precision: 0.4378 - recall: 0.4070 - auc: 0.7189 - prc: 0.4122 - val_loss: 0.5295 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6828 - val_prc: 0.3864\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7620 - tp: 169.0000 - fp: 231.0000 - tn: 1395.0000 - fn: 229.0000 - accuracy: 0.7727 - precision: 0.4225 - recall: 0.4246 - auc: 0.7178 - prc: 0.4301 - val_loss: 0.4835 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6848 - val_prc: 0.4079\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7645 - tp: 148.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 250.0000 - accuracy: 0.7806 - precision: 0.4327 - recall: 0.3719 - auc: 0.7150 - prc: 0.4228 - val_loss: 0.5218 - val_tp: 37.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 54.0000 - val_accuracy: 0.7727 - val_precision: 0.3776 - val_recall: 0.4066 - val_auc: 0.6837 - val_prc: 0.3857\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7619 - tp: 160.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 238.0000 - accuracy: 0.7757 - precision: 0.4255 - recall: 0.4020 - auc: 0.7183 - prc: 0.4263 - val_loss: 0.4972 - val_tp: 33.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 58.0000 - val_accuracy: 0.7905 - val_precision: 0.4074 - val_recall: 0.3626 - val_auc: 0.6849 - val_prc: 0.4000\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7636 - tp: 161.0000 - fp: 218.0000 - tn: 1408.0000 - fn: 237.0000 - accuracy: 0.7752 - precision: 0.4248 - recall: 0.4045 - auc: 0.7166 - prc: 0.4241 - val_loss: 0.5142 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6835 - val_prc: 0.3858\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7634 - tp: 157.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 241.0000 - accuracy: 0.7688 - precision: 0.4089 - recall: 0.3945 - auc: 0.7170 - prc: 0.4232 - val_loss: 0.5222 - val_tp: 37.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 54.0000 - val_accuracy: 0.7688 - val_precision: 0.3700 - val_recall: 0.4066 - val_auc: 0.6837 - val_prc: 0.3856\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7634 - tp: 165.0000 - fp: 235.0000 - tn: 1391.0000 - fn: 233.0000 - accuracy: 0.7688 - precision: 0.4125 - recall: 0.4146 - auc: 0.7171 - prc: 0.4185 - val_loss: 0.5196 - val_tp: 37.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 54.0000 - val_accuracy: 0.7747 - val_precision: 0.3814 - val_recall: 0.4066 - val_auc: 0.6837 - val_prc: 0.3857\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7674 - tp: 157.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 241.0000 - accuracy: 0.7851 - precision: 0.4473 - recall: 0.3945 - auc: 0.7119 - prc: 0.4256 - val_loss: 0.5822 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6830 - val_prc: 0.3788\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7641 - tp: 172.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 226.0000 - accuracy: 0.7693 - precision: 0.4165 - recall: 0.4322 - auc: 0.7162 - prc: 0.4078 - val_loss: 0.5110 - val_tp: 37.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 54.0000 - val_accuracy: 0.7826 - val_precision: 0.3978 - val_recall: 0.4066 - val_auc: 0.6837 - val_prc: 0.3949\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7670 - tp: 157.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 241.0000 - accuracy: 0.7762 - precision: 0.4255 - recall: 0.3945 - auc: 0.7127 - prc: 0.4168 - val_loss: 0.5183 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6841 - val_prc: 0.3863\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7611 - tp: 163.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 235.0000 - accuracy: 0.7693 - precision: 0.4127 - recall: 0.4095 - auc: 0.7196 - prc: 0.4275 - val_loss: 0.5380 - val_tp: 42.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 49.0000 - val_accuracy: 0.7530 - val_precision: 0.3559 - val_recall: 0.4615 - val_auc: 0.6837 - val_prc: 0.3922\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7627 - tp: 164.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 234.0000 - accuracy: 0.7811 - precision: 0.4397 - recall: 0.4121 - auc: 0.7196 - prc: 0.4164 - val_loss: 0.5635 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6843 - val_prc: 0.4024\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7636 - tp: 179.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 219.0000 - accuracy: 0.7727 - precision: 0.4262 - recall: 0.4497 - auc: 0.7163 - prc: 0.4173 - val_loss: 0.5555 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6838 - val_prc: 0.3986\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7608 - tp: 162.0000 - fp: 210.0000 - tn: 1416.0000 - fn: 236.0000 - accuracy: 0.7796 - precision: 0.4355 - recall: 0.4070 - auc: 0.7189 - prc: 0.4353 - val_loss: 0.5165 - val_tp: 37.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 54.0000 - val_accuracy: 0.7787 - val_precision: 0.3895 - val_recall: 0.4066 - val_auc: 0.6847 - val_prc: 0.3893\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7644 - tp: 165.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 233.0000 - accuracy: 0.7742 - precision: 0.4242 - recall: 0.4146 - auc: 0.7161 - prc: 0.4114 - val_loss: 0.5485 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6848 - val_prc: 0.3944\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7626 - tp: 163.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 235.0000 - accuracy: 0.7747 - precision: 0.4245 - recall: 0.4095 - auc: 0.7179 - prc: 0.4206 - val_loss: 0.5485 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6835 - val_prc: 0.3947\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7604 - tp: 169.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 229.0000 - accuracy: 0.7767 - precision: 0.4311 - recall: 0.4246 - auc: 0.7185 - prc: 0.4251 - val_loss: 0.5428 - val_tp: 42.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 49.0000 - val_accuracy: 0.7470 - val_precision: 0.3471 - val_recall: 0.4615 - val_auc: 0.6837 - val_prc: 0.3918\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7590 - tp: 165.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 233.0000 - accuracy: 0.7792 - precision: 0.4354 - recall: 0.4146 - auc: 0.7215 - prc: 0.4323 - val_loss: 0.5629 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6840 - val_prc: 0.4007\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7636 - tp: 159.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 239.0000 - accuracy: 0.7767 - precision: 0.4274 - recall: 0.3995 - auc: 0.7149 - prc: 0.4209 - val_loss: 0.5237 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6844 - val_prc: 0.3908\n",
      "Epoch 162/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7609 - tp: 170.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 228.0000 - accuracy: 0.7782 - precision: 0.4348 - recall: 0.4271 - auc: 0.7186 - prc: 0.4228 - val_loss: 0.4911 - val_tp: 33.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 58.0000 - val_accuracy: 0.7964 - val_precision: 0.4231 - val_recall: 0.3626 - val_auc: 0.6860 - val_prc: 0.4091\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7592 - tp: 162.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 236.0000 - accuracy: 0.7836 - precision: 0.4451 - recall: 0.4070 - auc: 0.7216 - prc: 0.4271 - val_loss: 0.4983 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6855 - val_prc: 0.4116\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7635 - tp: 158.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 240.0000 - accuracy: 0.7762 - precision: 0.4259 - recall: 0.3970 - auc: 0.7158 - prc: 0.4248 - val_loss: 0.5312 - val_tp: 38.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 53.0000 - val_accuracy: 0.7549 - val_precision: 0.3486 - val_recall: 0.4176 - val_auc: 0.6839 - val_prc: 0.3843\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7619 - tp: 161.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 237.0000 - accuracy: 0.7777 - precision: 0.4305 - recall: 0.4045 - auc: 0.7180 - prc: 0.4285 - val_loss: 0.5190 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6847 - val_prc: 0.3896\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7609 - tp: 154.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 244.0000 - accuracy: 0.7866 - precision: 0.4503 - recall: 0.3869 - auc: 0.7202 - prc: 0.4259 - val_loss: 0.5535 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6831 - val_prc: 0.3912\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7619 - tp: 164.0000 - fp: 218.0000 - tn: 1408.0000 - fn: 234.0000 - accuracy: 0.7767 - precision: 0.4293 - recall: 0.4121 - auc: 0.7189 - prc: 0.4305 - val_loss: 0.5044 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6852 - val_prc: 0.4003\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7645 - tp: 162.0000 - fp: 244.0000 - tn: 1382.0000 - fn: 236.0000 - accuracy: 0.7628 - precision: 0.3990 - recall: 0.4070 - auc: 0.7169 - prc: 0.4167 - val_loss: 0.4993 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6862 - val_prc: 0.4099\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7598 - tp: 164.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 234.0000 - accuracy: 0.7742 - precision: 0.4238 - recall: 0.4121 - auc: 0.7202 - prc: 0.4320 - val_loss: 0.5647 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6845 - val_prc: 0.4031\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7668 - tp: 160.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 238.0000 - accuracy: 0.7767 - precision: 0.4278 - recall: 0.4020 - auc: 0.7117 - prc: 0.4214 - val_loss: 0.5800 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6835 - val_prc: 0.3888\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7623 - tp: 157.0000 - fp: 225.0000 - tn: 1401.0000 - fn: 241.0000 - accuracy: 0.7698 - precision: 0.4110 - recall: 0.3945 - auc: 0.7182 - prc: 0.4246 - val_loss: 0.5632 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6836 - val_prc: 0.3933\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7635 - tp: 170.0000 - fp: 239.0000 - tn: 1387.0000 - fn: 228.0000 - accuracy: 0.7693 - precision: 0.4156 - recall: 0.4271 - auc: 0.7150 - prc: 0.4201 - val_loss: 0.5167 - val_tp: 37.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 54.0000 - val_accuracy: 0.7787 - val_precision: 0.3895 - val_recall: 0.4066 - val_auc: 0.6841 - val_prc: 0.3932\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7618 - tp: 166.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 232.0000 - accuracy: 0.7732 - precision: 0.4224 - recall: 0.4171 - auc: 0.7168 - prc: 0.4244 - val_loss: 0.5658 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6842 - val_prc: 0.3992\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7612 - tp: 162.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 236.0000 - accuracy: 0.7737 - precision: 0.4219 - recall: 0.4070 - auc: 0.7182 - prc: 0.4218 - val_loss: 0.5395 - val_tp: 42.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 49.0000 - val_accuracy: 0.7451 - val_precision: 0.3443 - val_recall: 0.4615 - val_auc: 0.6841 - val_prc: 0.3891\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7603 - tp: 170.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 228.0000 - accuracy: 0.7757 - precision: 0.4293 - recall: 0.4271 - auc: 0.7202 - prc: 0.4255 - val_loss: 0.4796 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6856 - val_prc: 0.4101\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7604 - tp: 153.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 245.0000 - accuracy: 0.7757 - precision: 0.4227 - recall: 0.3844 - auc: 0.7200 - prc: 0.4291 - val_loss: 0.5715 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6847 - val_prc: 0.4062\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7629 - tp: 154.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 244.0000 - accuracy: 0.7762 - precision: 0.4242 - recall: 0.3869 - auc: 0.7170 - prc: 0.4271 - val_loss: 0.5140 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6864 - val_prc: 0.4020\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7598 - tp: 168.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 230.0000 - accuracy: 0.7777 - precision: 0.4330 - recall: 0.4221 - auc: 0.7192 - prc: 0.4278 - val_loss: 0.5593 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6849 - val_prc: 0.4026\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7608 - tp: 162.0000 - fp: 229.0000 - tn: 1397.0000 - fn: 236.0000 - accuracy: 0.7703 - precision: 0.4143 - recall: 0.4070 - auc: 0.7212 - prc: 0.4234 - val_loss: 0.5421 - val_tp: 43.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 48.0000 - val_accuracy: 0.7470 - val_precision: 0.3496 - val_recall: 0.4725 - val_auc: 0.6854 - val_prc: 0.3945\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7643 - tp: 162.0000 - fp: 238.0000 - tn: 1388.0000 - fn: 236.0000 - accuracy: 0.7658 - precision: 0.4050 - recall: 0.4070 - auc: 0.7155 - prc: 0.4224 - val_loss: 0.5131 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6859 - val_prc: 0.4015\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7612 - tp: 161.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 237.0000 - accuracy: 0.7683 - precision: 0.4097 - recall: 0.4045 - auc: 0.7179 - prc: 0.4295 - val_loss: 0.5141 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6864 - val_prc: 0.4026\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7646 - tp: 160.0000 - fp: 219.0000 - tn: 1407.0000 - fn: 238.0000 - accuracy: 0.7742 - precision: 0.4222 - recall: 0.4020 - auc: 0.7132 - prc: 0.4193 - val_loss: 0.4994 - val_tp: 34.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 57.0000 - val_accuracy: 0.7866 - val_precision: 0.4000 - val_recall: 0.3736 - val_auc: 0.6854 - val_prc: 0.4100\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7631 - tp: 172.0000 - fp: 246.0000 - tn: 1380.0000 - fn: 226.0000 - accuracy: 0.7668 - precision: 0.4115 - recall: 0.4322 - auc: 0.7155 - prc: 0.4216 - val_loss: 0.4791 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6865 - val_prc: 0.4093\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7604 - tp: 158.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 240.0000 - accuracy: 0.7801 - precision: 0.4353 - recall: 0.3970 - auc: 0.7195 - prc: 0.4307 - val_loss: 0.5005 - val_tp: 34.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 57.0000 - val_accuracy: 0.7866 - val_precision: 0.4000 - val_recall: 0.3736 - val_auc: 0.6869 - val_prc: 0.4116\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7619 - tp: 166.0000 - fp: 229.0000 - tn: 1397.0000 - fn: 232.0000 - accuracy: 0.7722 - precision: 0.4203 - recall: 0.4171 - auc: 0.7171 - prc: 0.4238 - val_loss: 0.5267 - val_tp: 39.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 52.0000 - val_accuracy: 0.7668 - val_precision: 0.3714 - val_recall: 0.4286 - val_auc: 0.6857 - val_prc: 0.3910\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7617 - tp: 156.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 242.0000 - accuracy: 0.7806 - precision: 0.4358 - recall: 0.3920 - auc: 0.7175 - prc: 0.4343 - val_loss: 0.5049 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6868 - val_prc: 0.4112\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7605 - tp: 168.0000 - fp: 230.0000 - tn: 1396.0000 - fn: 230.0000 - accuracy: 0.7727 - precision: 0.4221 - recall: 0.4221 - auc: 0.7186 - prc: 0.4296 - val_loss: 0.5167 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6860 - val_prc: 0.4039\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7618 - tp: 158.0000 - fp: 219.0000 - tn: 1407.0000 - fn: 240.0000 - accuracy: 0.7732 - precision: 0.4191 - recall: 0.3970 - auc: 0.7177 - prc: 0.4219 - val_loss: 0.5873 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6843 - val_prc: 0.3915\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7619 - tp: 172.0000 - fp: 265.0000 - tn: 1361.0000 - fn: 226.0000 - accuracy: 0.7574 - precision: 0.3936 - recall: 0.4322 - auc: 0.7189 - prc: 0.4230 - val_loss: 0.5127 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6863 - val_prc: 0.4020\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7604 - tp: 165.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 233.0000 - accuracy: 0.7841 - precision: 0.4472 - recall: 0.4146 - auc: 0.7181 - prc: 0.4273 - val_loss: 0.5446 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6852 - val_prc: 0.3925\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7645 - tp: 160.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 238.0000 - accuracy: 0.7708 - precision: 0.4145 - recall: 0.4020 - auc: 0.7141 - prc: 0.4269 - val_loss: 0.5234 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6861 - val_prc: 0.3925\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7621 - tp: 162.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 236.0000 - accuracy: 0.7683 - precision: 0.4101 - recall: 0.4070 - auc: 0.7192 - prc: 0.4251 - val_loss: 0.5248 - val_tp: 38.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 53.0000 - val_accuracy: 0.7668 - val_precision: 0.3689 - val_recall: 0.4176 - val_auc: 0.6858 - val_prc: 0.4034\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7637 - tp: 163.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 235.0000 - accuracy: 0.7767 - precision: 0.4289 - recall: 0.4095 - auc: 0.7164 - prc: 0.4281 - val_loss: 0.4924 - val_tp: 33.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 58.0000 - val_accuracy: 0.7925 - val_precision: 0.4125 - val_recall: 0.3626 - val_auc: 0.6863 - val_prc: 0.4121\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7609 - tp: 170.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 228.0000 - accuracy: 0.7688 - precision: 0.4146 - recall: 0.4271 - auc: 0.7191 - prc: 0.4328 - val_loss: 0.4624 - val_tp: 25.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 66.0000 - val_accuracy: 0.8340 - val_precision: 0.5814 - val_recall: 0.2747 - val_auc: 0.6880 - val_prc: 0.4144\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7637 - tp: 158.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 240.0000 - accuracy: 0.7727 - precision: 0.4180 - recall: 0.3970 - auc: 0.7144 - prc: 0.4223 - val_loss: 0.5069 - val_tp: 36.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 55.0000 - val_accuracy: 0.7846 - val_precision: 0.4000 - val_recall: 0.3956 - val_auc: 0.6869 - val_prc: 0.4132\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7602 - tp: 157.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 241.0000 - accuracy: 0.7742 - precision: 0.4209 - recall: 0.3945 - auc: 0.7193 - prc: 0.4298 - val_loss: 0.4831 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6864 - val_prc: 0.4122\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7642 - tp: 157.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 241.0000 - accuracy: 0.7762 - precision: 0.4255 - recall: 0.3945 - auc: 0.7132 - prc: 0.4314 - val_loss: 0.5370 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6855 - val_prc: 0.3909\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7606 - tp: 164.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 234.0000 - accuracy: 0.7727 - precision: 0.4205 - recall: 0.4121 - auc: 0.7174 - prc: 0.4332 - val_loss: 0.4798 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6870 - val_prc: 0.4116\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7599 - tp: 161.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 237.0000 - accuracy: 0.7712 - precision: 0.4160 - recall: 0.4045 - auc: 0.7192 - prc: 0.4390 - val_loss: 0.5188 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6863 - val_prc: 0.4030\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7610 - tp: 170.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 228.0000 - accuracy: 0.7628 - precision: 0.4028 - recall: 0.4271 - auc: 0.7166 - prc: 0.4253 - val_loss: 0.5416 - val_tp: 43.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 48.0000 - val_accuracy: 0.7470 - val_precision: 0.3496 - val_recall: 0.4725 - val_auc: 0.6858 - val_prc: 0.3897\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7588 - tp: 165.0000 - fp: 235.0000 - tn: 1391.0000 - fn: 233.0000 - accuracy: 0.7688 - precision: 0.4125 - recall: 0.4146 - auc: 0.7217 - prc: 0.4266 - val_loss: 0.5174 - val_tp: 38.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 53.0000 - val_accuracy: 0.7787 - val_precision: 0.3918 - val_recall: 0.4176 - val_auc: 0.6864 - val_prc: 0.4029\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7593 - tp: 160.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 238.0000 - accuracy: 0.7752 - precision: 0.4244 - recall: 0.4020 - auc: 0.7199 - prc: 0.4307 - val_loss: 0.5176 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6865 - val_prc: 0.4037\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7587 - tp: 158.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 240.0000 - accuracy: 0.7772 - precision: 0.4282 - recall: 0.3970 - auc: 0.7187 - prc: 0.4356 - val_loss: 0.5702 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6859 - val_prc: 0.3964\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7638 - tp: 162.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 236.0000 - accuracy: 0.7633 - precision: 0.4000 - recall: 0.4070 - auc: 0.7152 - prc: 0.4237 - val_loss: 0.5072 - val_tp: 36.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 55.0000 - val_accuracy: 0.7846 - val_precision: 0.4000 - val_recall: 0.3956 - val_auc: 0.6865 - val_prc: 0.4119\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7598 - tp: 165.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 233.0000 - accuracy: 0.7722 - precision: 0.4198 - recall: 0.4146 - auc: 0.7192 - prc: 0.4263 - val_loss: 0.5060 - val_tp: 36.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 55.0000 - val_accuracy: 0.7846 - val_precision: 0.4000 - val_recall: 0.3956 - val_auc: 0.6870 - val_prc: 0.4131\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7624 - tp: 162.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 236.0000 - accuracy: 0.7782 - precision: 0.4320 - recall: 0.4070 - auc: 0.7145 - prc: 0.4314 - val_loss: 0.5004 - val_tp: 34.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 57.0000 - val_accuracy: 0.7846 - val_precision: 0.3953 - val_recall: 0.3736 - val_auc: 0.6871 - val_prc: 0.4125\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7610 - tp: 167.0000 - fp: 234.0000 - tn: 1392.0000 - fn: 231.0000 - accuracy: 0.7703 - precision: 0.4165 - recall: 0.4196 - auc: 0.7164 - prc: 0.4323 - val_loss: 0.5107 - val_tp: 37.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 54.0000 - val_accuracy: 0.7846 - val_precision: 0.4022 - val_recall: 0.4066 - val_auc: 0.6867 - val_prc: 0.4129\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7606 - tp: 165.0000 - fp: 225.0000 - tn: 1401.0000 - fn: 233.0000 - accuracy: 0.7737 - precision: 0.4231 - recall: 0.4146 - auc: 0.7175 - prc: 0.4322 - val_loss: 0.4841 - val_tp: 30.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 61.0000 - val_accuracy: 0.8004 - val_precision: 0.4286 - val_recall: 0.3297 - val_auc: 0.6865 - val_prc: 0.4117\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7592 - tp: 170.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 228.0000 - accuracy: 0.7747 - precision: 0.4271 - recall: 0.4271 - auc: 0.7197 - prc: 0.4323 - val_loss: 0.5014 - val_tp: 34.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 57.0000 - val_accuracy: 0.7846 - val_precision: 0.3953 - val_recall: 0.3736 - val_auc: 0.6867 - val_prc: 0.4125\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7659 - tp: 150.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 248.0000 - accuracy: 0.7688 - precision: 0.4054 - recall: 0.3769 - auc: 0.7131 - prc: 0.4157 - val_loss: 0.5209 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6855 - val_prc: 0.4019\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7587 - tp: 157.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 241.0000 - accuracy: 0.7816 - precision: 0.4385 - recall: 0.3945 - auc: 0.7201 - prc: 0.4390 - val_loss: 0.5486 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6853 - val_prc: 0.3900\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7596 - tp: 180.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 218.0000 - accuracy: 0.7658 - precision: 0.4128 - recall: 0.4523 - auc: 0.7193 - prc: 0.4288 - val_loss: 0.4889 - val_tp: 32.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 59.0000 - val_accuracy: 0.7984 - val_precision: 0.4267 - val_recall: 0.3516 - val_auc: 0.6876 - val_prc: 0.4130\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7580 - tp: 158.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 240.0000 - accuracy: 0.7801 - precision: 0.4353 - recall: 0.3970 - auc: 0.7207 - prc: 0.4385 - val_loss: 0.5613 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6855 - val_prc: 0.3924\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7613 - tp: 162.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 236.0000 - accuracy: 0.7712 - precision: 0.4165 - recall: 0.4070 - auc: 0.7170 - prc: 0.4359 - val_loss: 0.5115 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6865 - val_prc: 0.4129\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7596 - tp: 159.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 239.0000 - accuracy: 0.7747 - precision: 0.4229 - recall: 0.3995 - auc: 0.7205 - prc: 0.4301 - val_loss: 0.5014 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6867 - val_prc: 0.4127\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7602 - tp: 150.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 248.0000 - accuracy: 0.7717 - precision: 0.4121 - recall: 0.3769 - auc: 0.7208 - prc: 0.4302 - val_loss: 0.5381 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6857 - val_prc: 0.3921\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7594 - tp: 170.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 228.0000 - accuracy: 0.7688 - precision: 0.4146 - recall: 0.4271 - auc: 0.7199 - prc: 0.4268 - val_loss: 0.4986 - val_tp: 34.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 57.0000 - val_accuracy: 0.7866 - val_precision: 0.4000 - val_recall: 0.3736 - val_auc: 0.6864 - val_prc: 0.4126\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7600 - tp: 168.0000 - fp: 239.0000 - tn: 1387.0000 - fn: 230.0000 - accuracy: 0.7683 - precision: 0.4128 - recall: 0.4221 - auc: 0.7192 - prc: 0.4209 - val_loss: 0.5108 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6868 - val_prc: 0.4135\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7625 - tp: 169.0000 - fp: 229.0000 - tn: 1397.0000 - fn: 229.0000 - accuracy: 0.7737 - precision: 0.4246 - recall: 0.4246 - auc: 0.7157 - prc: 0.4109 - val_loss: 0.4925 - val_tp: 34.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 57.0000 - val_accuracy: 0.7925 - val_precision: 0.4146 - val_recall: 0.3736 - val_auc: 0.6868 - val_prc: 0.4125\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7598 - tp: 165.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 233.0000 - accuracy: 0.7752 - precision: 0.4264 - recall: 0.4146 - auc: 0.7170 - prc: 0.4325 - val_loss: 0.4741 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6874 - val_prc: 0.4117\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7620 - tp: 157.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 241.0000 - accuracy: 0.7747 - precision: 0.4220 - recall: 0.3945 - auc: 0.7188 - prc: 0.4272 - val_loss: 0.5150 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6865 - val_prc: 0.4131\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7589 - tp: 167.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 231.0000 - accuracy: 0.7663 - precision: 0.4083 - recall: 0.4196 - auc: 0.7195 - prc: 0.4377 - val_loss: 0.5399 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6866 - val_prc: 0.3928\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7573 - tp: 162.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 236.0000 - accuracy: 0.7767 - precision: 0.4286 - recall: 0.4070 - auc: 0.7217 - prc: 0.4353 - val_loss: 0.5470 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6853 - val_prc: 0.3871\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7578 - tp: 162.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 236.0000 - accuracy: 0.7742 - precision: 0.4230 - recall: 0.4070 - auc: 0.7214 - prc: 0.4292 - val_loss: 0.5484 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6865 - val_prc: 0.3887\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7572 - tp: 167.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 231.0000 - accuracy: 0.7732 - precision: 0.4228 - recall: 0.4196 - auc: 0.7214 - prc: 0.4405 - val_loss: 0.4959 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6871 - val_prc: 0.4124\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7588 - tp: 166.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 232.0000 - accuracy: 0.7767 - precision: 0.4301 - recall: 0.4171 - auc: 0.7201 - prc: 0.4321 - val_loss: 0.5308 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6867 - val_prc: 0.3975\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7589 - tp: 164.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 234.0000 - accuracy: 0.7737 - precision: 0.4227 - recall: 0.4121 - auc: 0.7186 - prc: 0.4284 - val_loss: 0.5326 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6857 - val_prc: 0.3916\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7585 - tp: 165.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 233.0000 - accuracy: 0.7722 - precision: 0.4198 - recall: 0.4146 - auc: 0.7209 - prc: 0.4288 - val_loss: 0.5142 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6873 - val_prc: 0.4139\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7595 - tp: 161.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 237.0000 - accuracy: 0.7708 - precision: 0.4149 - recall: 0.4045 - auc: 0.7191 - prc: 0.4399 - val_loss: 0.5001 - val_tp: 34.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 57.0000 - val_accuracy: 0.7885 - val_precision: 0.4048 - val_recall: 0.3736 - val_auc: 0.6868 - val_prc: 0.4124\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7582 - tp: 155.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 243.0000 - accuracy: 0.7856 - precision: 0.4480 - recall: 0.3894 - auc: 0.7206 - prc: 0.4344 - val_loss: 0.6021 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6866 - val_prc: 0.4052\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7664 - tp: 172.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 226.0000 - accuracy: 0.7520 - precision: 0.3839 - recall: 0.4322 - auc: 0.7132 - prc: 0.4187 - val_loss: 0.5183 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6868 - val_prc: 0.4128\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7568 - tp: 175.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 223.0000 - accuracy: 0.7796 - precision: 0.4397 - recall: 0.4397 - auc: 0.7228 - prc: 0.4300 - val_loss: 0.5218 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6860 - val_prc: 0.4031\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7580 - tp: 165.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 233.0000 - accuracy: 0.7648 - precision: 0.4044 - recall: 0.4146 - auc: 0.7209 - prc: 0.4323 - val_loss: 0.4914 - val_tp: 32.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 59.0000 - val_accuracy: 0.7905 - val_precision: 0.4051 - val_recall: 0.3516 - val_auc: 0.6874 - val_prc: 0.4128\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7601 - tp: 159.0000 - fp: 203.0000 - tn: 1423.0000 - fn: 239.0000 - accuracy: 0.7816 - precision: 0.4392 - recall: 0.3995 - auc: 0.7182 - prc: 0.4379 - val_loss: 0.5116 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6871 - val_prc: 0.4127\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7609 - tp: 162.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 236.0000 - accuracy: 0.7727 - precision: 0.4197 - recall: 0.4070 - auc: 0.7167 - prc: 0.4338 - val_loss: 0.5208 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6865 - val_prc: 0.4127\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7577 - tp: 166.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 232.0000 - accuracy: 0.7732 - precision: 0.4224 - recall: 0.4171 - auc: 0.7208 - prc: 0.4352 - val_loss: 0.5247 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6863 - val_prc: 0.4029\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7618 - tp: 159.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 239.0000 - accuracy: 0.7703 - precision: 0.4130 - recall: 0.3995 - auc: 0.7183 - prc: 0.4203 - val_loss: 0.5280 - val_tp: 40.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 51.0000 - val_accuracy: 0.7648 - val_precision: 0.3704 - val_recall: 0.4396 - val_auc: 0.6860 - val_prc: 0.4020\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7592 - tp: 171.0000 - fp: 235.0000 - tn: 1391.0000 - fn: 227.0000 - accuracy: 0.7717 - precision: 0.4212 - recall: 0.4296 - auc: 0.7194 - prc: 0.4260 - val_loss: 0.5172 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6869 - val_prc: 0.4127\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7578 - tp: 166.0000 - fp: 225.0000 - tn: 1401.0000 - fn: 232.0000 - accuracy: 0.7742 - precision: 0.4246 - recall: 0.4171 - auc: 0.7201 - prc: 0.4313 - val_loss: 0.5003 - val_tp: 34.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 57.0000 - val_accuracy: 0.7806 - val_precision: 0.3864 - val_recall: 0.3736 - val_auc: 0.6863 - val_prc: 0.4109\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7601 - tp: 167.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 231.0000 - accuracy: 0.7796 - precision: 0.4372 - recall: 0.4196 - auc: 0.7175 - prc: 0.4331 - val_loss: 0.4957 - val_tp: 34.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 57.0000 - val_accuracy: 0.7885 - val_precision: 0.4048 - val_recall: 0.3736 - val_auc: 0.6867 - val_prc: 0.4098\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7587 - tp: 164.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 234.0000 - accuracy: 0.7772 - precision: 0.4304 - recall: 0.4121 - auc: 0.7190 - prc: 0.4278 - val_loss: 0.5027 - val_tp: 34.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 57.0000 - val_accuracy: 0.7787 - val_precision: 0.3820 - val_recall: 0.3736 - val_auc: 0.6867 - val_prc: 0.4122\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7612 - tp: 160.0000 - fp: 218.0000 - tn: 1408.0000 - fn: 238.0000 - accuracy: 0.7747 - precision: 0.4233 - recall: 0.4020 - auc: 0.7164 - prc: 0.4290 - val_loss: 0.5530 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6863 - val_prc: 0.3919\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7602 - tp: 167.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 231.0000 - accuracy: 0.7708 - precision: 0.4175 - recall: 0.4196 - auc: 0.7185 - prc: 0.4335 - val_loss: 0.5206 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6862 - val_prc: 0.4118\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.7596 - tp: 163.0000 - fp: 200.0000 - tn: 1426.0000 - fn: 235.0000 - accuracy: 0.7851 - precision: 0.4490 - recall: 0.4095 - auc: 0.7192 - prc: 0.4317Restoring model weights from the end of the best epoch: 194.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7596 - tp: 163.0000 - fp: 200.0000 - tn: 1426.0000 - fn: 235.0000 - accuracy: 0.7851 - precision: 0.4490 - recall: 0.4095 - auc: 0.7192 - prc: 0.4317 - val_loss: 0.5174 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6863 - val_prc: 0.4109\n",
      "Epoch 244: early stopping\n",
      "26/26 [==============================] - 0s 549us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.1272 - tp: 38.0000 - fp: 62.0000 - tn: 1979.0000 - fn: 451.0000 - accuracy: 0.7972 - precision: 0.3800 - recall: 0.0777 - auc: 0.5064 - prc: 0.2345 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1033 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5028 - prc: 0.1953 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0819 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4818 - prc: 0.1876 - val_loss: 0.4796 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0624 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5111 - prc: 0.2030 - val_loss: 0.4838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0456 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5310 - prc: 0.2085 - val_loss: 0.4887 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4898 - prc: 0.1870 - val_loss: 0.4943 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0175 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - prc: 0.1890 - val_loss: 0.5000 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5127 - prc: 0.2024 - val_loss: 0.5054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5148 - val_prc: 0.1844\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9954 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5619 - prc: 0.2182 - val_loss: 0.5022 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6171 - val_prc: 0.2411\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9881 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5189 - prc: 0.2028 - val_loss: 0.5192 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5077 - val_prc: 0.1822\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5322 - prc: 0.2116 - val_loss: 0.5203 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5366 - val_prc: 0.1912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9697 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6406 - prc: 0.2717 - val_loss: 0.5037 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6602 - val_prc: 0.3133\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9611 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6366 - prc: 0.2729 - val_loss: 0.5143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6326 - val_prc: 0.2599\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9584 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6161 - prc: 0.2727 - val_loss: 0.5293 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5996 - val_prc: 0.2263\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9532 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6188 - prc: 0.2553 - val_loss: 0.5141 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6514 - val_prc: 0.2947\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9461 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6613 - prc: 0.3019 - val_loss: 0.5355 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6259 - val_prc: 0.2507\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9404 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6584 - prc: 0.2959 - val_loss: 0.5359 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6375 - val_prc: 0.2652\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9336 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6795 - prc: 0.3296 - val_loss: 0.5363 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6475 - val_prc: 0.2795\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9292 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6862 - prc: 0.3452 - val_loss: 0.5202 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6608 - val_prc: 0.3129\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9309 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6465 - prc: 0.2888 - val_loss: 0.5459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6425 - val_prc: 0.2691\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9216 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6877 - prc: 0.3518 - val_loss: 0.5174 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6606 - val_prc: 0.3130\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6844 - prc: 0.3503 - val_loss: 0.5378 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6557 - val_prc: 0.2915\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9140 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6793 - prc: 0.3128 - val_loss: 0.5399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6552 - val_prc: 0.2902\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6884 - prc: 0.3384 - val_loss: 0.5567 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6504 - val_prc: 0.2791\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9069 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6945 - prc: 0.3605 - val_loss: 0.5604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6513 - val_prc: 0.2806\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6954 - prc: 0.3634 - val_loss: 0.5090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6675 - val_prc: 0.3493\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6902 - prc: 0.3468 - val_loss: 0.5451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6616 - val_prc: 0.3043\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6939 - prc: 0.3550 - val_loss: 0.5406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6619 - val_prc: 0.3057\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8960 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6960 - prc: 0.3623 - val_loss: 0.5734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6551 - val_prc: 0.2858\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8937 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6977 - prc: 0.3635 - val_loss: 0.5484 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6627 - val_prc: 0.3051\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6973 - prc: 0.3586 - val_loss: 0.5114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6704 - val_prc: 0.3503\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8885 - tp: 101.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 297.0000 - accuracy: 0.7979 - precision: 0.4742 - recall: 0.2538 - auc: 0.6986 - prc: 0.3839 - val_loss: 0.5302 - val_tp: 26.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 65.0000 - val_accuracy: 0.8024 - val_precision: 0.4262 - val_recall: 0.2857 - val_auc: 0.6675 - val_prc: 0.3229\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8845 - tp: 152.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 246.0000 - accuracy: 0.7841 - precision: 0.4431 - recall: 0.3819 - auc: 0.7002 - prc: 0.3490 - val_loss: 0.4842 - val_tp: 5.0000 - val_fp: 3.0000 - val_tn: 412.0000 - val_fn: 86.0000 - val_accuracy: 0.8241 - val_precision: 0.6250 - val_recall: 0.0549 - val_auc: 0.6714 - val_prc: 0.3679\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8866 - tp: 139.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 259.0000 - accuracy: 0.7836 - precision: 0.4371 - recall: 0.3492 - auc: 0.6948 - prc: 0.3619 - val_loss: 0.5181 - val_tp: 23.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 68.0000 - val_accuracy: 0.8063 - val_precision: 0.4340 - val_recall: 0.2527 - val_auc: 0.6705 - val_prc: 0.3378\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8843 - tp: 140.0000 - fp: 190.0000 - tn: 1436.0000 - fn: 258.0000 - accuracy: 0.7787 - precision: 0.4242 - recall: 0.3518 - auc: 0.6962 - prc: 0.3599 - val_loss: 0.5479 - val_tp: 36.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 55.0000 - val_accuracy: 0.7727 - val_precision: 0.3750 - val_recall: 0.3956 - val_auc: 0.6687 - val_prc: 0.3220\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8797 - tp: 154.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 244.0000 - accuracy: 0.7826 - precision: 0.4400 - recall: 0.3869 - auc: 0.7016 - prc: 0.3572 - val_loss: 0.5254 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6713 - val_prc: 0.3353\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8809 - tp: 155.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 243.0000 - accuracy: 0.7767 - precision: 0.4258 - recall: 0.3894 - auc: 0.7006 - prc: 0.3677 - val_loss: 0.5754 - val_tp: 48.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 43.0000 - val_accuracy: 0.7273 - val_precision: 0.3357 - val_recall: 0.5275 - val_auc: 0.6633 - val_prc: 0.3009\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8814 - tp: 172.0000 - fp: 249.0000 - tn: 1377.0000 - fn: 226.0000 - accuracy: 0.7653 - precision: 0.4086 - recall: 0.4322 - auc: 0.6940 - prc: 0.3516 - val_loss: 0.5371 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6698 - val_prc: 0.3216\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8752 - tp: 165.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 233.0000 - accuracy: 0.7732 - precision: 0.4220 - recall: 0.4146 - auc: 0.7057 - prc: 0.3669 - val_loss: 0.5113 - val_tp: 25.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 66.0000 - val_accuracy: 0.8083 - val_precision: 0.4464 - val_recall: 0.2747 - val_auc: 0.6745 - val_prc: 0.3582\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8776 - tp: 152.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 246.0000 - accuracy: 0.7856 - precision: 0.4471 - recall: 0.3819 - auc: 0.6985 - prc: 0.3572 - val_loss: 0.5550 - val_tp: 41.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 50.0000 - val_accuracy: 0.7569 - val_precision: 0.3596 - val_recall: 0.4505 - val_auc: 0.6692 - val_prc: 0.3203\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8740 - tp: 174.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 224.0000 - accuracy: 0.7638 - precision: 0.4065 - recall: 0.4372 - auc: 0.7039 - prc: 0.3738 - val_loss: 0.5190 - val_tp: 30.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 61.0000 - val_accuracy: 0.7984 - val_precision: 0.4225 - val_recall: 0.3297 - val_auc: 0.6743 - val_prc: 0.3454\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8716 - tp: 160.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 238.0000 - accuracy: 0.7777 - precision: 0.4301 - recall: 0.4020 - auc: 0.7061 - prc: 0.3855 - val_loss: 0.5656 - val_tp: 43.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 48.0000 - val_accuracy: 0.7332 - val_precision: 0.3308 - val_recall: 0.4725 - val_auc: 0.6696 - val_prc: 0.3176\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8714 - tp: 153.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 245.0000 - accuracy: 0.7777 - precision: 0.4274 - recall: 0.3844 - auc: 0.7072 - prc: 0.3740 - val_loss: 0.6079 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6574 - val_prc: 0.2846\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8715 - tp: 180.0000 - fp: 274.0000 - tn: 1352.0000 - fn: 218.0000 - accuracy: 0.7569 - precision: 0.3965 - recall: 0.4523 - auc: 0.7029 - prc: 0.3638 - val_loss: 0.5778 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6703 - val_prc: 0.3152\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8715 - tp: 185.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 213.0000 - accuracy: 0.7624 - precision: 0.4084 - recall: 0.4648 - auc: 0.7012 - prc: 0.3616 - val_loss: 0.5682 - val_tp: 44.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 47.0000 - val_accuracy: 0.7233 - val_precision: 0.3212 - val_recall: 0.4835 - val_auc: 0.6713 - val_prc: 0.3216\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8677 - tp: 165.0000 - fp: 231.0000 - tn: 1395.0000 - fn: 233.0000 - accuracy: 0.7708 - precision: 0.4167 - recall: 0.4146 - auc: 0.7072 - prc: 0.3764 - val_loss: 0.5322 - val_tp: 39.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 52.0000 - val_accuracy: 0.7806 - val_precision: 0.3980 - val_recall: 0.4286 - val_auc: 0.6760 - val_prc: 0.3417\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8655 - tp: 178.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 220.0000 - accuracy: 0.7668 - precision: 0.4140 - recall: 0.4472 - auc: 0.7094 - prc: 0.3794 - val_loss: 0.5425 - val_tp: 39.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 52.0000 - val_accuracy: 0.7668 - val_precision: 0.3714 - val_recall: 0.4286 - val_auc: 0.6762 - val_prc: 0.3407\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8669 - tp: 180.0000 - fp: 265.0000 - tn: 1361.0000 - fn: 218.0000 - accuracy: 0.7614 - precision: 0.4045 - recall: 0.4523 - auc: 0.7066 - prc: 0.3682 - val_loss: 0.5829 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6704 - val_prc: 0.3149\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8648 - tp: 178.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 220.0000 - accuracy: 0.7535 - precision: 0.3895 - recall: 0.4472 - auc: 0.7097 - prc: 0.3765 - val_loss: 0.4858 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6769 - val_prc: 0.3793\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8643 - tp: 196.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 202.0000 - accuracy: 0.7594 - precision: 0.4075 - recall: 0.4925 - auc: 0.7047 - prc: 0.3658 - val_loss: 0.5307 - val_tp: 39.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 52.0000 - val_accuracy: 0.7767 - val_precision: 0.3900 - val_recall: 0.4286 - val_auc: 0.6773 - val_prc: 0.3515\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8674 - tp: 174.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 224.0000 - accuracy: 0.7673 - precision: 0.4133 - recall: 0.4372 - auc: 0.7044 - prc: 0.3850 - val_loss: 0.5182 - val_tp: 37.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 54.0000 - val_accuracy: 0.7964 - val_precision: 0.4302 - val_recall: 0.4066 - val_auc: 0.6779 - val_prc: 0.3641\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8650 - tp: 181.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 217.0000 - accuracy: 0.7609 - precision: 0.4040 - recall: 0.4548 - auc: 0.7045 - prc: 0.3748 - val_loss: 0.4928 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6771 - val_prc: 0.3775\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8624 - tp: 184.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 214.0000 - accuracy: 0.7549 - precision: 0.3948 - recall: 0.4623 - auc: 0.7083 - prc: 0.3836 - val_loss: 0.5612 - val_tp: 44.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 47.0000 - val_accuracy: 0.7332 - val_precision: 0.3333 - val_recall: 0.4835 - val_auc: 0.6751 - val_prc: 0.3336\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8653 - tp: 179.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 219.0000 - accuracy: 0.7544 - precision: 0.3917 - recall: 0.4497 - auc: 0.7037 - prc: 0.3759 - val_loss: 0.5141 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6782 - val_prc: 0.3713\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8620 - tp: 182.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 216.0000 - accuracy: 0.7456 - precision: 0.3784 - recall: 0.4573 - auc: 0.7080 - prc: 0.3783 - val_loss: 0.5190 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 54.0000 - val_accuracy: 0.7905 - val_precision: 0.4157 - val_recall: 0.4066 - val_auc: 0.6784 - val_prc: 0.3733\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8621 - tp: 173.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 225.0000 - accuracy: 0.7594 - precision: 0.3977 - recall: 0.4347 - auc: 0.7080 - prc: 0.3836 - val_loss: 0.5477 - val_tp: 41.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 50.0000 - val_accuracy: 0.7549 - val_precision: 0.3565 - val_recall: 0.4505 - val_auc: 0.6766 - val_prc: 0.3482\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8661 - tp: 195.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 203.0000 - accuracy: 0.7436 - precision: 0.3816 - recall: 0.4899 - auc: 0.7005 - prc: 0.3582 - val_loss: 0.5453 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6774 - val_prc: 0.3492\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8582 - tp: 191.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 207.0000 - accuracy: 0.7480 - precision: 0.3866 - recall: 0.4799 - auc: 0.7113 - prc: 0.3676 - val_loss: 0.6429 - val_tp: 63.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 28.0000 - val_accuracy: 0.5929 - val_precision: 0.2614 - val_recall: 0.6923 - val_auc: 0.6625 - val_prc: 0.2916\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8608 - tp: 189.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 209.0000 - accuracy: 0.7505 - precision: 0.3897 - recall: 0.4749 - auc: 0.7078 - prc: 0.3872 - val_loss: 0.5501 - val_tp: 41.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 50.0000 - val_accuracy: 0.7431 - val_precision: 0.3388 - val_recall: 0.4505 - val_auc: 0.6774 - val_prc: 0.3487\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8571 - tp: 182.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 216.0000 - accuracy: 0.7609 - precision: 0.4044 - recall: 0.4573 - auc: 0.7115 - prc: 0.3751 - val_loss: 0.6104 - val_tp: 57.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 34.0000 - val_accuracy: 0.6680 - val_precision: 0.2984 - val_recall: 0.6264 - val_auc: 0.6700 - val_prc: 0.3113\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8598 - tp: 189.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 209.0000 - accuracy: 0.7544 - precision: 0.3962 - recall: 0.4749 - auc: 0.7100 - prc: 0.3940 - val_loss: 0.5409 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6789 - val_prc: 0.3496\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8570 - tp: 187.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 211.0000 - accuracy: 0.7426 - precision: 0.3763 - recall: 0.4698 - auc: 0.7120 - prc: 0.3742 - val_loss: 0.5272 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6801 - val_prc: 0.3651\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8556 - tp: 190.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 208.0000 - accuracy: 0.7500 - precision: 0.3893 - recall: 0.4774 - auc: 0.7127 - prc: 0.3812 - val_loss: 0.6099 - val_tp: 57.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 34.0000 - val_accuracy: 0.6700 - val_precision: 0.3000 - val_recall: 0.6264 - val_auc: 0.6712 - val_prc: 0.3160\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8575 - tp: 197.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 201.0000 - accuracy: 0.7480 - precision: 0.3893 - recall: 0.4950 - auc: 0.7102 - prc: 0.3848 - val_loss: 0.5386 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6796 - val_prc: 0.3525\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8579 - tp: 187.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 211.0000 - accuracy: 0.7451 - precision: 0.3801 - recall: 0.4698 - auc: 0.7084 - prc: 0.3747 - val_loss: 0.5259 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6801 - val_prc: 0.3712\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8589 - tp: 186.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 212.0000 - accuracy: 0.7544 - precision: 0.3949 - recall: 0.4673 - auc: 0.7071 - prc: 0.3812 - val_loss: 0.5219 - val_tp: 38.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 53.0000 - val_accuracy: 0.7767 - val_precision: 0.3878 - val_recall: 0.4176 - val_auc: 0.6802 - val_prc: 0.3752\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8565 - tp: 187.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 211.0000 - accuracy: 0.7500 - precision: 0.3880 - recall: 0.4698 - auc: 0.7088 - prc: 0.3805 - val_loss: 0.5772 - val_tp: 44.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 47.0000 - val_accuracy: 0.7055 - val_precision: 0.3014 - val_recall: 0.4835 - val_auc: 0.6773 - val_prc: 0.3350\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8540 - tp: 192.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 206.0000 - accuracy: 0.7485 - precision: 0.3879 - recall: 0.4824 - auc: 0.7123 - prc: 0.3850 - val_loss: 0.6357 - val_tp: 62.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 29.0000 - val_accuracy: 0.6225 - val_precision: 0.2768 - val_recall: 0.6813 - val_auc: 0.6699 - val_prc: 0.3095\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8568 - tp: 200.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 198.0000 - accuracy: 0.7446 - precision: 0.3854 - recall: 0.5025 - auc: 0.7088 - prc: 0.3877 - val_loss: 0.5255 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6816 - val_prc: 0.3763\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8534 - tp: 194.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 204.0000 - accuracy: 0.7495 - precision: 0.3903 - recall: 0.4874 - auc: 0.7110 - prc: 0.3818 - val_loss: 0.5754 - val_tp: 44.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 47.0000 - val_accuracy: 0.7055 - val_precision: 0.3014 - val_recall: 0.4835 - val_auc: 0.6772 - val_prc: 0.3354\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8511 - tp: 190.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 208.0000 - accuracy: 0.7515 - precision: 0.3918 - recall: 0.4774 - auc: 0.7155 - prc: 0.3941 - val_loss: 0.5246 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6814 - val_prc: 0.3771\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8550 - tp: 195.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 203.0000 - accuracy: 0.7441 - precision: 0.3824 - recall: 0.4899 - auc: 0.7101 - prc: 0.3667 - val_loss: 0.5620 - val_tp: 44.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 47.0000 - val_accuracy: 0.7253 - val_precision: 0.3235 - val_recall: 0.4835 - val_auc: 0.6796 - val_prc: 0.3523\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8529 - tp: 193.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 205.0000 - accuracy: 0.7535 - precision: 0.3963 - recall: 0.4849 - auc: 0.7119 - prc: 0.3994 - val_loss: 0.5503 - val_tp: 41.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 50.0000 - val_accuracy: 0.7451 - val_precision: 0.3417 - val_recall: 0.4505 - val_auc: 0.6815 - val_prc: 0.3597\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8542 - tp: 185.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 213.0000 - accuracy: 0.7554 - precision: 0.3961 - recall: 0.4648 - auc: 0.7095 - prc: 0.3976 - val_loss: 0.5461 - val_tp: 41.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 50.0000 - val_accuracy: 0.7490 - val_precision: 0.3475 - val_recall: 0.4505 - val_auc: 0.6815 - val_prc: 0.3680\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8552 - tp: 187.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 211.0000 - accuracy: 0.7540 - precision: 0.3945 - recall: 0.4698 - auc: 0.7108 - prc: 0.3981 - val_loss: 0.5365 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6830 - val_prc: 0.3781\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8512 - tp: 192.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 206.0000 - accuracy: 0.7569 - precision: 0.4017 - recall: 0.4824 - auc: 0.7137 - prc: 0.3940 - val_loss: 0.5243 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6837 - val_prc: 0.3788\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8563 - tp: 195.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 203.0000 - accuracy: 0.7342 - precision: 0.3679 - recall: 0.4899 - auc: 0.7088 - prc: 0.3773 - val_loss: 0.5837 - val_tp: 47.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 44.0000 - val_accuracy: 0.7055 - val_precision: 0.3092 - val_recall: 0.5165 - val_auc: 0.6777 - val_prc: 0.3375\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8537 - tp: 192.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 206.0000 - accuracy: 0.7515 - precision: 0.3926 - recall: 0.4824 - auc: 0.7095 - prc: 0.3871 - val_loss: 0.6170 - val_tp: 57.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 34.0000 - val_accuracy: 0.6621 - val_precision: 0.2938 - val_recall: 0.6264 - val_auc: 0.6770 - val_prc: 0.3359\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8477 - tp: 213.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 185.0000 - accuracy: 0.7456 - precision: 0.3923 - recall: 0.5352 - auc: 0.7181 - prc: 0.3943 - val_loss: 0.4963 - val_tp: 35.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 56.0000 - val_accuracy: 0.8043 - val_precision: 0.4487 - val_recall: 0.3846 - val_auc: 0.6832 - val_prc: 0.3862\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8505 - tp: 194.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 204.0000 - accuracy: 0.7574 - precision: 0.4033 - recall: 0.4874 - auc: 0.7149 - prc: 0.4035 - val_loss: 0.5199 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6845 - val_prc: 0.3804\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8495 - tp: 194.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 204.0000 - accuracy: 0.7505 - precision: 0.3919 - recall: 0.4874 - auc: 0.7137 - prc: 0.3963 - val_loss: 0.5439 - val_tp: 41.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 50.0000 - val_accuracy: 0.7490 - val_precision: 0.3475 - val_recall: 0.4505 - val_auc: 0.6824 - val_prc: 0.3760\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8508 - tp: 184.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 214.0000 - accuracy: 0.7520 - precision: 0.3898 - recall: 0.4623 - auc: 0.7131 - prc: 0.4061 - val_loss: 0.5743 - val_tp: 45.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 46.0000 - val_accuracy: 0.7095 - val_precision: 0.3082 - val_recall: 0.4945 - val_auc: 0.6797 - val_prc: 0.3519\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8489 - tp: 190.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 208.0000 - accuracy: 0.7475 - precision: 0.3854 - recall: 0.4774 - auc: 0.7158 - prc: 0.4004 - val_loss: 0.5599 - val_tp: 43.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 48.0000 - val_accuracy: 0.7312 - val_precision: 0.3282 - val_recall: 0.4725 - val_auc: 0.6801 - val_prc: 0.3591\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8495 - tp: 189.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 209.0000 - accuracy: 0.7515 - precision: 0.3913 - recall: 0.4749 - auc: 0.7154 - prc: 0.4118 - val_loss: 0.5970 - val_tp: 52.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 39.0000 - val_accuracy: 0.7055 - val_precision: 0.3210 - val_recall: 0.5714 - val_auc: 0.6779 - val_prc: 0.3397\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8562 - tp: 195.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 203.0000 - accuracy: 0.7480 - precision: 0.3884 - recall: 0.4899 - auc: 0.7075 - prc: 0.3844 - val_loss: 0.6238 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.6774 - val_prc: 0.3367\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8485 - tp: 197.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 201.0000 - accuracy: 0.7500 - precision: 0.3924 - recall: 0.4950 - auc: 0.7157 - prc: 0.3969 - val_loss: 0.5465 - val_tp: 41.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 50.0000 - val_accuracy: 0.7451 - val_precision: 0.3417 - val_recall: 0.4505 - val_auc: 0.6822 - val_prc: 0.3836\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8552 - tp: 183.0000 - fp: 322.0000 - tn: 1304.0000 - fn: 215.0000 - accuracy: 0.7347 - precision: 0.3624 - recall: 0.4598 - auc: 0.7085 - prc: 0.3871 - val_loss: 0.5671 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6818 - val_prc: 0.3616\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8556 - tp: 194.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 204.0000 - accuracy: 0.7470 - precision: 0.3865 - recall: 0.4874 - auc: 0.7075 - prc: 0.3860 - val_loss: 0.4924 - val_tp: 31.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 60.0000 - val_accuracy: 0.8004 - val_precision: 0.4306 - val_recall: 0.3407 - val_auc: 0.6841 - val_prc: 0.3888\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8500 - tp: 179.0000 - fp: 274.0000 - tn: 1352.0000 - fn: 219.0000 - accuracy: 0.7564 - precision: 0.3951 - recall: 0.4497 - auc: 0.7144 - prc: 0.4089 - val_loss: 0.5791 - val_tp: 45.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 46.0000 - val_accuracy: 0.7055 - val_precision: 0.3041 - val_recall: 0.4945 - val_auc: 0.6802 - val_prc: 0.3558\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8512 - tp: 194.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 204.0000 - accuracy: 0.7411 - precision: 0.3774 - recall: 0.4874 - auc: 0.7101 - prc: 0.3756 - val_loss: 0.6016 - val_tp: 52.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 39.0000 - val_accuracy: 0.6917 - val_precision: 0.3077 - val_recall: 0.5714 - val_auc: 0.6777 - val_prc: 0.3367\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8477 - tp: 185.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 213.0000 - accuracy: 0.7574 - precision: 0.3996 - recall: 0.4648 - auc: 0.7158 - prc: 0.4039 - val_loss: 0.6197 - val_tp: 57.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 34.0000 - val_accuracy: 0.6640 - val_precision: 0.2953 - val_recall: 0.6264 - val_auc: 0.6757 - val_prc: 0.3310\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8497 - tp: 189.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 209.0000 - accuracy: 0.7470 - precision: 0.3841 - recall: 0.4749 - auc: 0.7130 - prc: 0.4094 - val_loss: 0.5696 - val_tp: 45.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 46.0000 - val_accuracy: 0.7174 - val_precision: 0.3169 - val_recall: 0.4945 - val_auc: 0.6811 - val_prc: 0.3609\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8486 - tp: 194.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 204.0000 - accuracy: 0.7421 - precision: 0.3789 - recall: 0.4874 - auc: 0.7161 - prc: 0.4025 - val_loss: 0.5618 - val_tp: 44.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 47.0000 - val_accuracy: 0.7332 - val_precision: 0.3333 - val_recall: 0.4835 - val_auc: 0.6825 - val_prc: 0.3839\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8517 - tp: 185.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 213.0000 - accuracy: 0.7569 - precision: 0.3987 - recall: 0.4648 - auc: 0.7114 - prc: 0.4025 - val_loss: 0.6030 - val_tp: 53.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 38.0000 - val_accuracy: 0.6937 - val_precision: 0.3118 - val_recall: 0.5824 - val_auc: 0.6778 - val_prc: 0.3387\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8500 - tp: 194.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 204.0000 - accuracy: 0.7535 - precision: 0.3967 - recall: 0.4874 - auc: 0.7134 - prc: 0.4100 - val_loss: 0.5313 - val_tp: 39.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 52.0000 - val_accuracy: 0.7589 - val_precision: 0.3578 - val_recall: 0.4286 - val_auc: 0.6821 - val_prc: 0.3878\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8467 - tp: 186.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 212.0000 - accuracy: 0.7520 - precision: 0.3908 - recall: 0.4673 - auc: 0.7152 - prc: 0.4087 - val_loss: 0.5814 - val_tp: 45.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 46.0000 - val_accuracy: 0.7036 - val_precision: 0.3020 - val_recall: 0.4945 - val_auc: 0.6805 - val_prc: 0.3595\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8496 - tp: 189.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 209.0000 - accuracy: 0.7530 - precision: 0.3938 - recall: 0.4749 - auc: 0.7114 - prc: 0.4103 - val_loss: 0.5581 - val_tp: 44.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 47.0000 - val_accuracy: 0.7391 - val_precision: 0.3411 - val_recall: 0.4835 - val_auc: 0.6819 - val_prc: 0.3786\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8446 - tp: 201.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 197.0000 - accuracy: 0.7505 - precision: 0.3949 - recall: 0.5050 - auc: 0.7169 - prc: 0.4068 - val_loss: 0.5568 - val_tp: 42.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 49.0000 - val_accuracy: 0.7372 - val_precision: 0.3333 - val_recall: 0.4615 - val_auc: 0.6832 - val_prc: 0.3800\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8471 - tp: 201.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 197.0000 - accuracy: 0.7460 - precision: 0.3880 - recall: 0.5050 - auc: 0.7161 - prc: 0.4165 - val_loss: 0.4909 - val_tp: 31.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 60.0000 - val_accuracy: 0.8043 - val_precision: 0.4429 - val_recall: 0.3407 - val_auc: 0.6857 - val_prc: 0.4034\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8516 - tp: 187.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 211.0000 - accuracy: 0.7544 - precision: 0.3953 - recall: 0.4698 - auc: 0.7108 - prc: 0.3999 - val_loss: 0.5159 - val_tp: 37.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 54.0000 - val_accuracy: 0.7826 - val_precision: 0.3978 - val_recall: 0.4066 - val_auc: 0.6848 - val_prc: 0.3893\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8466 - tp: 211.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 187.0000 - accuracy: 0.7451 - precision: 0.3907 - recall: 0.5302 - auc: 0.7178 - prc: 0.4012 - val_loss: 0.4858 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6853 - val_prc: 0.4024\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8505 - tp: 190.0000 - fp: 281.0000 - tn: 1345.0000 - fn: 208.0000 - accuracy: 0.7584 - precision: 0.4034 - recall: 0.4774 - auc: 0.7108 - prc: 0.4092 - val_loss: 0.5776 - val_tp: 45.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 46.0000 - val_accuracy: 0.7055 - val_precision: 0.3041 - val_recall: 0.4945 - val_auc: 0.6813 - val_prc: 0.3684\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8470 - tp: 193.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 205.0000 - accuracy: 0.7446 - precision: 0.3822 - recall: 0.4849 - auc: 0.7143 - prc: 0.4062 - val_loss: 0.5146 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6852 - val_prc: 0.3903\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8459 - tp: 181.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 217.0000 - accuracy: 0.7564 - precision: 0.3961 - recall: 0.4548 - auc: 0.7172 - prc: 0.4204 - val_loss: 0.5820 - val_tp: 45.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 46.0000 - val_accuracy: 0.7036 - val_precision: 0.3020 - val_recall: 0.4945 - val_auc: 0.6823 - val_prc: 0.3767\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8506 - tp: 201.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 197.0000 - accuracy: 0.7470 - precision: 0.3895 - recall: 0.5050 - auc: 0.7108 - prc: 0.3856 - val_loss: 0.6149 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6793 - val_prc: 0.3486\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8478 - tp: 195.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 203.0000 - accuracy: 0.7396 - precision: 0.3757 - recall: 0.4899 - auc: 0.7138 - prc: 0.4047 - val_loss: 0.5863 - val_tp: 47.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 44.0000 - val_accuracy: 0.7055 - val_precision: 0.3092 - val_recall: 0.5165 - val_auc: 0.6813 - val_prc: 0.3632\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8473 - tp: 207.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 191.0000 - accuracy: 0.7490 - precision: 0.3950 - recall: 0.5201 - auc: 0.7138 - prc: 0.3958 - val_loss: 0.5276 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6847 - val_prc: 0.3804\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8477 - tp: 189.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 209.0000 - accuracy: 0.7465 - precision: 0.3834 - recall: 0.4749 - auc: 0.7140 - prc: 0.4116 - val_loss: 0.5350 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6840 - val_prc: 0.3799\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8496 - tp: 196.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 202.0000 - accuracy: 0.7540 - precision: 0.3984 - recall: 0.4925 - auc: 0.7127 - prc: 0.3967 - val_loss: 0.6061 - val_tp: 53.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 38.0000 - val_accuracy: 0.6917 - val_precision: 0.3099 - val_recall: 0.5824 - val_auc: 0.6804 - val_prc: 0.3562\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8505 - tp: 192.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 206.0000 - accuracy: 0.7411 - precision: 0.3765 - recall: 0.4824 - auc: 0.7118 - prc: 0.4036 - val_loss: 0.5665 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6829 - val_prc: 0.3800\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8454 - tp: 193.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 205.0000 - accuracy: 0.7505 - precision: 0.3915 - recall: 0.4849 - auc: 0.7168 - prc: 0.4363 - val_loss: 0.5230 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6841 - val_prc: 0.3917\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8475 - tp: 187.0000 - fp: 284.0000 - tn: 1342.0000 - fn: 211.0000 - accuracy: 0.7554 - precision: 0.3970 - recall: 0.4698 - auc: 0.7140 - prc: 0.4058 - val_loss: 0.5735 - val_tp: 45.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 46.0000 - val_accuracy: 0.7115 - val_precision: 0.3103 - val_recall: 0.4945 - val_auc: 0.6831 - val_prc: 0.3822\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8445 - tp: 179.0000 - fp: 277.0000 - tn: 1349.0000 - fn: 219.0000 - accuracy: 0.7549 - precision: 0.3925 - recall: 0.4497 - auc: 0.7186 - prc: 0.4226 - val_loss: 0.5961 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6815 - val_prc: 0.3672\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8444 - tp: 188.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 210.0000 - accuracy: 0.7535 - precision: 0.3941 - recall: 0.4724 - auc: 0.7174 - prc: 0.4165 - val_loss: 0.5781 - val_tp: 46.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 45.0000 - val_accuracy: 0.7075 - val_precision: 0.3087 - val_recall: 0.5055 - val_auc: 0.6828 - val_prc: 0.3867\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8478 - tp: 199.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 199.0000 - accuracy: 0.7386 - precision: 0.3762 - recall: 0.5000 - auc: 0.7125 - prc: 0.4068 - val_loss: 0.5749 - val_tp: 45.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 46.0000 - val_accuracy: 0.7115 - val_precision: 0.3103 - val_recall: 0.4945 - val_auc: 0.6824 - val_prc: 0.3822\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8441 - tp: 187.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 211.0000 - accuracy: 0.7643 - precision: 0.4128 - recall: 0.4698 - auc: 0.7177 - prc: 0.4172 - val_loss: 0.5498 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6840 - val_prc: 0.3909\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8494 - tp: 200.0000 - fp: 353.0000 - tn: 1273.0000 - fn: 198.0000 - accuracy: 0.7278 - precision: 0.3617 - recall: 0.5025 - auc: 0.7141 - prc: 0.3989 - val_loss: 0.4926 - val_tp: 31.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 60.0000 - val_accuracy: 0.8024 - val_precision: 0.4366 - val_recall: 0.3407 - val_auc: 0.6853 - val_prc: 0.4078\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8460 - tp: 189.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 209.0000 - accuracy: 0.7500 - precision: 0.3889 - recall: 0.4749 - auc: 0.7151 - prc: 0.4133 - val_loss: 0.5174 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6845 - val_prc: 0.3922\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8429 - tp: 183.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 215.0000 - accuracy: 0.7609 - precision: 0.4049 - recall: 0.4598 - auc: 0.7193 - prc: 0.4111 - val_loss: 0.6333 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6803 - val_prc: 0.3514\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8412 - tp: 204.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 194.0000 - accuracy: 0.7391 - precision: 0.3792 - recall: 0.5126 - auc: 0.7196 - prc: 0.4168 - val_loss: 0.4769 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6862 - val_prc: 0.4073\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8472 - tp: 191.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 207.0000 - accuracy: 0.7540 - precision: 0.3963 - recall: 0.4799 - auc: 0.7133 - prc: 0.4067 - val_loss: 0.5621 - val_tp: 44.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 47.0000 - val_accuracy: 0.7332 - val_precision: 0.3333 - val_recall: 0.4835 - val_auc: 0.6836 - val_prc: 0.3923\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8464 - tp: 199.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 199.0000 - accuracy: 0.7515 - precision: 0.3956 - recall: 0.5000 - auc: 0.7144 - prc: 0.4105 - val_loss: 0.6079 - val_tp: 53.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 38.0000 - val_accuracy: 0.6858 - val_precision: 0.3046 - val_recall: 0.5824 - val_auc: 0.6818 - val_prc: 0.3674\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8458 - tp: 195.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 203.0000 - accuracy: 0.7436 - precision: 0.3816 - recall: 0.4899 - auc: 0.7136 - prc: 0.4211 - val_loss: 0.4993 - val_tp: 34.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 57.0000 - val_accuracy: 0.7984 - val_precision: 0.4304 - val_recall: 0.3736 - val_auc: 0.6850 - val_prc: 0.4081\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8474 - tp: 176.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 222.0000 - accuracy: 0.7451 - precision: 0.3745 - recall: 0.4422 - auc: 0.7119 - prc: 0.4212 - val_loss: 0.5255 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6847 - val_prc: 0.3945\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8418 - tp: 195.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 203.0000 - accuracy: 0.7470 - precision: 0.3869 - recall: 0.4899 - auc: 0.7199 - prc: 0.4221 - val_loss: 0.5145 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6849 - val_prc: 0.3986\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8456 - tp: 185.0000 - fp: 274.0000 - tn: 1352.0000 - fn: 213.0000 - accuracy: 0.7594 - precision: 0.4031 - recall: 0.4648 - auc: 0.7156 - prc: 0.4121 - val_loss: 0.6089 - val_tp: 54.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 37.0000 - val_accuracy: 0.6858 - val_precision: 0.3068 - val_recall: 0.5934 - val_auc: 0.6816 - val_prc: 0.3669\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8434 - tp: 200.0000 - fp: 328.0000 - tn: 1298.0000 - fn: 198.0000 - accuracy: 0.7401 - precision: 0.3788 - recall: 0.5025 - auc: 0.7169 - prc: 0.4121 - val_loss: 0.5558 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6841 - val_prc: 0.3887\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8450 - tp: 192.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 206.0000 - accuracy: 0.7460 - precision: 0.3840 - recall: 0.4824 - auc: 0.7170 - prc: 0.4219 - val_loss: 0.5122 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6860 - val_prc: 0.3990\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8457 - tp: 188.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 210.0000 - accuracy: 0.7485 - precision: 0.3860 - recall: 0.4724 - auc: 0.7155 - prc: 0.4108 - val_loss: 0.5627 - val_tp: 44.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 47.0000 - val_accuracy: 0.7253 - val_precision: 0.3235 - val_recall: 0.4835 - val_auc: 0.6832 - val_prc: 0.3913\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8435 - tp: 186.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 212.0000 - accuracy: 0.7470 - precision: 0.3827 - recall: 0.4673 - auc: 0.7173 - prc: 0.4181 - val_loss: 0.5651 - val_tp: 44.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 47.0000 - val_accuracy: 0.7233 - val_precision: 0.3212 - val_recall: 0.4835 - val_auc: 0.6839 - val_prc: 0.3926\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8428 - tp: 193.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 205.0000 - accuracy: 0.7406 - precision: 0.3762 - recall: 0.4849 - auc: 0.7172 - prc: 0.4209 - val_loss: 0.5488 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6842 - val_prc: 0.3839\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8411 - tp: 199.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 199.0000 - accuracy: 0.7436 - precision: 0.3834 - recall: 0.5000 - auc: 0.7200 - prc: 0.4155 - val_loss: 0.4931 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6864 - val_prc: 0.4089\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8537 - tp: 179.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 219.0000 - accuracy: 0.7431 - precision: 0.3729 - recall: 0.4497 - auc: 0.7068 - prc: 0.4098 - val_loss: 0.5289 - val_tp: 38.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 53.0000 - val_accuracy: 0.7628 - val_precision: 0.3619 - val_recall: 0.4176 - val_auc: 0.6860 - val_prc: 0.3938\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8413 - tp: 193.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 205.0000 - accuracy: 0.7441 - precision: 0.3814 - recall: 0.4849 - auc: 0.7195 - prc: 0.4262 - val_loss: 0.5231 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6850 - val_prc: 0.3999\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 197.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 201.0000 - accuracy: 0.7490 - precision: 0.3909 - recall: 0.4950 - auc: 0.7213 - prc: 0.4168 - val_loss: 0.4895 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6865 - val_prc: 0.4092\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8429 - tp: 188.0000 - fp: 284.0000 - tn: 1342.0000 - fn: 210.0000 - accuracy: 0.7559 - precision: 0.3983 - recall: 0.4724 - auc: 0.7162 - prc: 0.4195 - val_loss: 0.5687 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6844 - val_prc: 0.3926\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8469 - tp: 195.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 203.0000 - accuracy: 0.7564 - precision: 0.4021 - recall: 0.4899 - auc: 0.7115 - prc: 0.4221 - val_loss: 0.5610 - val_tp: 44.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 47.0000 - val_accuracy: 0.7312 - val_precision: 0.3308 - val_recall: 0.4835 - val_auc: 0.6842 - val_prc: 0.3887\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8456 - tp: 196.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 202.0000 - accuracy: 0.7460 - precision: 0.3858 - recall: 0.4925 - auc: 0.7145 - prc: 0.4123 - val_loss: 0.5631 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6836 - val_prc: 0.3897\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8446 - tp: 190.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 208.0000 - accuracy: 0.7549 - precision: 0.3975 - recall: 0.4774 - auc: 0.7150 - prc: 0.4250 - val_loss: 0.5935 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6833 - val_prc: 0.3835\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8428 - tp: 190.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 208.0000 - accuracy: 0.7480 - precision: 0.3862 - recall: 0.4774 - auc: 0.7174 - prc: 0.4133 - val_loss: 0.5741 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6840 - val_prc: 0.3929\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8422 - tp: 190.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 208.0000 - accuracy: 0.7421 - precision: 0.3770 - recall: 0.4774 - auc: 0.7164 - prc: 0.4264 - val_loss: 0.5503 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6845 - val_prc: 0.3840\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8415 - tp: 192.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 206.0000 - accuracy: 0.7480 - precision: 0.3871 - recall: 0.4824 - auc: 0.7183 - prc: 0.4200 - val_loss: 0.5610 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6840 - val_prc: 0.3884\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8412 - tp: 187.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 211.0000 - accuracy: 0.7564 - precision: 0.3987 - recall: 0.4698 - auc: 0.7190 - prc: 0.4265 - val_loss: 0.6155 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6829 - val_prc: 0.3774\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8469 - tp: 202.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 196.0000 - accuracy: 0.7292 - precision: 0.3646 - recall: 0.5075 - auc: 0.7130 - prc: 0.4042 - val_loss: 0.5641 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6849 - val_prc: 0.3904\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8412 - tp: 193.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 205.0000 - accuracy: 0.7564 - precision: 0.4012 - recall: 0.4849 - auc: 0.7194 - prc: 0.4204 - val_loss: 0.5290 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6877 - val_prc: 0.4007\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8429 - tp: 190.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 208.0000 - accuracy: 0.7470 - precision: 0.3846 - recall: 0.4774 - auc: 0.7166 - prc: 0.4140 - val_loss: 0.5964 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6839 - val_prc: 0.3882\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8440 - tp: 194.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 204.0000 - accuracy: 0.7441 - precision: 0.3819 - recall: 0.4874 - auc: 0.7147 - prc: 0.4176 - val_loss: 0.5451 - val_tp: 43.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 48.0000 - val_accuracy: 0.7510 - val_precision: 0.3554 - val_recall: 0.4725 - val_auc: 0.6846 - val_prc: 0.3870\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8462 - tp: 192.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 206.0000 - accuracy: 0.7431 - precision: 0.3794 - recall: 0.4824 - auc: 0.7128 - prc: 0.4176 - val_loss: 0.5215 - val_tp: 37.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 54.0000 - val_accuracy: 0.7747 - val_precision: 0.3814 - val_recall: 0.4066 - val_auc: 0.6861 - val_prc: 0.4012\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8430 - tp: 196.0000 - fp: 280.0000 - tn: 1346.0000 - fn: 202.0000 - accuracy: 0.7619 - precision: 0.4118 - recall: 0.4925 - auc: 0.7156 - prc: 0.4291 - val_loss: 0.5436 - val_tp: 42.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 49.0000 - val_accuracy: 0.7490 - val_precision: 0.3500 - val_recall: 0.4615 - val_auc: 0.6849 - val_prc: 0.3898\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8440 - tp: 192.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 206.0000 - accuracy: 0.7495 - precision: 0.3895 - recall: 0.4824 - auc: 0.7136 - prc: 0.4281 - val_loss: 0.5763 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6844 - val_prc: 0.3926\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8417 - tp: 196.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 202.0000 - accuracy: 0.7520 - precision: 0.3952 - recall: 0.4925 - auc: 0.7172 - prc: 0.4348 - val_loss: 0.5515 - val_tp: 43.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 48.0000 - val_accuracy: 0.7431 - val_precision: 0.3440 - val_recall: 0.4725 - val_auc: 0.6849 - val_prc: 0.3847\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8434 - tp: 190.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 208.0000 - accuracy: 0.7475 - precision: 0.3854 - recall: 0.4774 - auc: 0.7167 - prc: 0.4145 - val_loss: 0.6033 - val_tp: 52.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 39.0000 - val_accuracy: 0.6917 - val_precision: 0.3077 - val_recall: 0.5714 - val_auc: 0.6840 - val_prc: 0.4012\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8412 - tp: 196.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 202.0000 - accuracy: 0.7495 - precision: 0.3912 - recall: 0.4925 - auc: 0.7183 - prc: 0.4294 - val_loss: 0.5471 - val_tp: 42.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 49.0000 - val_accuracy: 0.7470 - val_precision: 0.3471 - val_recall: 0.4615 - val_auc: 0.6848 - val_prc: 0.3953\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8402 - tp: 189.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 209.0000 - accuracy: 0.7470 - precision: 0.3841 - recall: 0.4749 - auc: 0.7187 - prc: 0.4210 - val_loss: 0.5622 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6842 - val_prc: 0.3889\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8444 - tp: 204.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 194.0000 - accuracy: 0.7372 - precision: 0.3764 - recall: 0.5126 - auc: 0.7136 - prc: 0.4197 - val_loss: 0.4818 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6859 - val_prc: 0.4094\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8440 - tp: 182.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 216.0000 - accuracy: 0.7540 - precision: 0.3922 - recall: 0.4573 - auc: 0.7149 - prc: 0.4275 - val_loss: 0.5847 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6841 - val_prc: 0.3930\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8444 - tp: 196.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 202.0000 - accuracy: 0.7327 - precision: 0.3664 - recall: 0.4925 - auc: 0.7157 - prc: 0.4201 - val_loss: 0.5431 - val_tp: 42.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 49.0000 - val_accuracy: 0.7530 - val_precision: 0.3559 - val_recall: 0.4615 - val_auc: 0.6857 - val_prc: 0.4002\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8429 - tp: 186.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 212.0000 - accuracy: 0.7465 - precision: 0.3819 - recall: 0.4673 - auc: 0.7150 - prc: 0.4227 - val_loss: 0.5903 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6851 - val_prc: 0.3951\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8430 - tp: 182.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 216.0000 - accuracy: 0.7465 - precision: 0.3800 - recall: 0.4573 - auc: 0.7159 - prc: 0.4213 - val_loss: 0.5887 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6845 - val_prc: 0.3944\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8425 - tp: 188.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 210.0000 - accuracy: 0.7470 - precision: 0.3837 - recall: 0.4724 - auc: 0.7172 - prc: 0.4213 - val_loss: 0.5704 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6840 - val_prc: 0.3885\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8408 - tp: 196.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 202.0000 - accuracy: 0.7515 - precision: 0.3944 - recall: 0.4925 - auc: 0.7194 - prc: 0.4212 - val_loss: 0.5920 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6842 - val_prc: 0.3936\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8476 - tp: 192.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 206.0000 - accuracy: 0.7451 - precision: 0.3825 - recall: 0.4824 - auc: 0.7127 - prc: 0.4152 - val_loss: 0.5482 - val_tp: 42.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 49.0000 - val_accuracy: 0.7431 - val_precision: 0.3415 - val_recall: 0.4615 - val_auc: 0.6857 - val_prc: 0.3952\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8386 - tp: 200.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 198.0000 - accuracy: 0.7480 - precision: 0.3906 - recall: 0.5025 - auc: 0.7222 - prc: 0.4264 - val_loss: 0.5100 - val_tp: 37.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 54.0000 - val_accuracy: 0.7885 - val_precision: 0.4111 - val_recall: 0.4066 - val_auc: 0.6861 - val_prc: 0.4100\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8392 - tp: 179.0000 - fp: 271.0000 - tn: 1355.0000 - fn: 219.0000 - accuracy: 0.7579 - precision: 0.3978 - recall: 0.4497 - auc: 0.7189 - prc: 0.4382 - val_loss: 0.5978 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6847 - val_prc: 0.3990\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8411 - tp: 197.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 201.0000 - accuracy: 0.7391 - precision: 0.3760 - recall: 0.4950 - auc: 0.7174 - prc: 0.4305 - val_loss: 0.5044 - val_tp: 35.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 56.0000 - val_accuracy: 0.7905 - val_precision: 0.4118 - val_recall: 0.3846 - val_auc: 0.6859 - val_prc: 0.4094\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8441 - tp: 185.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 213.0000 - accuracy: 0.7535 - precision: 0.3928 - recall: 0.4648 - auc: 0.7131 - prc: 0.4242 - val_loss: 0.5484 - val_tp: 42.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 49.0000 - val_accuracy: 0.7431 - val_precision: 0.3415 - val_recall: 0.4615 - val_auc: 0.6860 - val_prc: 0.3952\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8410 - tp: 196.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 202.0000 - accuracy: 0.7485 - precision: 0.3897 - recall: 0.4925 - auc: 0.7174 - prc: 0.4302 - val_loss: 0.5107 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6867 - val_prc: 0.4100\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8465 - tp: 191.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 207.0000 - accuracy: 0.7391 - precision: 0.3730 - recall: 0.4799 - auc: 0.7113 - prc: 0.4036 - val_loss: 0.5875 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6848 - val_prc: 0.3937\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8437 - tp: 201.0000 - fp: 328.0000 - tn: 1298.0000 - fn: 197.0000 - accuracy: 0.7406 - precision: 0.3800 - recall: 0.5050 - auc: 0.7150 - prc: 0.4217 - val_loss: 0.5652 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6859 - val_prc: 0.3877\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8409 - tp: 189.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 209.0000 - accuracy: 0.7480 - precision: 0.3857 - recall: 0.4749 - auc: 0.7173 - prc: 0.4319 - val_loss: 0.5376 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6860 - val_prc: 0.4011\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8403 - tp: 193.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 205.0000 - accuracy: 0.7465 - precision: 0.3852 - recall: 0.4849 - auc: 0.7186 - prc: 0.4282 - val_loss: 0.5107 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6859 - val_prc: 0.4103\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8437 - tp: 180.0000 - fp: 284.0000 - tn: 1342.0000 - fn: 218.0000 - accuracy: 0.7520 - precision: 0.3879 - recall: 0.4523 - auc: 0.7165 - prc: 0.4244 - val_loss: 0.6455 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.6835 - val_prc: 0.3786\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8409 - tp: 197.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 201.0000 - accuracy: 0.7470 - precision: 0.3878 - recall: 0.4950 - auc: 0.7183 - prc: 0.4232 - val_loss: 0.5570 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6856 - val_prc: 0.3907\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8405 - tp: 190.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 208.0000 - accuracy: 0.7421 - precision: 0.3770 - recall: 0.4774 - auc: 0.7185 - prc: 0.4285 - val_loss: 0.5491 - val_tp: 42.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 49.0000 - val_accuracy: 0.7451 - val_precision: 0.3443 - val_recall: 0.4615 - val_auc: 0.6869 - val_prc: 0.4021\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8425 - tp: 181.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 217.0000 - accuracy: 0.7510 - precision: 0.3868 - recall: 0.4548 - auc: 0.7175 - prc: 0.4142 - val_loss: 0.5765 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6854 - val_prc: 0.3914\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8439 - tp: 193.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 205.0000 - accuracy: 0.7421 - precision: 0.3784 - recall: 0.4849 - auc: 0.7127 - prc: 0.4209 - val_loss: 0.5645 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6862 - val_prc: 0.3900\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8406 - tp: 194.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 204.0000 - accuracy: 0.7465 - precision: 0.3857 - recall: 0.4874 - auc: 0.7176 - prc: 0.4318 - val_loss: 0.5517 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6864 - val_prc: 0.4030\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8396 - tp: 182.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 216.0000 - accuracy: 0.7515 - precision: 0.3881 - recall: 0.4573 - auc: 0.7201 - prc: 0.4277 - val_loss: 0.5979 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6856 - val_prc: 0.3976\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8408 - tp: 205.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 193.0000 - accuracy: 0.7367 - precision: 0.3761 - recall: 0.5151 - auc: 0.7182 - prc: 0.4227 - val_loss: 0.5162 - val_tp: 38.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 53.0000 - val_accuracy: 0.7806 - val_precision: 0.3958 - val_recall: 0.4176 - val_auc: 0.6859 - val_prc: 0.4111\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8428 - tp: 191.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 207.0000 - accuracy: 0.7505 - precision: 0.3906 - recall: 0.4799 - auc: 0.7151 - prc: 0.4277 - val_loss: 0.5484 - val_tp: 43.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 48.0000 - val_accuracy: 0.7470 - val_precision: 0.3496 - val_recall: 0.4725 - val_auc: 0.6858 - val_prc: 0.4031\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8428 - tp: 189.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 209.0000 - accuracy: 0.7520 - precision: 0.3921 - recall: 0.4749 - auc: 0.7168 - prc: 0.4207 - val_loss: 0.6434 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.6834 - val_prc: 0.3768\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8384 - tp: 204.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 194.0000 - accuracy: 0.7470 - precision: 0.3908 - recall: 0.5126 - auc: 0.7204 - prc: 0.4348 - val_loss: 0.4993 - val_tp: 33.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 58.0000 - val_accuracy: 0.7885 - val_precision: 0.4024 - val_recall: 0.3626 - val_auc: 0.6873 - val_prc: 0.4116\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8437 - tp: 183.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 215.0000 - accuracy: 0.7500 - precision: 0.3861 - recall: 0.4598 - auc: 0.7154 - prc: 0.4265 - val_loss: 0.5723 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6861 - val_prc: 0.3927\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8396 - tp: 183.0000 - fp: 277.0000 - tn: 1349.0000 - fn: 215.0000 - accuracy: 0.7569 - precision: 0.3978 - recall: 0.4598 - auc: 0.7190 - prc: 0.4344 - val_loss: 0.6052 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6856 - val_prc: 0.3981\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8436 - tp: 201.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 197.0000 - accuracy: 0.7401 - precision: 0.3792 - recall: 0.5050 - auc: 0.7154 - prc: 0.4231 - val_loss: 0.5329 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6865 - val_prc: 0.4119\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8410 - tp: 201.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 197.0000 - accuracy: 0.7495 - precision: 0.3933 - recall: 0.5050 - auc: 0.7186 - prc: 0.4273 - val_loss: 0.5355 - val_tp: 41.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 50.0000 - val_accuracy: 0.7609 - val_precision: 0.3661 - val_recall: 0.4505 - val_auc: 0.6871 - val_prc: 0.4120\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8383 - tp: 192.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 206.0000 - accuracy: 0.7505 - precision: 0.3910 - recall: 0.4824 - auc: 0.7208 - prc: 0.4301 - val_loss: 0.5458 - val_tp: 42.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 49.0000 - val_accuracy: 0.7451 - val_precision: 0.3443 - val_recall: 0.4615 - val_auc: 0.6858 - val_prc: 0.4024\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8411 - tp: 188.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 210.0000 - accuracy: 0.7525 - precision: 0.3925 - recall: 0.4724 - auc: 0.7164 - prc: 0.4267 - val_loss: 0.5600 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6861 - val_prc: 0.4010\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8390 - tp: 198.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 200.0000 - accuracy: 0.7515 - precision: 0.3952 - recall: 0.4975 - auc: 0.7215 - prc: 0.4233 - val_loss: 0.5040 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6881 - val_prc: 0.4125\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8425 - tp: 188.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 210.0000 - accuracy: 0.7381 - precision: 0.3701 - recall: 0.4724 - auc: 0.7155 - prc: 0.4253 - val_loss: 0.5445 - val_tp: 42.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 49.0000 - val_accuracy: 0.7451 - val_precision: 0.3443 - val_recall: 0.4615 - val_auc: 0.6874 - val_prc: 0.4039\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8404 - tp: 194.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 204.0000 - accuracy: 0.7500 - precision: 0.3911 - recall: 0.4874 - auc: 0.7177 - prc: 0.4279 - val_loss: 0.5274 - val_tp: 38.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 53.0000 - val_accuracy: 0.7668 - val_precision: 0.3689 - val_recall: 0.4176 - val_auc: 0.6876 - val_prc: 0.4121\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8407 - tp: 188.0000 - fp: 284.0000 - tn: 1342.0000 - fn: 210.0000 - accuracy: 0.7559 - precision: 0.3983 - recall: 0.4724 - auc: 0.7174 - prc: 0.4268 - val_loss: 0.5482 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6869 - val_prc: 0.4040\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8420 - tp: 196.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 202.0000 - accuracy: 0.7495 - precision: 0.3912 - recall: 0.4925 - auc: 0.7160 - prc: 0.4259 - val_loss: 0.5936 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6860 - val_prc: 0.3935\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8418 - tp: 184.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 214.0000 - accuracy: 0.7436 - precision: 0.3763 - recall: 0.4623 - auc: 0.7169 - prc: 0.4222 - val_loss: 0.5721 - val_tp: 46.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 45.0000 - val_accuracy: 0.7154 - val_precision: 0.3172 - val_recall: 0.5055 - val_auc: 0.6859 - val_prc: 0.3894\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8417 - tp: 197.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 201.0000 - accuracy: 0.7288 - precision: 0.3615 - recall: 0.4950 - auc: 0.7157 - prc: 0.4313 - val_loss: 0.5656 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6854 - val_prc: 0.4022\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8413 - tp: 192.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 206.0000 - accuracy: 0.7441 - precision: 0.3810 - recall: 0.4824 - auc: 0.7174 - prc: 0.4235 - val_loss: 0.5130 - val_tp: 38.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 53.0000 - val_accuracy: 0.7885 - val_precision: 0.4130 - val_recall: 0.4176 - val_auc: 0.6879 - val_prc: 0.4123\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8380 - tp: 187.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 211.0000 - accuracy: 0.7510 - precision: 0.3896 - recall: 0.4698 - auc: 0.7197 - prc: 0.4352 - val_loss: 0.5841 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6856 - val_prc: 0.3909\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8380 - tp: 198.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 200.0000 - accuracy: 0.7411 - precision: 0.3793 - recall: 0.4975 - auc: 0.7202 - prc: 0.4346 - val_loss: 0.5470 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6864 - val_prc: 0.4032\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8397 - tp: 198.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 200.0000 - accuracy: 0.7465 - precision: 0.3875 - recall: 0.4975 - auc: 0.7184 - prc: 0.4298 - val_loss: 0.5591 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6863 - val_prc: 0.4033\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8427 - tp: 197.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 201.0000 - accuracy: 0.7470 - precision: 0.3878 - recall: 0.4950 - auc: 0.7170 - prc: 0.4228 - val_loss: 0.5725 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6866 - val_prc: 0.3881\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8416 - tp: 189.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 209.0000 - accuracy: 0.7485 - precision: 0.3865 - recall: 0.4749 - auc: 0.7151 - prc: 0.4274 - val_loss: 0.5621 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6872 - val_prc: 0.3965\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8389 - tp: 200.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 198.0000 - accuracy: 0.7465 - precision: 0.3883 - recall: 0.5025 - auc: 0.7182 - prc: 0.4267 - val_loss: 0.5581 - val_tp: 45.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 46.0000 - val_accuracy: 0.7372 - val_precision: 0.3409 - val_recall: 0.4945 - val_auc: 0.6874 - val_prc: 0.4047\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8405 - tp: 188.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 210.0000 - accuracy: 0.7535 - precision: 0.3941 - recall: 0.4724 - auc: 0.7180 - prc: 0.4311 - val_loss: 0.6225 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6857 - val_prc: 0.4043\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8439 - tp: 185.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 213.0000 - accuracy: 0.7401 - precision: 0.3715 - recall: 0.4648 - auc: 0.7128 - prc: 0.4318 - val_loss: 0.5853 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6869 - val_prc: 0.3912\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8388 - tp: 195.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 203.0000 - accuracy: 0.7451 - precision: 0.3839 - recall: 0.4899 - auc: 0.7191 - prc: 0.4308 - val_loss: 0.5631 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6866 - val_prc: 0.3975\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8399 - tp: 187.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 211.0000 - accuracy: 0.7520 - precision: 0.3912 - recall: 0.4698 - auc: 0.7169 - prc: 0.4290 - val_loss: 0.5626 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6859 - val_prc: 0.3933\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8414 - tp: 189.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 209.0000 - accuracy: 0.7446 - precision: 0.3803 - recall: 0.4749 - auc: 0.7149 - prc: 0.4343 - val_loss: 0.5656 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6857 - val_prc: 0.4012\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8375 - tp: 192.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 206.0000 - accuracy: 0.7495 - precision: 0.3895 - recall: 0.4824 - auc: 0.7180 - prc: 0.4434 - val_loss: 0.5876 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6859 - val_prc: 0.3933\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8407 - tp: 185.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 213.0000 - accuracy: 0.7510 - precision: 0.3887 - recall: 0.4648 - auc: 0.7189 - prc: 0.4288 - val_loss: 0.6028 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6858 - val_prc: 0.3979\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8433 - tp: 194.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 204.0000 - accuracy: 0.7391 - precision: 0.3745 - recall: 0.4874 - auc: 0.7150 - prc: 0.4254 - val_loss: 0.5672 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6863 - val_prc: 0.3959\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8393 - tp: 186.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 212.0000 - accuracy: 0.7451 - precision: 0.3796 - recall: 0.4673 - auc: 0.7181 - prc: 0.4320 - val_loss: 0.6017 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6864 - val_prc: 0.3941\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8382 - tp: 205.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 193.0000 - accuracy: 0.7367 - precision: 0.3761 - recall: 0.5151 - auc: 0.7203 - prc: 0.4287 - val_loss: 0.5534 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6875 - val_prc: 0.4140\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8403 - tp: 189.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 209.0000 - accuracy: 0.7441 - precision: 0.3795 - recall: 0.4749 - auc: 0.7171 - prc: 0.4243 - val_loss: 0.5659 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6868 - val_prc: 0.4035\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8386 - tp: 187.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 211.0000 - accuracy: 0.7505 - precision: 0.3888 - recall: 0.4698 - auc: 0.7188 - prc: 0.4362 - val_loss: 0.5785 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6860 - val_prc: 0.3883\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8386 - tp: 187.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 211.0000 - accuracy: 0.7495 - precision: 0.3872 - recall: 0.4698 - auc: 0.7186 - prc: 0.4391 - val_loss: 0.5629 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6871 - val_prc: 0.4043\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8379 - tp: 197.0000 - fp: 332.0000 - tn: 1294.0000 - fn: 201.0000 - accuracy: 0.7367 - precision: 0.3724 - recall: 0.4950 - auc: 0.7198 - prc: 0.4287 - val_loss: 0.5900 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6862 - val_prc: 0.3894\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8402 - tp: 196.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 202.0000 - accuracy: 0.7441 - precision: 0.3828 - recall: 0.4925 - auc: 0.7159 - prc: 0.4300 - val_loss: 0.5684 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6863 - val_prc: 0.4038\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 191.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 207.0000 - accuracy: 0.7475 - precision: 0.3859 - recall: 0.4799 - auc: 0.7170 - prc: 0.4397 - val_loss: 0.5192 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6879 - val_prc: 0.4118\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8398 - tp: 186.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 212.0000 - accuracy: 0.7441 - precision: 0.3780 - recall: 0.4673 - auc: 0.7166 - prc: 0.4329 - val_loss: 0.5628 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6867 - val_prc: 0.4038\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8422 - tp: 186.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 212.0000 - accuracy: 0.7500 - precision: 0.3875 - recall: 0.4673 - auc: 0.7145 - prc: 0.4295 - val_loss: 0.5431 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6873 - val_prc: 0.4137\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8381 - tp: 197.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 201.0000 - accuracy: 0.7391 - precision: 0.3760 - recall: 0.4950 - auc: 0.7216 - prc: 0.4182 - val_loss: 0.5453 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6876 - val_prc: 0.4139\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 195.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 203.0000 - accuracy: 0.7386 - precision: 0.3743 - recall: 0.4899 - auc: 0.7186 - prc: 0.4281 - val_loss: 0.5094 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6877 - val_prc: 0.4126\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8419 - tp: 192.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 206.0000 - accuracy: 0.7490 - precision: 0.3887 - recall: 0.4824 - auc: 0.7144 - prc: 0.4314 - val_loss: 0.4999 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6881 - val_prc: 0.4139\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8432 - tp: 191.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 207.0000 - accuracy: 0.7416 - precision: 0.3767 - recall: 0.4799 - auc: 0.7131 - prc: 0.4239 - val_loss: 0.5011 - val_tp: 34.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 57.0000 - val_accuracy: 0.7905 - val_precision: 0.4096 - val_recall: 0.3736 - val_auc: 0.6880 - val_prc: 0.4133\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8407 - tp: 182.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 216.0000 - accuracy: 0.7485 - precision: 0.3832 - recall: 0.4573 - auc: 0.7157 - prc: 0.4313 - val_loss: 0.5912 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6864 - val_prc: 0.3940\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8393 - tp: 195.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 203.0000 - accuracy: 0.7456 - precision: 0.3846 - recall: 0.4899 - auc: 0.7184 - prc: 0.4327 - val_loss: 0.5191 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6883 - val_prc: 0.4131\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8392 - tp: 185.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 213.0000 - accuracy: 0.7480 - precision: 0.3838 - recall: 0.4648 - auc: 0.7172 - prc: 0.4372 - val_loss: 0.5369 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6872 - val_prc: 0.4128\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 184.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 214.0000 - accuracy: 0.7446 - precision: 0.3778 - recall: 0.4623 - auc: 0.7194 - prc: 0.4247 - val_loss: 0.5684 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6869 - val_prc: 0.3977\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8384 - tp: 195.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 203.0000 - accuracy: 0.7475 - precision: 0.3877 - recall: 0.4899 - auc: 0.7213 - prc: 0.4293 - val_loss: 0.5219 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6878 - val_prc: 0.4130\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 196.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 202.0000 - accuracy: 0.7451 - precision: 0.3843 - recall: 0.4925 - auc: 0.7176 - prc: 0.4331 - val_loss: 0.5460 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6875 - val_prc: 0.4131\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8407 - tp: 186.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 212.0000 - accuracy: 0.7510 - precision: 0.3891 - recall: 0.4673 - auc: 0.7146 - prc: 0.4347 - val_loss: 0.5648 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6872 - val_prc: 0.4025\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 202.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 196.0000 - accuracy: 0.7470 - precision: 0.3900 - recall: 0.5075 - auc: 0.7187 - prc: 0.4257 - val_loss: 0.5092 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6886 - val_prc: 0.4130\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8418 - tp: 183.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 215.0000 - accuracy: 0.7485 - precision: 0.3836 - recall: 0.4598 - auc: 0.7174 - prc: 0.4234 - val_loss: 0.5770 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6874 - val_prc: 0.3930\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8403 - tp: 185.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 213.0000 - accuracy: 0.7436 - precision: 0.3768 - recall: 0.4648 - auc: 0.7169 - prc: 0.4326 - val_loss: 0.5830 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6859 - val_prc: 0.3933\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 190.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 208.0000 - accuracy: 0.7495 - precision: 0.3885 - recall: 0.4774 - auc: 0.7178 - prc: 0.4256 - val_loss: 0.6350 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6861 - val_prc: 0.4011\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8390 - tp: 201.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 197.0000 - accuracy: 0.7465 - precision: 0.3888 - recall: 0.5050 - auc: 0.7189 - prc: 0.4323 - val_loss: 0.5260 - val_tp: 38.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 53.0000 - val_accuracy: 0.7668 - val_precision: 0.3689 - val_recall: 0.4176 - val_auc: 0.6874 - val_prc: 0.4121\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8376 - tp: 186.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 212.0000 - accuracy: 0.7495 - precision: 0.3867 - recall: 0.4673 - auc: 0.7203 - prc: 0.4375 - val_loss: 0.5964 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6861 - val_prc: 0.3929\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8402 - tp: 181.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 217.0000 - accuracy: 0.7470 - precision: 0.3803 - recall: 0.4548 - auc: 0.7184 - prc: 0.4203 - val_loss: 0.6062 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6859 - val_prc: 0.3917\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8404 - tp: 196.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 202.0000 - accuracy: 0.7347 - precision: 0.3691 - recall: 0.4925 - auc: 0.7180 - prc: 0.4237 - val_loss: 0.5404 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6879 - val_prc: 0.4124\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8410 - tp: 193.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 205.0000 - accuracy: 0.7574 - precision: 0.4029 - recall: 0.4849 - auc: 0.7148 - prc: 0.4286 - val_loss: 0.5607 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6862 - val_prc: 0.4108\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8380 - tp: 194.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 204.0000 - accuracy: 0.7451 - precision: 0.3834 - recall: 0.4874 - auc: 0.7194 - prc: 0.4321 - val_loss: 0.5254 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6873 - val_prc: 0.4126\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8492 - tp: 196.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 202.0000 - accuracy: 0.7347 - precision: 0.3691 - recall: 0.4925 - auc: 0.7077 - prc: 0.4281 - val_loss: 0.5577 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6874 - val_prc: 0.4126\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8382 - tp: 187.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 211.0000 - accuracy: 0.7520 - precision: 0.3912 - recall: 0.4698 - auc: 0.7181 - prc: 0.4303 - val_loss: 0.5403 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6885 - val_prc: 0.4136\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8368 - tp: 201.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 197.0000 - accuracy: 0.7480 - precision: 0.3911 - recall: 0.5050 - auc: 0.7204 - prc: 0.4379 - val_loss: 0.5302 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6881 - val_prc: 0.4137\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8368 - tp: 190.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 208.0000 - accuracy: 0.7564 - precision: 0.4000 - recall: 0.4774 - auc: 0.7195 - prc: 0.4323 - val_loss: 0.5830 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6874 - val_prc: 0.4032\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8384 - tp: 201.0000 - fp: 323.0000 - tn: 1303.0000 - fn: 197.0000 - accuracy: 0.7431 - precision: 0.3836 - recall: 0.5050 - auc: 0.7176 - prc: 0.4390 - val_loss: 0.5468 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6876 - val_prc: 0.4122\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8357 - tp: 195.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 203.0000 - accuracy: 0.7431 - precision: 0.3809 - recall: 0.4899 - auc: 0.7225 - prc: 0.4377 - val_loss: 0.5143 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6885 - val_prc: 0.4135\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8387 - tp: 191.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 207.0000 - accuracy: 0.7475 - precision: 0.3859 - recall: 0.4799 - auc: 0.7191 - prc: 0.4325 - val_loss: 0.5373 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6879 - val_prc: 0.4137\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8427 - tp: 192.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 206.0000 - accuracy: 0.7411 - precision: 0.3765 - recall: 0.4824 - auc: 0.7128 - prc: 0.4415 - val_loss: 0.5179 - val_tp: 38.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 53.0000 - val_accuracy: 0.7767 - val_precision: 0.3878 - val_recall: 0.4176 - val_auc: 0.6886 - val_prc: 0.4134\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8364 - tp: 188.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 210.0000 - accuracy: 0.7475 - precision: 0.3845 - recall: 0.4724 - auc: 0.7209 - prc: 0.4376 - val_loss: 0.5531 - val_tp: 44.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 47.0000 - val_accuracy: 0.7391 - val_precision: 0.3411 - val_recall: 0.4835 - val_auc: 0.6878 - val_prc: 0.4134\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8392 - tp: 190.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 208.0000 - accuracy: 0.7500 - precision: 0.3893 - recall: 0.4774 - auc: 0.7165 - prc: 0.4349 - val_loss: 0.5906 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6876 - val_prc: 0.3916\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8420 - tp: 197.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 201.0000 - accuracy: 0.7391 - precision: 0.3760 - recall: 0.4950 - auc: 0.7147 - prc: 0.4309 - val_loss: 0.5731 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6875 - val_prc: 0.4117\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8378 - tp: 188.0000 - fp: 265.0000 - tn: 1361.0000 - fn: 210.0000 - accuracy: 0.7653 - precision: 0.4150 - recall: 0.4724 - auc: 0.7195 - prc: 0.4339 - val_loss: 0.6670 - val_tp: 62.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 29.0000 - val_accuracy: 0.6008 - val_precision: 0.2638 - val_recall: 0.6813 - val_auc: 0.6870 - val_prc: 0.4017\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8409 - tp: 205.0000 - fp: 362.0000 - tn: 1264.0000 - fn: 193.0000 - accuracy: 0.7258 - precision: 0.3616 - recall: 0.5151 - auc: 0.7189 - prc: 0.4283 - val_loss: 0.5183 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6879 - val_prc: 0.4145\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8393 - tp: 184.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 214.0000 - accuracy: 0.7416 - precision: 0.3732 - recall: 0.4623 - auc: 0.7181 - prc: 0.4335 - val_loss: 0.5501 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6874 - val_prc: 0.4129\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8370 - tp: 187.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 211.0000 - accuracy: 0.7510 - precision: 0.3896 - recall: 0.4698 - auc: 0.7197 - prc: 0.4394 - val_loss: 0.5754 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6870 - val_prc: 0.4125\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8385 - tp: 196.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 202.0000 - accuracy: 0.7490 - precision: 0.3904 - recall: 0.4925 - auc: 0.7190 - prc: 0.4363 - val_loss: 0.5355 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6877 - val_prc: 0.4141\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8402 - tp: 182.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 216.0000 - accuracy: 0.7406 - precision: 0.3707 - recall: 0.4573 - auc: 0.7160 - prc: 0.4353 - val_loss: 0.5375 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6881 - val_prc: 0.4131\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8361 - tp: 195.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 203.0000 - accuracy: 0.7431 - precision: 0.3809 - recall: 0.4899 - auc: 0.7229 - prc: 0.4330 - val_loss: 0.5171 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6884 - val_prc: 0.4149\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8381 - tp: 193.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 205.0000 - accuracy: 0.7510 - precision: 0.3923 - recall: 0.4849 - auc: 0.7176 - prc: 0.4482 - val_loss: 0.5791 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6882 - val_prc: 0.3995\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8435 - tp: 197.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 201.0000 - accuracy: 0.7396 - precision: 0.3767 - recall: 0.4950 - auc: 0.7128 - prc: 0.4253 - val_loss: 0.5490 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6876 - val_prc: 0.4128\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8450 - tp: 180.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 218.0000 - accuracy: 0.7446 - precision: 0.3758 - recall: 0.4523 - auc: 0.7115 - prc: 0.4307 - val_loss: 0.5301 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6878 - val_prc: 0.4140\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8381 - tp: 194.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 204.0000 - accuracy: 0.7381 - precision: 0.3731 - recall: 0.4874 - auc: 0.7191 - prc: 0.4335 - val_loss: 0.5832 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6879 - val_prc: 0.4137\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8398 - tp: 196.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 202.0000 - accuracy: 0.7386 - precision: 0.3748 - recall: 0.4925 - auc: 0.7168 - prc: 0.4326 - val_loss: 0.5715 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6887 - val_prc: 0.4137\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8389 - tp: 186.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 212.0000 - accuracy: 0.7391 - precision: 0.3705 - recall: 0.4673 - auc: 0.7171 - prc: 0.4344 - val_loss: 0.5429 - val_tp: 43.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 48.0000 - val_accuracy: 0.7470 - val_precision: 0.3496 - val_recall: 0.4725 - val_auc: 0.6889 - val_prc: 0.4143\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8387 - tp: 184.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 214.0000 - accuracy: 0.7584 - precision: 0.4009 - recall: 0.4623 - auc: 0.7187 - prc: 0.4380 - val_loss: 0.5924 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6875 - val_prc: 0.4029\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8427 - tp: 197.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 201.0000 - accuracy: 0.7426 - precision: 0.3810 - recall: 0.4950 - auc: 0.7138 - prc: 0.4301 - val_loss: 0.5489 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6889 - val_prc: 0.4138\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8395 - tp: 194.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 204.0000 - accuracy: 0.7475 - precision: 0.3872 - recall: 0.4874 - auc: 0.7185 - prc: 0.4317 - val_loss: 0.5347 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6893 - val_prc: 0.4153\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8382 - tp: 184.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 214.0000 - accuracy: 0.7451 - precision: 0.3786 - recall: 0.4623 - auc: 0.7190 - prc: 0.4373 - val_loss: 0.5958 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6873 - val_prc: 0.4034\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8413 - tp: 194.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 204.0000 - accuracy: 0.7362 - precision: 0.3702 - recall: 0.4874 - auc: 0.7156 - prc: 0.4330 - val_loss: 0.6246 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6876 - val_prc: 0.3916\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 200.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 198.0000 - accuracy: 0.7391 - precision: 0.3774 - recall: 0.5025 - auc: 0.7167 - prc: 0.4446 - val_loss: 0.5409 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6887 - val_prc: 0.4145\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8373 - tp: 196.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 202.0000 - accuracy: 0.7426 - precision: 0.3806 - recall: 0.4925 - auc: 0.7193 - prc: 0.4377 - val_loss: 0.5425 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6896 - val_prc: 0.4145\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8409 - tp: 185.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 213.0000 - accuracy: 0.7475 - precision: 0.3830 - recall: 0.4648 - auc: 0.7160 - prc: 0.4290 - val_loss: 0.5588 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6891 - val_prc: 0.4139\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8370 - tp: 189.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 209.0000 - accuracy: 0.7436 - precision: 0.3788 - recall: 0.4749 - auc: 0.7196 - prc: 0.4405 - val_loss: 0.5584 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6893 - val_prc: 0.4151\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8377 - tp: 192.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 206.0000 - accuracy: 0.7544 - precision: 0.3975 - recall: 0.4824 - auc: 0.7194 - prc: 0.4326 - val_loss: 0.5459 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6888 - val_prc: 0.4145\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8374 - tp: 193.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 205.0000 - accuracy: 0.7386 - precision: 0.3733 - recall: 0.4849 - auc: 0.7191 - prc: 0.4405 - val_loss: 0.5462 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6893 - val_prc: 0.4149\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8410 - tp: 188.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 210.0000 - accuracy: 0.7431 - precision: 0.3775 - recall: 0.4724 - auc: 0.7148 - prc: 0.4370 - val_loss: 0.5712 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6889 - val_prc: 0.4139\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8402 - tp: 190.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 208.0000 - accuracy: 0.7426 - precision: 0.3777 - recall: 0.4774 - auc: 0.7170 - prc: 0.4347 - val_loss: 0.6101 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6891 - val_prc: 0.3955\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8377 - tp: 188.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 210.0000 - accuracy: 0.7515 - precision: 0.3909 - recall: 0.4724 - auc: 0.7184 - prc: 0.4387 - val_loss: 0.5688 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6887 - val_prc: 0.4139\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8365 - tp: 182.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 216.0000 - accuracy: 0.7446 - precision: 0.3768 - recall: 0.4573 - auc: 0.7192 - prc: 0.4434 - val_loss: 0.6077 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6881 - val_prc: 0.3925\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8391 - tp: 186.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 212.0000 - accuracy: 0.7406 - precision: 0.3727 - recall: 0.4673 - auc: 0.7169 - prc: 0.4382 - val_loss: 0.5788 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6892 - val_prc: 0.4147\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8374 - tp: 207.0000 - fp: 322.0000 - tn: 1304.0000 - fn: 191.0000 - accuracy: 0.7465 - precision: 0.3913 - recall: 0.5201 - auc: 0.7198 - prc: 0.4292 - val_loss: 0.5020 - val_tp: 35.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 56.0000 - val_accuracy: 0.7866 - val_precision: 0.4023 - val_recall: 0.3846 - val_auc: 0.6907 - val_prc: 0.4167\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8393 - tp: 190.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 208.0000 - accuracy: 0.7411 - precision: 0.3755 - recall: 0.4774 - auc: 0.7178 - prc: 0.4275 - val_loss: 0.5523 - val_tp: 44.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 47.0000 - val_accuracy: 0.7391 - val_precision: 0.3411 - val_recall: 0.4835 - val_auc: 0.6901 - val_prc: 0.4141\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8419 - tp: 193.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 205.0000 - accuracy: 0.7327 - precision: 0.3648 - recall: 0.4849 - auc: 0.7149 - prc: 0.4309 - val_loss: 0.5813 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6889 - val_prc: 0.4133\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8411 - tp: 192.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 206.0000 - accuracy: 0.7465 - precision: 0.3848 - recall: 0.4824 - auc: 0.7157 - prc: 0.4341 - val_loss: 0.5206 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6890 - val_prc: 0.4146\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8381 - tp: 196.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 202.0000 - accuracy: 0.7465 - precision: 0.3866 - recall: 0.4925 - auc: 0.7176 - prc: 0.4371 - val_loss: 0.5456 - val_tp: 43.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 48.0000 - val_accuracy: 0.7490 - val_precision: 0.3525 - val_recall: 0.4725 - val_auc: 0.6905 - val_prc: 0.4161\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8398 - tp: 189.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 209.0000 - accuracy: 0.7549 - precision: 0.3971 - recall: 0.4749 - auc: 0.7182 - prc: 0.4356 - val_loss: 0.5596 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6900 - val_prc: 0.4151\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8348 - tp: 193.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 205.0000 - accuracy: 0.7362 - precision: 0.3697 - recall: 0.4849 - auc: 0.7215 - prc: 0.4459 - val_loss: 0.5003 - val_tp: 34.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 57.0000 - val_accuracy: 0.7866 - val_precision: 0.4000 - val_recall: 0.3736 - val_auc: 0.6899 - val_prc: 0.4158\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8379 - tp: 187.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 211.0000 - accuracy: 0.7505 - precision: 0.3888 - recall: 0.4698 - auc: 0.7189 - prc: 0.4391 - val_loss: 0.5573 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6904 - val_prc: 0.4160\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8363 - tp: 195.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 203.0000 - accuracy: 0.7426 - precision: 0.3801 - recall: 0.4899 - auc: 0.7200 - prc: 0.4396 - val_loss: 0.5265 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6897 - val_prc: 0.4156\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8366 - tp: 189.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 209.0000 - accuracy: 0.7495 - precision: 0.3881 - recall: 0.4749 - auc: 0.7226 - prc: 0.4343 - val_loss: 0.5570 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6899 - val_prc: 0.4152\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8369 - tp: 192.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 206.0000 - accuracy: 0.7426 - precision: 0.3787 - recall: 0.4824 - auc: 0.7200 - prc: 0.4369 - val_loss: 0.5449 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6892 - val_prc: 0.4151\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8370 - tp: 188.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 210.0000 - accuracy: 0.7441 - precision: 0.3790 - recall: 0.4724 - auc: 0.7187 - prc: 0.4398 - val_loss: 0.5562 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6894 - val_prc: 0.4159\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8376 - tp: 189.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 209.0000 - accuracy: 0.7401 - precision: 0.3735 - recall: 0.4749 - auc: 0.7173 - prc: 0.4433 - val_loss: 0.5478 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6900 - val_prc: 0.4164\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8363 - tp: 185.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 213.0000 - accuracy: 0.7465 - precision: 0.3814 - recall: 0.4648 - auc: 0.7205 - prc: 0.4424 - val_loss: 0.5961 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6891 - val_prc: 0.4151\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8386 - tp: 195.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 203.0000 - accuracy: 0.7480 - precision: 0.3884 - recall: 0.4899 - auc: 0.7182 - prc: 0.4345 - val_loss: 0.5426 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6907 - val_prc: 0.4161\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8351 - tp: 192.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 206.0000 - accuracy: 0.7485 - precision: 0.3879 - recall: 0.4824 - auc: 0.7218 - prc: 0.4444 - val_loss: 0.5153 - val_tp: 37.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 54.0000 - val_accuracy: 0.7727 - val_precision: 0.3776 - val_recall: 0.4066 - val_auc: 0.6898 - val_prc: 0.4157\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8416 - tp: 182.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 216.0000 - accuracy: 0.7426 - precision: 0.3737 - recall: 0.4573 - auc: 0.7161 - prc: 0.4353 - val_loss: 0.5814 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6891 - val_prc: 0.4137\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8393 - tp: 192.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 206.0000 - accuracy: 0.7436 - precision: 0.3802 - recall: 0.4824 - auc: 0.7178 - prc: 0.4319 - val_loss: 0.5795 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6897 - val_prc: 0.4154\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8375 - tp: 185.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 213.0000 - accuracy: 0.7362 - precision: 0.3656 - recall: 0.4648 - auc: 0.7206 - prc: 0.4296 - val_loss: 0.5891 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6899 - val_prc: 0.4155\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8356 - tp: 207.0000 - fp: 325.0000 - tn: 1301.0000 - fn: 191.0000 - accuracy: 0.7451 - precision: 0.3891 - recall: 0.5201 - auc: 0.7217 - prc: 0.4375 - val_loss: 0.5146 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6908 - val_prc: 0.4154\n",
      "Epoch 302/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8382 - tp: 190.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 208.0000 - accuracy: 0.7535 - precision: 0.3950 - recall: 0.4774 - auc: 0.7175 - prc: 0.4280 - val_loss: 0.5475 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6915 - val_prc: 0.4152\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8355 - tp: 188.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 210.0000 - accuracy: 0.7540 - precision: 0.3950 - recall: 0.4724 - auc: 0.7207 - prc: 0.4450 - val_loss: 0.5849 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6889 - val_prc: 0.4133\n",
      "Epoch 304/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8378 - tp: 196.0000 - fp: 322.0000 - tn: 1304.0000 - fn: 202.0000 - accuracy: 0.7411 - precision: 0.3784 - recall: 0.4925 - auc: 0.7177 - prc: 0.4418 - val_loss: 0.5219 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6906 - val_prc: 0.4141\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8365 - tp: 190.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 208.0000 - accuracy: 0.7510 - precision: 0.3909 - recall: 0.4774 - auc: 0.7185 - prc: 0.4404 - val_loss: 0.5237 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6914 - val_prc: 0.4142\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8349 - tp: 184.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 214.0000 - accuracy: 0.7584 - precision: 0.4009 - recall: 0.4623 - auc: 0.7228 - prc: 0.4421 - val_loss: 0.5868 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6908 - val_prc: 0.4144\n",
      "Epoch 307/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8371 - tp: 195.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 203.0000 - accuracy: 0.7559 - precision: 0.4012 - recall: 0.4899 - auc: 0.7186 - prc: 0.4414 - val_loss: 0.5513 - val_tp: 44.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 47.0000 - val_accuracy: 0.7451 - val_precision: 0.3492 - val_recall: 0.4835 - val_auc: 0.6915 - val_prc: 0.4140\n",
      "Epoch 308/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8385 - tp: 189.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 209.0000 - accuracy: 0.7446 - precision: 0.3803 - recall: 0.4749 - auc: 0.7176 - prc: 0.4333 - val_loss: 0.5653 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6912 - val_prc: 0.4128\n",
      "Epoch 309/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8351 - tp: 189.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 209.0000 - accuracy: 0.7490 - precision: 0.3873 - recall: 0.4749 - auc: 0.7218 - prc: 0.4380 - val_loss: 0.5053 - val_tp: 35.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 56.0000 - val_accuracy: 0.7806 - val_precision: 0.3889 - val_recall: 0.3846 - val_auc: 0.6922 - val_prc: 0.4142\n",
      "Epoch 310/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8381 - tp: 188.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 210.0000 - accuracy: 0.7495 - precision: 0.3876 - recall: 0.4724 - auc: 0.7172 - prc: 0.4341 - val_loss: 0.5242 - val_tp: 38.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 53.0000 - val_accuracy: 0.7767 - val_precision: 0.3878 - val_recall: 0.4176 - val_auc: 0.6914 - val_prc: 0.4132\n",
      "Epoch 311/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8355 - tp: 186.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 212.0000 - accuracy: 0.7544 - precision: 0.3949 - recall: 0.4673 - auc: 0.7205 - prc: 0.4477 - val_loss: 0.5538 - val_tp: 45.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 46.0000 - val_accuracy: 0.7490 - val_precision: 0.3571 - val_recall: 0.4945 - val_auc: 0.6914 - val_prc: 0.4139\n",
      "Epoch 312/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8353 - tp: 179.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 219.0000 - accuracy: 0.7525 - precision: 0.3883 - recall: 0.4497 - auc: 0.7202 - prc: 0.4423 - val_loss: 0.5875 - val_tp: 49.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 42.0000 - val_accuracy: 0.7134 - val_precision: 0.3224 - val_recall: 0.5385 - val_auc: 0.6904 - val_prc: 0.4127\n",
      "Epoch 313/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8383 - tp: 181.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 217.0000 - accuracy: 0.7614 - precision: 0.4049 - recall: 0.4548 - auc: 0.7199 - prc: 0.4356 - val_loss: 0.5695 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6913 - val_prc: 0.4124\n",
      "Epoch 314/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8375 - tp: 202.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 196.0000 - accuracy: 0.7416 - precision: 0.3819 - recall: 0.5075 - auc: 0.7175 - prc: 0.4407 - val_loss: 0.5294 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6900 - val_prc: 0.4114\n",
      "Epoch 315/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8345 - tp: 185.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 213.0000 - accuracy: 0.7505 - precision: 0.3878 - recall: 0.4648 - auc: 0.7214 - prc: 0.4422 - val_loss: 0.5238 - val_tp: 39.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 52.0000 - val_accuracy: 0.7747 - val_precision: 0.3861 - val_recall: 0.4286 - val_auc: 0.6916 - val_prc: 0.4115\n",
      "Epoch 316/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8350 - tp: 192.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 206.0000 - accuracy: 0.7470 - precision: 0.3855 - recall: 0.4824 - auc: 0.7211 - prc: 0.4396 - val_loss: 0.5509 - val_tp: 45.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 46.0000 - val_accuracy: 0.7549 - val_precision: 0.3659 - val_recall: 0.4945 - val_auc: 0.6897 - val_prc: 0.4106\n",
      "Epoch 317/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8352 - tp: 181.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 217.0000 - accuracy: 0.7663 - precision: 0.4142 - recall: 0.4548 - auc: 0.7215 - prc: 0.4396 - val_loss: 0.5648 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6909 - val_prc: 0.4107\n",
      "Epoch 318/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8339 - tp: 190.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 208.0000 - accuracy: 0.7480 - precision: 0.3862 - recall: 0.4774 - auc: 0.7207 - prc: 0.4374 - val_loss: 0.5116 - val_tp: 36.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 55.0000 - val_accuracy: 0.7806 - val_precision: 0.3913 - val_recall: 0.3956 - val_auc: 0.6891 - val_prc: 0.4101\n",
      "Epoch 319/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8370 - tp: 194.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 204.0000 - accuracy: 0.7540 - precision: 0.3975 - recall: 0.4874 - auc: 0.7208 - prc: 0.4312 - val_loss: 0.5504 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6906 - val_prc: 0.4115\n",
      "Epoch 320/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8361 - tp: 189.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 209.0000 - accuracy: 0.7589 - precision: 0.4038 - recall: 0.4749 - auc: 0.7176 - prc: 0.4443 - val_loss: 0.5923 - val_tp: 51.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 40.0000 - val_accuracy: 0.7154 - val_precision: 0.3290 - val_recall: 0.5604 - val_auc: 0.6914 - val_prc: 0.3975\n",
      "Epoch 321/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8352 - tp: 179.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 219.0000 - accuracy: 0.7559 - precision: 0.3943 - recall: 0.4497 - auc: 0.7209 - prc: 0.4377 - val_loss: 0.6314 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6890 - val_prc: 0.3962\n",
      "Epoch 322/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8399 - tp: 205.0000 - fp: 342.0000 - tn: 1284.0000 - fn: 193.0000 - accuracy: 0.7357 - precision: 0.3748 - recall: 0.5151 - auc: 0.7161 - prc: 0.4364 - val_loss: 0.4963 - val_tp: 34.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 57.0000 - val_accuracy: 0.7984 - val_precision: 0.4304 - val_recall: 0.3736 - val_auc: 0.6888 - val_prc: 0.4124\n",
      "Epoch 323/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8355 - tp: 180.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 218.0000 - accuracy: 0.7624 - precision: 0.4063 - recall: 0.4523 - auc: 0.7207 - prc: 0.4383 - val_loss: 0.5727 - val_tp: 48.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 43.0000 - val_accuracy: 0.7233 - val_precision: 0.3310 - val_recall: 0.5275 - val_auc: 0.6914 - val_prc: 0.4130\n",
      "Epoch 324/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8383 - tp: 187.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 211.0000 - accuracy: 0.7411 - precision: 0.3740 - recall: 0.4698 - auc: 0.7183 - prc: 0.4351 - val_loss: 0.5630 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6908 - val_prc: 0.4118\n",
      "Epoch 325/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8380 - tp: 180.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 218.0000 - accuracy: 0.7530 - precision: 0.3896 - recall: 0.4523 - auc: 0.7191 - prc: 0.4406 - val_loss: 0.5796 - val_tp: 49.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 42.0000 - val_accuracy: 0.7154 - val_precision: 0.3245 - val_recall: 0.5385 - val_auc: 0.6909 - val_prc: 0.4120\n",
      "Epoch 326/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8342 - tp: 196.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 202.0000 - accuracy: 0.7520 - precision: 0.3952 - recall: 0.4925 - auc: 0.7211 - prc: 0.4360 - val_loss: 0.5569 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6910 - val_prc: 0.4131\n",
      "Epoch 327/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8365 - tp: 186.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 212.0000 - accuracy: 0.7451 - precision: 0.3796 - recall: 0.4673 - auc: 0.7194 - prc: 0.4446 - val_loss: 0.5265 - val_tp: 39.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 52.0000 - val_accuracy: 0.7688 - val_precision: 0.3750 - val_recall: 0.4286 - val_auc: 0.6910 - val_prc: 0.4137\n",
      "Epoch 328/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8357 - tp: 185.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 213.0000 - accuracy: 0.7460 - precision: 0.3807 - recall: 0.4648 - auc: 0.7198 - prc: 0.4377 - val_loss: 0.5676 - val_tp: 47.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 44.0000 - val_accuracy: 0.7372 - val_precision: 0.3456 - val_recall: 0.5165 - val_auc: 0.6924 - val_prc: 0.4131\n",
      "Epoch 329/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8349 - tp: 192.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 206.0000 - accuracy: 0.7485 - precision: 0.3879 - recall: 0.4824 - auc: 0.7196 - prc: 0.4415 - val_loss: 0.5316 - val_tp: 40.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 51.0000 - val_accuracy: 0.7708 - val_precision: 0.3810 - val_recall: 0.4396 - val_auc: 0.6913 - val_prc: 0.4152\n",
      "Epoch 330/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8380 - tp: 182.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 216.0000 - accuracy: 0.7619 - precision: 0.4062 - recall: 0.4573 - auc: 0.7171 - prc: 0.4412 - val_loss: 0.5734 - val_tp: 47.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 44.0000 - val_accuracy: 0.7372 - val_precision: 0.3456 - val_recall: 0.5165 - val_auc: 0.6916 - val_prc: 0.4138\n",
      "Epoch 331/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8344 - tp: 188.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 210.0000 - accuracy: 0.7564 - precision: 0.3992 - recall: 0.4724 - auc: 0.7219 - prc: 0.4433 - val_loss: 0.5474 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6907 - val_prc: 0.4131\n",
      "Epoch 332/500\n",
      " 96/102 [===========================>..] - ETA: 0s - loss: 0.8387 - tp: 179.0000 - fp: 273.0000 - tn: 1265.0000 - fn: 203.0000 - accuracy: 0.7521 - precision: 0.3960 - recall: 0.4686 - auc: 0.7215 - prc: 0.4475   Restoring model weights from the end of the best epoch: 282.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8339 - tp: 189.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 209.0000 - accuracy: 0.7554 - precision: 0.3979 - recall: 0.4749 - auc: 0.7223 - prc: 0.4466 - val_loss: 0.5553 - val_tp: 44.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 47.0000 - val_accuracy: 0.7490 - val_precision: 0.3548 - val_recall: 0.4835 - val_auc: 0.6905 - val_prc: 0.4139\n",
      "Epoch 332: early stopping\n",
      "26/26 [==============================] - 0s 562us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.2866 - tp: 44.0000 - fp: 80.0000 - tn: 1961.0000 - fn: 445.0000 - accuracy: 0.7925 - precision: 0.3548 - recall: 0.0900 - auc: 0.4984 - prc: 0.2320 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2568 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1988 - val_loss: 0.4760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2284 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5044 - prc: 0.1983 - val_loss: 0.4797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2025 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4739 - prc: 0.1909 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5306 - prc: 0.2155 - val_loss: 0.4894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1579 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5062 - prc: 0.1959 - val_loss: 0.4954 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - prc: 0.1980 - val_loss: 0.5021 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1229 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4901 - prc: 0.1933 - val_loss: 0.5090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1084 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4723 - prc: 0.1817 - val_loss: 0.5165 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0955 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4690 - prc: 0.1837 - val_loss: 0.5244 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0846 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5060 - prc: 0.2003 - val_loss: 0.5321 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0751 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4963 - prc: 0.1944 - val_loss: 0.5397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0667 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4979 - prc: 0.1974 - val_loss: 0.5480 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0599 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4942 - prc: 0.1910 - val_loss: 0.5558 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0540 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4952 - prc: 0.1947 - val_loss: 0.5633 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0493 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4983 - prc: 0.1944 - val_loss: 0.5703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5039 - prc: 0.1995 - val_loss: 0.5773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0420 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5025 - prc: 0.1976 - val_loss: 0.5845 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - prc: 0.1867 - val_loss: 0.5901 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0373 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4971 - prc: 0.1942 - val_loss: 0.5957 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5091 - prc: 0.2025 - val_loss: 0.6014 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0339 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - prc: 0.1920 - val_loss: 0.6069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0326 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4952 - prc: 0.1939 - val_loss: 0.6109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0322 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4993 - prc: 0.1962 - val_loss: 0.6154 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - prc: 0.1853 - val_loss: 0.6196 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5159 - prc: 0.2032 - val_loss: 0.6225 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0300 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4843 - prc: 0.1891 - val_loss: 0.6256 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0297 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.6284 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4755 - prc: 0.1873 - val_loss: 0.6307 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0294 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.6332 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0291 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.6344 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0287 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4983 - prc: 0.1955 - val_loss: 0.6357 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0284 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5064 - prc: 0.1987 - val_loss: 0.6383 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0289 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5027 - prc: 0.1975 - val_loss: 0.6390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5006 - val_prc: 0.1800\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0271 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4931 - prc: 0.1872 - val_loss: 0.5201 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6576 - val_prc: 0.3401\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0141 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5616 - prc: 0.2127 - val_loss: 0.6457 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5089 - val_prc: 0.1825\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0239 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5309 - prc: 0.2072 - val_loss: 0.5963 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6198 - val_prc: 0.2441\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9996 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6536 - prc: 0.2825 - val_loss: 0.5491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6536 - val_prc: 0.3047\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9926 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6788 - prc: 0.3417 - val_loss: 0.5450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6582 - val_prc: 0.3125\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6761 - prc: 0.3345 - val_loss: 0.5912 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6453 - val_prc: 0.2755\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9860 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6713 - prc: 0.3129 - val_loss: 0.5599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6602 - val_prc: 0.3141\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9806 - tp: 128.0000 - fp: 163.0000 - tn: 1463.0000 - fn: 270.0000 - accuracy: 0.7861 - precision: 0.4399 - recall: 0.3216 - auc: 0.6857 - prc: 0.3437 - val_loss: 0.5662 - val_tp: 29.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 62.0000 - val_accuracy: 0.7806 - val_precision: 0.3718 - val_recall: 0.3187 - val_auc: 0.6617 - val_prc: 0.3137\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9889 - tp: 223.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 175.0000 - accuracy: 0.6630 - precision: 0.3055 - recall: 0.5603 - auc: 0.6454 - prc: 0.2831 - val_loss: 0.5858 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6538 - val_prc: 0.2869\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9770 - tp: 164.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 234.0000 - accuracy: 0.7619 - precision: 0.3981 - recall: 0.4121 - auc: 0.6813 - prc: 0.3322 - val_loss: 0.5708 - val_tp: 36.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 55.0000 - val_accuracy: 0.7708 - val_precision: 0.3711 - val_recall: 0.3956 - val_auc: 0.6598 - val_prc: 0.3016\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9724 - tp: 169.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 229.0000 - accuracy: 0.7520 - precision: 0.3824 - recall: 0.4246 - auc: 0.6892 - prc: 0.3487 - val_loss: 0.5571 - val_tp: 30.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 61.0000 - val_accuracy: 0.7826 - val_precision: 0.3797 - val_recall: 0.3297 - val_auc: 0.6640 - val_prc: 0.3166\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9663 - tp: 170.0000 - fp: 250.0000 - tn: 1376.0000 - fn: 228.0000 - accuracy: 0.7638 - precision: 0.4048 - recall: 0.4271 - auc: 0.6950 - prc: 0.3432 - val_loss: 0.6014 - val_tp: 54.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 37.0000 - val_accuracy: 0.7055 - val_precision: 0.3253 - val_recall: 0.5934 - val_auc: 0.6576 - val_prc: 0.2906\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9658 - tp: 187.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 211.0000 - accuracy: 0.7530 - precision: 0.3929 - recall: 0.4698 - auc: 0.6966 - prc: 0.3762 - val_loss: 0.5485 - val_tp: 30.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 61.0000 - val_accuracy: 0.7964 - val_precision: 0.4167 - val_recall: 0.3297 - val_auc: 0.6655 - val_prc: 0.3255\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9597 - tp: 170.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 228.0000 - accuracy: 0.7747 - precision: 0.4271 - recall: 0.4271 - auc: 0.7038 - prc: 0.3675 - val_loss: 0.5682 - val_tp: 37.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 54.0000 - val_accuracy: 0.7628 - val_precision: 0.3592 - val_recall: 0.4066 - val_auc: 0.6663 - val_prc: 0.3194\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9674 - tp: 173.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 225.0000 - accuracy: 0.7628 - precision: 0.4042 - recall: 0.4347 - auc: 0.6877 - prc: 0.3596 - val_loss: 0.5656 - val_tp: 37.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 54.0000 - val_accuracy: 0.7688 - val_precision: 0.3700 - val_recall: 0.4066 - val_auc: 0.6681 - val_prc: 0.3240\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9585 - tp: 178.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 220.0000 - accuracy: 0.7569 - precision: 0.3956 - recall: 0.4472 - auc: 0.6989 - prc: 0.3506 - val_loss: 0.6426 - val_tp: 60.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 31.0000 - val_accuracy: 0.5810 - val_precision: 0.2490 - val_recall: 0.6593 - val_auc: 0.6576 - val_prc: 0.2865\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9591 - tp: 187.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 211.0000 - accuracy: 0.7376 - precision: 0.3688 - recall: 0.4698 - auc: 0.6924 - prc: 0.3498 - val_loss: 0.6187 - val_tp: 57.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 34.0000 - val_accuracy: 0.6542 - val_precision: 0.2879 - val_recall: 0.6264 - val_auc: 0.6627 - val_prc: 0.2945\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9555 - tp: 206.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 192.0000 - accuracy: 0.7381 - precision: 0.3787 - recall: 0.5176 - auc: 0.6966 - prc: 0.3492 - val_loss: 0.5534 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6755 - val_prc: 0.3431\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9534 - tp: 197.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 201.0000 - accuracy: 0.7337 - precision: 0.3682 - recall: 0.4950 - auc: 0.6965 - prc: 0.3580 - val_loss: 0.6197 - val_tp: 57.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 34.0000 - val_accuracy: 0.6383 - val_precision: 0.2767 - val_recall: 0.6264 - val_auc: 0.6637 - val_prc: 0.2963\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9473 - tp: 199.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 199.0000 - accuracy: 0.7367 - precision: 0.3734 - recall: 0.5000 - auc: 0.7056 - prc: 0.3676 - val_loss: 0.5570 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6768 - val_prc: 0.3404\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9465 - tp: 199.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 199.0000 - accuracy: 0.7465 - precision: 0.3879 - recall: 0.5000 - auc: 0.7057 - prc: 0.3741 - val_loss: 0.5687 - val_tp: 43.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 48.0000 - val_accuracy: 0.7332 - val_precision: 0.3308 - val_recall: 0.4725 - val_auc: 0.6749 - val_prc: 0.3302\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9508 - tp: 197.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 201.0000 - accuracy: 0.7159 - precision: 0.3450 - recall: 0.4950 - auc: 0.6942 - prc: 0.3477 - val_loss: 0.5792 - val_tp: 44.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 47.0000 - val_accuracy: 0.7134 - val_precision: 0.3099 - val_recall: 0.4835 - val_auc: 0.6731 - val_prc: 0.3237\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9459 - tp: 205.0000 - fp: 358.0000 - tn: 1268.0000 - fn: 193.0000 - accuracy: 0.7278 - precision: 0.3641 - recall: 0.5151 - auc: 0.7033 - prc: 0.3699 - val_loss: 0.5807 - val_tp: 44.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 47.0000 - val_accuracy: 0.7134 - val_precision: 0.3099 - val_recall: 0.4835 - val_auc: 0.6751 - val_prc: 0.3281\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9416 - tp: 208.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 190.0000 - accuracy: 0.7406 - precision: 0.3831 - recall: 0.5226 - auc: 0.7076 - prc: 0.3741 - val_loss: 0.5595 - val_tp: 41.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 50.0000 - val_accuracy: 0.7470 - val_precision: 0.3445 - val_recall: 0.4505 - val_auc: 0.6786 - val_prc: 0.3484\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9402 - tp: 216.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 182.0000 - accuracy: 0.7307 - precision: 0.3731 - recall: 0.5427 - auc: 0.7096 - prc: 0.3757 - val_loss: 0.5347 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6791 - val_prc: 0.3674\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9496 - tp: 202.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 196.0000 - accuracy: 0.7278 - precision: 0.3627 - recall: 0.5075 - auc: 0.6946 - prc: 0.3571 - val_loss: 0.5523 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6791 - val_prc: 0.3495\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9426 - tp: 200.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 198.0000 - accuracy: 0.7411 - precision: 0.3802 - recall: 0.5025 - auc: 0.7048 - prc: 0.3785 - val_loss: 0.5539 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6796 - val_prc: 0.3556\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9397 - tp: 213.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 185.0000 - accuracy: 0.7278 - precision: 0.3679 - recall: 0.5352 - auc: 0.7036 - prc: 0.3521 - val_loss: 0.5375 - val_tp: 39.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 52.0000 - val_accuracy: 0.7747 - val_precision: 0.3861 - val_recall: 0.4286 - val_auc: 0.6802 - val_prc: 0.3648\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9400 - tp: 206.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 192.0000 - accuracy: 0.7332 - precision: 0.3718 - recall: 0.5176 - auc: 0.7075 - prc: 0.3749 - val_loss: 0.5246 - val_tp: 36.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 55.0000 - val_accuracy: 0.7885 - val_precision: 0.4091 - val_recall: 0.3956 - val_auc: 0.6801 - val_prc: 0.3710\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9433 - tp: 207.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 191.0000 - accuracy: 0.7283 - precision: 0.3657 - recall: 0.5201 - auc: 0.7015 - prc: 0.3793 - val_loss: 0.6524 - val_tp: 65.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 26.0000 - val_accuracy: 0.5791 - val_precision: 0.2579 - val_recall: 0.7143 - val_auc: 0.6696 - val_prc: 0.3061\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9403 - tp: 198.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 200.0000 - accuracy: 0.7273 - precision: 0.3600 - recall: 0.4975 - auc: 0.7046 - prc: 0.3791 - val_loss: 0.6075 - val_tp: 56.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 35.0000 - val_accuracy: 0.6838 - val_precision: 0.3094 - val_recall: 0.6154 - val_auc: 0.6771 - val_prc: 0.3324\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9395 - tp: 219.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 179.0000 - accuracy: 0.7045 - precision: 0.3433 - recall: 0.5503 - auc: 0.7006 - prc: 0.3604 - val_loss: 0.5374 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6814 - val_prc: 0.3741\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9329 - tp: 203.0000 - fp: 322.0000 - tn: 1304.0000 - fn: 195.0000 - accuracy: 0.7446 - precision: 0.3867 - recall: 0.5101 - auc: 0.7116 - prc: 0.3770 - val_loss: 0.6533 - val_tp: 65.0000 - val_fp: 186.0000 - val_tn: 229.0000 - val_fn: 26.0000 - val_accuracy: 0.5810 - val_precision: 0.2590 - val_recall: 0.7143 - val_auc: 0.6703 - val_prc: 0.3079\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9367 - tp: 226.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 172.0000 - accuracy: 0.6966 - precision: 0.3383 - recall: 0.5678 - auc: 0.7061 - prc: 0.3674 - val_loss: 0.4993 - val_tp: 26.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 65.0000 - val_accuracy: 0.8083 - val_precision: 0.4483 - val_recall: 0.2857 - val_auc: 0.6821 - val_prc: 0.3801\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9400 - tp: 190.0000 - fp: 322.0000 - tn: 1304.0000 - fn: 208.0000 - accuracy: 0.7381 - precision: 0.3711 - recall: 0.4774 - auc: 0.7019 - prc: 0.3828 - val_loss: 0.6353 - val_tp: 62.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 29.0000 - val_accuracy: 0.6245 - val_precision: 0.2780 - val_recall: 0.6813 - val_auc: 0.6767 - val_prc: 0.3273\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9415 - tp: 211.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 187.0000 - accuracy: 0.6971 - precision: 0.3312 - recall: 0.5302 - auc: 0.6979 - prc: 0.3556 - val_loss: 0.6393 - val_tp: 63.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 28.0000 - val_accuracy: 0.6146 - val_precision: 0.2739 - val_recall: 0.6923 - val_auc: 0.6755 - val_prc: 0.3235\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9313 - tp: 222.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 176.0000 - accuracy: 0.7213 - precision: 0.3639 - recall: 0.5578 - auc: 0.7111 - prc: 0.3814 - val_loss: 0.5393 - val_tp: 39.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 52.0000 - val_accuracy: 0.7668 - val_precision: 0.3714 - val_recall: 0.4286 - val_auc: 0.6810 - val_prc: 0.3721\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9330 - tp: 210.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 188.0000 - accuracy: 0.7263 - precision: 0.3646 - recall: 0.5276 - auc: 0.7091 - prc: 0.3858 - val_loss: 0.5486 - val_tp: 41.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 50.0000 - val_accuracy: 0.7569 - val_precision: 0.3596 - val_recall: 0.4505 - val_auc: 0.6821 - val_prc: 0.3757\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9326 - tp: 222.0000 - fp: 371.0000 - tn: 1255.0000 - fn: 176.0000 - accuracy: 0.7297 - precision: 0.3744 - recall: 0.5578 - auc: 0.7078 - prc: 0.3823 - val_loss: 0.5742 - val_tp: 44.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 47.0000 - val_accuracy: 0.7134 - val_precision: 0.3099 - val_recall: 0.4835 - val_auc: 0.6820 - val_prc: 0.3588\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9289 - tp: 207.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 191.0000 - accuracy: 0.7263 - precision: 0.3632 - recall: 0.5201 - auc: 0.7115 - prc: 0.3955 - val_loss: 0.5781 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6812 - val_prc: 0.3586\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9291 - tp: 216.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 182.0000 - accuracy: 0.7372 - precision: 0.3816 - recall: 0.5427 - auc: 0.7125 - prc: 0.3881 - val_loss: 0.6845 - val_tp: 67.0000 - val_fp: 207.0000 - val_tn: 208.0000 - val_fn: 24.0000 - val_accuracy: 0.5435 - val_precision: 0.2445 - val_recall: 0.7363 - val_auc: 0.6701 - val_prc: 0.3046\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9342 - tp: 226.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 172.0000 - accuracy: 0.6976 - precision: 0.3393 - recall: 0.5678 - auc: 0.7055 - prc: 0.3752 - val_loss: 0.5703 - val_tp: 45.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 46.0000 - val_accuracy: 0.7174 - val_precision: 0.3169 - val_recall: 0.4945 - val_auc: 0.6821 - val_prc: 0.3732\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9293 - tp: 219.0000 - fp: 365.0000 - tn: 1261.0000 - fn: 179.0000 - accuracy: 0.7312 - precision: 0.3750 - recall: 0.5503 - auc: 0.7115 - prc: 0.3906 - val_loss: 0.5729 - val_tp: 45.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 46.0000 - val_accuracy: 0.7134 - val_precision: 0.3125 - val_recall: 0.4945 - val_auc: 0.6822 - val_prc: 0.3609\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9298 - tp: 209.0000 - fp: 373.0000 - tn: 1253.0000 - fn: 189.0000 - accuracy: 0.7223 - precision: 0.3591 - recall: 0.5251 - auc: 0.7103 - prc: 0.3932 - val_loss: 0.5677 - val_tp: 44.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 47.0000 - val_accuracy: 0.7273 - val_precision: 0.3259 - val_recall: 0.4835 - val_auc: 0.6831 - val_prc: 0.3755\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9291 - tp: 227.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 171.0000 - accuracy: 0.7228 - precision: 0.3679 - recall: 0.5704 - auc: 0.7101 - prc: 0.3838 - val_loss: 0.5814 - val_tp: 45.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 46.0000 - val_accuracy: 0.7016 - val_precision: 0.3000 - val_recall: 0.4945 - val_auc: 0.6824 - val_prc: 0.3637\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9280 - tp: 218.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 180.0000 - accuracy: 0.7218 - precision: 0.3627 - recall: 0.5477 - auc: 0.7114 - prc: 0.3892 - val_loss: 0.6021 - val_tp: 52.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 39.0000 - val_accuracy: 0.6937 - val_precision: 0.3095 - val_recall: 0.5714 - val_auc: 0.6815 - val_prc: 0.3521\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9257 - tp: 223.0000 - fp: 392.0000 - tn: 1234.0000 - fn: 175.0000 - accuracy: 0.7199 - precision: 0.3626 - recall: 0.5603 - auc: 0.7138 - prc: 0.4003 - val_loss: 0.5642 - val_tp: 43.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 48.0000 - val_accuracy: 0.7312 - val_precision: 0.3282 - val_recall: 0.4725 - val_auc: 0.6833 - val_prc: 0.3783\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9252 - tp: 229.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 169.0000 - accuracy: 0.7149 - precision: 0.3595 - recall: 0.5754 - auc: 0.7117 - prc: 0.3719 - val_loss: 0.5711 - val_tp: 45.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 46.0000 - val_accuracy: 0.7134 - val_precision: 0.3125 - val_recall: 0.4945 - val_auc: 0.6844 - val_prc: 0.3819\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9286 - tp: 223.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 175.0000 - accuracy: 0.7120 - precision: 0.3534 - recall: 0.5603 - auc: 0.7102 - prc: 0.3754 - val_loss: 0.5394 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6836 - val_prc: 0.3772\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9277 - tp: 224.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 174.0000 - accuracy: 0.7169 - precision: 0.3596 - recall: 0.5628 - auc: 0.7120 - prc: 0.3862 - val_loss: 0.5657 - val_tp: 43.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 48.0000 - val_accuracy: 0.7253 - val_precision: 0.3209 - val_recall: 0.4725 - val_auc: 0.6838 - val_prc: 0.3785\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9261 - tp: 213.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 185.0000 - accuracy: 0.7174 - precision: 0.3550 - recall: 0.5352 - auc: 0.7118 - prc: 0.3824 - val_loss: 0.6433 - val_tp: 62.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 29.0000 - val_accuracy: 0.6047 - val_precision: 0.2661 - val_recall: 0.6813 - val_auc: 0.6807 - val_prc: 0.3422\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9263 - tp: 211.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 187.0000 - accuracy: 0.7228 - precision: 0.3607 - recall: 0.5302 - auc: 0.7121 - prc: 0.3860 - val_loss: 0.6619 - val_tp: 65.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 26.0000 - val_accuracy: 0.5771 - val_precision: 0.2569 - val_recall: 0.7143 - val_auc: 0.6786 - val_prc: 0.3318\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9264 - tp: 232.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 166.0000 - accuracy: 0.7139 - precision: 0.3597 - recall: 0.5829 - auc: 0.7131 - prc: 0.3893 - val_loss: 0.6206 - val_tp: 58.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 33.0000 - val_accuracy: 0.6522 - val_precision: 0.2886 - val_recall: 0.6374 - val_auc: 0.6801 - val_prc: 0.3377\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9280 - tp: 215.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 183.0000 - accuracy: 0.7080 - precision: 0.3451 - recall: 0.5402 - auc: 0.7099 - prc: 0.3892 - val_loss: 0.5671 - val_tp: 44.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 47.0000 - val_accuracy: 0.7253 - val_precision: 0.3235 - val_recall: 0.4835 - val_auc: 0.6836 - val_prc: 0.3783\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9261 - tp: 209.0000 - fp: 360.0000 - tn: 1266.0000 - fn: 189.0000 - accuracy: 0.7288 - precision: 0.3673 - recall: 0.5251 - auc: 0.7127 - prc: 0.4052 - val_loss: 0.5616 - val_tp: 43.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 48.0000 - val_accuracy: 0.7332 - val_precision: 0.3308 - val_recall: 0.4725 - val_auc: 0.6845 - val_prc: 0.3802\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9246 - tp: 218.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 180.0000 - accuracy: 0.7204 - precision: 0.3609 - recall: 0.5477 - auc: 0.7130 - prc: 0.3896 - val_loss: 0.5433 - val_tp: 41.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 50.0000 - val_accuracy: 0.7569 - val_precision: 0.3596 - val_recall: 0.4505 - val_auc: 0.6845 - val_prc: 0.3797\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9270 - tp: 215.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 183.0000 - accuracy: 0.7258 - precision: 0.3663 - recall: 0.5402 - auc: 0.7099 - prc: 0.3977 - val_loss: 0.5596 - val_tp: 43.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 48.0000 - val_accuracy: 0.7332 - val_precision: 0.3308 - val_recall: 0.4725 - val_auc: 0.6852 - val_prc: 0.3915\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9285 - tp: 209.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 189.0000 - accuracy: 0.7100 - precision: 0.3443 - recall: 0.5251 - auc: 0.7080 - prc: 0.3991 - val_loss: 0.5968 - val_tp: 48.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 43.0000 - val_accuracy: 0.6858 - val_precision: 0.2927 - val_recall: 0.5275 - val_auc: 0.6840 - val_prc: 0.3724\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9233 - tp: 218.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 180.0000 - accuracy: 0.7233 - precision: 0.3645 - recall: 0.5477 - auc: 0.7142 - prc: 0.4022 - val_loss: 0.6211 - val_tp: 57.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 34.0000 - val_accuracy: 0.6542 - val_precision: 0.2879 - val_recall: 0.6264 - val_auc: 0.6823 - val_prc: 0.3561\n",
      "Epoch 94/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9221 - tp: 223.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 175.0000 - accuracy: 0.7144 - precision: 0.3562 - recall: 0.5603 - auc: 0.7158 - prc: 0.4053 - val_loss: 0.5841 - val_tp: 45.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 46.0000 - val_accuracy: 0.6996 - val_precision: 0.2980 - val_recall: 0.4945 - val_auc: 0.6846 - val_prc: 0.3840\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9235 - tp: 220.0000 - fp: 382.0000 - tn: 1244.0000 - fn: 178.0000 - accuracy: 0.7233 - precision: 0.3654 - recall: 0.5528 - auc: 0.7135 - prc: 0.4015 - val_loss: 0.5641 - val_tp: 43.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 48.0000 - val_accuracy: 0.7273 - val_precision: 0.3233 - val_recall: 0.4725 - val_auc: 0.6849 - val_prc: 0.3870\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9210 - tp: 218.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 180.0000 - accuracy: 0.7149 - precision: 0.3545 - recall: 0.5477 - auc: 0.7154 - prc: 0.3850 - val_loss: 0.5174 - val_tp: 36.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 55.0000 - val_accuracy: 0.7866 - val_precision: 0.4045 - val_recall: 0.3956 - val_auc: 0.6847 - val_prc: 0.3897\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9261 - tp: 215.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 183.0000 - accuracy: 0.7322 - precision: 0.3746 - recall: 0.5402 - auc: 0.7104 - prc: 0.4091 - val_loss: 0.5462 - val_tp: 42.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 49.0000 - val_accuracy: 0.7530 - val_precision: 0.3559 - val_recall: 0.4615 - val_auc: 0.6850 - val_prc: 0.3820\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9241 - tp: 216.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 182.0000 - accuracy: 0.7139 - precision: 0.3524 - recall: 0.5427 - auc: 0.7111 - prc: 0.4007 - val_loss: 0.5845 - val_tp: 46.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 45.0000 - val_accuracy: 0.7016 - val_precision: 0.3026 - val_recall: 0.5055 - val_auc: 0.6841 - val_prc: 0.3828\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9220 - tp: 210.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 188.0000 - accuracy: 0.7278 - precision: 0.3665 - recall: 0.5276 - auc: 0.7154 - prc: 0.4084 - val_loss: 0.6102 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6847 - val_prc: 0.3735\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9219 - tp: 219.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 179.0000 - accuracy: 0.7233 - precision: 0.3650 - recall: 0.5503 - auc: 0.7150 - prc: 0.4155 - val_loss: 0.6259 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.6831 - val_prc: 0.3541\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9277 - tp: 215.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 183.0000 - accuracy: 0.7070 - precision: 0.3440 - recall: 0.5402 - auc: 0.7062 - prc: 0.3886 - val_loss: 0.5825 - val_tp: 45.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 46.0000 - val_accuracy: 0.6996 - val_precision: 0.2980 - val_recall: 0.4945 - val_auc: 0.6847 - val_prc: 0.3897\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9185 - tp: 220.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 178.0000 - accuracy: 0.7144 - precision: 0.3548 - recall: 0.5528 - auc: 0.7162 - prc: 0.4221 - val_loss: 0.5580 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6849 - val_prc: 0.3822\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9216 - tp: 213.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 185.0000 - accuracy: 0.7194 - precision: 0.3574 - recall: 0.5352 - auc: 0.7157 - prc: 0.4063 - val_loss: 0.6521 - val_tp: 62.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 29.0000 - val_accuracy: 0.6028 - val_precision: 0.2650 - val_recall: 0.6813 - val_auc: 0.6811 - val_prc: 0.3423\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9253 - tp: 214.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 184.0000 - accuracy: 0.7144 - precision: 0.3520 - recall: 0.5377 - auc: 0.7100 - prc: 0.3810 - val_loss: 0.5808 - val_tp: 45.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 46.0000 - val_accuracy: 0.7016 - val_precision: 0.3000 - val_recall: 0.4945 - val_auc: 0.6851 - val_prc: 0.3901\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9212 - tp: 219.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 179.0000 - accuracy: 0.7100 - precision: 0.3493 - recall: 0.5503 - auc: 0.7131 - prc: 0.4049 - val_loss: 0.5544 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6847 - val_prc: 0.3818\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9216 - tp: 223.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 175.0000 - accuracy: 0.7189 - precision: 0.3614 - recall: 0.5603 - auc: 0.7135 - prc: 0.3985 - val_loss: 0.5554 - val_tp: 43.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 48.0000 - val_accuracy: 0.7372 - val_precision: 0.3359 - val_recall: 0.4725 - val_auc: 0.6849 - val_prc: 0.3827\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9225 - tp: 217.0000 - fp: 401.0000 - tn: 1225.0000 - fn: 181.0000 - accuracy: 0.7125 - precision: 0.3511 - recall: 0.5452 - auc: 0.7135 - prc: 0.3987 - val_loss: 0.5477 - val_tp: 42.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 49.0000 - val_accuracy: 0.7490 - val_precision: 0.3500 - val_recall: 0.4615 - val_auc: 0.6858 - val_prc: 0.3838\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9237 - tp: 217.0000 - fp: 373.0000 - tn: 1253.0000 - fn: 181.0000 - accuracy: 0.7263 - precision: 0.3678 - recall: 0.5452 - auc: 0.7111 - prc: 0.3980 - val_loss: 0.6565 - val_tp: 63.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 28.0000 - val_accuracy: 0.6008 - val_precision: 0.2658 - val_recall: 0.6923 - val_auc: 0.6813 - val_prc: 0.3421\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9232 - tp: 222.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 176.0000 - accuracy: 0.7075 - precision: 0.3480 - recall: 0.5578 - auc: 0.7128 - prc: 0.4042 - val_loss: 0.6652 - val_tp: 64.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 27.0000 - val_accuracy: 0.5850 - val_precision: 0.2591 - val_recall: 0.7033 - val_auc: 0.6813 - val_prc: 0.3404\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9215 - tp: 227.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 171.0000 - accuracy: 0.7228 - precision: 0.3679 - recall: 0.5704 - auc: 0.7135 - prc: 0.4027 - val_loss: 0.5677 - val_tp: 43.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 48.0000 - val_accuracy: 0.7154 - val_precision: 0.3094 - val_recall: 0.4725 - val_auc: 0.6849 - val_prc: 0.3853\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9186 - tp: 218.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 180.0000 - accuracy: 0.7125 - precision: 0.3516 - recall: 0.5477 - auc: 0.7162 - prc: 0.4085 - val_loss: 0.5436 - val_tp: 41.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 50.0000 - val_accuracy: 0.7530 - val_precision: 0.3534 - val_recall: 0.4505 - val_auc: 0.6858 - val_prc: 0.3883\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9278 - tp: 204.0000 - fp: 393.0000 - tn: 1233.0000 - fn: 194.0000 - accuracy: 0.7100 - precision: 0.3417 - recall: 0.5126 - auc: 0.7060 - prc: 0.3969 - val_loss: 0.6215 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6844 - val_prc: 0.3787\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9186 - tp: 238.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 160.0000 - accuracy: 0.6957 - precision: 0.3429 - recall: 0.5980 - auc: 0.7153 - prc: 0.3990 - val_loss: 0.5385 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6858 - val_prc: 0.3910\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9190 - tp: 209.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 189.0000 - accuracy: 0.7238 - precision: 0.3610 - recall: 0.5251 - auc: 0.7161 - prc: 0.4117 - val_loss: 0.6557 - val_tp: 62.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 29.0000 - val_accuracy: 0.5988 - val_precision: 0.2627 - val_recall: 0.6813 - val_auc: 0.6824 - val_prc: 0.3500\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9219 - tp: 225.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 173.0000 - accuracy: 0.7174 - precision: 0.3606 - recall: 0.5653 - auc: 0.7122 - prc: 0.3945 - val_loss: 0.6098 - val_tp: 54.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 37.0000 - val_accuracy: 0.6818 - val_precision: 0.3034 - val_recall: 0.5934 - val_auc: 0.6853 - val_prc: 0.3888\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9238 - tp: 216.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 182.0000 - accuracy: 0.7129 - precision: 0.3512 - recall: 0.5427 - auc: 0.7115 - prc: 0.4082 - val_loss: 0.5640 - val_tp: 43.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 48.0000 - val_accuracy: 0.7233 - val_precision: 0.3185 - val_recall: 0.4725 - val_auc: 0.6855 - val_prc: 0.3843\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9221 - tp: 216.0000 - fp: 392.0000 - tn: 1234.0000 - fn: 182.0000 - accuracy: 0.7164 - precision: 0.3553 - recall: 0.5427 - auc: 0.7119 - prc: 0.4145 - val_loss: 0.5346 - val_tp: 41.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 50.0000 - val_accuracy: 0.7668 - val_precision: 0.3761 - val_recall: 0.4505 - val_auc: 0.6857 - val_prc: 0.4086\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9219 - tp: 213.0000 - fp: 391.0000 - tn: 1235.0000 - fn: 185.0000 - accuracy: 0.7154 - precision: 0.3526 - recall: 0.5352 - auc: 0.7126 - prc: 0.4040 - val_loss: 0.5810 - val_tp: 46.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 45.0000 - val_accuracy: 0.7055 - val_precision: 0.3067 - val_recall: 0.5055 - val_auc: 0.6855 - val_prc: 0.3867\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9158 - tp: 215.0000 - fp: 375.0000 - tn: 1251.0000 - fn: 183.0000 - accuracy: 0.7243 - precision: 0.3644 - recall: 0.5402 - auc: 0.7203 - prc: 0.4125 - val_loss: 0.6484 - val_tp: 60.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 31.0000 - val_accuracy: 0.6067 - val_precision: 0.2632 - val_recall: 0.6593 - val_auc: 0.6836 - val_prc: 0.3572\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9201 - tp: 227.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 171.0000 - accuracy: 0.7110 - precision: 0.3541 - recall: 0.5704 - auc: 0.7138 - prc: 0.4155 - val_loss: 0.6040 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6857 - val_prc: 0.3937\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9175 - tp: 214.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 184.0000 - accuracy: 0.7105 - precision: 0.3474 - recall: 0.5377 - auc: 0.7159 - prc: 0.4091 - val_loss: 0.6051 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6859 - val_prc: 0.3929\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9221 - tp: 216.0000 - fp: 393.0000 - tn: 1233.0000 - fn: 182.0000 - accuracy: 0.7159 - precision: 0.3547 - recall: 0.5427 - auc: 0.7129 - prc: 0.4139 - val_loss: 0.6205 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6855 - val_prc: 0.3904\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9185 - tp: 221.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 177.0000 - accuracy: 0.7149 - precision: 0.3559 - recall: 0.5553 - auc: 0.7142 - prc: 0.4131 - val_loss: 0.5914 - val_tp: 48.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 43.0000 - val_accuracy: 0.6937 - val_precision: 0.3000 - val_recall: 0.5275 - val_auc: 0.6857 - val_prc: 0.3950\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9232 - tp: 209.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 189.0000 - accuracy: 0.7120 - precision: 0.3466 - recall: 0.5251 - auc: 0.7107 - prc: 0.4099 - val_loss: 0.5306 - val_tp: 39.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 52.0000 - val_accuracy: 0.7688 - val_precision: 0.3750 - val_recall: 0.4286 - val_auc: 0.6861 - val_prc: 0.4092\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9199 - tp: 221.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 177.0000 - accuracy: 0.7125 - precision: 0.3530 - recall: 0.5553 - auc: 0.7136 - prc: 0.4088 - val_loss: 0.5747 - val_tp: 45.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 46.0000 - val_accuracy: 0.7095 - val_precision: 0.3082 - val_recall: 0.4945 - val_auc: 0.6861 - val_prc: 0.3844\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9178 - tp: 221.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 177.0000 - accuracy: 0.7218 - precision: 0.3641 - recall: 0.5553 - auc: 0.7175 - prc: 0.4123 - val_loss: 0.5763 - val_tp: 45.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 46.0000 - val_accuracy: 0.7055 - val_precision: 0.3041 - val_recall: 0.4945 - val_auc: 0.6866 - val_prc: 0.3860\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9221 - tp: 221.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 177.0000 - accuracy: 0.7199 - precision: 0.3617 - recall: 0.5553 - auc: 0.7122 - prc: 0.3984 - val_loss: 0.5554 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6864 - val_prc: 0.3929\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9160 - tp: 224.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 174.0000 - accuracy: 0.7120 - precision: 0.3539 - recall: 0.5628 - auc: 0.7178 - prc: 0.4159 - val_loss: 0.5226 - val_tp: 38.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 53.0000 - val_accuracy: 0.7806 - val_precision: 0.3958 - val_recall: 0.4176 - val_auc: 0.6861 - val_prc: 0.4086\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9216 - tp: 219.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 179.0000 - accuracy: 0.7199 - precision: 0.3608 - recall: 0.5503 - auc: 0.7116 - prc: 0.4100 - val_loss: 0.6057 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6858 - val_prc: 0.3958\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9224 - tp: 217.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 181.0000 - accuracy: 0.7120 - precision: 0.3506 - recall: 0.5452 - auc: 0.7100 - prc: 0.4110 - val_loss: 0.6015 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6856 - val_prc: 0.3941\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9143 - tp: 218.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 180.0000 - accuracy: 0.7125 - precision: 0.3516 - recall: 0.5477 - auc: 0.7178 - prc: 0.4102 - val_loss: 0.5509 - val_tp: 42.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 49.0000 - val_accuracy: 0.7451 - val_precision: 0.3443 - val_recall: 0.4615 - val_auc: 0.6865 - val_prc: 0.3925\n",
      "Epoch 132/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9190 - tp: 220.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 178.0000 - accuracy: 0.7213 - precision: 0.3630 - recall: 0.5528 - auc: 0.7147 - prc: 0.4166 - val_loss: 0.5978 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6855 - val_prc: 0.3939\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9159 - tp: 219.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 179.0000 - accuracy: 0.7204 - precision: 0.3614 - recall: 0.5503 - auc: 0.7167 - prc: 0.4211 - val_loss: 0.6144 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6865 - val_prc: 0.3949\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9242 - tp: 215.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 183.0000 - accuracy: 0.6947 - precision: 0.3308 - recall: 0.5402 - auc: 0.7087 - prc: 0.4026 - val_loss: 0.5842 - val_tp: 47.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 44.0000 - val_accuracy: 0.7036 - val_precision: 0.3072 - val_recall: 0.5165 - val_auc: 0.6860 - val_prc: 0.3867\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9184 - tp: 213.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 185.0000 - accuracy: 0.7223 - precision: 0.3610 - recall: 0.5352 - auc: 0.7144 - prc: 0.4208 - val_loss: 0.5882 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6860 - val_prc: 0.3866\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9151 - tp: 219.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 179.0000 - accuracy: 0.7208 - precision: 0.3620 - recall: 0.5503 - auc: 0.7196 - prc: 0.4136 - val_loss: 0.5883 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6857 - val_prc: 0.3853\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9170 - tp: 214.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 184.0000 - accuracy: 0.7228 - precision: 0.3621 - recall: 0.5377 - auc: 0.7164 - prc: 0.4218 - val_loss: 0.6028 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6859 - val_prc: 0.3926\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9155 - tp: 212.0000 - fp: 371.0000 - tn: 1255.0000 - fn: 186.0000 - accuracy: 0.7248 - precision: 0.3636 - recall: 0.5327 - auc: 0.7176 - prc: 0.4241 - val_loss: 0.5932 - val_tp: 49.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 42.0000 - val_accuracy: 0.6917 - val_precision: 0.3006 - val_recall: 0.5385 - val_auc: 0.6864 - val_prc: 0.3882\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9141 - tp: 224.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 174.0000 - accuracy: 0.7120 - precision: 0.3539 - recall: 0.5628 - auc: 0.7185 - prc: 0.4131 - val_loss: 0.5919 - val_tp: 49.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 42.0000 - val_accuracy: 0.6957 - val_precision: 0.3043 - val_recall: 0.5385 - val_auc: 0.6869 - val_prc: 0.3894\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9135 - tp: 218.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 180.0000 - accuracy: 0.7184 - precision: 0.3586 - recall: 0.5477 - auc: 0.7188 - prc: 0.4149 - val_loss: 0.6687 - val_tp: 65.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 26.0000 - val_accuracy: 0.5850 - val_precision: 0.2610 - val_recall: 0.7143 - val_auc: 0.6855 - val_prc: 0.3722\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9155 - tp: 233.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 165.0000 - accuracy: 0.7021 - precision: 0.3472 - recall: 0.5854 - auc: 0.7178 - prc: 0.4122 - val_loss: 0.5233 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6860 - val_prc: 0.4100\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9185 - tp: 236.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 162.0000 - accuracy: 0.7164 - precision: 0.3642 - recall: 0.5930 - auc: 0.7145 - prc: 0.4119 - val_loss: 0.5319 - val_tp: 40.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 51.0000 - val_accuracy: 0.7648 - val_precision: 0.3704 - val_recall: 0.4396 - val_auc: 0.6868 - val_prc: 0.4097\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9191 - tp: 208.0000 - fp: 375.0000 - tn: 1251.0000 - fn: 190.0000 - accuracy: 0.7208 - precision: 0.3568 - recall: 0.5226 - auc: 0.7139 - prc: 0.4228 - val_loss: 0.5833 - val_tp: 47.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 44.0000 - val_accuracy: 0.7036 - val_precision: 0.3072 - val_recall: 0.5165 - val_auc: 0.6863 - val_prc: 0.3865\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9154 - tp: 213.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 185.0000 - accuracy: 0.7110 - precision: 0.3475 - recall: 0.5352 - auc: 0.7153 - prc: 0.4243 - val_loss: 0.6131 - val_tp: 55.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 36.0000 - val_accuracy: 0.6739 - val_precision: 0.2989 - val_recall: 0.6044 - val_auc: 0.6869 - val_prc: 0.3951\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9143 - tp: 212.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 186.0000 - accuracy: 0.7115 - precision: 0.3475 - recall: 0.5327 - auc: 0.7185 - prc: 0.4309 - val_loss: 0.5833 - val_tp: 47.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 44.0000 - val_accuracy: 0.7036 - val_precision: 0.3072 - val_recall: 0.5165 - val_auc: 0.6865 - val_prc: 0.3873\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9159 - tp: 222.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 176.0000 - accuracy: 0.7036 - precision: 0.3437 - recall: 0.5578 - auc: 0.7165 - prc: 0.4151 - val_loss: 0.5963 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6869 - val_prc: 0.3903\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9160 - tp: 214.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 184.0000 - accuracy: 0.7228 - precision: 0.3621 - recall: 0.5377 - auc: 0.7164 - prc: 0.4210 - val_loss: 0.5972 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6871 - val_prc: 0.3903\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9155 - tp: 216.0000 - fp: 395.0000 - tn: 1231.0000 - fn: 182.0000 - accuracy: 0.7149 - precision: 0.3535 - recall: 0.5427 - auc: 0.7167 - prc: 0.4203 - val_loss: 0.5807 - val_tp: 47.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 44.0000 - val_accuracy: 0.7055 - val_precision: 0.3092 - val_recall: 0.5165 - val_auc: 0.6865 - val_prc: 0.3875\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9222 - tp: 212.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 186.0000 - accuracy: 0.7095 - precision: 0.3453 - recall: 0.5327 - auc: 0.7099 - prc: 0.4198 - val_loss: 0.5942 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6874 - val_prc: 0.3877\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9139 - tp: 218.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 180.0000 - accuracy: 0.7080 - precision: 0.3466 - recall: 0.5477 - auc: 0.7178 - prc: 0.4140 - val_loss: 0.5405 - val_tp: 41.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 50.0000 - val_accuracy: 0.7549 - val_precision: 0.3565 - val_recall: 0.4505 - val_auc: 0.6869 - val_prc: 0.4102\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9144 - tp: 230.0000 - fp: 406.0000 - tn: 1220.0000 - fn: 168.0000 - accuracy: 0.7164 - precision: 0.3616 - recall: 0.5779 - auc: 0.7181 - prc: 0.4243 - val_loss: 0.5404 - val_tp: 41.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 50.0000 - val_accuracy: 0.7549 - val_precision: 0.3565 - val_recall: 0.4505 - val_auc: 0.6880 - val_prc: 0.4115\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9143 - tp: 217.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 181.0000 - accuracy: 0.7352 - precision: 0.3794 - recall: 0.5452 - auc: 0.7179 - prc: 0.4189 - val_loss: 0.6721 - val_tp: 65.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 26.0000 - val_accuracy: 0.5850 - val_precision: 0.2610 - val_recall: 0.7143 - val_auc: 0.6869 - val_prc: 0.3840\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9186 - tp: 237.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 161.0000 - accuracy: 0.7011 - precision: 0.3480 - recall: 0.5955 - auc: 0.7147 - prc: 0.4143 - val_loss: 0.5120 - val_tp: 36.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 55.0000 - val_accuracy: 0.7885 - val_precision: 0.4091 - val_recall: 0.3956 - val_auc: 0.6877 - val_prc: 0.4112\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9157 - tp: 218.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 180.0000 - accuracy: 0.7120 - precision: 0.3510 - recall: 0.5477 - auc: 0.7147 - prc: 0.4214 - val_loss: 0.4967 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6874 - val_prc: 0.4124\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9179 - tp: 211.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 187.0000 - accuracy: 0.7357 - precision: 0.3775 - recall: 0.5302 - auc: 0.7131 - prc: 0.4214 - val_loss: 0.6052 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6880 - val_prc: 0.3903\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9175 - tp: 216.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 182.0000 - accuracy: 0.7174 - precision: 0.3564 - recall: 0.5427 - auc: 0.7141 - prc: 0.4302 - val_loss: 0.5744 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6878 - val_prc: 0.4011\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9116 - tp: 209.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 189.0000 - accuracy: 0.7238 - precision: 0.3610 - recall: 0.5251 - auc: 0.7204 - prc: 0.4323 - val_loss: 0.6076 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6871 - val_prc: 0.3901\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9162 - tp: 228.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 170.0000 - accuracy: 0.7045 - precision: 0.3476 - recall: 0.5729 - auc: 0.7152 - prc: 0.4087 - val_loss: 0.5786 - val_tp: 46.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 45.0000 - val_accuracy: 0.7154 - val_precision: 0.3172 - val_recall: 0.5055 - val_auc: 0.6881 - val_prc: 0.3944\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9172 - tp: 211.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 187.0000 - accuracy: 0.7337 - precision: 0.3748 - recall: 0.5302 - auc: 0.7155 - prc: 0.4235 - val_loss: 0.6911 - val_tp: 68.0000 - val_fp: 201.0000 - val_tn: 214.0000 - val_fn: 23.0000 - val_accuracy: 0.5573 - val_precision: 0.2528 - val_recall: 0.7473 - val_auc: 0.6872 - val_prc: 0.3738\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9190 - tp: 232.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 166.0000 - accuracy: 0.6976 - precision: 0.3422 - recall: 0.5829 - auc: 0.7128 - prc: 0.4118 - val_loss: 0.5846 - val_tp: 47.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 44.0000 - val_accuracy: 0.7016 - val_precision: 0.3052 - val_recall: 0.5165 - val_auc: 0.6881 - val_prc: 0.3878\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9152 - tp: 213.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 185.0000 - accuracy: 0.7258 - precision: 0.3654 - recall: 0.5352 - auc: 0.7169 - prc: 0.4309 - val_loss: 0.5417 - val_tp: 41.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 50.0000 - val_accuracy: 0.7569 - val_precision: 0.3596 - val_recall: 0.4505 - val_auc: 0.6883 - val_prc: 0.4106\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9156 - tp: 225.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 173.0000 - accuracy: 0.7115 - precision: 0.3538 - recall: 0.5653 - auc: 0.7161 - prc: 0.4209 - val_loss: 0.5698 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6883 - val_prc: 0.3951\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9130 - tp: 208.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 190.0000 - accuracy: 0.7199 - precision: 0.3556 - recall: 0.5226 - auc: 0.7194 - prc: 0.4134 - val_loss: 0.6163 - val_tp: 56.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 35.0000 - val_accuracy: 0.6739 - val_precision: 0.3011 - val_recall: 0.6154 - val_auc: 0.6891 - val_prc: 0.4017\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9153 - tp: 226.0000 - fp: 421.0000 - tn: 1205.0000 - fn: 172.0000 - accuracy: 0.7070 - precision: 0.3493 - recall: 0.5678 - auc: 0.7167 - prc: 0.4165 - val_loss: 0.5779 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6880 - val_prc: 0.3959\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9170 - tp: 218.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 180.0000 - accuracy: 0.7199 - precision: 0.3603 - recall: 0.5477 - auc: 0.7150 - prc: 0.4216 - val_loss: 0.5606 - val_tp: 43.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 48.0000 - val_accuracy: 0.7253 - val_precision: 0.3209 - val_recall: 0.4725 - val_auc: 0.6881 - val_prc: 0.4104\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9125 - tp: 220.0000 - fp: 365.0000 - tn: 1261.0000 - fn: 178.0000 - accuracy: 0.7317 - precision: 0.3761 - recall: 0.5528 - auc: 0.7184 - prc: 0.4299 - val_loss: 0.6022 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6883 - val_prc: 0.3884\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9155 - tp: 212.0000 - fp: 379.0000 - tn: 1247.0000 - fn: 186.0000 - accuracy: 0.7208 - precision: 0.3587 - recall: 0.5327 - auc: 0.7158 - prc: 0.4161 - val_loss: 0.5559 - val_tp: 42.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 49.0000 - val_accuracy: 0.7332 - val_precision: 0.3281 - val_recall: 0.4615 - val_auc: 0.6880 - val_prc: 0.4113\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9118 - tp: 227.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 171.0000 - accuracy: 0.7134 - precision: 0.3569 - recall: 0.5704 - auc: 0.7195 - prc: 0.4282 - val_loss: 0.5709 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6880 - val_prc: 0.4021\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9171 - tp: 210.0000 - fp: 382.0000 - tn: 1244.0000 - fn: 188.0000 - accuracy: 0.7184 - precision: 0.3547 - recall: 0.5276 - auc: 0.7131 - prc: 0.4200 - val_loss: 0.6827 - val_tp: 67.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 24.0000 - val_accuracy: 0.5751 - val_precision: 0.2597 - val_recall: 0.7363 - val_auc: 0.6869 - val_prc: 0.3794\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9195 - tp: 228.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 170.0000 - accuracy: 0.7075 - precision: 0.3508 - recall: 0.5729 - auc: 0.7109 - prc: 0.4099 - val_loss: 0.5599 - val_tp: 43.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 48.0000 - val_accuracy: 0.7312 - val_precision: 0.3282 - val_recall: 0.4725 - val_auc: 0.6886 - val_prc: 0.4025\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9133 - tp: 213.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 185.0000 - accuracy: 0.7189 - precision: 0.3568 - recall: 0.5352 - auc: 0.7162 - prc: 0.4254 - val_loss: 0.5448 - val_tp: 42.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 49.0000 - val_accuracy: 0.7549 - val_precision: 0.3590 - val_recall: 0.4615 - val_auc: 0.6893 - val_prc: 0.4117\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9118 - tp: 220.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 178.0000 - accuracy: 0.7090 - precision: 0.3487 - recall: 0.5528 - auc: 0.7183 - prc: 0.4221 - val_loss: 0.5473 - val_tp: 42.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 49.0000 - val_accuracy: 0.7549 - val_precision: 0.3590 - val_recall: 0.4615 - val_auc: 0.6889 - val_prc: 0.4117\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9164 - tp: 200.0000 - fp: 364.0000 - tn: 1262.0000 - fn: 198.0000 - accuracy: 0.7223 - precision: 0.3546 - recall: 0.5025 - auc: 0.7134 - prc: 0.4212 - val_loss: 0.6029 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6887 - val_prc: 0.3897\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9130 - tp: 215.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 183.0000 - accuracy: 0.7189 - precision: 0.3577 - recall: 0.5402 - auc: 0.7168 - prc: 0.4319 - val_loss: 0.5538 - val_tp: 42.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 49.0000 - val_accuracy: 0.7411 - val_precision: 0.3387 - val_recall: 0.4615 - val_auc: 0.6884 - val_prc: 0.4119\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9134 - tp: 216.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 182.0000 - accuracy: 0.7154 - precision: 0.3541 - recall: 0.5427 - auc: 0.7175 - prc: 0.4364 - val_loss: 0.5832 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6887 - val_prc: 0.3966\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9122 - tp: 216.0000 - fp: 378.0000 - tn: 1248.0000 - fn: 182.0000 - accuracy: 0.7233 - precision: 0.3636 - recall: 0.5427 - auc: 0.7180 - prc: 0.4308 - val_loss: 0.5870 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6884 - val_prc: 0.3875\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9178 - tp: 229.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 169.0000 - accuracy: 0.7090 - precision: 0.3529 - recall: 0.5754 - auc: 0.7149 - prc: 0.4164 - val_loss: 0.5709 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6883 - val_prc: 0.4111\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9116 - tp: 211.0000 - fp: 376.0000 - tn: 1250.0000 - fn: 187.0000 - accuracy: 0.7218 - precision: 0.3595 - recall: 0.5302 - auc: 0.7187 - prc: 0.4340 - val_loss: 0.6095 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6887 - val_prc: 0.3906\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9147 - tp: 218.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 180.0000 - accuracy: 0.7080 - precision: 0.3466 - recall: 0.5477 - auc: 0.7152 - prc: 0.4278 - val_loss: 0.6042 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6886 - val_prc: 0.3901\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9119 - tp: 212.0000 - fp: 367.0000 - tn: 1259.0000 - fn: 186.0000 - accuracy: 0.7268 - precision: 0.3661 - recall: 0.5327 - auc: 0.7196 - prc: 0.4300 - val_loss: 0.5620 - val_tp: 44.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 47.0000 - val_accuracy: 0.7253 - val_precision: 0.3235 - val_recall: 0.4835 - val_auc: 0.6889 - val_prc: 0.4126\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9178 - tp: 224.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 174.0000 - accuracy: 0.7095 - precision: 0.3511 - recall: 0.5628 - auc: 0.7137 - prc: 0.4210 - val_loss: 0.5943 - val_tp: 51.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 40.0000 - val_accuracy: 0.7016 - val_precision: 0.3148 - val_recall: 0.5604 - val_auc: 0.6888 - val_prc: 0.3878\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9111 - tp: 211.0000 - fp: 365.0000 - tn: 1261.0000 - fn: 187.0000 - accuracy: 0.7273 - precision: 0.3663 - recall: 0.5302 - auc: 0.7201 - prc: 0.4203 - val_loss: 0.6718 - val_tp: 63.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 28.0000 - val_accuracy: 0.5830 - val_precision: 0.2561 - val_recall: 0.6923 - val_auc: 0.6879 - val_prc: 0.3821\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9165 - tp: 221.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 177.0000 - accuracy: 0.7031 - precision: 0.3426 - recall: 0.5553 - auc: 0.7138 - prc: 0.4293 - val_loss: 0.5926 - val_tp: 51.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 40.0000 - val_accuracy: 0.7016 - val_precision: 0.3148 - val_recall: 0.5604 - val_auc: 0.6892 - val_prc: 0.3885\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9135 - tp: 224.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 174.0000 - accuracy: 0.7139 - precision: 0.3561 - recall: 0.5628 - auc: 0.7158 - prc: 0.4283 - val_loss: 0.5912 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6890 - val_prc: 0.3880\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9144 - tp: 217.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 181.0000 - accuracy: 0.7129 - precision: 0.3517 - recall: 0.5452 - auc: 0.7162 - prc: 0.4237 - val_loss: 0.5674 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6882 - val_prc: 0.4106\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9126 - tp: 214.0000 - fp: 385.0000 - tn: 1241.0000 - fn: 184.0000 - accuracy: 0.7189 - precision: 0.3573 - recall: 0.5377 - auc: 0.7189 - prc: 0.4242 - val_loss: 0.6129 - val_tp: 55.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 36.0000 - val_accuracy: 0.6779 - val_precision: 0.3022 - val_recall: 0.6044 - val_auc: 0.6894 - val_prc: 0.3938\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9117 - tp: 218.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 180.0000 - accuracy: 0.7302 - precision: 0.3733 - recall: 0.5477 - auc: 0.7191 - prc: 0.4271 - val_loss: 0.6653 - val_tp: 63.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 28.0000 - val_accuracy: 0.5889 - val_precision: 0.2593 - val_recall: 0.6923 - val_auc: 0.6893 - val_prc: 0.3997\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9130 - tp: 229.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 169.0000 - accuracy: 0.7174 - precision: 0.3623 - recall: 0.5754 - auc: 0.7193 - prc: 0.4230 - val_loss: 0.6188 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.6891 - val_prc: 0.3936\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9151 - tp: 220.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 178.0000 - accuracy: 0.7120 - precision: 0.3520 - recall: 0.5528 - auc: 0.7149 - prc: 0.4152 - val_loss: 0.6229 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6897 - val_prc: 0.4003\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9102 - tp: 218.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 180.0000 - accuracy: 0.7263 - precision: 0.3682 - recall: 0.5477 - auc: 0.7205 - prc: 0.4319 - val_loss: 0.5710 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6889 - val_prc: 0.4041\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9082 - tp: 228.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 170.0000 - accuracy: 0.7125 - precision: 0.3562 - recall: 0.5729 - auc: 0.7227 - prc: 0.4335 - val_loss: 0.4876 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6875 - val_prc: 0.4080\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9166 - tp: 203.0000 - fp: 356.0000 - tn: 1270.0000 - fn: 195.0000 - accuracy: 0.7278 - precision: 0.3631 - recall: 0.5101 - auc: 0.7156 - prc: 0.4277 - val_loss: 0.5942 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.6890 - val_prc: 0.3908\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9088 - tp: 219.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 179.0000 - accuracy: 0.7129 - precision: 0.3527 - recall: 0.5503 - auc: 0.7209 - prc: 0.4333 - val_loss: 0.5675 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6893 - val_prc: 0.4123\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9142 - tp: 215.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 183.0000 - accuracy: 0.7179 - precision: 0.3566 - recall: 0.5402 - auc: 0.7166 - prc: 0.4184 - val_loss: 0.6512 - val_tp: 61.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 30.0000 - val_accuracy: 0.6107 - val_precision: 0.2675 - val_recall: 0.6703 - val_auc: 0.6903 - val_prc: 0.4093\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9097 - tp: 217.0000 - fp: 392.0000 - tn: 1234.0000 - fn: 181.0000 - accuracy: 0.7169 - precision: 0.3563 - recall: 0.5452 - auc: 0.7216 - prc: 0.4276 - val_loss: 0.6290 - val_tp: 56.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 35.0000 - val_accuracy: 0.6443 - val_precision: 0.2786 - val_recall: 0.6154 - val_auc: 0.6891 - val_prc: 0.4063\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9109 - tp: 224.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 174.0000 - accuracy: 0.7120 - precision: 0.3539 - recall: 0.5628 - auc: 0.7206 - prc: 0.4215 - val_loss: 0.5899 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6885 - val_prc: 0.3901\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9108 - tp: 228.0000 - fp: 427.0000 - tn: 1199.0000 - fn: 170.0000 - accuracy: 0.7050 - precision: 0.3481 - recall: 0.5729 - auc: 0.7200 - prc: 0.4230 - val_loss: 0.5566 - val_tp: 44.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 47.0000 - val_accuracy: 0.7352 - val_precision: 0.3359 - val_recall: 0.4835 - val_auc: 0.6884 - val_prc: 0.4113\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9107 - tp: 218.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 180.0000 - accuracy: 0.7213 - precision: 0.3621 - recall: 0.5477 - auc: 0.7200 - prc: 0.4230 - val_loss: 0.6131 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6891 - val_prc: 0.3936\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9127 - tp: 210.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 188.0000 - accuracy: 0.7248 - precision: 0.3627 - recall: 0.5276 - auc: 0.7168 - prc: 0.4297 - val_loss: 0.5522 - val_tp: 43.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 48.0000 - val_accuracy: 0.7391 - val_precision: 0.3386 - val_recall: 0.4725 - val_auc: 0.6889 - val_prc: 0.4119\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9130 - tp: 224.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 174.0000 - accuracy: 0.7036 - precision: 0.3446 - recall: 0.5628 - auc: 0.7174 - prc: 0.4359 - val_loss: 0.5860 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6893 - val_prc: 0.4046\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9138 - tp: 212.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 186.0000 - accuracy: 0.7273 - precision: 0.3668 - recall: 0.5327 - auc: 0.7162 - prc: 0.4319 - val_loss: 0.5859 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6893 - val_prc: 0.3930\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9086 - tp: 222.0000 - fp: 389.0000 - tn: 1237.0000 - fn: 176.0000 - accuracy: 0.7208 - precision: 0.3633 - recall: 0.5578 - auc: 0.7231 - prc: 0.4262 - val_loss: 0.6131 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6895 - val_prc: 0.3947\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9115 - tp: 220.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 178.0000 - accuracy: 0.7159 - precision: 0.3566 - recall: 0.5528 - auc: 0.7182 - prc: 0.4344 - val_loss: 0.6090 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6892 - val_prc: 0.3935\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9111 - tp: 226.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 172.0000 - accuracy: 0.7204 - precision: 0.3645 - recall: 0.5678 - auc: 0.7173 - prc: 0.4309 - val_loss: 0.5873 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6894 - val_prc: 0.3931\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9101 - tp: 222.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 176.0000 - accuracy: 0.7204 - precision: 0.3627 - recall: 0.5578 - auc: 0.7199 - prc: 0.4371 - val_loss: 0.5679 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6893 - val_prc: 0.4132\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9126 - tp: 212.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 186.0000 - accuracy: 0.7258 - precision: 0.3649 - recall: 0.5327 - auc: 0.7172 - prc: 0.4163 - val_loss: 0.5623 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6894 - val_prc: 0.4125\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9108 - tp: 208.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 190.0000 - accuracy: 0.7100 - precision: 0.3438 - recall: 0.5226 - auc: 0.7164 - prc: 0.4367 - val_loss: 0.5827 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6897 - val_prc: 0.4042\n",
      "Epoch 208/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9143 - tp: 210.0000 - fp: 360.0000 - tn: 1266.0000 - fn: 188.0000 - accuracy: 0.7292 - precision: 0.3684 - recall: 0.5276 - auc: 0.7153 - prc: 0.4312 - val_loss: 0.5790 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6894 - val_prc: 0.4049\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9089 - tp: 219.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 179.0000 - accuracy: 0.7278 - precision: 0.3706 - recall: 0.5503 - auc: 0.7209 - prc: 0.4320 - val_loss: 0.5942 - val_tp: 51.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 40.0000 - val_accuracy: 0.6976 - val_precision: 0.3110 - val_recall: 0.5604 - val_auc: 0.6892 - val_prc: 0.3934\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9110 - tp: 218.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 180.0000 - accuracy: 0.7228 - precision: 0.3639 - recall: 0.5477 - auc: 0.7186 - prc: 0.4287 - val_loss: 0.5629 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6891 - val_prc: 0.4131\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9092 - tp: 215.0000 - fp: 379.0000 - tn: 1247.0000 - fn: 183.0000 - accuracy: 0.7223 - precision: 0.3620 - recall: 0.5402 - auc: 0.7205 - prc: 0.4336 - val_loss: 0.6439 - val_tp: 59.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 32.0000 - val_accuracy: 0.6245 - val_precision: 0.2719 - val_recall: 0.6484 - val_auc: 0.6898 - val_prc: 0.4006\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9095 - tp: 219.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 179.0000 - accuracy: 0.7169 - precision: 0.3573 - recall: 0.5503 - auc: 0.7197 - prc: 0.4292 - val_loss: 0.5237 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6886 - val_prc: 0.4156\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9146 - tp: 215.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 183.0000 - accuracy: 0.7134 - precision: 0.3513 - recall: 0.5402 - auc: 0.7141 - prc: 0.4223 - val_loss: 0.6060 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6902 - val_prc: 0.3951\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9113 - tp: 219.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 179.0000 - accuracy: 0.7223 - precision: 0.3638 - recall: 0.5503 - auc: 0.7161 - prc: 0.4302 - val_loss: 0.5983 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6896 - val_prc: 0.3890\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9086 - tp: 215.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 183.0000 - accuracy: 0.7169 - precision: 0.3554 - recall: 0.5402 - auc: 0.7211 - prc: 0.4342 - val_loss: 0.5800 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6894 - val_prc: 0.4119\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9082 - tp: 228.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 170.0000 - accuracy: 0.7164 - precision: 0.3608 - recall: 0.5729 - auc: 0.7215 - prc: 0.4308 - val_loss: 0.5547 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6888 - val_prc: 0.4100\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9110 - tp: 221.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 177.0000 - accuracy: 0.7278 - precision: 0.3714 - recall: 0.5553 - auc: 0.7179 - prc: 0.4373 - val_loss: 0.5645 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6889 - val_prc: 0.4125\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9073 - tp: 228.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 170.0000 - accuracy: 0.7164 - precision: 0.3608 - recall: 0.5729 - auc: 0.7215 - prc: 0.4369 - val_loss: 0.5552 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6891 - val_prc: 0.4126\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9088 - tp: 206.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 192.0000 - accuracy: 0.7258 - precision: 0.3620 - recall: 0.5176 - auc: 0.7200 - prc: 0.4376 - val_loss: 0.5567 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6887 - val_prc: 0.4125\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9072 - tp: 215.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 183.0000 - accuracy: 0.7288 - precision: 0.3701 - recall: 0.5402 - auc: 0.7208 - prc: 0.4395 - val_loss: 0.6198 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.6896 - val_prc: 0.3939\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9071 - tp: 224.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 174.0000 - accuracy: 0.7100 - precision: 0.3516 - recall: 0.5628 - auc: 0.7237 - prc: 0.4332 - val_loss: 0.5144 - val_tp: 37.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 54.0000 - val_accuracy: 0.7885 - val_precision: 0.4111 - val_recall: 0.4066 - val_auc: 0.6887 - val_prc: 0.4129\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9120 - tp: 213.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 185.0000 - accuracy: 0.7204 - precision: 0.3586 - recall: 0.5352 - auc: 0.7183 - prc: 0.4313 - val_loss: 0.6032 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6895 - val_prc: 0.3889\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9120 - tp: 220.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 178.0000 - accuracy: 0.7134 - precision: 0.3537 - recall: 0.5528 - auc: 0.7174 - prc: 0.4188 - val_loss: 0.5788 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6894 - val_prc: 0.3925\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9131 - tp: 210.0000 - fp: 358.0000 - tn: 1268.0000 - fn: 188.0000 - accuracy: 0.7302 - precision: 0.3697 - recall: 0.5276 - auc: 0.7175 - prc: 0.4218 - val_loss: 0.5818 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6895 - val_prc: 0.4124\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9055 - tp: 228.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 170.0000 - accuracy: 0.7105 - precision: 0.3540 - recall: 0.5729 - auc: 0.7246 - prc: 0.4347 - val_loss: 0.5524 - val_tp: 44.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 47.0000 - val_accuracy: 0.7510 - val_precision: 0.3577 - val_recall: 0.4835 - val_auc: 0.6889 - val_prc: 0.4132\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9102 - tp: 208.0000 - fp: 365.0000 - tn: 1261.0000 - fn: 190.0000 - accuracy: 0.7258 - precision: 0.3630 - recall: 0.5226 - auc: 0.7196 - prc: 0.4301 - val_loss: 0.6979 - val_tp: 65.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 26.0000 - val_accuracy: 0.5593 - val_precision: 0.2481 - val_recall: 0.7143 - val_auc: 0.6887 - val_prc: 0.3849\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9116 - tp: 226.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 172.0000 - accuracy: 0.7060 - precision: 0.3482 - recall: 0.5678 - auc: 0.7201 - prc: 0.4312 - val_loss: 0.5695 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6891 - val_prc: 0.4133\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9106 - tp: 212.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 186.0000 - accuracy: 0.7169 - precision: 0.3539 - recall: 0.5327 - auc: 0.7167 - prc: 0.4398 - val_loss: 0.6034 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6895 - val_prc: 0.3892\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9099 - tp: 212.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 186.0000 - accuracy: 0.7070 - precision: 0.3425 - recall: 0.5327 - auc: 0.7169 - prc: 0.4369 - val_loss: 0.6089 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6892 - val_prc: 0.3889\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9098 - tp: 210.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 188.0000 - accuracy: 0.7248 - precision: 0.3627 - recall: 0.5276 - auc: 0.7188 - prc: 0.4311 - val_loss: 0.6157 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6898 - val_prc: 0.3951\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9111 - tp: 228.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 170.0000 - accuracy: 0.7120 - precision: 0.3557 - recall: 0.5729 - auc: 0.7185 - prc: 0.4181 - val_loss: 0.5787 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6892 - val_prc: 0.4090\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9074 - tp: 218.0000 - fp: 382.0000 - tn: 1244.0000 - fn: 180.0000 - accuracy: 0.7223 - precision: 0.3633 - recall: 0.5477 - auc: 0.7219 - prc: 0.4317 - val_loss: 0.5593 - val_tp: 44.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 47.0000 - val_accuracy: 0.7352 - val_precision: 0.3359 - val_recall: 0.4835 - val_auc: 0.6896 - val_prc: 0.4075\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9067 - tp: 221.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 177.0000 - accuracy: 0.7233 - precision: 0.3659 - recall: 0.5553 - auc: 0.7217 - prc: 0.4366 - val_loss: 0.5812 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6888 - val_prc: 0.4018\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9100 - tp: 214.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 184.0000 - accuracy: 0.7213 - precision: 0.3603 - recall: 0.5377 - auc: 0.7199 - prc: 0.4279 - val_loss: 0.5728 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6892 - val_prc: 0.4070\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9090 - tp: 219.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 179.0000 - accuracy: 0.7149 - precision: 0.3549 - recall: 0.5503 - auc: 0.7197 - prc: 0.4268 - val_loss: 0.6251 - val_tp: 56.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 35.0000 - val_accuracy: 0.6601 - val_precision: 0.2902 - val_recall: 0.6154 - val_auc: 0.6890 - val_prc: 0.3903\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9091 - tp: 223.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 175.0000 - accuracy: 0.7243 - precision: 0.3680 - recall: 0.5603 - auc: 0.7197 - prc: 0.4164 - val_loss: 0.5773 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6895 - val_prc: 0.4031\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9116 - tp: 219.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 179.0000 - accuracy: 0.7288 - precision: 0.3718 - recall: 0.5503 - auc: 0.7174 - prc: 0.4214 - val_loss: 0.6047 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6892 - val_prc: 0.3895\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9122 - tp: 238.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 160.0000 - accuracy: 0.7026 - precision: 0.3500 - recall: 0.5980 - auc: 0.7161 - prc: 0.4213 - val_loss: 0.5776 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6888 - val_prc: 0.3864\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9114 - tp: 221.0000 - fp: 395.0000 - tn: 1231.0000 - fn: 177.0000 - accuracy: 0.7174 - precision: 0.3588 - recall: 0.5553 - auc: 0.7189 - prc: 0.4294 - val_loss: 0.5711 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6890 - val_prc: 0.3969\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9075 - tp: 226.0000 - fp: 382.0000 - tn: 1244.0000 - fn: 172.0000 - accuracy: 0.7263 - precision: 0.3717 - recall: 0.5678 - auc: 0.7218 - prc: 0.4375 - val_loss: 0.5431 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6884 - val_prc: 0.3912\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9048 - tp: 227.0000 - fp: 392.0000 - tn: 1234.0000 - fn: 171.0000 - accuracy: 0.7218 - precision: 0.3667 - recall: 0.5704 - auc: 0.7239 - prc: 0.4405 - val_loss: 0.5144 - val_tp: 38.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 53.0000 - val_accuracy: 0.7905 - val_precision: 0.4176 - val_recall: 0.4176 - val_auc: 0.6880 - val_prc: 0.4002\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9079 - tp: 213.0000 - fp: 362.0000 - tn: 1264.0000 - fn: 185.0000 - accuracy: 0.7297 - precision: 0.3704 - recall: 0.5352 - auc: 0.7196 - prc: 0.4317 - val_loss: 0.5439 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6892 - val_prc: 0.3973\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9116 - tp: 226.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 172.0000 - accuracy: 0.7100 - precision: 0.3526 - recall: 0.5678 - auc: 0.7165 - prc: 0.4217 - val_loss: 0.6120 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6890 - val_prc: 0.3825\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9068 - tp: 219.0000 - fp: 361.0000 - tn: 1265.0000 - fn: 179.0000 - accuracy: 0.7332 - precision: 0.3776 - recall: 0.5503 - auc: 0.7228 - prc: 0.4350 - val_loss: 0.6045 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6892 - val_prc: 0.3804\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9104 - tp: 232.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 166.0000 - accuracy: 0.7129 - precision: 0.3586 - recall: 0.5829 - auc: 0.7207 - prc: 0.4278 - val_loss: 0.5672 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6889 - val_prc: 0.3957\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9078 - tp: 215.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 183.0000 - accuracy: 0.7273 - precision: 0.3682 - recall: 0.5402 - auc: 0.7206 - prc: 0.4317 - val_loss: 0.5427 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6892 - val_prc: 0.3967\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9062 - tp: 228.0000 - fp: 393.0000 - tn: 1233.0000 - fn: 170.0000 - accuracy: 0.7218 - precision: 0.3671 - recall: 0.5729 - auc: 0.7230 - prc: 0.4384 - val_loss: 0.5649 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6890 - val_prc: 0.3973\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9060 - tp: 214.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 184.0000 - accuracy: 0.7194 - precision: 0.3579 - recall: 0.5377 - auc: 0.7218 - prc: 0.4321 - val_loss: 0.5544 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6889 - val_prc: 0.4061\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9046 - tp: 217.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 181.0000 - accuracy: 0.7268 - precision: 0.3684 - recall: 0.5452 - auc: 0.7235 - prc: 0.4436 - val_loss: 0.6427 - val_tp: 59.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 32.0000 - val_accuracy: 0.6304 - val_precision: 0.2757 - val_recall: 0.6484 - val_auc: 0.6894 - val_prc: 0.3893\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9095 - tp: 223.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 175.0000 - accuracy: 0.7164 - precision: 0.3585 - recall: 0.5603 - auc: 0.7196 - prc: 0.4343 - val_loss: 0.5974 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6887 - val_prc: 0.3826\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9091 - tp: 224.0000 - fp: 382.0000 - tn: 1244.0000 - fn: 174.0000 - accuracy: 0.7253 - precision: 0.3696 - recall: 0.5628 - auc: 0.7180 - prc: 0.4346 - val_loss: 0.5951 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6889 - val_prc: 0.3825\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9114 - tp: 219.0000 - fp: 395.0000 - tn: 1231.0000 - fn: 179.0000 - accuracy: 0.7164 - precision: 0.3567 - recall: 0.5503 - auc: 0.7164 - prc: 0.4213 - val_loss: 0.5734 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6885 - val_prc: 0.3971\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9067 - tp: 212.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 186.0000 - accuracy: 0.7204 - precision: 0.3581 - recall: 0.5327 - auc: 0.7214 - prc: 0.4291 - val_loss: 0.6039 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6888 - val_prc: 0.3788\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9065 - tp: 217.0000 - fp: 371.0000 - tn: 1255.0000 - fn: 181.0000 - accuracy: 0.7273 - precision: 0.3690 - recall: 0.5452 - auc: 0.7218 - prc: 0.4344 - val_loss: 0.5722 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6887 - val_prc: 0.3974\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9100 - tp: 214.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 184.0000 - accuracy: 0.7125 - precision: 0.3497 - recall: 0.5377 - auc: 0.7185 - prc: 0.4283 - val_loss: 0.6232 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6886 - val_prc: 0.3864\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9075 - tp: 221.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 177.0000 - accuracy: 0.7115 - precision: 0.3519 - recall: 0.5553 - auc: 0.7203 - prc: 0.4354 - val_loss: 0.5483 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6892 - val_prc: 0.3966\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9080 - tp: 214.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 184.0000 - accuracy: 0.7263 - precision: 0.3664 - recall: 0.5377 - auc: 0.7199 - prc: 0.4358 - val_loss: 0.5718 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6892 - val_prc: 0.3977\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9060 - tp: 211.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 187.0000 - accuracy: 0.7312 - precision: 0.3715 - recall: 0.5302 - auc: 0.7228 - prc: 0.4355 - val_loss: 0.5625 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6887 - val_prc: 0.3972\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9051 - tp: 223.0000 - fp: 375.0000 - tn: 1251.0000 - fn: 175.0000 - accuracy: 0.7283 - precision: 0.3729 - recall: 0.5603 - auc: 0.7222 - prc: 0.4383 - val_loss: 0.5777 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6890 - val_prc: 0.3979\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9047 - tp: 214.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 184.0000 - accuracy: 0.7268 - precision: 0.3671 - recall: 0.5377 - auc: 0.7240 - prc: 0.4357 - val_loss: 0.6410 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6888 - val_prc: 0.3870\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9050 - tp: 231.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 167.0000 - accuracy: 0.7115 - precision: 0.3565 - recall: 0.5804 - auc: 0.7236 - prc: 0.4317 - val_loss: 0.5975 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6888 - val_prc: 0.3829\n",
      "Epoch 262/500\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 0.9038 - tp: 205.0000 - fp: 356.0000 - tn: 1221.0000 - fn: 178.0000 - accuracy: 0.7276 - precision: 0.3654 - recall: 0.5352 - auc: 0.7209 - prc: 0.4329Restoring model weights from the end of the best epoch: 212.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9062 - tp: 217.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 181.0000 - accuracy: 0.7243 - precision: 0.3653 - recall: 0.5452 - auc: 0.7217 - prc: 0.4357 - val_loss: 0.5844 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6889 - val_prc: 0.3824\n",
      "Epoch 262: early stopping\n",
      "26/26 [==============================] - 0s 580us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.4426 - tp: 48.0000 - fp: 102.0000 - tn: 1939.0000 - fn: 441.0000 - accuracy: 0.7854 - precision: 0.3200 - recall: 0.0982 - auc: 0.5120 - prc: 0.2298 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4954 - prc: 0.1948 - val_loss: 0.4762 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3712 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4694 - prc: 0.1826 - val_loss: 0.4800 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3391 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4857 - prc: 0.1901 - val_loss: 0.4847 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - prc: 0.1917 - val_loss: 0.4904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2834 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5132 - prc: 0.1996 - val_loss: 0.4966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5089 - val_prc: 0.1825\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2584 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - prc: 0.1902 - val_loss: 0.5041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2369 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5112 - prc: 0.2008 - val_loss: 0.5118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2174 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5156 - prc: 0.2041 - val_loss: 0.5202 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2000 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4846 - prc: 0.1884 - val_loss: 0.5288 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1848 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4859 - prc: 0.1890 - val_loss: 0.5378 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1714 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5193 - prc: 0.2035 - val_loss: 0.5467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1598 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5240 - prc: 0.2117 - val_loss: 0.5559 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1496 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4947 - prc: 0.1939 - val_loss: 0.5659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1409 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4925 - prc: 0.1922 - val_loss: 0.5754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1337 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4930 - prc: 0.1911 - val_loss: 0.5841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1275 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4905 - prc: 0.1929 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1225 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4974 - prc: 0.1931 - val_loss: 0.6014 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1186 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4953 - prc: 0.1946 - val_loss: 0.6087 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5795 - prc: 0.2287 - val_loss: 0.6150 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5256 - val_prc: 0.1879\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1016 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6326 - prc: 0.2893 - val_loss: 0.5490 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6492 - val_prc: 0.3012\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0917 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6725 - prc: 0.3139 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6240 - val_prc: 0.2499\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0878 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6635 - prc: 0.3007 - val_loss: 0.6139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5859 - val_prc: 0.2162\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0831 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6621 - prc: 0.3054 - val_loss: 0.5808 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6521 - val_prc: 0.2910\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0799 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6667 - prc: 0.3121 - val_loss: 0.5787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6533 - val_prc: 0.2973\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0712 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6801 - prc: 0.3367 - val_loss: 0.6004 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6488 - val_prc: 0.2833\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0712 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6679 - prc: 0.3144 - val_loss: 0.5951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6545 - val_prc: 0.2939\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0625 - tp: 75.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 323.0000 - accuracy: 0.7895 - precision: 0.4213 - recall: 0.1884 - auc: 0.6776 - prc: 0.3127 - val_loss: 0.6083 - val_tp: 50.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.7174 - val_precision: 0.3289 - val_recall: 0.5495 - val_auc: 0.6493 - val_prc: 0.2813\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0597 - tp: 165.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 233.0000 - accuracy: 0.7520 - precision: 0.3802 - recall: 0.4146 - auc: 0.6836 - prc: 0.3308 - val_loss: 0.5856 - val_tp: 37.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 54.0000 - val_accuracy: 0.7708 - val_precision: 0.3737 - val_recall: 0.4066 - val_auc: 0.6582 - val_prc: 0.3035\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0631 - tp: 209.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 189.0000 - accuracy: 0.6803 - precision: 0.3133 - recall: 0.5251 - auc: 0.6593 - prc: 0.3055 - val_loss: 0.5786 - val_tp: 34.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 57.0000 - val_accuracy: 0.7806 - val_precision: 0.3864 - val_recall: 0.3736 - val_auc: 0.6615 - val_prc: 0.3177\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0528 - tp: 182.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 216.0000 - accuracy: 0.7490 - precision: 0.3840 - recall: 0.4573 - auc: 0.6878 - prc: 0.3406 - val_loss: 0.5922 - val_tp: 40.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 51.0000 - val_accuracy: 0.7451 - val_precision: 0.3390 - val_recall: 0.4396 - val_auc: 0.6605 - val_prc: 0.3083\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0508 - tp: 205.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 193.0000 - accuracy: 0.7208 - precision: 0.3553 - recall: 0.5151 - auc: 0.6825 - prc: 0.3369 - val_loss: 0.5480 - val_tp: 20.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 71.0000 - val_accuracy: 0.8004 - val_precision: 0.4000 - val_recall: 0.2198 - val_auc: 0.6665 - val_prc: 0.3567\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0446 - tp: 193.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 205.0000 - accuracy: 0.7441 - precision: 0.3814 - recall: 0.4849 - auc: 0.6916 - prc: 0.3370 - val_loss: 0.6088 - val_tp: 53.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 38.0000 - val_accuracy: 0.7036 - val_precision: 0.3212 - val_recall: 0.5824 - val_auc: 0.6554 - val_prc: 0.2895\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0455 - tp: 199.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 199.0000 - accuracy: 0.7297 - precision: 0.3638 - recall: 0.5000 - auc: 0.6844 - prc: 0.3379 - val_loss: 0.6026 - val_tp: 52.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 39.0000 - val_accuracy: 0.7273 - val_precision: 0.3444 - val_recall: 0.5714 - val_auc: 0.6614 - val_prc: 0.3058\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0385 - tp: 201.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 197.0000 - accuracy: 0.7500 - precision: 0.3941 - recall: 0.5050 - auc: 0.6958 - prc: 0.3453 - val_loss: 0.6554 - val_tp: 61.0000 - val_fp: 198.0000 - val_tn: 217.0000 - val_fn: 30.0000 - val_accuracy: 0.5494 - val_precision: 0.2355 - val_recall: 0.6703 - val_auc: 0.6455 - val_prc: 0.2721\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0399 - tp: 221.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 177.0000 - accuracy: 0.7065 - precision: 0.3464 - recall: 0.5553 - auc: 0.6886 - prc: 0.3443 - val_loss: 0.6187 - val_tp: 56.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 35.0000 - val_accuracy: 0.6818 - val_precision: 0.3077 - val_recall: 0.6154 - val_auc: 0.6606 - val_prc: 0.3001\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0356 - tp: 218.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 180.0000 - accuracy: 0.7045 - precision: 0.3428 - recall: 0.5477 - auc: 0.6912 - prc: 0.3436 - val_loss: 0.5272 - val_tp: 17.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 74.0000 - val_accuracy: 0.8162 - val_precision: 0.4722 - val_recall: 0.1868 - val_auc: 0.6680 - val_prc: 0.3561\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0303 - tp: 208.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 190.0000 - accuracy: 0.7307 - precision: 0.3694 - recall: 0.5226 - auc: 0.7003 - prc: 0.3625 - val_loss: 0.6789 - val_tp: 68.0000 - val_fp: 229.0000 - val_tn: 186.0000 - val_fn: 23.0000 - val_accuracy: 0.5020 - val_precision: 0.2290 - val_recall: 0.7473 - val_auc: 0.6419 - val_prc: 0.2657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0284 - tp: 216.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 182.0000 - accuracy: 0.7055 - precision: 0.3429 - recall: 0.5427 - auc: 0.6981 - prc: 0.3521 - val_loss: 0.6472 - val_tp: 61.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 30.0000 - val_accuracy: 0.5929 - val_precision: 0.2574 - val_recall: 0.6703 - val_auc: 0.6563 - val_prc: 0.2881\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0307 - tp: 218.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 180.0000 - accuracy: 0.6868 - precision: 0.3244 - recall: 0.5477 - auc: 0.6925 - prc: 0.3543 - val_loss: 0.6220 - val_tp: 56.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 35.0000 - val_accuracy: 0.6640 - val_precision: 0.2932 - val_recall: 0.6154 - val_auc: 0.6635 - val_prc: 0.3061\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0299 - tp: 234.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 164.0000 - accuracy: 0.7016 - precision: 0.3472 - recall: 0.5879 - auc: 0.6908 - prc: 0.3533 - val_loss: 0.5231 - val_tp: 22.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 69.0000 - val_accuracy: 0.8162 - val_precision: 0.4783 - val_recall: 0.2418 - val_auc: 0.6710 - val_prc: 0.3642\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0304 - tp: 227.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 171.0000 - accuracy: 0.6695 - precision: 0.3131 - recall: 0.5704 - auc: 0.6838 - prc: 0.3261 - val_loss: 0.6213 - val_tp: 56.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 35.0000 - val_accuracy: 0.6640 - val_precision: 0.2932 - val_recall: 0.6154 - val_auc: 0.6643 - val_prc: 0.3095\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0191 - tp: 221.0000 - fp: 392.0000 - tn: 1234.0000 - fn: 177.0000 - accuracy: 0.7189 - precision: 0.3605 - recall: 0.5553 - auc: 0.7051 - prc: 0.3774 - val_loss: 0.6377 - val_tp: 60.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 31.0000 - val_accuracy: 0.6225 - val_precision: 0.2727 - val_recall: 0.6593 - val_auc: 0.6645 - val_prc: 0.3069\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0188 - tp: 233.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 165.0000 - accuracy: 0.7050 - precision: 0.3504 - recall: 0.5854 - auc: 0.7028 - prc: 0.3665 - val_loss: 0.6235 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6663 - val_prc: 0.3152\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0211 - tp: 231.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 167.0000 - accuracy: 0.6961 - precision: 0.3402 - recall: 0.5804 - auc: 0.6969 - prc: 0.3600 - val_loss: 0.6179 - val_tp: 55.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 36.0000 - val_accuracy: 0.6858 - val_precision: 0.3090 - val_recall: 0.6044 - val_auc: 0.6710 - val_prc: 0.3324\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0146 - tp: 230.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 168.0000 - accuracy: 0.7199 - precision: 0.3657 - recall: 0.5779 - auc: 0.7059 - prc: 0.3774 - val_loss: 0.5925 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6707 - val_prc: 0.3334\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0167 - tp: 235.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 163.0000 - accuracy: 0.7110 - precision: 0.3577 - recall: 0.5905 - auc: 0.7018 - prc: 0.3662 - val_loss: 0.5986 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6719 - val_prc: 0.3346\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0105 - tp: 231.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 167.0000 - accuracy: 0.7184 - precision: 0.3644 - recall: 0.5804 - auc: 0.7082 - prc: 0.3750 - val_loss: 0.6254 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6698 - val_prc: 0.3243\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0098 - tp: 233.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 165.0000 - accuracy: 0.6952 - precision: 0.3401 - recall: 0.5854 - auc: 0.7062 - prc: 0.3700 - val_loss: 0.6822 - val_tp: 67.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 24.0000 - val_accuracy: 0.5336 - val_precision: 0.2401 - val_recall: 0.7363 - val_auc: 0.6584 - val_prc: 0.2894\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0094 - tp: 236.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 162.0000 - accuracy: 0.7139 - precision: 0.3614 - recall: 0.5930 - auc: 0.7064 - prc: 0.3675 - val_loss: 0.6785 - val_tp: 65.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 26.0000 - val_accuracy: 0.5415 - val_precision: 0.2399 - val_recall: 0.7143 - val_auc: 0.6609 - val_prc: 0.2946\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0112 - tp: 251.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 147.0000 - accuracy: 0.6808 - precision: 0.3347 - recall: 0.6307 - auc: 0.7011 - prc: 0.3611 - val_loss: 0.6087 - val_tp: 54.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 37.0000 - val_accuracy: 0.6937 - val_precision: 0.3140 - val_recall: 0.5934 - val_auc: 0.6710 - val_prc: 0.3242\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0066 - tp: 241.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 157.0000 - accuracy: 0.6971 - precision: 0.3458 - recall: 0.6055 - auc: 0.7083 - prc: 0.3770 - val_loss: 0.5898 - val_tp: 47.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 44.0000 - val_accuracy: 0.7194 - val_precision: 0.3241 - val_recall: 0.5165 - val_auc: 0.6756 - val_prc: 0.3470\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0102 - tp: 227.0000 - fp: 429.0000 - tn: 1197.0000 - fn: 171.0000 - accuracy: 0.7036 - precision: 0.3460 - recall: 0.5704 - auc: 0.7010 - prc: 0.3794 - val_loss: 0.6213 - val_tp: 56.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 35.0000 - val_accuracy: 0.6700 - val_precision: 0.2979 - val_recall: 0.6154 - val_auc: 0.6732 - val_prc: 0.3275\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0126 - tp: 235.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 163.0000 - accuracy: 0.6858 - precision: 0.3319 - recall: 0.5905 - auc: 0.6966 - prc: 0.3552 - val_loss: 0.5834 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6757 - val_prc: 0.3446\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0026 - tp: 249.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 149.0000 - accuracy: 0.6902 - precision: 0.3425 - recall: 0.6256 - auc: 0.7101 - prc: 0.3831 - val_loss: 0.5370 - val_tp: 39.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 52.0000 - val_accuracy: 0.7866 - val_precision: 0.4105 - val_recall: 0.4286 - val_auc: 0.6778 - val_prc: 0.3791\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0072 - tp: 225.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 173.0000 - accuracy: 0.7179 - precision: 0.3612 - recall: 0.5653 - auc: 0.7058 - prc: 0.3861 - val_loss: 0.6128 - val_tp: 55.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 36.0000 - val_accuracy: 0.6877 - val_precision: 0.3107 - val_recall: 0.6044 - val_auc: 0.6759 - val_prc: 0.3384\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0010 - tp: 238.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 160.0000 - accuracy: 0.7001 - precision: 0.3474 - recall: 0.5980 - auc: 0.7091 - prc: 0.3717 - val_loss: 0.7046 - val_tp: 67.0000 - val_fp: 228.0000 - val_tn: 187.0000 - val_fn: 24.0000 - val_accuracy: 0.5020 - val_precision: 0.2271 - val_recall: 0.7363 - val_auc: 0.6616 - val_prc: 0.2924\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0024 - tp: 245.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 153.0000 - accuracy: 0.6764 - precision: 0.3280 - recall: 0.6156 - auc: 0.7065 - prc: 0.3627 - val_loss: 0.6682 - val_tp: 65.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 26.0000 - val_accuracy: 0.5711 - val_precision: 0.2539 - val_recall: 0.7143 - val_auc: 0.6716 - val_prc: 0.3192\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0003 - tp: 239.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 159.0000 - accuracy: 0.6892 - precision: 0.3371 - recall: 0.6005 - auc: 0.7104 - prc: 0.3839 - val_loss: 0.6266 - val_tp: 57.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 34.0000 - val_accuracy: 0.6542 - val_precision: 0.2879 - val_recall: 0.6264 - val_auc: 0.6748 - val_prc: 0.3308\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0024 - tp: 248.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 150.0000 - accuracy: 0.6650 - precision: 0.3196 - recall: 0.6231 - auc: 0.7033 - prc: 0.3615 - val_loss: 0.5637 - val_tp: 41.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 50.0000 - val_accuracy: 0.7312 - val_precision: 0.3228 - val_recall: 0.4505 - val_auc: 0.6783 - val_prc: 0.3666\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0001 - tp: 239.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 159.0000 - accuracy: 0.7060 - precision: 0.3541 - recall: 0.6005 - auc: 0.7091 - prc: 0.3669 - val_loss: 0.6504 - val_tp: 63.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 28.0000 - val_accuracy: 0.6047 - val_precision: 0.2681 - val_recall: 0.6923 - val_auc: 0.6749 - val_prc: 0.3319\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9982 - tp: 247.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 151.0000 - accuracy: 0.6744 - precision: 0.3272 - recall: 0.6206 - auc: 0.7096 - prc: 0.3829 - val_loss: 0.6023 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.6786 - val_prc: 0.3524\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0010 - tp: 236.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 162.0000 - accuracy: 0.6976 - precision: 0.3440 - recall: 0.5930 - auc: 0.7066 - prc: 0.3854 - val_loss: 0.5917 - val_tp: 47.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 44.0000 - val_accuracy: 0.7075 - val_precision: 0.3113 - val_recall: 0.5165 - val_auc: 0.6790 - val_prc: 0.3595\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9976 - tp: 240.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 158.0000 - accuracy: 0.6887 - precision: 0.3371 - recall: 0.6030 - auc: 0.7087 - prc: 0.3839 - val_loss: 0.6053 - val_tp: 52.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 39.0000 - val_accuracy: 0.6937 - val_precision: 0.3095 - val_recall: 0.5714 - val_auc: 0.6782 - val_prc: 0.3491\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9956 - tp: 245.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 153.0000 - accuracy: 0.7031 - precision: 0.3535 - recall: 0.6156 - auc: 0.7117 - prc: 0.3873 - val_loss: 0.6524 - val_tp: 63.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 28.0000 - val_accuracy: 0.5988 - val_precision: 0.2647 - val_recall: 0.6923 - val_auc: 0.6766 - val_prc: 0.3327\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9955 - tp: 252.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 146.0000 - accuracy: 0.6744 - precision: 0.3294 - recall: 0.6332 - auc: 0.7118 - prc: 0.3855 - val_loss: 0.5792 - val_tp: 45.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 46.0000 - val_accuracy: 0.7154 - val_precision: 0.3147 - val_recall: 0.4945 - val_auc: 0.6791 - val_prc: 0.3738\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9955 - tp: 236.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 162.0000 - accuracy: 0.6917 - precision: 0.3381 - recall: 0.5930 - auc: 0.7102 - prc: 0.3816 - val_loss: 0.6261 - val_tp: 58.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 33.0000 - val_accuracy: 0.6542 - val_precision: 0.2900 - val_recall: 0.6374 - val_auc: 0.6773 - val_prc: 0.3390\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9970 - tp: 245.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 153.0000 - accuracy: 0.6966 - precision: 0.3470 - recall: 0.6156 - auc: 0.7081 - prc: 0.3746 - val_loss: 0.6680 - val_tp: 65.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 26.0000 - val_accuracy: 0.5850 - val_precision: 0.2610 - val_recall: 0.7143 - val_auc: 0.6775 - val_prc: 0.3378\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9961 - tp: 251.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 147.0000 - accuracy: 0.6833 - precision: 0.3369 - recall: 0.6307 - auc: 0.7100 - prc: 0.3824 - val_loss: 0.6384 - val_tp: 60.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 31.0000 - val_accuracy: 0.6344 - val_precision: 0.2804 - val_recall: 0.6593 - val_auc: 0.6761 - val_prc: 0.3306\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9941 - tp: 246.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 152.0000 - accuracy: 0.6808 - precision: 0.3324 - recall: 0.6181 - auc: 0.7106 - prc: 0.3800 - val_loss: 0.6228 - val_tp: 56.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 35.0000 - val_accuracy: 0.6601 - val_precision: 0.2902 - val_recall: 0.6154 - val_auc: 0.6797 - val_prc: 0.3550\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9963 - tp: 238.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 160.0000 - accuracy: 0.6858 - precision: 0.3333 - recall: 0.5980 - auc: 0.7083 - prc: 0.3790 - val_loss: 0.6620 - val_tp: 64.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 27.0000 - val_accuracy: 0.5949 - val_precision: 0.2645 - val_recall: 0.7033 - val_auc: 0.6777 - val_prc: 0.3368\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9930 - tp: 246.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 152.0000 - accuracy: 0.6803 - precision: 0.3320 - recall: 0.6181 - auc: 0.7103 - prc: 0.3860 - val_loss: 0.6365 - val_tp: 58.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 33.0000 - val_accuracy: 0.6403 - val_precision: 0.2802 - val_recall: 0.6374 - val_auc: 0.6786 - val_prc: 0.3398\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9970 - tp: 236.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 162.0000 - accuracy: 0.6838 - precision: 0.3305 - recall: 0.5930 - auc: 0.7065 - prc: 0.3812 - val_loss: 0.5871 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6812 - val_prc: 0.3753\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9948 - tp: 231.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 167.0000 - accuracy: 0.7045 - precision: 0.3489 - recall: 0.5804 - auc: 0.7109 - prc: 0.3984 - val_loss: 0.6497 - val_tp: 61.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 30.0000 - val_accuracy: 0.6186 - val_precision: 0.2723 - val_recall: 0.6703 - val_auc: 0.6780 - val_prc: 0.3331\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9903 - tp: 240.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 158.0000 - accuracy: 0.6957 - precision: 0.3438 - recall: 0.6030 - auc: 0.7143 - prc: 0.4072 - val_loss: 0.6279 - val_tp: 58.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 33.0000 - val_accuracy: 0.6542 - val_precision: 0.2900 - val_recall: 0.6374 - val_auc: 0.6802 - val_prc: 0.3523\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9920 - tp: 252.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 146.0000 - accuracy: 0.6808 - precision: 0.3351 - recall: 0.6332 - auc: 0.7114 - prc: 0.3889 - val_loss: 0.5828 - val_tp: 45.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 46.0000 - val_accuracy: 0.7095 - val_precision: 0.3082 - val_recall: 0.4945 - val_auc: 0.6812 - val_prc: 0.3766\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9882 - tp: 240.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 158.0000 - accuracy: 0.6947 - precision: 0.3429 - recall: 0.6030 - auc: 0.7158 - prc: 0.3963 - val_loss: 0.6409 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6801 - val_prc: 0.3490\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9913 - tp: 244.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 154.0000 - accuracy: 0.6927 - precision: 0.3427 - recall: 0.6131 - auc: 0.7113 - prc: 0.3818 - val_loss: 0.6498 - val_tp: 61.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 30.0000 - val_accuracy: 0.6206 - val_precision: 0.2735 - val_recall: 0.6703 - val_auc: 0.6787 - val_prc: 0.3358\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9888 - tp: 247.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 151.0000 - accuracy: 0.6917 - precision: 0.3431 - recall: 0.6206 - auc: 0.7144 - prc: 0.3955 - val_loss: 0.6098 - val_tp: 50.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 41.0000 - val_accuracy: 0.6858 - val_precision: 0.2976 - val_recall: 0.5495 - val_auc: 0.6809 - val_prc: 0.3667\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9882 - tp: 257.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 141.0000 - accuracy: 0.6774 - precision: 0.3342 - recall: 0.6457 - auc: 0.7146 - prc: 0.3935 - val_loss: 0.5530 - val_tp: 42.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 49.0000 - val_accuracy: 0.7589 - val_precision: 0.3652 - val_recall: 0.4615 - val_auc: 0.6790 - val_prc: 0.3832\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9884 - tp: 234.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 164.0000 - accuracy: 0.6932 - precision: 0.3386 - recall: 0.5879 - auc: 0.7135 - prc: 0.3867 - val_loss: 0.6633 - val_tp: 63.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 28.0000 - val_accuracy: 0.6028 - val_precision: 0.2669 - val_recall: 0.6923 - val_auc: 0.6788 - val_prc: 0.3361\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9883 - tp: 248.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 150.0000 - accuracy: 0.6902 - precision: 0.3421 - recall: 0.6231 - auc: 0.7139 - prc: 0.3680 - val_loss: 0.5997 - val_tp: 47.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 44.0000 - val_accuracy: 0.6957 - val_precision: 0.2994 - val_recall: 0.5165 - val_auc: 0.6815 - val_prc: 0.3767\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9937 - tp: 247.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 151.0000 - accuracy: 0.6877 - precision: 0.3393 - recall: 0.6206 - auc: 0.7078 - prc: 0.3818 - val_loss: 0.7159 - val_tp: 68.0000 - val_fp: 217.0000 - val_tn: 198.0000 - val_fn: 23.0000 - val_accuracy: 0.5257 - val_precision: 0.2386 - val_recall: 0.7473 - val_auc: 0.6749 - val_prc: 0.3199\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9971 - tp: 242.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 156.0000 - accuracy: 0.6749 - precision: 0.3253 - recall: 0.6080 - auc: 0.7053 - prc: 0.3830 - val_loss: 0.6877 - val_tp: 67.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 24.0000 - val_accuracy: 0.5692 - val_precision: 0.2567 - val_recall: 0.7363 - val_auc: 0.6788 - val_prc: 0.3353\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9927 - tp: 237.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 161.0000 - accuracy: 0.6823 - precision: 0.3296 - recall: 0.5955 - auc: 0.7072 - prc: 0.3973 - val_loss: 0.6246 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6807 - val_prc: 0.3598\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9884 - tp: 234.0000 - fp: 427.0000 - tn: 1199.0000 - fn: 164.0000 - accuracy: 0.7080 - precision: 0.3540 - recall: 0.5879 - auc: 0.7127 - prc: 0.3970 - val_loss: 0.6882 - val_tp: 67.0000 - val_fp: 195.0000 - val_tn: 220.0000 - val_fn: 24.0000 - val_accuracy: 0.5672 - val_precision: 0.2557 - val_recall: 0.7363 - val_auc: 0.6806 - val_prc: 0.3396\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9929 - tp: 243.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 155.0000 - accuracy: 0.6744 - precision: 0.3253 - recall: 0.6106 - auc: 0.7077 - prc: 0.3835 - val_loss: 0.6695 - val_tp: 64.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 27.0000 - val_accuracy: 0.5949 - val_precision: 0.2645 - val_recall: 0.7033 - val_auc: 0.6791 - val_prc: 0.3362\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9884 - tp: 229.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 169.0000 - accuracy: 0.7001 - precision: 0.3433 - recall: 0.5754 - auc: 0.7127 - prc: 0.3890 - val_loss: 0.7375 - val_tp: 68.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 23.0000 - val_accuracy: 0.4783 - val_precision: 0.2201 - val_recall: 0.7473 - val_auc: 0.6749 - val_prc: 0.3190\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9914 - tp: 248.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 150.0000 - accuracy: 0.6640 - precision: 0.3188 - recall: 0.6231 - auc: 0.7086 - prc: 0.3960 - val_loss: 0.5674 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6800 - val_prc: 0.3748\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9951 - tp: 233.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 165.0000 - accuracy: 0.6714 - precision: 0.3179 - recall: 0.5854 - auc: 0.7056 - prc: 0.3780 - val_loss: 0.5777 - val_tp: 45.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 46.0000 - val_accuracy: 0.7134 - val_precision: 0.3125 - val_recall: 0.4945 - val_auc: 0.6822 - val_prc: 0.3856\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9895 - tp: 235.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 163.0000 - accuracy: 0.6877 - precision: 0.3338 - recall: 0.5905 - auc: 0.7111 - prc: 0.3970 - val_loss: 0.5936 - val_tp: 45.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 46.0000 - val_accuracy: 0.6957 - val_precision: 0.2941 - val_recall: 0.4945 - val_auc: 0.6824 - val_prc: 0.3830\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9866 - tp: 242.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 156.0000 - accuracy: 0.6976 - precision: 0.3467 - recall: 0.6080 - auc: 0.7142 - prc: 0.3921 - val_loss: 0.6289 - val_tp: 58.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 33.0000 - val_accuracy: 0.6581 - val_precision: 0.2929 - val_recall: 0.6374 - val_auc: 0.6816 - val_prc: 0.3601\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9824 - tp: 259.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 139.0000 - accuracy: 0.6769 - precision: 0.3346 - recall: 0.6508 - auc: 0.7190 - prc: 0.4072 - val_loss: 0.5468 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6797 - val_prc: 0.3841\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9891 - tp: 231.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 167.0000 - accuracy: 0.6922 - precision: 0.3362 - recall: 0.5804 - auc: 0.7099 - prc: 0.3912 - val_loss: 0.6955 - val_tp: 67.0000 - val_fp: 198.0000 - val_tn: 217.0000 - val_fn: 24.0000 - val_accuracy: 0.5613 - val_precision: 0.2528 - val_recall: 0.7363 - val_auc: 0.6790 - val_prc: 0.3336\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9835 - tp: 240.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 158.0000 - accuracy: 0.6803 - precision: 0.3292 - recall: 0.6030 - auc: 0.7149 - prc: 0.4012 - val_loss: 0.5898 - val_tp: 45.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 46.0000 - val_accuracy: 0.6957 - val_precision: 0.2941 - val_recall: 0.4945 - val_auc: 0.6815 - val_prc: 0.3844\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9847 - tp: 245.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 153.0000 - accuracy: 0.6873 - precision: 0.3379 - recall: 0.6156 - auc: 0.7151 - prc: 0.3958 - val_loss: 0.6019 - val_tp: 47.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 44.0000 - val_accuracy: 0.6858 - val_precision: 0.2901 - val_recall: 0.5165 - val_auc: 0.6816 - val_prc: 0.3834\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9875 - tp: 241.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 157.0000 - accuracy: 0.6947 - precision: 0.3433 - recall: 0.6055 - auc: 0.7120 - prc: 0.3977 - val_loss: 0.6722 - val_tp: 65.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 26.0000 - val_accuracy: 0.5968 - val_precision: 0.2675 - val_recall: 0.7143 - val_auc: 0.6801 - val_prc: 0.3396\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9909 - tp: 243.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 155.0000 - accuracy: 0.6853 - precision: 0.3352 - recall: 0.6106 - auc: 0.7084 - prc: 0.3925 - val_loss: 0.6119 - val_tp: 53.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 38.0000 - val_accuracy: 0.6858 - val_precision: 0.3046 - val_recall: 0.5824 - val_auc: 0.6820 - val_prc: 0.3777\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9813 - tp: 243.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 155.0000 - accuracy: 0.6966 - precision: 0.3462 - recall: 0.6106 - auc: 0.7182 - prc: 0.3959 - val_loss: 0.6696 - val_tp: 62.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 29.0000 - val_accuracy: 0.5988 - val_precision: 0.2627 - val_recall: 0.6813 - val_auc: 0.6814 - val_prc: 0.3521\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9833 - tp: 244.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 154.0000 - accuracy: 0.6927 - precision: 0.3427 - recall: 0.6131 - auc: 0.7160 - prc: 0.3982 - val_loss: 0.6496 - val_tp: 59.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 32.0000 - val_accuracy: 0.6324 - val_precision: 0.2770 - val_recall: 0.6484 - val_auc: 0.6815 - val_prc: 0.3557\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9858 - tp: 239.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 159.0000 - accuracy: 0.6868 - precision: 0.3347 - recall: 0.6005 - auc: 0.7141 - prc: 0.4008 - val_loss: 0.6349 - val_tp: 58.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 33.0000 - val_accuracy: 0.6462 - val_precision: 0.2843 - val_recall: 0.6374 - val_auc: 0.6818 - val_prc: 0.3601\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9807 - tp: 246.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 152.0000 - accuracy: 0.6947 - precision: 0.3455 - recall: 0.6181 - auc: 0.7191 - prc: 0.4039 - val_loss: 0.6852 - val_tp: 66.0000 - val_fp: 190.0000 - val_tn: 225.0000 - val_fn: 25.0000 - val_accuracy: 0.5751 - val_precision: 0.2578 - val_recall: 0.7253 - val_auc: 0.6791 - val_prc: 0.3379\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9861 - tp: 231.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 167.0000 - accuracy: 0.6912 - precision: 0.3353 - recall: 0.5804 - auc: 0.7125 - prc: 0.4109 - val_loss: 0.6266 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6812 - val_prc: 0.3782\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9848 - tp: 239.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 159.0000 - accuracy: 0.6907 - precision: 0.3385 - recall: 0.6005 - auc: 0.7143 - prc: 0.4065 - val_loss: 0.6502 - val_tp: 59.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 32.0000 - val_accuracy: 0.6324 - val_precision: 0.2770 - val_recall: 0.6484 - val_auc: 0.6817 - val_prc: 0.3597\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9907 - tp: 240.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 158.0000 - accuracy: 0.6714 - precision: 0.3213 - recall: 0.6030 - auc: 0.7080 - prc: 0.3899 - val_loss: 0.7337 - val_tp: 68.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 23.0000 - val_accuracy: 0.4980 - val_precision: 0.2274 - val_recall: 0.7473 - val_auc: 0.6796 - val_prc: 0.3377\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9877 - tp: 245.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 153.0000 - accuracy: 0.6892 - precision: 0.3398 - recall: 0.6156 - auc: 0.7118 - prc: 0.3950 - val_loss: 0.6349 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.6830 - val_prc: 0.3766\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9837 - tp: 235.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 163.0000 - accuracy: 0.6957 - precision: 0.3416 - recall: 0.5905 - auc: 0.7149 - prc: 0.4100 - val_loss: 0.6426 - val_tp: 58.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 33.0000 - val_accuracy: 0.6403 - val_precision: 0.2802 - val_recall: 0.6374 - val_auc: 0.6834 - val_prc: 0.3726\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9834 - tp: 243.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 155.0000 - accuracy: 0.6957 - precision: 0.3452 - recall: 0.6106 - auc: 0.7140 - prc: 0.3926 - val_loss: 0.7523 - val_tp: 68.0000 - val_fp: 238.0000 - val_tn: 177.0000 - val_fn: 23.0000 - val_accuracy: 0.4842 - val_precision: 0.2222 - val_recall: 0.7473 - val_auc: 0.6754 - val_prc: 0.3216\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9856 - tp: 254.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 144.0000 - accuracy: 0.6695 - precision: 0.3261 - recall: 0.6382 - auc: 0.7127 - prc: 0.3983 - val_loss: 0.5889 - val_tp: 45.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 46.0000 - val_accuracy: 0.6957 - val_precision: 0.2941 - val_recall: 0.4945 - val_auc: 0.6828 - val_prc: 0.3874\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9766 - tp: 227.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 171.0000 - accuracy: 0.7090 - precision: 0.3519 - recall: 0.5704 - auc: 0.7218 - prc: 0.4137 - val_loss: 0.7296 - val_tp: 68.0000 - val_fp: 228.0000 - val_tn: 187.0000 - val_fn: 23.0000 - val_accuracy: 0.5040 - val_precision: 0.2297 - val_recall: 0.7473 - val_auc: 0.6795 - val_prc: 0.3343\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9856 - tp: 245.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 153.0000 - accuracy: 0.6705 - precision: 0.3228 - recall: 0.6156 - auc: 0.7136 - prc: 0.3976 - val_loss: 0.6214 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6831 - val_prc: 0.3794\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9841 - tp: 249.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 149.0000 - accuracy: 0.6892 - precision: 0.3416 - recall: 0.6256 - auc: 0.7139 - prc: 0.4058 - val_loss: 0.6513 - val_tp: 59.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 32.0000 - val_accuracy: 0.6324 - val_precision: 0.2770 - val_recall: 0.6484 - val_auc: 0.6827 - val_prc: 0.3673\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9835 - tp: 234.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 164.0000 - accuracy: 0.7006 - precision: 0.3462 - recall: 0.5879 - auc: 0.7154 - prc: 0.4139 - val_loss: 0.6325 - val_tp: 56.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 35.0000 - val_accuracy: 0.6581 - val_precision: 0.2887 - val_recall: 0.6154 - val_auc: 0.6828 - val_prc: 0.3828\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9843 - tp: 236.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 162.0000 - accuracy: 0.6838 - precision: 0.3305 - recall: 0.5930 - auc: 0.7131 - prc: 0.4050 - val_loss: 0.6862 - val_tp: 66.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 25.0000 - val_accuracy: 0.5791 - val_precision: 0.2598 - val_recall: 0.7253 - val_auc: 0.6812 - val_prc: 0.3490\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9858 - tp: 243.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 155.0000 - accuracy: 0.6818 - precision: 0.3320 - recall: 0.6106 - auc: 0.7127 - prc: 0.4081 - val_loss: 0.5745 - val_tp: 43.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 48.0000 - val_accuracy: 0.7273 - val_precision: 0.3233 - val_recall: 0.4725 - val_auc: 0.6799 - val_prc: 0.3898\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9857 - tp: 232.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 166.0000 - accuracy: 0.6986 - precision: 0.3432 - recall: 0.5829 - auc: 0.7118 - prc: 0.4071 - val_loss: 0.7000 - val_tp: 67.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 24.0000 - val_accuracy: 0.5692 - val_precision: 0.2567 - val_recall: 0.7363 - val_auc: 0.6807 - val_prc: 0.3417\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9816 - tp: 247.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 151.0000 - accuracy: 0.6947 - precision: 0.3459 - recall: 0.6206 - auc: 0.7170 - prc: 0.4037 - val_loss: 0.5987 - val_tp: 46.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 45.0000 - val_accuracy: 0.6917 - val_precision: 0.2930 - val_recall: 0.5055 - val_auc: 0.6833 - val_prc: 0.3822\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9804 - tp: 232.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 166.0000 - accuracy: 0.6976 - precision: 0.3422 - recall: 0.5829 - auc: 0.7172 - prc: 0.4309 - val_loss: 0.5986 - val_tp: 46.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 45.0000 - val_accuracy: 0.6917 - val_precision: 0.2930 - val_recall: 0.5055 - val_auc: 0.6842 - val_prc: 0.3824\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9819 - tp: 240.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 158.0000 - accuracy: 0.6897 - precision: 0.3380 - recall: 0.6030 - auc: 0.7132 - prc: 0.4202 - val_loss: 0.5764 - val_tp: 44.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 47.0000 - val_accuracy: 0.7213 - val_precision: 0.3188 - val_recall: 0.4835 - val_auc: 0.6835 - val_prc: 0.3896\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9843 - tp: 235.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 163.0000 - accuracy: 0.6882 - precision: 0.3343 - recall: 0.5905 - auc: 0.7130 - prc: 0.4048 - val_loss: 0.6137 - val_tp: 52.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 39.0000 - val_accuracy: 0.6818 - val_precision: 0.2989 - val_recall: 0.5714 - val_auc: 0.6829 - val_prc: 0.3870\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9823 - tp: 239.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 159.0000 - accuracy: 0.6927 - precision: 0.3405 - recall: 0.6005 - auc: 0.7155 - prc: 0.4096 - val_loss: 0.5682 - val_tp: 43.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 48.0000 - val_accuracy: 0.7292 - val_precision: 0.3258 - val_recall: 0.4725 - val_auc: 0.6834 - val_prc: 0.3897\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9837 - tp: 243.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 155.0000 - accuracy: 0.6897 - precision: 0.3394 - recall: 0.6106 - auc: 0.7147 - prc: 0.3966 - val_loss: 0.6466 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6841 - val_prc: 0.3873\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9795 - tp: 236.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 162.0000 - accuracy: 0.6882 - precision: 0.3348 - recall: 0.5930 - auc: 0.7179 - prc: 0.4183 - val_loss: 0.6163 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6843 - val_prc: 0.3894\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9800 - tp: 239.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 159.0000 - accuracy: 0.6863 - precision: 0.3343 - recall: 0.6005 - auc: 0.7162 - prc: 0.3991 - val_loss: 0.5793 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6837 - val_prc: 0.3895\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9846 - tp: 243.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 155.0000 - accuracy: 0.6833 - precision: 0.3333 - recall: 0.6106 - auc: 0.7122 - prc: 0.3989 - val_loss: 0.6104 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6845 - val_prc: 0.3892\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9854 - tp: 237.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 161.0000 - accuracy: 0.6932 - precision: 0.3400 - recall: 0.5955 - auc: 0.7132 - prc: 0.4059 - val_loss: 0.6215 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6843 - val_prc: 0.3902\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9785 - tp: 237.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 161.0000 - accuracy: 0.6991 - precision: 0.3460 - recall: 0.5955 - auc: 0.7190 - prc: 0.4131 - val_loss: 0.6744 - val_tp: 63.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 28.0000 - val_accuracy: 0.5988 - val_precision: 0.2647 - val_recall: 0.6923 - val_auc: 0.6830 - val_prc: 0.3712\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9793 - tp: 247.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 151.0000 - accuracy: 0.6873 - precision: 0.3388 - recall: 0.6206 - auc: 0.7178 - prc: 0.4126 - val_loss: 0.6281 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6838 - val_prc: 0.3895\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9838 - tp: 242.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 156.0000 - accuracy: 0.6784 - precision: 0.3284 - recall: 0.6080 - auc: 0.7147 - prc: 0.3857 - val_loss: 0.6009 - val_tp: 47.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 44.0000 - val_accuracy: 0.6937 - val_precision: 0.2975 - val_recall: 0.5165 - val_auc: 0.6844 - val_prc: 0.3833\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9855 - tp: 241.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 157.0000 - accuracy: 0.6907 - precision: 0.3394 - recall: 0.6055 - auc: 0.7105 - prc: 0.3901 - val_loss: 0.6072 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6844 - val_prc: 0.3897\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9827 - tp: 244.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 154.0000 - accuracy: 0.6843 - precision: 0.3347 - recall: 0.6131 - auc: 0.7148 - prc: 0.4044 - val_loss: 0.6370 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6842 - val_prc: 0.3895\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9779 - tp: 236.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 162.0000 - accuracy: 0.7115 - precision: 0.3587 - recall: 0.5930 - auc: 0.7208 - prc: 0.4272 - val_loss: 0.7009 - val_tp: 66.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 25.0000 - val_accuracy: 0.5672 - val_precision: 0.2538 - val_recall: 0.7253 - val_auc: 0.6828 - val_prc: 0.3586\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9808 - tp: 246.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 152.0000 - accuracy: 0.6877 - precision: 0.3388 - recall: 0.6181 - auc: 0.7150 - prc: 0.4059 - val_loss: 0.6602 - val_tp: 61.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 30.0000 - val_accuracy: 0.6126 - val_precision: 0.2687 - val_recall: 0.6703 - val_auc: 0.6811 - val_prc: 0.3784\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9829 - tp: 236.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 162.0000 - accuracy: 0.6912 - precision: 0.3376 - recall: 0.5930 - auc: 0.7121 - prc: 0.4148 - val_loss: 0.6119 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6832 - val_prc: 0.3866\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9789 - tp: 245.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 153.0000 - accuracy: 0.6927 - precision: 0.3431 - recall: 0.6156 - auc: 0.7176 - prc: 0.4123 - val_loss: 0.7293 - val_tp: 68.0000 - val_fp: 227.0000 - val_tn: 188.0000 - val_fn: 23.0000 - val_accuracy: 0.5059 - val_precision: 0.2305 - val_recall: 0.7473 - val_auc: 0.6806 - val_prc: 0.3369\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9855 - tp: 244.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 154.0000 - accuracy: 0.6858 - precision: 0.3361 - recall: 0.6131 - auc: 0.7108 - prc: 0.3895 - val_loss: 0.7141 - val_tp: 68.0000 - val_fp: 208.0000 - val_tn: 207.0000 - val_fn: 23.0000 - val_accuracy: 0.5435 - val_precision: 0.2464 - val_recall: 0.7473 - val_auc: 0.6818 - val_prc: 0.3490\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9807 - tp: 242.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 156.0000 - accuracy: 0.6897 - precision: 0.3389 - recall: 0.6080 - auc: 0.7168 - prc: 0.4095 - val_loss: 0.6340 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6838 - val_prc: 0.3891\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9785 - tp: 245.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 153.0000 - accuracy: 0.6833 - precision: 0.3342 - recall: 0.6156 - auc: 0.7177 - prc: 0.4087 - val_loss: 0.5799 - val_tp: 45.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 46.0000 - val_accuracy: 0.7115 - val_precision: 0.3103 - val_recall: 0.4945 - val_auc: 0.6840 - val_prc: 0.3894\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9813 - tp: 240.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 158.0000 - accuracy: 0.6937 - precision: 0.3419 - recall: 0.6030 - auc: 0.7151 - prc: 0.4144 - val_loss: 0.6192 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6841 - val_prc: 0.3881\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9796 - tp: 242.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 156.0000 - accuracy: 0.6961 - precision: 0.3452 - recall: 0.6080 - auc: 0.7167 - prc: 0.4172 - val_loss: 0.6279 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6842 - val_prc: 0.3885\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9803 - tp: 225.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 173.0000 - accuracy: 0.7041 - precision: 0.3456 - recall: 0.5653 - auc: 0.7166 - prc: 0.4126 - val_loss: 0.6736 - val_tp: 64.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 27.0000 - val_accuracy: 0.6047 - val_precision: 0.2700 - val_recall: 0.7033 - val_auc: 0.6834 - val_prc: 0.3716\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9784 - tp: 252.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 146.0000 - accuracy: 0.6779 - precision: 0.3325 - recall: 0.6332 - auc: 0.7177 - prc: 0.4000 - val_loss: 0.5894 - val_tp: 46.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 45.0000 - val_accuracy: 0.7016 - val_precision: 0.3026 - val_recall: 0.5055 - val_auc: 0.6839 - val_prc: 0.3910\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9813 - tp: 230.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 168.0000 - accuracy: 0.7075 - precision: 0.3517 - recall: 0.5779 - auc: 0.7136 - prc: 0.4228 - val_loss: 0.6652 - val_tp: 60.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 31.0000 - val_accuracy: 0.6087 - val_precision: 0.2643 - val_recall: 0.6593 - val_auc: 0.6841 - val_prc: 0.3814\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9796 - tp: 237.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 161.0000 - accuracy: 0.6798 - precision: 0.3273 - recall: 0.5955 - auc: 0.7159 - prc: 0.4021 - val_loss: 0.6373 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6844 - val_prc: 0.3884\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9773 - tp: 243.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 155.0000 - accuracy: 0.6848 - precision: 0.3347 - recall: 0.6106 - auc: 0.7185 - prc: 0.4197 - val_loss: 0.5777 - val_tp: 44.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 47.0000 - val_accuracy: 0.7194 - val_precision: 0.3165 - val_recall: 0.4835 - val_auc: 0.6839 - val_prc: 0.3909\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9764 - tp: 226.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 172.0000 - accuracy: 0.7045 - precision: 0.3466 - recall: 0.5678 - auc: 0.7193 - prc: 0.4202 - val_loss: 0.7123 - val_tp: 68.0000 - val_fp: 204.0000 - val_tn: 211.0000 - val_fn: 23.0000 - val_accuracy: 0.5514 - val_precision: 0.2500 - val_recall: 0.7473 - val_auc: 0.6827 - val_prc: 0.3551\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9822 - tp: 238.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 160.0000 - accuracy: 0.6912 - precision: 0.3385 - recall: 0.5980 - auc: 0.7158 - prc: 0.4075 - val_loss: 0.6778 - val_tp: 63.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 28.0000 - val_accuracy: 0.5949 - val_precision: 0.2625 - val_recall: 0.6923 - val_auc: 0.6839 - val_prc: 0.3813\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9776 - tp: 249.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 149.0000 - accuracy: 0.6942 - precision: 0.3463 - recall: 0.6256 - auc: 0.7191 - prc: 0.4236 - val_loss: 0.6122 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6829 - val_prc: 0.3820\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9811 - tp: 248.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 150.0000 - accuracy: 0.6947 - precision: 0.3464 - recall: 0.6231 - auc: 0.7157 - prc: 0.4172 - val_loss: 0.6776 - val_tp: 63.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 28.0000 - val_accuracy: 0.5929 - val_precision: 0.2614 - val_recall: 0.6923 - val_auc: 0.6842 - val_prc: 0.3789\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9804 - tp: 231.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 167.0000 - accuracy: 0.6873 - precision: 0.3314 - recall: 0.5804 - auc: 0.7154 - prc: 0.4203 - val_loss: 0.5882 - val_tp: 46.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 45.0000 - val_accuracy: 0.7016 - val_precision: 0.3026 - val_recall: 0.5055 - val_auc: 0.6840 - val_prc: 0.3908\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9770 - tp: 238.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 160.0000 - accuracy: 0.6961 - precision: 0.3434 - recall: 0.5980 - auc: 0.7183 - prc: 0.4186 - val_loss: 0.6398 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6850 - val_prc: 0.3899\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9779 - tp: 237.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 161.0000 - accuracy: 0.6897 - precision: 0.3366 - recall: 0.5955 - auc: 0.7179 - prc: 0.4187 - val_loss: 0.6671 - val_tp: 60.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 31.0000 - val_accuracy: 0.6087 - val_precision: 0.2643 - val_recall: 0.6593 - val_auc: 0.6841 - val_prc: 0.3868\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9765 - tp: 239.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 159.0000 - accuracy: 0.6907 - precision: 0.3385 - recall: 0.6005 - auc: 0.7196 - prc: 0.4226 - val_loss: 0.6156 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6832 - val_prc: 0.3809\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9801 - tp: 241.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 157.0000 - accuracy: 0.6947 - precision: 0.3433 - recall: 0.6055 - auc: 0.7159 - prc: 0.4120 - val_loss: 0.5876 - val_tp: 46.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 45.0000 - val_accuracy: 0.7055 - val_precision: 0.3067 - val_recall: 0.5055 - val_auc: 0.6851 - val_prc: 0.3913\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9865 - tp: 244.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 154.0000 - accuracy: 0.6759 - precision: 0.3271 - recall: 0.6131 - auc: 0.7105 - prc: 0.4057 - val_loss: 0.5910 - val_tp: 46.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 45.0000 - val_accuracy: 0.7016 - val_precision: 0.3026 - val_recall: 0.5055 - val_auc: 0.6839 - val_prc: 0.3907\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9795 - tp: 241.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 157.0000 - accuracy: 0.6902 - precision: 0.3390 - recall: 0.6055 - auc: 0.7150 - prc: 0.4180 - val_loss: 0.6073 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6843 - val_prc: 0.3910\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9759 - tp: 239.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 159.0000 - accuracy: 0.6868 - precision: 0.3347 - recall: 0.6005 - auc: 0.7193 - prc: 0.4186 - val_loss: 0.6382 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6849 - val_prc: 0.3886\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9771 - tp: 232.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 166.0000 - accuracy: 0.6957 - precision: 0.3402 - recall: 0.5829 - auc: 0.7194 - prc: 0.4206 - val_loss: 0.6197 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6847 - val_prc: 0.3854\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9826 - tp: 234.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 164.0000 - accuracy: 0.6996 - precision: 0.3451 - recall: 0.5879 - auc: 0.7121 - prc: 0.4174 - val_loss: 0.6314 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6846 - val_prc: 0.3889\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9762 - tp: 237.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 161.0000 - accuracy: 0.7036 - precision: 0.3506 - recall: 0.5955 - auc: 0.7204 - prc: 0.4245 - val_loss: 0.6978 - val_tp: 65.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 26.0000 - val_accuracy: 0.5711 - val_precision: 0.2539 - val_recall: 0.7143 - val_auc: 0.6843 - val_prc: 0.3757\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9760 - tp: 249.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 149.0000 - accuracy: 0.6868 - precision: 0.3392 - recall: 0.6256 - auc: 0.7200 - prc: 0.4213 - val_loss: 0.6154 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6848 - val_prc: 0.3854\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9821 - tp: 237.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 161.0000 - accuracy: 0.6922 - precision: 0.3391 - recall: 0.5955 - auc: 0.7144 - prc: 0.4162 - val_loss: 0.6612 - val_tp: 59.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 32.0000 - val_accuracy: 0.6087 - val_precision: 0.2622 - val_recall: 0.6484 - val_auc: 0.6845 - val_prc: 0.3878\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9777 - tp: 234.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 164.0000 - accuracy: 0.6937 - precision: 0.3391 - recall: 0.5879 - auc: 0.7175 - prc: 0.4328 - val_loss: 0.6026 - val_tp: 49.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 42.0000 - val_accuracy: 0.7016 - val_precision: 0.3101 - val_recall: 0.5385 - val_auc: 0.6845 - val_prc: 0.3920\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9793 - tp: 235.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 163.0000 - accuracy: 0.7001 - precision: 0.3461 - recall: 0.5905 - auc: 0.7164 - prc: 0.4244 - val_loss: 0.5765 - val_tp: 44.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 47.0000 - val_accuracy: 0.7213 - val_precision: 0.3188 - val_recall: 0.4835 - val_auc: 0.6845 - val_prc: 0.3954\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9812 - tp: 237.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 161.0000 - accuracy: 0.6912 - precision: 0.3381 - recall: 0.5955 - auc: 0.7153 - prc: 0.4139 - val_loss: 0.5763 - val_tp: 44.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 47.0000 - val_accuracy: 0.7213 - val_precision: 0.3188 - val_recall: 0.4835 - val_auc: 0.6845 - val_prc: 0.3943\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9744 - tp: 235.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 163.0000 - accuracy: 0.6996 - precision: 0.3456 - recall: 0.5905 - auc: 0.7200 - prc: 0.4240 - val_loss: 0.6769 - val_tp: 63.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 28.0000 - val_accuracy: 0.5949 - val_precision: 0.2625 - val_recall: 0.6923 - val_auc: 0.6844 - val_prc: 0.3875\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9794 - tp: 235.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 163.0000 - accuracy: 0.6868 - precision: 0.3329 - recall: 0.5905 - auc: 0.7149 - prc: 0.4236 - val_loss: 0.6459 - val_tp: 57.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 34.0000 - val_accuracy: 0.6403 - val_precision: 0.2780 - val_recall: 0.6264 - val_auc: 0.6856 - val_prc: 0.3885\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9767 - tp: 235.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 163.0000 - accuracy: 0.7050 - precision: 0.3513 - recall: 0.5905 - auc: 0.7186 - prc: 0.4266 - val_loss: 0.6220 - val_tp: 55.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 36.0000 - val_accuracy: 0.6759 - val_precision: 0.3005 - val_recall: 0.6044 - val_auc: 0.6852 - val_prc: 0.3883\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9744 - tp: 238.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 160.0000 - accuracy: 0.7070 - precision: 0.3547 - recall: 0.5980 - auc: 0.7208 - prc: 0.4278 - val_loss: 0.7171 - val_tp: 68.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 23.0000 - val_accuracy: 0.5415 - val_precision: 0.2455 - val_recall: 0.7473 - val_auc: 0.6838 - val_prc: 0.3676\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9774 - tp: 237.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 161.0000 - accuracy: 0.6927 - precision: 0.3395 - recall: 0.5955 - auc: 0.7170 - prc: 0.4251 - val_loss: 0.6895 - val_tp: 64.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 27.0000 - val_accuracy: 0.5810 - val_precision: 0.2570 - val_recall: 0.7033 - val_auc: 0.6850 - val_prc: 0.3841\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9765 - tp: 248.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 150.0000 - accuracy: 0.6927 - precision: 0.3444 - recall: 0.6231 - auc: 0.7188 - prc: 0.4069 - val_loss: 0.7143 - val_tp: 67.0000 - val_fp: 205.0000 - val_tn: 210.0000 - val_fn: 24.0000 - val_accuracy: 0.5474 - val_precision: 0.2463 - val_recall: 0.7363 - val_auc: 0.6835 - val_prc: 0.3709\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9771 - tp: 246.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 152.0000 - accuracy: 0.6952 - precision: 0.3460 - recall: 0.6181 - auc: 0.7191 - prc: 0.4190 - val_loss: 0.6480 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6856 - val_prc: 0.3911\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9761 - tp: 244.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 154.0000 - accuracy: 0.6932 - precision: 0.3432 - recall: 0.6131 - auc: 0.7183 - prc: 0.4192 - val_loss: 0.5865 - val_tp: 46.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 45.0000 - val_accuracy: 0.7075 - val_precision: 0.3087 - val_recall: 0.5055 - val_auc: 0.6851 - val_prc: 0.3977\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9759 - tp: 240.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 158.0000 - accuracy: 0.7011 - precision: 0.3493 - recall: 0.6030 - auc: 0.7195 - prc: 0.4152 - val_loss: 0.5845 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6852 - val_prc: 0.3986\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9762 - tp: 238.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 160.0000 - accuracy: 0.6976 - precision: 0.3449 - recall: 0.5980 - auc: 0.7190 - prc: 0.4171 - val_loss: 0.6422 - val_tp: 56.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 35.0000 - val_accuracy: 0.6423 - val_precision: 0.2772 - val_recall: 0.6154 - val_auc: 0.6853 - val_prc: 0.3896\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9760 - tp: 241.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 157.0000 - accuracy: 0.6818 - precision: 0.3310 - recall: 0.6055 - auc: 0.7171 - prc: 0.4216 - val_loss: 0.6174 - val_tp: 54.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 37.0000 - val_accuracy: 0.6858 - val_precision: 0.3068 - val_recall: 0.5934 - val_auc: 0.6864 - val_prc: 0.3963\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9807 - tp: 243.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 155.0000 - accuracy: 0.6808 - precision: 0.3311 - recall: 0.6106 - auc: 0.7126 - prc: 0.4220 - val_loss: 0.5849 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6861 - val_prc: 0.3979\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9753 - tp: 240.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 158.0000 - accuracy: 0.6808 - precision: 0.3297 - recall: 0.6030 - auc: 0.7179 - prc: 0.4263 - val_loss: 0.5830 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6865 - val_prc: 0.3976\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9724 - tp: 229.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 169.0000 - accuracy: 0.7149 - precision: 0.3595 - recall: 0.5754 - auc: 0.7230 - prc: 0.4281 - val_loss: 0.6866 - val_tp: 64.0000 - val_fp: 182.0000 - val_tn: 233.0000 - val_fn: 27.0000 - val_accuracy: 0.5870 - val_precision: 0.2602 - val_recall: 0.7033 - val_auc: 0.6864 - val_prc: 0.3883\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9717 - tp: 241.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 157.0000 - accuracy: 0.6976 - precision: 0.3463 - recall: 0.6055 - auc: 0.7224 - prc: 0.4268 - val_loss: 0.6683 - val_tp: 61.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 30.0000 - val_accuracy: 0.6107 - val_precision: 0.2675 - val_recall: 0.6703 - val_auc: 0.6868 - val_prc: 0.3915\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9767 - tp: 247.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 151.0000 - accuracy: 0.6897 - precision: 0.3412 - recall: 0.6206 - auc: 0.7176 - prc: 0.4195 - val_loss: 0.5793 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6861 - val_prc: 0.3971\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9793 - tp: 241.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 157.0000 - accuracy: 0.6907 - precision: 0.3394 - recall: 0.6055 - auc: 0.7143 - prc: 0.4166 - val_loss: 0.5820 - val_tp: 46.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 45.0000 - val_accuracy: 0.7115 - val_precision: 0.3129 - val_recall: 0.5055 - val_auc: 0.6862 - val_prc: 0.3971\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9823 - tp: 233.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 165.0000 - accuracy: 0.6922 - precision: 0.3372 - recall: 0.5854 - auc: 0.7139 - prc: 0.4092 - val_loss: 0.6027 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6869 - val_prc: 0.4021\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9756 - tp: 232.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 166.0000 - accuracy: 0.6952 - precision: 0.3397 - recall: 0.5829 - auc: 0.7204 - prc: 0.4224 - val_loss: 0.5830 - val_tp: 46.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 45.0000 - val_accuracy: 0.7115 - val_precision: 0.3129 - val_recall: 0.5055 - val_auc: 0.6859 - val_prc: 0.3982\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9744 - tp: 241.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 157.0000 - accuracy: 0.6981 - precision: 0.3468 - recall: 0.6055 - auc: 0.7203 - prc: 0.4239 - val_loss: 0.6372 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6865 - val_prc: 0.3921\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9731 - tp: 233.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 165.0000 - accuracy: 0.6961 - precision: 0.3411 - recall: 0.5854 - auc: 0.7203 - prc: 0.4299 - val_loss: 0.6331 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6858 - val_prc: 0.3943\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9740 - tp: 235.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 163.0000 - accuracy: 0.7001 - precision: 0.3461 - recall: 0.5905 - auc: 0.7205 - prc: 0.4283 - val_loss: 0.6767 - val_tp: 62.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 29.0000 - val_accuracy: 0.5929 - val_precision: 0.2594 - val_recall: 0.6813 - val_auc: 0.6845 - val_prc: 0.3847\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9763 - tp: 244.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 154.0000 - accuracy: 0.6813 - precision: 0.3320 - recall: 0.6131 - auc: 0.7172 - prc: 0.4189 - val_loss: 0.6241 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6866 - val_prc: 0.3946\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9736 - tp: 236.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 162.0000 - accuracy: 0.6981 - precision: 0.3445 - recall: 0.5930 - auc: 0.7212 - prc: 0.4268 - val_loss: 0.6491 - val_tp: 57.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 34.0000 - val_accuracy: 0.6245 - val_precision: 0.2676 - val_recall: 0.6264 - val_auc: 0.6864 - val_prc: 0.3914\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9747 - tp: 246.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 152.0000 - accuracy: 0.6848 - precision: 0.3361 - recall: 0.6181 - auc: 0.7199 - prc: 0.4281 - val_loss: 0.5986 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6863 - val_prc: 0.3984\n",
      "Epoch 191/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9750 - tp: 232.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 166.0000 - accuracy: 0.7045 - precision: 0.3494 - recall: 0.5829 - auc: 0.7199 - prc: 0.4241 - val_loss: 0.6634 - val_tp: 60.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 31.0000 - val_accuracy: 0.6107 - val_precision: 0.2655 - val_recall: 0.6593 - val_auc: 0.6856 - val_prc: 0.3903\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9791 - tp: 242.0000 - fp: 524.0000 - tn: 1102.0000 - fn: 156.0000 - accuracy: 0.6640 - precision: 0.3159 - recall: 0.6080 - auc: 0.7152 - prc: 0.4167 - val_loss: 0.6257 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.6863 - val_prc: 0.3949\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9742 - tp: 233.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 165.0000 - accuracy: 0.6976 - precision: 0.3426 - recall: 0.5854 - auc: 0.7196 - prc: 0.4249 - val_loss: 0.5916 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6873 - val_prc: 0.3993\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9735 - tp: 235.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 163.0000 - accuracy: 0.6991 - precision: 0.3451 - recall: 0.5905 - auc: 0.7198 - prc: 0.4317 - val_loss: 0.6759 - val_tp: 61.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 30.0000 - val_accuracy: 0.5909 - val_precision: 0.2563 - val_recall: 0.6703 - val_auc: 0.6867 - val_prc: 0.3908\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9736 - tp: 251.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 147.0000 - accuracy: 0.6942 - precision: 0.3472 - recall: 0.6307 - auc: 0.7215 - prc: 0.4247 - val_loss: 0.5628 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6873 - val_prc: 0.4067\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9713 - tp: 234.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 164.0000 - accuracy: 0.6961 - precision: 0.3416 - recall: 0.5879 - auc: 0.7212 - prc: 0.4354 - val_loss: 0.6284 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6869 - val_prc: 0.3950\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9733 - tp: 244.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 154.0000 - accuracy: 0.6863 - precision: 0.3366 - recall: 0.6131 - auc: 0.7217 - prc: 0.4251 - val_loss: 0.5965 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6867 - val_prc: 0.4012\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9781 - tp: 239.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 159.0000 - accuracy: 0.6902 - precision: 0.3380 - recall: 0.6005 - auc: 0.7157 - prc: 0.4214 - val_loss: 0.5579 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6859 - val_prc: 0.4068\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9741 - tp: 242.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 156.0000 - accuracy: 0.6848 - precision: 0.3343 - recall: 0.6080 - auc: 0.7204 - prc: 0.4286 - val_loss: 0.5386 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6851 - val_prc: 0.4082\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9805 - tp: 226.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 172.0000 - accuracy: 0.7060 - precision: 0.3482 - recall: 0.5678 - auc: 0.7149 - prc: 0.4139 - val_loss: 0.6528 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6869 - val_prc: 0.3939\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9726 - tp: 241.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 157.0000 - accuracy: 0.6922 - precision: 0.3409 - recall: 0.6055 - auc: 0.7212 - prc: 0.4271 - val_loss: 0.6803 - val_tp: 61.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 30.0000 - val_accuracy: 0.5889 - val_precision: 0.2552 - val_recall: 0.6703 - val_auc: 0.6865 - val_prc: 0.3949\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9705 - tp: 243.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 155.0000 - accuracy: 0.6892 - precision: 0.3389 - recall: 0.6106 - auc: 0.7210 - prc: 0.4308 - val_loss: 0.6177 - val_tp: 54.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 37.0000 - val_accuracy: 0.6838 - val_precision: 0.3051 - val_recall: 0.5934 - val_auc: 0.6876 - val_prc: 0.4027\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9731 - tp: 235.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 163.0000 - accuracy: 0.7139 - precision: 0.3610 - recall: 0.5905 - auc: 0.7221 - prc: 0.4316 - val_loss: 0.7148 - val_tp: 68.0000 - val_fp: 204.0000 - val_tn: 211.0000 - val_fn: 23.0000 - val_accuracy: 0.5514 - val_precision: 0.2500 - val_recall: 0.7473 - val_auc: 0.6859 - val_prc: 0.3900\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9783 - tp: 246.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 152.0000 - accuracy: 0.6774 - precision: 0.3293 - recall: 0.6181 - auc: 0.7143 - prc: 0.4189 - val_loss: 0.5655 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6869 - val_prc: 0.4081\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9813 - tp: 247.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 151.0000 - accuracy: 0.6853 - precision: 0.3370 - recall: 0.6206 - auc: 0.7135 - prc: 0.4091 - val_loss: 0.6628 - val_tp: 58.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 33.0000 - val_accuracy: 0.6067 - val_precision: 0.2589 - val_recall: 0.6374 - val_auc: 0.6867 - val_prc: 0.3883\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9738 - tp: 237.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 161.0000 - accuracy: 0.6942 - precision: 0.3410 - recall: 0.5955 - auc: 0.7203 - prc: 0.4274 - val_loss: 0.6522 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6857 - val_prc: 0.3938\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9738 - tp: 249.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 149.0000 - accuracy: 0.6853 - precision: 0.3379 - recall: 0.6256 - auc: 0.7204 - prc: 0.4255 - val_loss: 0.6281 - val_tp: 56.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 35.0000 - val_accuracy: 0.6660 - val_precision: 0.2947 - val_recall: 0.6154 - val_auc: 0.6869 - val_prc: 0.3960\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9729 - tp: 238.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 160.0000 - accuracy: 0.6853 - precision: 0.3329 - recall: 0.5980 - auc: 0.7206 - prc: 0.4291 - val_loss: 0.6505 - val_tp: 57.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 34.0000 - val_accuracy: 0.6186 - val_precision: 0.2639 - val_recall: 0.6264 - val_auc: 0.6867 - val_prc: 0.3942\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9717 - tp: 239.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 159.0000 - accuracy: 0.6961 - precision: 0.3439 - recall: 0.6005 - auc: 0.7225 - prc: 0.4301 - val_loss: 0.6836 - val_tp: 64.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 27.0000 - val_accuracy: 0.5909 - val_precision: 0.2623 - val_recall: 0.7033 - val_auc: 0.6857 - val_prc: 0.3951\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9735 - tp: 241.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 157.0000 - accuracy: 0.6877 - precision: 0.3366 - recall: 0.6055 - auc: 0.7191 - prc: 0.4230 - val_loss: 0.6283 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6874 - val_prc: 0.3957\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9753 - tp: 234.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 164.0000 - accuracy: 0.6892 - precision: 0.3348 - recall: 0.5879 - auc: 0.7181 - prc: 0.4270 - val_loss: 0.6376 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6862 - val_prc: 0.3963\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9788 - tp: 244.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 154.0000 - accuracy: 0.6863 - precision: 0.3366 - recall: 0.6131 - auc: 0.7148 - prc: 0.4274 - val_loss: 0.6229 - val_tp: 55.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 36.0000 - val_accuracy: 0.6739 - val_precision: 0.2989 - val_recall: 0.6044 - val_auc: 0.6870 - val_prc: 0.4023\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9739 - tp: 241.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 157.0000 - accuracy: 0.6873 - precision: 0.3361 - recall: 0.6055 - auc: 0.7200 - prc: 0.4279 - val_loss: 0.5841 - val_tp: 46.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 45.0000 - val_accuracy: 0.7055 - val_precision: 0.3067 - val_recall: 0.5055 - val_auc: 0.6868 - val_prc: 0.4003\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9753 - tp: 252.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 146.0000 - accuracy: 0.6764 - precision: 0.3311 - recall: 0.6332 - auc: 0.7178 - prc: 0.4194 - val_loss: 0.5771 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6867 - val_prc: 0.4078\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9796 - tp: 239.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 159.0000 - accuracy: 0.7001 - precision: 0.3479 - recall: 0.6005 - auc: 0.7144 - prc: 0.4048 - val_loss: 0.6490 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6858 - val_prc: 0.3992\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9712 - tp: 240.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 158.0000 - accuracy: 0.6907 - precision: 0.3390 - recall: 0.6030 - auc: 0.7220 - prc: 0.4305 - val_loss: 0.5851 - val_tp: 46.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 45.0000 - val_accuracy: 0.7036 - val_precision: 0.3046 - val_recall: 0.5055 - val_auc: 0.6875 - val_prc: 0.4086\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9723 - tp: 237.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 161.0000 - accuracy: 0.6917 - precision: 0.3386 - recall: 0.5955 - auc: 0.7206 - prc: 0.4311 - val_loss: 0.5933 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6871 - val_prc: 0.3997\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9733 - tp: 235.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 163.0000 - accuracy: 0.6986 - precision: 0.3446 - recall: 0.5905 - auc: 0.7211 - prc: 0.4323 - val_loss: 0.7185 - val_tp: 69.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 22.0000 - val_accuracy: 0.5435 - val_precision: 0.2482 - val_recall: 0.7582 - val_auc: 0.6848 - val_prc: 0.3848\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9741 - tp: 247.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 151.0000 - accuracy: 0.6912 - precision: 0.3426 - recall: 0.6206 - auc: 0.7197 - prc: 0.4214 - val_loss: 0.6014 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6877 - val_prc: 0.4011\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9696 - tp: 244.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 154.0000 - accuracy: 0.6922 - precision: 0.3422 - recall: 0.6131 - auc: 0.7232 - prc: 0.4344 - val_loss: 0.5537 - val_tp: 44.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 47.0000 - val_accuracy: 0.7470 - val_precision: 0.3520 - val_recall: 0.4835 - val_auc: 0.6873 - val_prc: 0.4085\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9711 - tp: 233.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 165.0000 - accuracy: 0.6937 - precision: 0.3387 - recall: 0.5854 - auc: 0.7208 - prc: 0.4371 - val_loss: 0.6081 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6876 - val_prc: 0.4019\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9763 - tp: 248.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 150.0000 - accuracy: 0.6789 - precision: 0.3316 - recall: 0.6231 - auc: 0.7166 - prc: 0.4194 - val_loss: 0.5729 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6864 - val_prc: 0.4092\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9746 - tp: 229.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 169.0000 - accuracy: 0.6986 - precision: 0.3418 - recall: 0.5754 - auc: 0.7160 - prc: 0.4367 - val_loss: 0.7064 - val_tp: 68.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 23.0000 - val_accuracy: 0.5534 - val_precision: 0.2509 - val_recall: 0.7473 - val_auc: 0.6873 - val_prc: 0.3964\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9741 - tp: 236.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 162.0000 - accuracy: 0.6838 - precision: 0.3305 - recall: 0.5930 - auc: 0.7190 - prc: 0.4308 - val_loss: 0.6354 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6871 - val_prc: 0.3967\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9720 - tp: 251.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 147.0000 - accuracy: 0.6922 - precision: 0.3453 - recall: 0.6307 - auc: 0.7209 - prc: 0.4314 - val_loss: 0.5731 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6855 - val_prc: 0.4089\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9707 - tp: 244.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 154.0000 - accuracy: 0.6957 - precision: 0.3456 - recall: 0.6131 - auc: 0.7228 - prc: 0.4351 - val_loss: 0.7108 - val_tp: 69.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 22.0000 - val_accuracy: 0.5672 - val_precision: 0.2594 - val_recall: 0.7582 - val_auc: 0.6858 - val_prc: 0.3854\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9715 - tp: 244.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 154.0000 - accuracy: 0.6937 - precision: 0.3437 - recall: 0.6131 - auc: 0.7214 - prc: 0.4375 - val_loss: 0.5851 - val_tp: 47.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 44.0000 - val_accuracy: 0.7055 - val_precision: 0.3092 - val_recall: 0.5165 - val_auc: 0.6866 - val_prc: 0.3995\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9725 - tp: 250.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 148.0000 - accuracy: 0.6996 - precision: 0.3521 - recall: 0.6281 - auc: 0.7213 - prc: 0.4243 - val_loss: 0.5925 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6874 - val_prc: 0.4007\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9738 - tp: 232.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 166.0000 - accuracy: 0.7090 - precision: 0.3542 - recall: 0.5829 - auc: 0.7216 - prc: 0.4264 - val_loss: 0.6704 - val_tp: 59.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 32.0000 - val_accuracy: 0.5988 - val_precision: 0.2565 - val_recall: 0.6484 - val_auc: 0.6868 - val_prc: 0.3949\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9712 - tp: 245.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 153.0000 - accuracy: 0.6961 - precision: 0.3465 - recall: 0.6156 - auc: 0.7211 - prc: 0.4351 - val_loss: 0.6552 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6871 - val_prc: 0.4006\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9696 - tp: 249.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 149.0000 - accuracy: 0.6868 - precision: 0.3392 - recall: 0.6256 - auc: 0.7246 - prc: 0.4201 - val_loss: 0.6636 - val_tp: 58.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 33.0000 - val_accuracy: 0.6047 - val_precision: 0.2578 - val_recall: 0.6374 - val_auc: 0.6850 - val_prc: 0.3934\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9737 - tp: 233.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 165.0000 - accuracy: 0.6798 - precision: 0.3254 - recall: 0.5854 - auc: 0.7197 - prc: 0.4243 - val_loss: 0.7321 - val_tp: 69.0000 - val_fp: 213.0000 - val_tn: 202.0000 - val_fn: 22.0000 - val_accuracy: 0.5356 - val_precision: 0.2447 - val_recall: 0.7582 - val_auc: 0.6836 - val_prc: 0.3794\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9784 - tp: 247.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 151.0000 - accuracy: 0.6843 - precision: 0.3361 - recall: 0.6206 - auc: 0.7141 - prc: 0.4258 - val_loss: 0.6916 - val_tp: 65.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 26.0000 - val_accuracy: 0.5850 - val_precision: 0.2610 - val_recall: 0.7143 - val_auc: 0.6864 - val_prc: 0.3907\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9720 - tp: 239.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 159.0000 - accuracy: 0.6942 - precision: 0.3419 - recall: 0.6005 - auc: 0.7214 - prc: 0.4271 - val_loss: 0.6627 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6864 - val_prc: 0.4016\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9702 - tp: 245.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 153.0000 - accuracy: 0.6907 - precision: 0.3412 - recall: 0.6156 - auc: 0.7214 - prc: 0.4329 - val_loss: 0.5746 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6874 - val_prc: 0.4089\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9702 - tp: 240.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 158.0000 - accuracy: 0.7016 - precision: 0.3499 - recall: 0.6030 - auc: 0.7218 - prc: 0.4319 - val_loss: 0.6593 - val_tp: 58.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 33.0000 - val_accuracy: 0.6107 - val_precision: 0.2613 - val_recall: 0.6374 - val_auc: 0.6873 - val_prc: 0.3992\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9713 - tp: 247.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 151.0000 - accuracy: 0.6917 - precision: 0.3431 - recall: 0.6206 - auc: 0.7226 - prc: 0.4286 - val_loss: 0.6252 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.6876 - val_prc: 0.4021\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9770 - tp: 239.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 159.0000 - accuracy: 0.7031 - precision: 0.3510 - recall: 0.6005 - auc: 0.7172 - prc: 0.4173 - val_loss: 0.7130 - val_tp: 69.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 22.0000 - val_accuracy: 0.5573 - val_precision: 0.2546 - val_recall: 0.7582 - val_auc: 0.6857 - val_prc: 0.3851\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9743 - tp: 247.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 151.0000 - accuracy: 0.6937 - precision: 0.3450 - recall: 0.6206 - auc: 0.7203 - prc: 0.4209 - val_loss: 0.7065 - val_tp: 67.0000 - val_fp: 201.0000 - val_tn: 214.0000 - val_fn: 24.0000 - val_accuracy: 0.5553 - val_precision: 0.2500 - val_recall: 0.7363 - val_auc: 0.6868 - val_prc: 0.3945\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9702 - tp: 241.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 157.0000 - accuracy: 0.6927 - precision: 0.3414 - recall: 0.6055 - auc: 0.7223 - prc: 0.4352 - val_loss: 0.6490 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.6874 - val_prc: 0.4000\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9737 - tp: 241.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 157.0000 - accuracy: 0.6961 - precision: 0.3448 - recall: 0.6055 - auc: 0.7192 - prc: 0.4261 - val_loss: 0.6370 - val_tp: 55.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 36.0000 - val_accuracy: 0.6423 - val_precision: 0.2750 - val_recall: 0.6044 - val_auc: 0.6861 - val_prc: 0.4036\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9710 - tp: 241.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 157.0000 - accuracy: 0.6922 - precision: 0.3409 - recall: 0.6055 - auc: 0.7219 - prc: 0.4248 - val_loss: 0.6513 - val_tp: 57.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 34.0000 - val_accuracy: 0.6206 - val_precision: 0.2651 - val_recall: 0.6264 - val_auc: 0.6868 - val_prc: 0.3997\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9705 - tp: 245.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 153.0000 - accuracy: 0.6877 - precision: 0.3384 - recall: 0.6156 - auc: 0.7221 - prc: 0.4318 - val_loss: 0.6343 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6876 - val_prc: 0.4038\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9712 - tp: 245.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 153.0000 - accuracy: 0.6917 - precision: 0.3422 - recall: 0.6156 - auc: 0.7221 - prc: 0.4244 - val_loss: 0.6073 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6879 - val_prc: 0.4017\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9742 - tp: 238.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 160.0000 - accuracy: 0.6932 - precision: 0.3405 - recall: 0.5980 - auc: 0.7199 - prc: 0.4204 - val_loss: 0.6644 - val_tp: 58.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 33.0000 - val_accuracy: 0.6028 - val_precision: 0.2566 - val_recall: 0.6374 - val_auc: 0.6872 - val_prc: 0.3998\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9736 - tp: 244.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 154.0000 - accuracy: 0.6892 - precision: 0.3394 - recall: 0.6131 - auc: 0.7186 - prc: 0.4229 - val_loss: 0.6360 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6869 - val_prc: 0.4018\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9737 - tp: 243.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 155.0000 - accuracy: 0.6947 - precision: 0.3442 - recall: 0.6106 - auc: 0.7198 - prc: 0.4307 - val_loss: 0.6170 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6876 - val_prc: 0.4013\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9712 - tp: 232.0000 - fp: 427.0000 - tn: 1199.0000 - fn: 166.0000 - accuracy: 0.7070 - precision: 0.3520 - recall: 0.5829 - auc: 0.7216 - prc: 0.4315 - val_loss: 0.6424 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6873 - val_prc: 0.4039\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9707 - tp: 247.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 151.0000 - accuracy: 0.6823 - precision: 0.3342 - recall: 0.6206 - auc: 0.7217 - prc: 0.4275 - val_loss: 0.6618 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6861 - val_prc: 0.3994\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9684 - tp: 235.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 163.0000 - accuracy: 0.6996 - precision: 0.3456 - recall: 0.5905 - auc: 0.7238 - prc: 0.4348 - val_loss: 0.6913 - val_tp: 66.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 25.0000 - val_accuracy: 0.5850 - val_precision: 0.2629 - val_recall: 0.7253 - val_auc: 0.6855 - val_prc: 0.3967\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9766 - tp: 241.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 157.0000 - accuracy: 0.6907 - precision: 0.3394 - recall: 0.6055 - auc: 0.7147 - prc: 0.4313 - val_loss: 0.5971 - val_tp: 49.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 42.0000 - val_accuracy: 0.6937 - val_precision: 0.3025 - val_recall: 0.5385 - val_auc: 0.6842 - val_prc: 0.4116\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9722 - tp: 251.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 147.0000 - accuracy: 0.6793 - precision: 0.3333 - recall: 0.6307 - auc: 0.7213 - prc: 0.4256 - val_loss: 0.6443 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6862 - val_prc: 0.4069\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9710 - tp: 243.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 155.0000 - accuracy: 0.6991 - precision: 0.3486 - recall: 0.6106 - auc: 0.7215 - prc: 0.4357 - val_loss: 0.6311 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6869 - val_prc: 0.4024\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9731 - tp: 245.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 153.0000 - accuracy: 0.6922 - precision: 0.3427 - recall: 0.6156 - auc: 0.7197 - prc: 0.4284 - val_loss: 0.6536 - val_tp: 58.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 33.0000 - val_accuracy: 0.6225 - val_precision: 0.2685 - val_recall: 0.6374 - val_auc: 0.6859 - val_prc: 0.3988\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9771 - tp: 241.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 157.0000 - accuracy: 0.6709 - precision: 0.3213 - recall: 0.6055 - auc: 0.7152 - prc: 0.4209 - val_loss: 0.5686 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6869 - val_prc: 0.4104\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9707 - tp: 236.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 162.0000 - accuracy: 0.7021 - precision: 0.3486 - recall: 0.5930 - auc: 0.7216 - prc: 0.4296 - val_loss: 0.6452 - val_tp: 56.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 35.0000 - val_accuracy: 0.6304 - val_precision: 0.2692 - val_recall: 0.6154 - val_auc: 0.6867 - val_prc: 0.4043\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9706 - tp: 248.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 150.0000 - accuracy: 0.6902 - precision: 0.3421 - recall: 0.6231 - auc: 0.7219 - prc: 0.4343 - val_loss: 0.5807 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6880 - val_prc: 0.4103\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9702 - tp: 246.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 152.0000 - accuracy: 0.6907 - precision: 0.3417 - recall: 0.6181 - auc: 0.7214 - prc: 0.4360 - val_loss: 0.6561 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6865 - val_prc: 0.3997\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9709 - tp: 249.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 149.0000 - accuracy: 0.6986 - precision: 0.3507 - recall: 0.6256 - auc: 0.7210 - prc: 0.4286 - val_loss: 0.5817 - val_tp: 47.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.3133 - val_recall: 0.5165 - val_auc: 0.6871 - val_prc: 0.4088\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9701 - tp: 239.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 159.0000 - accuracy: 0.6942 - precision: 0.3419 - recall: 0.6005 - auc: 0.7216 - prc: 0.4334 - val_loss: 0.6161 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6877 - val_prc: 0.4027\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9717 - tp: 242.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 156.0000 - accuracy: 0.6957 - precision: 0.3447 - recall: 0.6080 - auc: 0.7204 - prc: 0.4333 - val_loss: 0.5902 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6873 - val_prc: 0.4104\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9724 - tp: 235.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 163.0000 - accuracy: 0.6971 - precision: 0.3431 - recall: 0.5905 - auc: 0.7202 - prc: 0.4402 - val_loss: 0.6518 - val_tp: 57.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 34.0000 - val_accuracy: 0.6186 - val_precision: 0.2639 - val_recall: 0.6264 - val_auc: 0.6870 - val_prc: 0.4042\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9801 - tp: 241.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 157.0000 - accuracy: 0.6843 - precision: 0.3333 - recall: 0.6055 - auc: 0.7133 - prc: 0.4188 - val_loss: 0.6209 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6876 - val_prc: 0.4020\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9689 - tp: 240.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 158.0000 - accuracy: 0.6838 - precision: 0.3324 - recall: 0.6030 - auc: 0.7233 - prc: 0.4314 - val_loss: 0.6378 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6871 - val_prc: 0.4030\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9732 - tp: 240.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 158.0000 - accuracy: 0.6868 - precision: 0.3352 - recall: 0.6030 - auc: 0.7184 - prc: 0.4262 - val_loss: 0.6301 - val_tp: 56.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 35.0000 - val_accuracy: 0.6561 - val_precision: 0.2872 - val_recall: 0.6154 - val_auc: 0.6866 - val_prc: 0.4018\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9728 - tp: 249.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 149.0000 - accuracy: 0.6966 - precision: 0.3487 - recall: 0.6256 - auc: 0.7194 - prc: 0.4260 - val_loss: 0.6458 - val_tp: 56.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 35.0000 - val_accuracy: 0.6324 - val_precision: 0.2705 - val_recall: 0.6154 - val_auc: 0.6871 - val_prc: 0.4032\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9719 - tp: 239.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 159.0000 - accuracy: 0.6932 - precision: 0.3409 - recall: 0.6005 - auc: 0.7208 - prc: 0.4377 - val_loss: 0.6520 - val_tp: 58.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 33.0000 - val_accuracy: 0.6225 - val_precision: 0.2685 - val_recall: 0.6374 - val_auc: 0.6861 - val_prc: 0.4071\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9730 - tp: 240.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 158.0000 - accuracy: 0.6897 - precision: 0.3380 - recall: 0.6030 - auc: 0.7204 - prc: 0.4288 - val_loss: 0.6301 - val_tp: 56.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 35.0000 - val_accuracy: 0.6561 - val_precision: 0.2872 - val_recall: 0.6154 - val_auc: 0.6870 - val_prc: 0.4026\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9771 - tp: 236.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 162.0000 - accuracy: 0.6882 - precision: 0.3348 - recall: 0.5930 - auc: 0.7137 - prc: 0.4342 - val_loss: 0.5765 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6877 - val_prc: 0.4071\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9730 - tp: 240.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 158.0000 - accuracy: 0.6907 - precision: 0.3390 - recall: 0.6030 - auc: 0.7187 - prc: 0.4289 - val_loss: 0.6109 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6882 - val_prc: 0.4026\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9699 - tp: 240.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 158.0000 - accuracy: 0.6942 - precision: 0.3424 - recall: 0.6030 - auc: 0.7220 - prc: 0.4325 - val_loss: 0.6312 - val_tp: 56.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 35.0000 - val_accuracy: 0.6561 - val_precision: 0.2872 - val_recall: 0.6154 - val_auc: 0.6866 - val_prc: 0.4025\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9690 - tp: 241.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 157.0000 - accuracy: 0.6991 - precision: 0.3478 - recall: 0.6055 - auc: 0.7231 - prc: 0.4334 - val_loss: 0.6146 - val_tp: 54.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 37.0000 - val_accuracy: 0.6838 - val_precision: 0.3051 - val_recall: 0.5934 - val_auc: 0.6874 - val_prc: 0.4001\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9710 - tp: 238.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 160.0000 - accuracy: 0.7036 - precision: 0.3510 - recall: 0.5980 - auc: 0.7214 - prc: 0.4328 - val_loss: 0.6471 - val_tp: 56.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 35.0000 - val_accuracy: 0.6265 - val_precision: 0.2667 - val_recall: 0.6154 - val_auc: 0.6875 - val_prc: 0.4043\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9744 - tp: 254.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 144.0000 - accuracy: 0.6670 - precision: 0.3240 - recall: 0.6382 - auc: 0.7190 - prc: 0.4231 - val_loss: 0.6107 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6870 - val_prc: 0.4105\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9715 - tp: 245.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 153.0000 - accuracy: 0.6892 - precision: 0.3398 - recall: 0.6156 - auc: 0.7215 - prc: 0.4266 - val_loss: 0.5913 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6871 - val_prc: 0.4053\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9706 - tp: 233.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 165.0000 - accuracy: 0.7001 - precision: 0.3452 - recall: 0.5854 - auc: 0.7210 - prc: 0.4398 - val_loss: 0.6687 - val_tp: 59.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 32.0000 - val_accuracy: 0.5988 - val_precision: 0.2565 - val_recall: 0.6484 - val_auc: 0.6858 - val_prc: 0.3976\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9689 - tp: 243.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 155.0000 - accuracy: 0.7006 - precision: 0.3501 - recall: 0.6106 - auc: 0.7236 - prc: 0.4309 - val_loss: 0.6253 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6861 - val_prc: 0.3987\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9693 - tp: 247.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 151.0000 - accuracy: 0.6961 - precision: 0.3474 - recall: 0.6206 - auc: 0.7232 - prc: 0.4299 - val_loss: 0.6859 - val_tp: 63.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 28.0000 - val_accuracy: 0.5810 - val_precision: 0.2551 - val_recall: 0.6923 - val_auc: 0.6860 - val_prc: 0.3933\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9671 - tp: 254.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 144.0000 - accuracy: 0.6774 - precision: 0.3329 - recall: 0.6382 - auc: 0.7249 - prc: 0.4265 - val_loss: 0.5711 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6865 - val_prc: 0.4030\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9688 - tp: 240.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 158.0000 - accuracy: 0.7011 - precision: 0.3493 - recall: 0.6030 - auc: 0.7217 - prc: 0.4344 - val_loss: 0.6763 - val_tp: 61.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 30.0000 - val_accuracy: 0.5968 - val_precision: 0.2596 - val_recall: 0.6703 - val_auc: 0.6863 - val_prc: 0.3993\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9692 - tp: 242.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 156.0000 - accuracy: 0.6961 - precision: 0.3452 - recall: 0.6080 - auc: 0.7233 - prc: 0.4358 - val_loss: 0.6586 - val_tp: 59.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 32.0000 - val_accuracy: 0.6126 - val_precision: 0.2646 - val_recall: 0.6484 - val_auc: 0.6872 - val_prc: 0.4033\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9673 - tp: 254.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 144.0000 - accuracy: 0.6873 - precision: 0.3419 - recall: 0.6382 - auc: 0.7240 - prc: 0.4343 - val_loss: 0.5805 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6876 - val_prc: 0.4047\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9708 - tp: 236.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 162.0000 - accuracy: 0.6996 - precision: 0.3460 - recall: 0.5930 - auc: 0.7221 - prc: 0.4250 - val_loss: 0.5940 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6872 - val_prc: 0.4054\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9795 - tp: 239.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 159.0000 - accuracy: 0.6882 - precision: 0.3361 - recall: 0.6005 - auc: 0.7131 - prc: 0.4217 - val_loss: 0.6530 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6866 - val_prc: 0.4018\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9694 - tp: 255.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 143.0000 - accuracy: 0.6784 - precision: 0.3342 - recall: 0.6407 - auc: 0.7218 - prc: 0.4322 - val_loss: 0.6208 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6863 - val_prc: 0.3985\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9691 - tp: 242.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 156.0000 - accuracy: 0.7080 - precision: 0.3575 - recall: 0.6080 - auc: 0.7242 - prc: 0.4286 - val_loss: 0.6578 - val_tp: 59.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 32.0000 - val_accuracy: 0.6166 - val_precision: 0.2670 - val_recall: 0.6484 - val_auc: 0.6863 - val_prc: 0.4046\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9765 - tp: 245.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 153.0000 - accuracy: 0.6789 - precision: 0.3302 - recall: 0.6156 - auc: 0.7158 - prc: 0.4257 - val_loss: 0.6484 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6864 - val_prc: 0.4027\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9756 - tp: 236.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 162.0000 - accuracy: 0.7100 - precision: 0.3570 - recall: 0.5930 - auc: 0.7184 - prc: 0.4216 - val_loss: 0.6945 - val_tp: 67.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 24.0000 - val_accuracy: 0.5830 - val_precision: 0.2638 - val_recall: 0.7363 - val_auc: 0.6846 - val_prc: 0.3925\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9766 - tp: 240.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 158.0000 - accuracy: 0.6873 - precision: 0.3357 - recall: 0.6030 - auc: 0.7150 - prc: 0.4286 - val_loss: 0.6338 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6874 - val_prc: 0.3997\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9701 - tp: 243.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 155.0000 - accuracy: 0.6897 - precision: 0.3394 - recall: 0.6106 - auc: 0.7210 - prc: 0.4309 - val_loss: 0.6826 - val_tp: 63.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 28.0000 - val_accuracy: 0.5870 - val_precision: 0.2582 - val_recall: 0.6923 - val_auc: 0.6856 - val_prc: 0.3991\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9703 - tp: 239.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 159.0000 - accuracy: 0.6991 - precision: 0.3469 - recall: 0.6005 - auc: 0.7201 - prc: 0.4343 - val_loss: 0.6947 - val_tp: 65.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 26.0000 - val_accuracy: 0.5751 - val_precision: 0.2559 - val_recall: 0.7143 - val_auc: 0.6863 - val_prc: 0.3999\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9731 - tp: 250.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 148.0000 - accuracy: 0.6868 - precision: 0.3397 - recall: 0.6281 - auc: 0.7186 - prc: 0.4372 - val_loss: 0.6265 - val_tp: 56.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 35.0000 - val_accuracy: 0.6660 - val_precision: 0.2947 - val_recall: 0.6154 - val_auc: 0.6866 - val_prc: 0.3983\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9721 - tp: 245.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 153.0000 - accuracy: 0.6887 - precision: 0.3393 - recall: 0.6156 - auc: 0.7214 - prc: 0.4275 - val_loss: 0.6924 - val_tp: 65.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 26.0000 - val_accuracy: 0.5771 - val_precision: 0.2569 - val_recall: 0.7143 - val_auc: 0.6862 - val_prc: 0.4007\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9713 - tp: 241.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 157.0000 - accuracy: 0.6961 - precision: 0.3448 - recall: 0.6055 - auc: 0.7204 - prc: 0.4292 - val_loss: 0.6466 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6874 - val_prc: 0.4008\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9666 - tp: 249.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 149.0000 - accuracy: 0.6912 - precision: 0.3434 - recall: 0.6256 - auc: 0.7255 - prc: 0.4340 - val_loss: 0.5881 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6872 - val_prc: 0.4056\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9716 - tp: 240.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 158.0000 - accuracy: 0.6986 - precision: 0.3468 - recall: 0.6030 - auc: 0.7206 - prc: 0.4289 - val_loss: 0.6596 - val_tp: 61.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 30.0000 - val_accuracy: 0.6107 - val_precision: 0.2675 - val_recall: 0.6703 - val_auc: 0.6876 - val_prc: 0.4024\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9680 - tp: 237.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 161.0000 - accuracy: 0.7036 - precision: 0.3506 - recall: 0.5955 - auc: 0.7238 - prc: 0.4377 - val_loss: 0.6466 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6872 - val_prc: 0.4013\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9704 - tp: 243.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 155.0000 - accuracy: 0.6793 - precision: 0.3297 - recall: 0.6106 - auc: 0.7211 - prc: 0.4315 - val_loss: 0.6206 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6878 - val_prc: 0.3993\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9681 - tp: 231.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 167.0000 - accuracy: 0.7060 - precision: 0.3505 - recall: 0.5804 - auc: 0.7243 - prc: 0.4361 - val_loss: 0.7087 - val_tp: 69.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 22.0000 - val_accuracy: 0.5553 - val_precision: 0.2537 - val_recall: 0.7582 - val_auc: 0.6866 - val_prc: 0.3944\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9668 - tp: 250.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 148.0000 - accuracy: 0.6961 - precision: 0.3487 - recall: 0.6281 - auc: 0.7246 - prc: 0.4360 - val_loss: 0.6427 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6864 - val_prc: 0.4008\n",
      "Epoch 301/500\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 0.9757 - tp: 237.0000 - fp: 450.0000 - tn: 1072.0000 - fn: 141.0000 - accuracy: 0.6889 - precision: 0.3450 - recall: 0.6270 - auc: 0.7197 - prc: 0.4352Restoring model weights from the end of the best epoch: 251.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9682 - tp: 251.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 147.0000 - accuracy: 0.6882 - precision: 0.3415 - recall: 0.6307 - auc: 0.7228 - prc: 0.4322 - val_loss: 0.6267 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6872 - val_prc: 0.3982\n",
      "Epoch 301: early stopping\n",
      "26/26 [==============================] - 0s 593us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.5984 - tp: 54.0000 - fp: 136.0000 - tn: 1905.0000 - fn: 435.0000 - accuracy: 0.7743 - precision: 0.2842 - recall: 0.1104 - auc: 0.4956 - prc: 0.2280 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.5529 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4940 - prc: 0.1989 - val_loss: 0.4767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.5101 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1992 - val_loss: 0.4809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4705 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4843 - prc: 0.1913 - val_loss: 0.4862 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4344 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5038 - prc: 0.2026 - val_loss: 0.4923 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4020 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4892 - prc: 0.1910 - val_loss: 0.4992 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3720 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5021 - prc: 0.2015 - val_loss: 0.5069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3449 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5170 - prc: 0.2052 - val_loss: 0.5155 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3206 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5213 - prc: 0.2057 - val_loss: 0.5249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2986 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5248 - prc: 0.2077 - val_loss: 0.5344 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5120 - prc: 0.2075 - val_loss: 0.5445 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2629 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - prc: 0.1907 - val_loss: 0.5548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2483 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4800 - prc: 0.1919 - val_loss: 0.5648 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2357 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4653 - prc: 0.1815 - val_loss: 0.5752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5210 - prc: 0.2050 - val_loss: 0.5854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2143 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5194 - prc: 0.2052 - val_loss: 0.5959 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4954 - prc: 0.1970 - val_loss: 0.6058 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5013 - prc: 0.1963 - val_loss: 0.6163 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1933 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5244 - prc: 0.2076 - val_loss: 0.6254 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4906 - prc: 0.1921 - val_loss: 0.6344 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1843 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4992 - prc: 0.2056 - val_loss: 0.6423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1811 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5049 - prc: 0.1990 - val_loss: 0.6508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1784 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4885 - prc: 0.1925 - val_loss: 0.6572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1763 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4948 - prc: 0.1910 - val_loss: 0.6650 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1744 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4873 - prc: 0.1876 - val_loss: 0.6717 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4744 - prc: 0.1840 - val_loss: 0.6771 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1718 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.6813 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1710 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4738 - prc: 0.1869 - val_loss: 0.6862 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1702 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5024 - prc: 0.1980 - val_loss: 0.6906 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1696 - tp: 177.0000 - fp: 723.0000 - tn: 903.0000 - fn: 221.0000 - accuracy: 0.5336 - precision: 0.1967 - recall: 0.4447 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.6945 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1690 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.5088 - prc: 0.1998 - val_loss: 0.6989 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1687 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.7020 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1682 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.4984 - prc: 0.1960 - val_loss: 0.7052 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1681 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.4846 - prc: 0.1868 - val_loss: 0.7084 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1678 - tp: 398.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 0.0000e+00 - accuracy: 0.2001 - precision: 0.1973 - recall: 1.0000 - auc: 0.4901 - prc: 0.1930 - val_loss: 0.7103 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1676 - tp: 398.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 0.0000e+00 - accuracy: 0.2001 - precision: 0.1973 - recall: 1.0000 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.7136 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1676 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.4870 - prc: 0.1889 - val_loss: 0.7153 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1676 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.4912 - prc: 0.1935 - val_loss: 0.7151 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1674 - tp: 397.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 1.0000 - accuracy: 0.1996 - precision: 0.1969 - recall: 0.9975 - auc: 0.4997 - prc: 0.1965 - val_loss: 0.7168 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1674 - tp: 398.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 0.0000e+00 - accuracy: 0.2001 - precision: 0.1973 - recall: 1.0000 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.7188 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1671 - tp: 398.0000 - fp: 1619.0000 - tn: 7.0000 - fn: 0.0000e+00 - accuracy: 0.2001 - precision: 0.1973 - recall: 1.0000 - auc: 0.5022 - prc: 0.1973 - val_loss: 0.7181 - val_tp: 91.0000 - val_fp: 412.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1858 - val_precision: 0.1809 - val_recall: 1.0000 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1677 - tp: 395.0000 - fp: 1617.0000 - tn: 9.0000 - fn: 3.0000 - accuracy: 0.1996 - precision: 0.1963 - recall: 0.9925 - auc: 0.4996 - prc: 0.1965 - val_loss: 0.7188 - val_tp: 91.0000 - val_fp: 411.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1877 - val_precision: 0.1813 - val_recall: 1.0000 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1672 - tp: 397.0000 - fp: 1618.0000 - tn: 8.0000 - fn: 1.0000 - accuracy: 0.2001 - precision: 0.1970 - recall: 0.9975 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.7200 - val_tp: 91.0000 - val_fp: 411.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1877 - val_precision: 0.1813 - val_recall: 1.0000 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1586 - tp: 358.0000 - fp: 1351.0000 - tn: 275.0000 - fn: 40.0000 - accuracy: 0.3127 - precision: 0.2095 - recall: 0.8995 - auc: 0.5410 - prc: 0.2171 - val_loss: 0.5867 - val_tp: 36.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 55.0000 - val_accuracy: 0.7648 - val_precision: 0.3600 - val_recall: 0.3956 - val_auc: 0.6557 - val_prc: 0.3101\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1454 - tp: 295.0000 - fp: 921.0000 - tn: 705.0000 - fn: 103.0000 - accuracy: 0.4941 - precision: 0.2426 - recall: 0.7412 - auc: 0.6010 - prc: 0.2433 - val_loss: 0.6020 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.6529 - val_prc: 0.2959\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1425 - tp: 302.0000 - fp: 949.0000 - tn: 677.0000 - fn: 96.0000 - accuracy: 0.4837 - precision: 0.2414 - recall: 0.7588 - auc: 0.5862 - prc: 0.2311 - val_loss: 0.5323 - val_tp: 14.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 77.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1538 - val_auc: 0.6616 - val_prc: 0.3425\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1265 - tp: 228.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 170.0000 - accuracy: 0.6759 - precision: 0.3193 - recall: 0.5729 - auc: 0.6749 - prc: 0.3321 - val_loss: 0.6494 - val_tp: 61.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 30.0000 - val_accuracy: 0.5791 - val_precision: 0.2500 - val_recall: 0.6703 - val_auc: 0.6482 - val_prc: 0.2800\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1170 - tp: 227.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 171.0000 - accuracy: 0.6724 - precision: 0.3157 - recall: 0.5704 - auc: 0.6802 - prc: 0.3357 - val_loss: 0.6158 - val_tp: 53.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 38.0000 - val_accuracy: 0.7016 - val_precision: 0.3193 - val_recall: 0.5824 - val_auc: 0.6626 - val_prc: 0.3141\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1106 - tp: 230.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 168.0000 - accuracy: 0.6823 - precision: 0.3262 - recall: 0.5779 - auc: 0.6906 - prc: 0.3479 - val_loss: 0.6246 - val_tp: 55.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 36.0000 - val_accuracy: 0.6858 - val_precision: 0.3090 - val_recall: 0.6044 - val_auc: 0.6632 - val_prc: 0.3122\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1067 - tp: 255.0000 - fp: 583.0000 - tn: 1043.0000 - fn: 143.0000 - accuracy: 0.6413 - precision: 0.3043 - recall: 0.6407 - auc: 0.6794 - prc: 0.3109 - val_loss: 0.6066 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6656 - val_prc: 0.3229\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0992 - tp: 254.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 144.0000 - accuracy: 0.6754 - precision: 0.3312 - recall: 0.6382 - auc: 0.6950 - prc: 0.3436 - val_loss: 0.6359 - val_tp: 57.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 34.0000 - val_accuracy: 0.6364 - val_precision: 0.2754 - val_recall: 0.6264 - val_auc: 0.6611 - val_prc: 0.3052\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0992 - tp: 263.0000 - fp: 567.0000 - tn: 1059.0000 - fn: 135.0000 - accuracy: 0.6532 - precision: 0.3169 - recall: 0.6608 - auc: 0.6937 - prc: 0.3501 - val_loss: 0.5610 - val_tp: 36.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 55.0000 - val_accuracy: 0.7885 - val_precision: 0.4091 - val_recall: 0.3956 - val_auc: 0.6696 - val_prc: 0.3624\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0951 - tp: 248.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 150.0000 - accuracy: 0.6492 - precision: 0.3069 - recall: 0.6231 - auc: 0.6920 - prc: 0.3391 - val_loss: 0.6653 - val_tp: 64.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 27.0000 - val_accuracy: 0.5474 - val_precision: 0.2406 - val_recall: 0.7033 - val_auc: 0.6605 - val_prc: 0.2971\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1002 - tp: 243.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 155.0000 - accuracy: 0.6477 - precision: 0.3034 - recall: 0.6106 - auc: 0.6842 - prc: 0.3381 - val_loss: 0.5773 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6709 - val_prc: 0.3495\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0926 - tp: 250.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 148.0000 - accuracy: 0.6542 - precision: 0.3117 - recall: 0.6281 - auc: 0.6946 - prc: 0.3570 - val_loss: 0.6478 - val_tp: 60.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 31.0000 - val_accuracy: 0.6146 - val_precision: 0.2679 - val_recall: 0.6593 - val_auc: 0.6655 - val_prc: 0.3114\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0871 - tp: 253.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 145.0000 - accuracy: 0.6784 - precision: 0.3333 - recall: 0.6357 - auc: 0.6988 - prc: 0.3601 - val_loss: 0.6767 - val_tp: 66.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 25.0000 - val_accuracy: 0.5356 - val_precision: 0.2391 - val_recall: 0.7253 - val_auc: 0.6617 - val_prc: 0.2986\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0860 - tp: 256.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 142.0000 - accuracy: 0.6532 - precision: 0.3137 - recall: 0.6432 - auc: 0.6974 - prc: 0.3423 - val_loss: 0.6990 - val_tp: 67.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 24.0000 - val_accuracy: 0.4763 - val_precision: 0.2175 - val_recall: 0.7363 - val_auc: 0.6558 - val_prc: 0.2858\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0878 - tp: 261.0000 - fp: 606.0000 - tn: 1020.0000 - fn: 137.0000 - accuracy: 0.6329 - precision: 0.3010 - recall: 0.6558 - auc: 0.6898 - prc: 0.3392 - val_loss: 0.7052 - val_tp: 68.0000 - val_fp: 247.0000 - val_tn: 168.0000 - val_fn: 23.0000 - val_accuracy: 0.4664 - val_precision: 0.2159 - val_recall: 0.7473 - val_auc: 0.6572 - val_prc: 0.2881\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0779 - tp: 238.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 160.0000 - accuracy: 0.6833 - precision: 0.3310 - recall: 0.5980 - auc: 0.7075 - prc: 0.3806 - val_loss: 0.7434 - val_tp: 72.0000 - val_fp: 275.0000 - val_tn: 140.0000 - val_fn: 19.0000 - val_accuracy: 0.4190 - val_precision: 0.2075 - val_recall: 0.7912 - val_auc: 0.6444 - val_prc: 0.2678\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0908 - tp: 287.0000 - fp: 762.0000 - tn: 864.0000 - fn: 111.0000 - accuracy: 0.5687 - precision: 0.2736 - recall: 0.7211 - auc: 0.6724 - prc: 0.3016 - val_loss: 0.6558 - val_tp: 63.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 28.0000 - val_accuracy: 0.6008 - val_precision: 0.2658 - val_recall: 0.6923 - val_auc: 0.6668 - val_prc: 0.3142\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0841 - tp: 253.0000 - fp: 566.0000 - tn: 1060.0000 - fn: 145.0000 - accuracy: 0.6487 - precision: 0.3089 - recall: 0.6357 - auc: 0.6951 - prc: 0.3705 - val_loss: 0.6483 - val_tp: 62.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 29.0000 - val_accuracy: 0.6166 - val_precision: 0.2731 - val_recall: 0.6813 - val_auc: 0.6692 - val_prc: 0.3224\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0733 - tp: 259.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 139.0000 - accuracy: 0.6571 - precision: 0.3182 - recall: 0.6508 - auc: 0.7042 - prc: 0.3503 - val_loss: 0.7483 - val_tp: 72.0000 - val_fp: 274.0000 - val_tn: 141.0000 - val_fn: 19.0000 - val_accuracy: 0.4209 - val_precision: 0.2081 - val_recall: 0.7912 - val_auc: 0.6470 - val_prc: 0.2709\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0779 - tp: 255.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 143.0000 - accuracy: 0.6635 - precision: 0.3216 - recall: 0.6407 - auc: 0.7014 - prc: 0.3792 - val_loss: 0.7192 - val_tp: 68.0000 - val_fp: 250.0000 - val_tn: 165.0000 - val_fn: 23.0000 - val_accuracy: 0.4605 - val_precision: 0.2138 - val_recall: 0.7473 - val_auc: 0.6555 - val_prc: 0.2832\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0762 - tp: 279.0000 - fp: 672.0000 - tn: 954.0000 - fn: 119.0000 - accuracy: 0.6092 - precision: 0.2934 - recall: 0.7010 - auc: 0.7009 - prc: 0.3566 - val_loss: 0.6224 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6718 - val_prc: 0.3336\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0696 - tp: 250.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 148.0000 - accuracy: 0.6838 - precision: 0.3369 - recall: 0.6281 - auc: 0.7071 - prc: 0.3718 - val_loss: 0.6795 - val_tp: 66.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 25.0000 - val_accuracy: 0.5494 - val_precision: 0.2454 - val_recall: 0.7253 - val_auc: 0.6694 - val_prc: 0.3178\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0673 - tp: 259.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 139.0000 - accuracy: 0.6714 - precision: 0.3299 - recall: 0.6508 - auc: 0.7095 - prc: 0.3770 - val_loss: 0.7176 - val_tp: 67.0000 - val_fp: 247.0000 - val_tn: 168.0000 - val_fn: 24.0000 - val_accuracy: 0.4644 - val_precision: 0.2134 - val_recall: 0.7363 - val_auc: 0.6597 - val_prc: 0.2896\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0720 - tp: 270.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 128.0000 - accuracy: 0.6403 - precision: 0.3103 - recall: 0.6784 - auc: 0.7017 - prc: 0.3667 - val_loss: 0.6153 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6752 - val_prc: 0.3467\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0705 - tp: 248.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 150.0000 - accuracy: 0.6665 - precision: 0.3208 - recall: 0.6231 - auc: 0.7038 - prc: 0.3700 - val_loss: 0.7141 - val_tp: 67.0000 - val_fp: 239.0000 - val_tn: 176.0000 - val_fn: 24.0000 - val_accuracy: 0.4802 - val_precision: 0.2190 - val_recall: 0.7363 - val_auc: 0.6653 - val_prc: 0.3023\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0664 - tp: 255.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 143.0000 - accuracy: 0.6571 - precision: 0.3164 - recall: 0.6407 - auc: 0.7074 - prc: 0.3855 - val_loss: 0.6796 - val_tp: 65.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 26.0000 - val_accuracy: 0.5534 - val_precision: 0.2453 - val_recall: 0.7143 - val_auc: 0.6722 - val_prc: 0.3272\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0638 - tp: 271.0000 - fp: 598.0000 - tn: 1028.0000 - fn: 127.0000 - accuracy: 0.6418 - precision: 0.3119 - recall: 0.6809 - auc: 0.7082 - prc: 0.3692 - val_loss: 0.6243 - val_tp: 57.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 34.0000 - val_accuracy: 0.6640 - val_precision: 0.2953 - val_recall: 0.6264 - val_auc: 0.6767 - val_prc: 0.3505\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0653 - tp: 263.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 135.0000 - accuracy: 0.6611 - precision: 0.3231 - recall: 0.6608 - auc: 0.7067 - prc: 0.3648 - val_loss: 0.6787 - val_tp: 65.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 26.0000 - val_accuracy: 0.5593 - val_precision: 0.2481 - val_recall: 0.7143 - val_auc: 0.6746 - val_prc: 0.3341\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0679 - tp: 259.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 139.0000 - accuracy: 0.6601 - precision: 0.3205 - recall: 0.6508 - auc: 0.7037 - prc: 0.3714 - val_loss: 0.6480 - val_tp: 61.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 30.0000 - val_accuracy: 0.6166 - val_precision: 0.2711 - val_recall: 0.6703 - val_auc: 0.6743 - val_prc: 0.3331\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0673 - tp: 275.0000 - fp: 653.0000 - tn: 973.0000 - fn: 123.0000 - accuracy: 0.6166 - precision: 0.2963 - recall: 0.6910 - auc: 0.6990 - prc: 0.3454 - val_loss: 0.7801 - val_tp: 72.0000 - val_fp: 282.0000 - val_tn: 133.0000 - val_fn: 19.0000 - val_accuracy: 0.4051 - val_precision: 0.2034 - val_recall: 0.7912 - val_auc: 0.6575 - val_prc: 0.2822\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0661 - tp: 271.0000 - fp: 597.0000 - tn: 1029.0000 - fn: 127.0000 - accuracy: 0.6423 - precision: 0.3122 - recall: 0.6809 - auc: 0.7028 - prc: 0.3716 - val_loss: 0.6983 - val_tp: 66.0000 - val_fp: 215.0000 - val_tn: 200.0000 - val_fn: 25.0000 - val_accuracy: 0.5257 - val_precision: 0.2349 - val_recall: 0.7253 - val_auc: 0.6732 - val_prc: 0.3230\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0643 - tp: 279.0000 - fp: 643.0000 - tn: 983.0000 - fn: 119.0000 - accuracy: 0.6235 - precision: 0.3026 - recall: 0.7010 - auc: 0.7040 - prc: 0.3607 - val_loss: 0.5649 - val_tp: 41.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 50.0000 - val_accuracy: 0.7411 - val_precision: 0.3361 - val_recall: 0.4505 - val_auc: 0.6773 - val_prc: 0.3764\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0648 - tp: 255.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 143.0000 - accuracy: 0.6581 - precision: 0.3172 - recall: 0.6407 - auc: 0.7031 - prc: 0.3746 - val_loss: 0.6439 - val_tp: 59.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 32.0000 - val_accuracy: 0.6265 - val_precision: 0.2731 - val_recall: 0.6484 - val_auc: 0.6771 - val_prc: 0.3454\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0607 - tp: 260.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 138.0000 - accuracy: 0.6532 - precision: 0.3155 - recall: 0.6533 - auc: 0.7072 - prc: 0.3773 - val_loss: 0.6342 - val_tp: 58.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 33.0000 - val_accuracy: 0.6502 - val_precision: 0.2871 - val_recall: 0.6374 - val_auc: 0.6781 - val_prc: 0.3486\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0605 - tp: 260.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 138.0000 - accuracy: 0.6472 - precision: 0.3110 - recall: 0.6533 - auc: 0.7075 - prc: 0.3835 - val_loss: 0.6578 - val_tp: 64.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 27.0000 - val_accuracy: 0.6087 - val_precision: 0.2723 - val_recall: 0.7033 - val_auc: 0.6757 - val_prc: 0.3317\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0626 - tp: 254.0000 - fp: 563.0000 - tn: 1063.0000 - fn: 144.0000 - accuracy: 0.6507 - precision: 0.3109 - recall: 0.6382 - auc: 0.7044 - prc: 0.3739 - val_loss: 0.7102 - val_tp: 67.0000 - val_fp: 222.0000 - val_tn: 193.0000 - val_fn: 24.0000 - val_accuracy: 0.5138 - val_precision: 0.2318 - val_recall: 0.7363 - val_auc: 0.6757 - val_prc: 0.3310\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0614 - tp: 257.0000 - fp: 607.0000 - tn: 1019.0000 - fn: 141.0000 - accuracy: 0.6304 - precision: 0.2975 - recall: 0.6457 - auc: 0.7061 - prc: 0.3808 - val_loss: 0.7084 - val_tp: 67.0000 - val_fp: 220.0000 - val_tn: 195.0000 - val_fn: 24.0000 - val_accuracy: 0.5178 - val_precision: 0.2334 - val_recall: 0.7363 - val_auc: 0.6753 - val_prc: 0.3290\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0600 - tp: 260.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 138.0000 - accuracy: 0.6354 - precision: 0.3023 - recall: 0.6533 - auc: 0.7055 - prc: 0.3797 - val_loss: 0.6661 - val_tp: 64.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 27.0000 - val_accuracy: 0.5909 - val_precision: 0.2623 - val_recall: 0.7033 - val_auc: 0.6765 - val_prc: 0.3322\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0578 - tp: 263.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 135.0000 - accuracy: 0.6487 - precision: 0.3135 - recall: 0.6608 - auc: 0.7076 - prc: 0.3805 - val_loss: 0.6499 - val_tp: 61.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 30.0000 - val_accuracy: 0.6225 - val_precision: 0.2748 - val_recall: 0.6703 - val_auc: 0.6798 - val_prc: 0.3580\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0578 - tp: 264.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 134.0000 - accuracy: 0.6522 - precision: 0.3165 - recall: 0.6633 - auc: 0.7092 - prc: 0.3856 - val_loss: 0.6322 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.6791 - val_prc: 0.3559\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0584 - tp: 263.0000 - fp: 583.0000 - tn: 1043.0000 - fn: 135.0000 - accuracy: 0.6453 - precision: 0.3109 - recall: 0.6608 - auc: 0.7068 - prc: 0.3821 - val_loss: 0.6454 - val_tp: 61.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 30.0000 - val_accuracy: 0.6285 - val_precision: 0.2785 - val_recall: 0.6703 - val_auc: 0.6789 - val_prc: 0.3466\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0549 - tp: 260.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 138.0000 - accuracy: 0.6650 - precision: 0.3250 - recall: 0.6533 - auc: 0.7118 - prc: 0.3985 - val_loss: 0.6943 - val_tp: 66.0000 - val_fp: 205.0000 - val_tn: 210.0000 - val_fn: 25.0000 - val_accuracy: 0.5455 - val_precision: 0.2435 - val_recall: 0.7253 - val_auc: 0.6781 - val_prc: 0.3358\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0603 - tp: 272.0000 - fp: 667.0000 - tn: 959.0000 - fn: 126.0000 - accuracy: 0.6082 - precision: 0.2897 - recall: 0.6834 - auc: 0.7039 - prc: 0.3667 - val_loss: 0.6864 - val_tp: 66.0000 - val_fp: 198.0000 - val_tn: 217.0000 - val_fn: 25.0000 - val_accuracy: 0.5593 - val_precision: 0.2500 - val_recall: 0.7253 - val_auc: 0.6775 - val_prc: 0.3346\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0583 - tp: 268.0000 - fp: 586.0000 - tn: 1040.0000 - fn: 130.0000 - accuracy: 0.6462 - precision: 0.3138 - recall: 0.6734 - auc: 0.7080 - prc: 0.3791 - val_loss: 0.5734 - val_tp: 43.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 48.0000 - val_accuracy: 0.7253 - val_precision: 0.3209 - val_recall: 0.4725 - val_auc: 0.6793 - val_prc: 0.3788\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0571 - tp: 251.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 147.0000 - accuracy: 0.6665 - precision: 0.3222 - recall: 0.6307 - auc: 0.7077 - prc: 0.3849 - val_loss: 0.7373 - val_tp: 68.0000 - val_fp: 240.0000 - val_tn: 175.0000 - val_fn: 23.0000 - val_accuracy: 0.4802 - val_precision: 0.2208 - val_recall: 0.7473 - val_auc: 0.6746 - val_prc: 0.3217\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0562 - tp: 265.0000 - fp: 575.0000 - tn: 1051.0000 - fn: 133.0000 - accuracy: 0.6502 - precision: 0.3155 - recall: 0.6658 - auc: 0.7074 - prc: 0.3829 - val_loss: 0.6674 - val_tp: 64.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 27.0000 - val_accuracy: 0.5929 - val_precision: 0.2634 - val_recall: 0.7033 - val_auc: 0.6776 - val_prc: 0.3385\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0510 - tp: 262.0000 - fp: 553.0000 - tn: 1073.0000 - fn: 136.0000 - accuracy: 0.6596 - precision: 0.3215 - recall: 0.6583 - auc: 0.7142 - prc: 0.4022 - val_loss: 0.7531 - val_tp: 68.0000 - val_fp: 250.0000 - val_tn: 165.0000 - val_fn: 23.0000 - val_accuracy: 0.4605 - val_precision: 0.2138 - val_recall: 0.7473 - val_auc: 0.6712 - val_prc: 0.3112\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0642 - tp: 265.0000 - fp: 644.0000 - tn: 982.0000 - fn: 133.0000 - accuracy: 0.6161 - precision: 0.2915 - recall: 0.6658 - auc: 0.6981 - prc: 0.3719 - val_loss: 0.6929 - val_tp: 66.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 25.0000 - val_accuracy: 0.5514 - val_precision: 0.2463 - val_recall: 0.7253 - val_auc: 0.6775 - val_prc: 0.3344\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0496 - tp: 263.0000 - fp: 561.0000 - tn: 1065.0000 - fn: 135.0000 - accuracy: 0.6561 - precision: 0.3192 - recall: 0.6608 - auc: 0.7143 - prc: 0.3768 - val_loss: 0.6703 - val_tp: 64.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 27.0000 - val_accuracy: 0.5889 - val_precision: 0.2612 - val_recall: 0.7033 - val_auc: 0.6790 - val_prc: 0.3395\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0504 - tp: 260.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 138.0000 - accuracy: 0.6502 - precision: 0.3133 - recall: 0.6533 - auc: 0.7123 - prc: 0.3917 - val_loss: 0.6952 - val_tp: 66.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 25.0000 - val_accuracy: 0.5494 - val_precision: 0.2454 - val_recall: 0.7253 - val_auc: 0.6782 - val_prc: 0.3346\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0565 - tp: 268.0000 - fp: 595.0000 - tn: 1031.0000 - fn: 130.0000 - accuracy: 0.6418 - precision: 0.3105 - recall: 0.6734 - auc: 0.7084 - prc: 0.3761 - val_loss: 0.6615 - val_tp: 63.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 28.0000 - val_accuracy: 0.6047 - val_precision: 0.2681 - val_recall: 0.6923 - val_auc: 0.6806 - val_prc: 0.3550\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0533 - tp: 266.0000 - fp: 584.0000 - tn: 1042.0000 - fn: 132.0000 - accuracy: 0.6462 - precision: 0.3129 - recall: 0.6683 - auc: 0.7093 - prc: 0.3728 - val_loss: 0.6666 - val_tp: 64.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 27.0000 - val_accuracy: 0.6028 - val_precision: 0.2689 - val_recall: 0.7033 - val_auc: 0.6794 - val_prc: 0.3414\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0510 - tp: 257.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 141.0000 - accuracy: 0.6581 - precision: 0.3181 - recall: 0.6457 - auc: 0.7127 - prc: 0.3970 - val_loss: 0.5995 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6813 - val_prc: 0.3771\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0458 - tp: 259.0000 - fp: 561.0000 - tn: 1065.0000 - fn: 139.0000 - accuracy: 0.6542 - precision: 0.3159 - recall: 0.6508 - auc: 0.7171 - prc: 0.3867 - val_loss: 0.5746 - val_tp: 43.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 48.0000 - val_accuracy: 0.7213 - val_precision: 0.3162 - val_recall: 0.4725 - val_auc: 0.6800 - val_prc: 0.3819\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0528 - tp: 259.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 139.0000 - accuracy: 0.6616 - precision: 0.3217 - recall: 0.6508 - auc: 0.7098 - prc: 0.3935 - val_loss: 0.7553 - val_tp: 68.0000 - val_fp: 248.0000 - val_tn: 167.0000 - val_fn: 23.0000 - val_accuracy: 0.4644 - val_precision: 0.2152 - val_recall: 0.7473 - val_auc: 0.6757 - val_prc: 0.3245\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0485 - tp: 261.0000 - fp: 572.0000 - tn: 1054.0000 - fn: 137.0000 - accuracy: 0.6497 - precision: 0.3133 - recall: 0.6558 - auc: 0.7138 - prc: 0.3850 - val_loss: 0.7984 - val_tp: 71.0000 - val_fp: 272.0000 - val_tn: 143.0000 - val_fn: 20.0000 - val_accuracy: 0.4229 - val_precision: 0.2070 - val_recall: 0.7802 - val_auc: 0.6695 - val_prc: 0.3037\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0500 - tp: 268.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 130.0000 - accuracy: 0.6443 - precision: 0.3124 - recall: 0.6734 - auc: 0.7100 - prc: 0.3895 - val_loss: 0.6496 - val_tp: 60.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 31.0000 - val_accuracy: 0.6206 - val_precision: 0.2715 - val_recall: 0.6593 - val_auc: 0.6820 - val_prc: 0.3630\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0514 - tp: 266.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 132.0000 - accuracy: 0.6665 - precision: 0.3288 - recall: 0.6683 - auc: 0.7120 - prc: 0.3969 - val_loss: 0.6182 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6816 - val_prc: 0.3765\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0456 - tp: 252.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 146.0000 - accuracy: 0.6680 - precision: 0.3239 - recall: 0.6332 - auc: 0.7144 - prc: 0.4194 - val_loss: 0.7371 - val_tp: 68.0000 - val_fp: 239.0000 - val_tn: 176.0000 - val_fn: 23.0000 - val_accuracy: 0.4822 - val_precision: 0.2215 - val_recall: 0.7473 - val_auc: 0.6803 - val_prc: 0.3421\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0521 - tp: 264.0000 - fp: 602.0000 - tn: 1024.0000 - fn: 134.0000 - accuracy: 0.6364 - precision: 0.3048 - recall: 0.6633 - auc: 0.7087 - prc: 0.3890 - val_loss: 0.7310 - val_tp: 68.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 23.0000 - val_accuracy: 0.4980 - val_precision: 0.2274 - val_recall: 0.7473 - val_auc: 0.6794 - val_prc: 0.3390\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0482 - tp: 266.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 132.0000 - accuracy: 0.6413 - precision: 0.3093 - recall: 0.6683 - auc: 0.7127 - prc: 0.3826 - val_loss: 0.5829 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6824 - val_prc: 0.3847\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0502 - tp: 263.0000 - fp: 584.0000 - tn: 1042.0000 - fn: 135.0000 - accuracy: 0.6448 - precision: 0.3105 - recall: 0.6608 - auc: 0.7097 - prc: 0.3890 - val_loss: 0.6037 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6829 - val_prc: 0.3847\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0547 - tp: 266.0000 - fp: 573.0000 - tn: 1053.0000 - fn: 132.0000 - accuracy: 0.6517 - precision: 0.3170 - recall: 0.6683 - auc: 0.7079 - prc: 0.3820 - val_loss: 0.6405 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6823 - val_prc: 0.3754\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0466 - tp: 269.0000 - fp: 579.0000 - tn: 1047.0000 - fn: 129.0000 - accuracy: 0.6502 - precision: 0.3172 - recall: 0.6759 - auc: 0.7160 - prc: 0.3954 - val_loss: 0.6662 - val_tp: 62.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 29.0000 - val_accuracy: 0.6028 - val_precision: 0.2650 - val_recall: 0.6813 - val_auc: 0.6812 - val_prc: 0.3559\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0484 - tp: 262.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 136.0000 - accuracy: 0.6645 - precision: 0.3255 - recall: 0.6583 - auc: 0.7121 - prc: 0.3936 - val_loss: 0.6867 - val_tp: 65.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 26.0000 - val_accuracy: 0.5751 - val_precision: 0.2559 - val_recall: 0.7143 - val_auc: 0.6816 - val_prc: 0.3526\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0519 - tp: 261.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 137.0000 - accuracy: 0.6408 - precision: 0.3067 - recall: 0.6558 - auc: 0.7080 - prc: 0.3966 - val_loss: 0.5865 - val_tp: 44.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 47.0000 - val_accuracy: 0.6996 - val_precision: 0.2953 - val_recall: 0.4835 - val_auc: 0.6799 - val_prc: 0.3867\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0462 - tp: 260.0000 - fp: 563.0000 - tn: 1063.0000 - fn: 138.0000 - accuracy: 0.6537 - precision: 0.3159 - recall: 0.6533 - auc: 0.7127 - prc: 0.3965 - val_loss: 0.7793 - val_tp: 68.0000 - val_fp: 259.0000 - val_tn: 156.0000 - val_fn: 23.0000 - val_accuracy: 0.4427 - val_precision: 0.2080 - val_recall: 0.7473 - val_auc: 0.6747 - val_prc: 0.3188\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0466 - tp: 267.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 131.0000 - accuracy: 0.6388 - precision: 0.3080 - recall: 0.6709 - auc: 0.7132 - prc: 0.4061 - val_loss: 0.6177 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6821 - val_prc: 0.3844\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0469 - tp: 259.0000 - fp: 575.0000 - tn: 1051.0000 - fn: 139.0000 - accuracy: 0.6472 - precision: 0.3106 - recall: 0.6508 - auc: 0.7139 - prc: 0.4100 - val_loss: 0.6785 - val_tp: 65.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 26.0000 - val_accuracy: 0.5929 - val_precision: 0.2653 - val_recall: 0.7143 - val_auc: 0.6827 - val_prc: 0.3596\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0471 - tp: 266.0000 - fp: 588.0000 - tn: 1038.0000 - fn: 132.0000 - accuracy: 0.6443 - precision: 0.3115 - recall: 0.6683 - auc: 0.7124 - prc: 0.3975 - val_loss: 0.6469 - val_tp: 59.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 32.0000 - val_accuracy: 0.6285 - val_precision: 0.2744 - val_recall: 0.6484 - val_auc: 0.6835 - val_prc: 0.3833\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0463 - tp: 259.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 139.0000 - accuracy: 0.6640 - precision: 0.3237 - recall: 0.6508 - auc: 0.7156 - prc: 0.4128 - val_loss: 0.6906 - val_tp: 67.0000 - val_fp: 199.0000 - val_tn: 216.0000 - val_fn: 24.0000 - val_accuracy: 0.5593 - val_precision: 0.2519 - val_recall: 0.7363 - val_auc: 0.6819 - val_prc: 0.3621\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0454 - tp: 253.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 145.0000 - accuracy: 0.6650 - precision: 0.3219 - recall: 0.6357 - auc: 0.7148 - prc: 0.4082 - val_loss: 0.6948 - val_tp: 67.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 24.0000 - val_accuracy: 0.5534 - val_precision: 0.2491 - val_recall: 0.7363 - val_auc: 0.6821 - val_prc: 0.3563\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0458 - tp: 265.0000 - fp: 587.0000 - tn: 1039.0000 - fn: 133.0000 - accuracy: 0.6443 - precision: 0.3110 - recall: 0.6658 - auc: 0.7146 - prc: 0.3961 - val_loss: 0.6594 - val_tp: 60.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 31.0000 - val_accuracy: 0.6107 - val_precision: 0.2655 - val_recall: 0.6593 - val_auc: 0.6838 - val_prc: 0.3772\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0444 - tp: 266.0000 - fp: 559.0000 - tn: 1067.0000 - fn: 132.0000 - accuracy: 0.6586 - precision: 0.3224 - recall: 0.6683 - auc: 0.7159 - prc: 0.4036 - val_loss: 0.5798 - val_tp: 44.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 47.0000 - val_accuracy: 0.7134 - val_precision: 0.3099 - val_recall: 0.4835 - val_auc: 0.6819 - val_prc: 0.3866\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0427 - tp: 263.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 135.0000 - accuracy: 0.6576 - precision: 0.3203 - recall: 0.6608 - auc: 0.7150 - prc: 0.4067 - val_loss: 0.6995 - val_tp: 67.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 24.0000 - val_accuracy: 0.5514 - val_precision: 0.2481 - val_recall: 0.7363 - val_auc: 0.6828 - val_prc: 0.3563\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0431 - tp: 267.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 131.0000 - accuracy: 0.6482 - precision: 0.3149 - recall: 0.6709 - auc: 0.7163 - prc: 0.4065 - val_loss: 0.5259 - val_tp: 37.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 54.0000 - val_accuracy: 0.7885 - val_precision: 0.4111 - val_recall: 0.4066 - val_auc: 0.6808 - val_prc: 0.4019\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0484 - tp: 264.0000 - fp: 579.0000 - tn: 1047.0000 - fn: 134.0000 - accuracy: 0.6477 - precision: 0.3132 - recall: 0.6633 - auc: 0.7103 - prc: 0.3978 - val_loss: 0.6184 - val_tp: 54.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 37.0000 - val_accuracy: 0.6818 - val_precision: 0.3034 - val_recall: 0.5934 - val_auc: 0.6834 - val_prc: 0.3869\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0457 - tp: 262.0000 - fp: 571.0000 - tn: 1055.0000 - fn: 136.0000 - accuracy: 0.6507 - precision: 0.3145 - recall: 0.6583 - auc: 0.7130 - prc: 0.3989 - val_loss: 0.5837 - val_tp: 45.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 46.0000 - val_accuracy: 0.7055 - val_precision: 0.3041 - val_recall: 0.4945 - val_auc: 0.6816 - val_prc: 0.3872\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0493 - tp: 248.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 150.0000 - accuracy: 0.6655 - precision: 0.3200 - recall: 0.6231 - auc: 0.7096 - prc: 0.4063 - val_loss: 0.7357 - val_tp: 68.0000 - val_fp: 229.0000 - val_tn: 186.0000 - val_fn: 23.0000 - val_accuracy: 0.5020 - val_precision: 0.2290 - val_recall: 0.7473 - val_auc: 0.6798 - val_prc: 0.3370\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0457 - tp: 267.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 131.0000 - accuracy: 0.6482 - precision: 0.3149 - recall: 0.6709 - auc: 0.7135 - prc: 0.3957 - val_loss: 0.6320 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6829 - val_prc: 0.3868\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0455 - tp: 264.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 134.0000 - accuracy: 0.6551 - precision: 0.3188 - recall: 0.6633 - auc: 0.7139 - prc: 0.4022 - val_loss: 0.6322 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6840 - val_prc: 0.3869\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0435 - tp: 256.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 142.0000 - accuracy: 0.6660 - precision: 0.3241 - recall: 0.6432 - auc: 0.7149 - prc: 0.4101 - val_loss: 0.6956 - val_tp: 67.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 24.0000 - val_accuracy: 0.5692 - val_precision: 0.2567 - val_recall: 0.7363 - val_auc: 0.6829 - val_prc: 0.3598\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0441 - tp: 268.0000 - fp: 577.0000 - tn: 1049.0000 - fn: 130.0000 - accuracy: 0.6507 - precision: 0.3172 - recall: 0.6734 - auc: 0.7143 - prc: 0.4113 - val_loss: 0.6186 - val_tp: 54.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 37.0000 - val_accuracy: 0.6858 - val_precision: 0.3068 - val_recall: 0.5934 - val_auc: 0.6836 - val_prc: 0.3810\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0475 - tp: 255.0000 - fp: 559.0000 - tn: 1067.0000 - fn: 143.0000 - accuracy: 0.6532 - precision: 0.3133 - recall: 0.6407 - auc: 0.7105 - prc: 0.3977 - val_loss: 0.6525 - val_tp: 59.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 32.0000 - val_accuracy: 0.6245 - val_precision: 0.2719 - val_recall: 0.6484 - val_auc: 0.6845 - val_prc: 0.3858\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0431 - tp: 267.0000 - fp: 550.0000 - tn: 1076.0000 - fn: 131.0000 - accuracy: 0.6635 - precision: 0.3268 - recall: 0.6709 - auc: 0.7153 - prc: 0.4137 - val_loss: 0.6051 - val_tp: 48.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 43.0000 - val_accuracy: 0.6838 - val_precision: 0.2909 - val_recall: 0.5275 - val_auc: 0.6836 - val_prc: 0.3890\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0424 - tp: 266.0000 - fp: 567.0000 - tn: 1059.0000 - fn: 132.0000 - accuracy: 0.6546 - precision: 0.3193 - recall: 0.6683 - auc: 0.7159 - prc: 0.4083 - val_loss: 0.6733 - val_tp: 65.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 26.0000 - val_accuracy: 0.5968 - val_precision: 0.2675 - val_recall: 0.7143 - val_auc: 0.6851 - val_prc: 0.3824\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0437 - tp: 262.0000 - fp: 573.0000 - tn: 1053.0000 - fn: 136.0000 - accuracy: 0.6497 - precision: 0.3138 - recall: 0.6583 - auc: 0.7147 - prc: 0.4081 - val_loss: 0.6930 - val_tp: 67.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 24.0000 - val_accuracy: 0.5751 - val_precision: 0.2597 - val_recall: 0.7363 - val_auc: 0.6843 - val_prc: 0.3772\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0445 - tp: 270.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 128.0000 - accuracy: 0.6581 - precision: 0.3237 - recall: 0.6784 - auc: 0.7143 - prc: 0.4144 - val_loss: 0.6852 - val_tp: 65.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 26.0000 - val_accuracy: 0.5830 - val_precision: 0.2600 - val_recall: 0.7143 - val_auc: 0.6842 - val_prc: 0.3822\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0455 - tp: 265.0000 - fp: 579.0000 - tn: 1047.0000 - fn: 133.0000 - accuracy: 0.6482 - precision: 0.3140 - recall: 0.6658 - auc: 0.7122 - prc: 0.3942 - val_loss: 0.6788 - val_tp: 65.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 26.0000 - val_accuracy: 0.5909 - val_precision: 0.2642 - val_recall: 0.7143 - val_auc: 0.6842 - val_prc: 0.3824\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0491 - tp: 268.0000 - fp: 595.0000 - tn: 1031.0000 - fn: 130.0000 - accuracy: 0.6418 - precision: 0.3105 - recall: 0.6734 - auc: 0.7093 - prc: 0.4017 - val_loss: 0.6569 - val_tp: 59.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 32.0000 - val_accuracy: 0.6087 - val_precision: 0.2622 - val_recall: 0.6484 - val_auc: 0.6844 - val_prc: 0.3884\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0388 - tp: 268.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 130.0000 - accuracy: 0.6443 - precision: 0.3124 - recall: 0.6734 - auc: 0.7197 - prc: 0.4122 - val_loss: 0.5962 - val_tp: 46.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 45.0000 - val_accuracy: 0.6937 - val_precision: 0.2949 - val_recall: 0.5055 - val_auc: 0.6841 - val_prc: 0.3902\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0499 - tp: 255.0000 - fp: 568.0000 - tn: 1058.0000 - fn: 143.0000 - accuracy: 0.6487 - precision: 0.3098 - recall: 0.6407 - auc: 0.7080 - prc: 0.4125 - val_loss: 0.5966 - val_tp: 46.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 45.0000 - val_accuracy: 0.6877 - val_precision: 0.2893 - val_recall: 0.5055 - val_auc: 0.6839 - val_prc: 0.3901\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0409 - tp: 259.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 139.0000 - accuracy: 0.6601 - precision: 0.3205 - recall: 0.6508 - auc: 0.7167 - prc: 0.4172 - val_loss: 0.6294 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6840 - val_prc: 0.3785\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0418 - tp: 268.0000 - fp: 588.0000 - tn: 1038.0000 - fn: 130.0000 - accuracy: 0.6453 - precision: 0.3131 - recall: 0.6734 - auc: 0.7155 - prc: 0.4037 - val_loss: 0.6397 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.6845 - val_prc: 0.3795\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0426 - tp: 260.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 138.0000 - accuracy: 0.6640 - precision: 0.3242 - recall: 0.6533 - auc: 0.7141 - prc: 0.4199 - val_loss: 0.6994 - val_tp: 67.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 24.0000 - val_accuracy: 0.5632 - val_precision: 0.2538 - val_recall: 0.7363 - val_auc: 0.6843 - val_prc: 0.3821\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0413 - tp: 252.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 146.0000 - accuracy: 0.6591 - precision: 0.3166 - recall: 0.6332 - auc: 0.7150 - prc: 0.4089 - val_loss: 0.7563 - val_tp: 68.0000 - val_fp: 239.0000 - val_tn: 176.0000 - val_fn: 23.0000 - val_accuracy: 0.4822 - val_precision: 0.2215 - val_recall: 0.7473 - val_auc: 0.6799 - val_prc: 0.3365\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0418 - tp: 267.0000 - fp: 569.0000 - tn: 1057.0000 - fn: 131.0000 - accuracy: 0.6542 - precision: 0.3194 - recall: 0.6709 - auc: 0.7163 - prc: 0.3994 - val_loss: 0.7328 - val_tp: 68.0000 - val_fp: 220.0000 - val_tn: 195.0000 - val_fn: 23.0000 - val_accuracy: 0.5198 - val_precision: 0.2361 - val_recall: 0.7473 - val_auc: 0.6815 - val_prc: 0.3493\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0408 - tp: 267.0000 - fp: 562.0000 - tn: 1064.0000 - fn: 131.0000 - accuracy: 0.6576 - precision: 0.3221 - recall: 0.6709 - auc: 0.7163 - prc: 0.4088 - val_loss: 0.6838 - val_tp: 65.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 26.0000 - val_accuracy: 0.5791 - val_precision: 0.2579 - val_recall: 0.7143 - val_auc: 0.6842 - val_prc: 0.3816\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0450 - tp: 261.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 137.0000 - accuracy: 0.6576 - precision: 0.3195 - recall: 0.6558 - auc: 0.7116 - prc: 0.4095 - val_loss: 0.7355 - val_tp: 68.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 23.0000 - val_accuracy: 0.4980 - val_precision: 0.2274 - val_recall: 0.7473 - val_auc: 0.6828 - val_prc: 0.3557\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0396 - tp: 266.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 132.0000 - accuracy: 0.6581 - precision: 0.3220 - recall: 0.6683 - auc: 0.7162 - prc: 0.4049 - val_loss: 0.6927 - val_tp: 66.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 25.0000 - val_accuracy: 0.5731 - val_precision: 0.2568 - val_recall: 0.7253 - val_auc: 0.6842 - val_prc: 0.3868\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0434 - tp: 259.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 139.0000 - accuracy: 0.6630 - precision: 0.3229 - recall: 0.6508 - auc: 0.7131 - prc: 0.4188 - val_loss: 0.6645 - val_tp: 63.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 28.0000 - val_accuracy: 0.6047 - val_precision: 0.2681 - val_recall: 0.6923 - val_auc: 0.6845 - val_prc: 0.3886\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0361 - tp: 274.0000 - fp: 601.0000 - tn: 1025.0000 - fn: 124.0000 - accuracy: 0.6418 - precision: 0.3131 - recall: 0.6884 - auc: 0.7205 - prc: 0.4037 - val_loss: 0.5715 - val_tp: 43.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 48.0000 - val_accuracy: 0.7292 - val_precision: 0.3258 - val_recall: 0.4725 - val_auc: 0.6850 - val_prc: 0.4043\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0428 - tp: 268.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 130.0000 - accuracy: 0.6393 - precision: 0.3088 - recall: 0.6734 - auc: 0.7134 - prc: 0.4007 - val_loss: 0.5912 - val_tp: 45.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 46.0000 - val_accuracy: 0.6976 - val_precision: 0.2961 - val_recall: 0.4945 - val_auc: 0.6836 - val_prc: 0.3885\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0429 - tp: 256.0000 - fp: 548.0000 - tn: 1078.0000 - fn: 142.0000 - accuracy: 0.6591 - precision: 0.3184 - recall: 0.6432 - auc: 0.7133 - prc: 0.4089 - val_loss: 0.6797 - val_tp: 64.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 27.0000 - val_accuracy: 0.5830 - val_precision: 0.2581 - val_recall: 0.7033 - val_auc: 0.6845 - val_prc: 0.3796\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0406 - tp: 259.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 139.0000 - accuracy: 0.6571 - precision: 0.3182 - recall: 0.6508 - auc: 0.7160 - prc: 0.4172 - val_loss: 0.7258 - val_tp: 68.0000 - val_fp: 215.0000 - val_tn: 200.0000 - val_fn: 23.0000 - val_accuracy: 0.5296 - val_precision: 0.2403 - val_recall: 0.7473 - val_auc: 0.6828 - val_prc: 0.3597\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0425 - tp: 270.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 128.0000 - accuracy: 0.6433 - precision: 0.3125 - recall: 0.6784 - auc: 0.7136 - prc: 0.4048 - val_loss: 0.5625 - val_tp: 43.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 48.0000 - val_accuracy: 0.7431 - val_precision: 0.3440 - val_recall: 0.4725 - val_auc: 0.6854 - val_prc: 0.4056\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0453 - tp: 259.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 139.0000 - accuracy: 0.6586 - precision: 0.3194 - recall: 0.6508 - auc: 0.7110 - prc: 0.4048 - val_loss: 0.6893 - val_tp: 65.0000 - val_fp: 186.0000 - val_tn: 229.0000 - val_fn: 26.0000 - val_accuracy: 0.5810 - val_precision: 0.2590 - val_recall: 0.7143 - val_auc: 0.6846 - val_prc: 0.3816\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0401 - tp: 272.0000 - fp: 582.0000 - tn: 1044.0000 - fn: 126.0000 - accuracy: 0.6502 - precision: 0.3185 - recall: 0.6834 - auc: 0.7175 - prc: 0.4042 - val_loss: 0.5954 - val_tp: 47.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 44.0000 - val_accuracy: 0.6976 - val_precision: 0.3013 - val_recall: 0.5165 - val_auc: 0.6854 - val_prc: 0.3887\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0404 - tp: 254.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 144.0000 - accuracy: 0.6685 - precision: 0.3252 - recall: 0.6382 - auc: 0.7157 - prc: 0.4227 - val_loss: 0.6359 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6848 - val_prc: 0.3827\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0404 - tp: 249.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 149.0000 - accuracy: 0.6705 - precision: 0.3246 - recall: 0.6256 - auc: 0.7164 - prc: 0.4174 - val_loss: 0.7663 - val_tp: 69.0000 - val_fp: 247.0000 - val_tn: 168.0000 - val_fn: 22.0000 - val_accuracy: 0.4684 - val_precision: 0.2184 - val_recall: 0.7582 - val_auc: 0.6817 - val_prc: 0.3417\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0502 - tp: 272.0000 - fp: 647.0000 - tn: 979.0000 - fn: 126.0000 - accuracy: 0.6181 - precision: 0.2960 - recall: 0.6834 - auc: 0.7067 - prc: 0.3998 - val_loss: 0.6805 - val_tp: 64.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 27.0000 - val_accuracy: 0.5889 - val_precision: 0.2612 - val_recall: 0.7033 - val_auc: 0.6849 - val_prc: 0.3899\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0445 - tp: 271.0000 - fp: 619.0000 - tn: 1007.0000 - fn: 127.0000 - accuracy: 0.6314 - precision: 0.3045 - recall: 0.6809 - auc: 0.7129 - prc: 0.4080 - val_loss: 0.6292 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6844 - val_prc: 0.3918\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0423 - tp: 254.0000 - fp: 537.0000 - tn: 1089.0000 - fn: 144.0000 - accuracy: 0.6635 - precision: 0.3211 - recall: 0.6382 - auc: 0.7142 - prc: 0.4048 - val_loss: 0.7549 - val_tp: 69.0000 - val_fp: 243.0000 - val_tn: 172.0000 - val_fn: 22.0000 - val_accuracy: 0.4763 - val_precision: 0.2212 - val_recall: 0.7582 - val_auc: 0.6838 - val_prc: 0.3590\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0398 - tp: 262.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 136.0000 - accuracy: 0.6458 - precision: 0.3108 - recall: 0.6583 - auc: 0.7153 - prc: 0.4035 - val_loss: 0.6450 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6851 - val_prc: 0.3830\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0396 - tp: 256.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 142.0000 - accuracy: 0.6724 - precision: 0.3295 - recall: 0.6432 - auc: 0.7181 - prc: 0.4249 - val_loss: 0.7366 - val_tp: 68.0000 - val_fp: 228.0000 - val_tn: 187.0000 - val_fn: 23.0000 - val_accuracy: 0.5040 - val_precision: 0.2297 - val_recall: 0.7473 - val_auc: 0.6844 - val_prc: 0.3676\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0423 - tp: 259.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 139.0000 - accuracy: 0.6448 - precision: 0.3087 - recall: 0.6508 - auc: 0.7127 - prc: 0.4129 - val_loss: 0.7446 - val_tp: 68.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 23.0000 - val_accuracy: 0.4980 - val_precision: 0.2274 - val_recall: 0.7473 - val_auc: 0.6842 - val_prc: 0.3588\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0350 - tp: 267.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 131.0000 - accuracy: 0.6507 - precision: 0.3167 - recall: 0.6709 - auc: 0.7206 - prc: 0.4221 - val_loss: 0.6030 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6870 - val_prc: 0.3909\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0389 - tp: 265.0000 - fp: 574.0000 - tn: 1052.0000 - fn: 133.0000 - accuracy: 0.6507 - precision: 0.3159 - recall: 0.6658 - auc: 0.7159 - prc: 0.4198 - val_loss: 0.5552 - val_tp: 42.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 49.0000 - val_accuracy: 0.7490 - val_precision: 0.3500 - val_recall: 0.4615 - val_auc: 0.6856 - val_prc: 0.4081\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0405 - tp: 264.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 134.0000 - accuracy: 0.6665 - precision: 0.3280 - recall: 0.6633 - auc: 0.7169 - prc: 0.4104 - val_loss: 0.6345 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6860 - val_prc: 0.3866\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0436 - tp: 262.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 136.0000 - accuracy: 0.6635 - precision: 0.3247 - recall: 0.6583 - auc: 0.7125 - prc: 0.4108 - val_loss: 0.7266 - val_tp: 68.0000 - val_fp: 218.0000 - val_tn: 197.0000 - val_fn: 23.0000 - val_accuracy: 0.5237 - val_precision: 0.2378 - val_recall: 0.7473 - val_auc: 0.6845 - val_prc: 0.3672\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0472 - tp: 270.0000 - fp: 620.0000 - tn: 1006.0000 - fn: 128.0000 - accuracy: 0.6304 - precision: 0.3034 - recall: 0.6784 - auc: 0.7086 - prc: 0.3987 - val_loss: 0.6453 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6854 - val_prc: 0.3852\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0380 - tp: 261.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 137.0000 - accuracy: 0.6566 - precision: 0.3187 - recall: 0.6558 - auc: 0.7172 - prc: 0.4212 - val_loss: 0.6177 - val_tp: 52.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 39.0000 - val_accuracy: 0.6759 - val_precision: 0.2938 - val_recall: 0.5714 - val_auc: 0.6867 - val_prc: 0.3923\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0368 - tp: 260.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 138.0000 - accuracy: 0.6621 - precision: 0.3226 - recall: 0.6533 - auc: 0.7180 - prc: 0.4200 - val_loss: 0.6959 - val_tp: 65.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 26.0000 - val_accuracy: 0.5692 - val_precision: 0.2529 - val_recall: 0.7143 - val_auc: 0.6855 - val_prc: 0.3880\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0370 - tp: 270.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 128.0000 - accuracy: 0.6581 - precision: 0.3237 - recall: 0.6784 - auc: 0.7177 - prc: 0.4202 - val_loss: 0.6869 - val_tp: 65.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 26.0000 - val_accuracy: 0.5830 - val_precision: 0.2600 - val_recall: 0.7143 - val_auc: 0.6865 - val_prc: 0.3924\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0391 - tp: 262.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 136.0000 - accuracy: 0.6655 - precision: 0.3263 - recall: 0.6583 - auc: 0.7157 - prc: 0.4173 - val_loss: 0.6493 - val_tp: 57.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 34.0000 - val_accuracy: 0.6245 - val_precision: 0.2676 - val_recall: 0.6264 - val_auc: 0.6863 - val_prc: 0.3867\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0400 - tp: 266.0000 - fp: 572.0000 - tn: 1054.0000 - fn: 132.0000 - accuracy: 0.6522 - precision: 0.3174 - recall: 0.6683 - auc: 0.7160 - prc: 0.4129 - val_loss: 0.6370 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6867 - val_prc: 0.3823\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0371 - tp: 257.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 141.0000 - accuracy: 0.6645 - precision: 0.3233 - recall: 0.6457 - auc: 0.7180 - prc: 0.4244 - val_loss: 0.6895 - val_tp: 65.0000 - val_fp: 186.0000 - val_tn: 229.0000 - val_fn: 26.0000 - val_accuracy: 0.5810 - val_precision: 0.2590 - val_recall: 0.7143 - val_auc: 0.6859 - val_prc: 0.3885\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0395 - tp: 260.0000 - fp: 572.0000 - tn: 1054.0000 - fn: 138.0000 - accuracy: 0.6492 - precision: 0.3125 - recall: 0.6533 - auc: 0.7154 - prc: 0.4236 - val_loss: 0.7040 - val_tp: 68.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 23.0000 - val_accuracy: 0.5553 - val_precision: 0.2519 - val_recall: 0.7473 - val_auc: 0.6863 - val_prc: 0.3830\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0417 - tp: 268.0000 - fp: 607.0000 - tn: 1019.0000 - fn: 130.0000 - accuracy: 0.6359 - precision: 0.3063 - recall: 0.6734 - auc: 0.7140 - prc: 0.4041 - val_loss: 0.5672 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6862 - val_prc: 0.4098\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0424 - tp: 262.0000 - fp: 559.0000 - tn: 1067.0000 - fn: 136.0000 - accuracy: 0.6566 - precision: 0.3191 - recall: 0.6583 - auc: 0.7141 - prc: 0.4062 - val_loss: 0.6673 - val_tp: 62.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 29.0000 - val_accuracy: 0.6047 - val_precision: 0.2661 - val_recall: 0.6813 - val_auc: 0.6861 - val_prc: 0.3904\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0343 - tp: 251.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 147.0000 - accuracy: 0.6739 - precision: 0.3285 - recall: 0.6307 - auc: 0.7207 - prc: 0.4274 - val_loss: 0.7581 - val_tp: 69.0000 - val_fp: 239.0000 - val_tn: 176.0000 - val_fn: 22.0000 - val_accuracy: 0.4842 - val_precision: 0.2240 - val_recall: 0.7582 - val_auc: 0.6844 - val_prc: 0.3659\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0408 - tp: 259.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 139.0000 - accuracy: 0.6443 - precision: 0.3083 - recall: 0.6508 - auc: 0.7130 - prc: 0.4202 - val_loss: 0.7110 - val_tp: 68.0000 - val_fp: 208.0000 - val_tn: 207.0000 - val_fn: 23.0000 - val_accuracy: 0.5435 - val_precision: 0.2464 - val_recall: 0.7473 - val_auc: 0.6859 - val_prc: 0.3876\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0432 - tp: 259.0000 - fp: 573.0000 - tn: 1053.0000 - fn: 139.0000 - accuracy: 0.6482 - precision: 0.3113 - recall: 0.6508 - auc: 0.7103 - prc: 0.4209 - val_loss: 0.7196 - val_tp: 68.0000 - val_fp: 220.0000 - val_tn: 195.0000 - val_fn: 23.0000 - val_accuracy: 0.5198 - val_precision: 0.2361 - val_recall: 0.7473 - val_auc: 0.6855 - val_prc: 0.3829\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0433 - tp: 269.0000 - fp: 606.0000 - tn: 1020.0000 - fn: 129.0000 - accuracy: 0.6369 - precision: 0.3074 - recall: 0.6759 - auc: 0.7122 - prc: 0.3958 - val_loss: 0.6745 - val_tp: 62.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 29.0000 - val_accuracy: 0.5909 - val_precision: 0.2583 - val_recall: 0.6813 - val_auc: 0.6868 - val_prc: 0.3916\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0372 - tp: 254.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 144.0000 - accuracy: 0.6546 - precision: 0.3140 - recall: 0.6382 - auc: 0.7158 - prc: 0.4180 - val_loss: 0.6764 - val_tp: 63.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 28.0000 - val_accuracy: 0.5870 - val_precision: 0.2582 - val_recall: 0.6923 - val_auc: 0.6872 - val_prc: 0.3922\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0394 - tp: 263.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 135.0000 - accuracy: 0.6369 - precision: 0.3048 - recall: 0.6608 - auc: 0.7155 - prc: 0.4102 - val_loss: 0.6547 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6876 - val_prc: 0.3873\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0350 - tp: 256.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 142.0000 - accuracy: 0.6739 - precision: 0.3307 - recall: 0.6432 - auc: 0.7186 - prc: 0.4282 - val_loss: 0.7574 - val_tp: 70.0000 - val_fp: 242.0000 - val_tn: 173.0000 - val_fn: 21.0000 - val_accuracy: 0.4802 - val_precision: 0.2244 - val_recall: 0.7692 - val_auc: 0.6849 - val_prc: 0.3675\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0399 - tp: 261.0000 - fp: 562.0000 - tn: 1064.0000 - fn: 137.0000 - accuracy: 0.6546 - precision: 0.3171 - recall: 0.6558 - auc: 0.7141 - prc: 0.4213 - val_loss: 0.6941 - val_tp: 66.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 25.0000 - val_accuracy: 0.5711 - val_precision: 0.2558 - val_recall: 0.7253 - val_auc: 0.6877 - val_prc: 0.3926\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0401 - tp: 262.0000 - fp: 561.0000 - tn: 1065.0000 - fn: 136.0000 - accuracy: 0.6556 - precision: 0.3183 - recall: 0.6583 - auc: 0.7147 - prc: 0.4132 - val_loss: 0.7977 - val_tp: 71.0000 - val_fp: 259.0000 - val_tn: 156.0000 - val_fn: 20.0000 - val_accuracy: 0.4486 - val_precision: 0.2152 - val_recall: 0.7802 - val_auc: 0.6832 - val_prc: 0.3453\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0374 - tp: 260.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 138.0000 - accuracy: 0.6561 - precision: 0.3178 - recall: 0.6533 - auc: 0.7159 - prc: 0.4213 - val_loss: 0.7008 - val_tp: 68.0000 - val_fp: 199.0000 - val_tn: 216.0000 - val_fn: 23.0000 - val_accuracy: 0.5613 - val_precision: 0.2547 - val_recall: 0.7473 - val_auc: 0.6872 - val_prc: 0.3940\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0370 - tp: 264.0000 - fp: 595.0000 - tn: 1031.0000 - fn: 134.0000 - accuracy: 0.6398 - precision: 0.3073 - recall: 0.6633 - auc: 0.7157 - prc: 0.4164 - val_loss: 0.6232 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6874 - val_prc: 0.3997\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0401 - tp: 257.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 141.0000 - accuracy: 0.6561 - precision: 0.3165 - recall: 0.6457 - auc: 0.7137 - prc: 0.4226 - val_loss: 0.6435 - val_tp: 56.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 35.0000 - val_accuracy: 0.6225 - val_precision: 0.2642 - val_recall: 0.6154 - val_auc: 0.6889 - val_prc: 0.3883\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0354 - tp: 256.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 142.0000 - accuracy: 0.6586 - precision: 0.3180 - recall: 0.6432 - auc: 0.7176 - prc: 0.4319 - val_loss: 0.6744 - val_tp: 62.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 29.0000 - val_accuracy: 0.5889 - val_precision: 0.2573 - val_recall: 0.6813 - val_auc: 0.6885 - val_prc: 0.3913\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0357 - tp: 269.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 129.0000 - accuracy: 0.6546 - precision: 0.3206 - recall: 0.6759 - auc: 0.7191 - prc: 0.4097 - val_loss: 0.7042 - val_tp: 68.0000 - val_fp: 201.0000 - val_tn: 214.0000 - val_fn: 23.0000 - val_accuracy: 0.5573 - val_precision: 0.2528 - val_recall: 0.7473 - val_auc: 0.6880 - val_prc: 0.4005\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0357 - tp: 262.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 136.0000 - accuracy: 0.6482 - precision: 0.3126 - recall: 0.6583 - auc: 0.7187 - prc: 0.4216 - val_loss: 0.6166 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6871 - val_prc: 0.4005\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0411 - tp: 259.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 139.0000 - accuracy: 0.6616 - precision: 0.3217 - recall: 0.6508 - auc: 0.7142 - prc: 0.4339 - val_loss: 0.6894 - val_tp: 65.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 26.0000 - val_accuracy: 0.5751 - val_precision: 0.2559 - val_recall: 0.7143 - val_auc: 0.6879 - val_prc: 0.3921\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0374 - tp: 264.0000 - fp: 572.0000 - tn: 1054.0000 - fn: 134.0000 - accuracy: 0.6512 - precision: 0.3158 - recall: 0.6633 - auc: 0.7164 - prc: 0.4230 - val_loss: 0.6260 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6884 - val_prc: 0.3993\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0380 - tp: 260.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 138.0000 - accuracy: 0.6561 - precision: 0.3178 - recall: 0.6533 - auc: 0.7166 - prc: 0.4227 - val_loss: 0.6515 - val_tp: 57.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 34.0000 - val_accuracy: 0.6166 - val_precision: 0.2627 - val_recall: 0.6264 - val_auc: 0.6878 - val_prc: 0.3881\n",
      "Epoch 192/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0403 - tp: 262.0000 - fp: 585.0000 - tn: 1041.0000 - fn: 136.0000 - accuracy: 0.6438 - precision: 0.3093 - recall: 0.6583 - auc: 0.7123 - prc: 0.4167 - val_loss: 0.7481 - val_tp: 70.0000 - val_fp: 234.0000 - val_tn: 181.0000 - val_fn: 21.0000 - val_accuracy: 0.4960 - val_precision: 0.2303 - val_recall: 0.7692 - val_auc: 0.6861 - val_prc: 0.3774\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0368 - tp: 266.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 132.0000 - accuracy: 0.6502 - precision: 0.3159 - recall: 0.6683 - auc: 0.7181 - prc: 0.4160 - val_loss: 0.6913 - val_tp: 66.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 25.0000 - val_accuracy: 0.5672 - val_precision: 0.2538 - val_recall: 0.7253 - val_auc: 0.6878 - val_prc: 0.3910\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0366 - tp: 261.0000 - fp: 603.0000 - tn: 1023.0000 - fn: 137.0000 - accuracy: 0.6344 - precision: 0.3021 - recall: 0.6558 - auc: 0.7174 - prc: 0.4171 - val_loss: 0.6882 - val_tp: 64.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 27.0000 - val_accuracy: 0.5751 - val_precision: 0.2540 - val_recall: 0.7033 - val_auc: 0.6879 - val_prc: 0.3918\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0415 - tp: 257.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 141.0000 - accuracy: 0.6611 - precision: 0.3204 - recall: 0.6457 - auc: 0.7142 - prc: 0.4031 - val_loss: 0.6624 - val_tp: 61.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 30.0000 - val_accuracy: 0.6126 - val_precision: 0.2687 - val_recall: 0.6703 - val_auc: 0.6883 - val_prc: 0.3881\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0387 - tp: 270.0000 - fp: 628.0000 - tn: 998.0000 - fn: 128.0000 - accuracy: 0.6265 - precision: 0.3007 - recall: 0.6784 - auc: 0.7161 - prc: 0.4140 - val_loss: 0.6438 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.6883 - val_prc: 0.3949\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0355 - tp: 262.0000 - fp: 571.0000 - tn: 1055.0000 - fn: 136.0000 - accuracy: 0.6507 - precision: 0.3145 - recall: 0.6583 - auc: 0.7177 - prc: 0.4286 - val_loss: 0.6547 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6888 - val_prc: 0.3895\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0356 - tp: 255.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 143.0000 - accuracy: 0.6734 - precision: 0.3299 - recall: 0.6407 - auc: 0.7180 - prc: 0.4274 - val_loss: 0.7202 - val_tp: 69.0000 - val_fp: 215.0000 - val_tn: 200.0000 - val_fn: 22.0000 - val_accuracy: 0.5316 - val_precision: 0.2430 - val_recall: 0.7582 - val_auc: 0.6877 - val_prc: 0.3884\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0350 - tp: 264.0000 - fp: 584.0000 - tn: 1042.0000 - fn: 134.0000 - accuracy: 0.6453 - precision: 0.3113 - recall: 0.6633 - auc: 0.7165 - prc: 0.4304 - val_loss: 0.6976 - val_tp: 69.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 22.0000 - val_accuracy: 0.5672 - val_precision: 0.2594 - val_recall: 0.7582 - val_auc: 0.6879 - val_prc: 0.3906\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0361 - tp: 259.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 139.0000 - accuracy: 0.6625 - precision: 0.3225 - recall: 0.6508 - auc: 0.7155 - prc: 0.4247 - val_loss: 0.6990 - val_tp: 67.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 24.0000 - val_accuracy: 0.5692 - val_precision: 0.2567 - val_recall: 0.7363 - val_auc: 0.6879 - val_prc: 0.3914\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0359 - tp: 260.0000 - fp: 557.0000 - tn: 1069.0000 - fn: 138.0000 - accuracy: 0.6566 - precision: 0.3182 - recall: 0.6533 - auc: 0.7173 - prc: 0.4232 - val_loss: 0.7175 - val_tp: 70.0000 - val_fp: 219.0000 - val_tn: 196.0000 - val_fn: 21.0000 - val_accuracy: 0.5257 - val_precision: 0.2422 - val_recall: 0.7692 - val_auc: 0.6878 - val_prc: 0.3946\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0354 - tp: 267.0000 - fp: 575.0000 - tn: 1051.0000 - fn: 131.0000 - accuracy: 0.6512 - precision: 0.3171 - recall: 0.6709 - auc: 0.7175 - prc: 0.4198 - val_loss: 0.6240 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.6890 - val_prc: 0.4004\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0349 - tp: 256.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 142.0000 - accuracy: 0.6655 - precision: 0.3236 - recall: 0.6432 - auc: 0.7166 - prc: 0.4324 - val_loss: 0.6484 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6888 - val_prc: 0.3952\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0293 - tp: 258.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 140.0000 - accuracy: 0.6611 - precision: 0.3209 - recall: 0.6482 - auc: 0.7231 - prc: 0.4315 - val_loss: 0.7514 - val_tp: 71.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 20.0000 - val_accuracy: 0.4842 - val_precision: 0.2276 - val_recall: 0.7802 - val_auc: 0.6871 - val_prc: 0.3759\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0380 - tp: 264.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 134.0000 - accuracy: 0.6374 - precision: 0.3056 - recall: 0.6633 - auc: 0.7154 - prc: 0.4209 - val_loss: 0.6573 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6883 - val_prc: 0.3924\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0398 - tp: 263.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 135.0000 - accuracy: 0.6517 - precision: 0.3157 - recall: 0.6608 - auc: 0.7143 - prc: 0.4206 - val_loss: 0.5956 - val_tp: 48.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 43.0000 - val_accuracy: 0.7036 - val_precision: 0.3097 - val_recall: 0.5275 - val_auc: 0.6885 - val_prc: 0.4103\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0346 - tp: 259.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 139.0000 - accuracy: 0.6601 - precision: 0.3205 - recall: 0.6508 - auc: 0.7187 - prc: 0.4296 - val_loss: 0.6288 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6892 - val_prc: 0.4015\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0363 - tp: 252.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 146.0000 - accuracy: 0.6640 - precision: 0.3206 - recall: 0.6332 - auc: 0.7176 - prc: 0.4217 - val_loss: 0.7431 - val_tp: 70.0000 - val_fp: 224.0000 - val_tn: 191.0000 - val_fn: 21.0000 - val_accuracy: 0.5158 - val_precision: 0.2381 - val_recall: 0.7692 - val_auc: 0.6868 - val_prc: 0.3755\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0350 - tp: 263.0000 - fp: 565.0000 - tn: 1061.0000 - fn: 135.0000 - accuracy: 0.6542 - precision: 0.3176 - recall: 0.6608 - auc: 0.7196 - prc: 0.4205 - val_loss: 0.6086 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6881 - val_prc: 0.4080\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0472 - tp: 260.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 138.0000 - accuracy: 0.6502 - precision: 0.3133 - recall: 0.6533 - auc: 0.7081 - prc: 0.3888 - val_loss: 0.6739 - val_tp: 61.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 30.0000 - val_accuracy: 0.5909 - val_precision: 0.2563 - val_recall: 0.6703 - val_auc: 0.6887 - val_prc: 0.3938\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0329 - tp: 257.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 141.0000 - accuracy: 0.6665 - precision: 0.3249 - recall: 0.6457 - auc: 0.7197 - prc: 0.4297 - val_loss: 0.7515 - val_tp: 71.0000 - val_fp: 234.0000 - val_tn: 181.0000 - val_fn: 20.0000 - val_accuracy: 0.4980 - val_precision: 0.2328 - val_recall: 0.7802 - val_auc: 0.6866 - val_prc: 0.3760\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0356 - tp: 259.0000 - fp: 596.0000 - tn: 1030.0000 - fn: 139.0000 - accuracy: 0.6369 - precision: 0.3029 - recall: 0.6508 - auc: 0.7162 - prc: 0.4207 - val_loss: 0.6498 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6885 - val_prc: 0.4023\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0375 - tp: 270.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 128.0000 - accuracy: 0.6522 - precision: 0.3191 - recall: 0.6784 - auc: 0.7155 - prc: 0.4231 - val_loss: 0.7091 - val_tp: 69.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 22.0000 - val_accuracy: 0.5613 - val_precision: 0.2565 - val_recall: 0.7582 - val_auc: 0.6882 - val_prc: 0.3930\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0427 - tp: 255.0000 - fp: 592.0000 - tn: 1034.0000 - fn: 143.0000 - accuracy: 0.6369 - precision: 0.3011 - recall: 0.6407 - auc: 0.7094 - prc: 0.4135 - val_loss: 0.6028 - val_tp: 51.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 40.0000 - val_accuracy: 0.6976 - val_precision: 0.3110 - val_recall: 0.5604 - val_auc: 0.6883 - val_prc: 0.4092\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0353 - tp: 267.0000 - fp: 575.0000 - tn: 1051.0000 - fn: 131.0000 - accuracy: 0.6512 - precision: 0.3171 - recall: 0.6709 - auc: 0.7189 - prc: 0.4224 - val_loss: 0.5683 - val_tp: 43.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 48.0000 - val_accuracy: 0.7372 - val_precision: 0.3359 - val_recall: 0.4725 - val_auc: 0.6880 - val_prc: 0.4117\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0387 - tp: 256.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 142.0000 - accuracy: 0.6616 - precision: 0.3204 - recall: 0.6432 - auc: 0.7131 - prc: 0.4296 - val_loss: 0.6436 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6892 - val_prc: 0.4012\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0323 - tp: 264.0000 - fp: 571.0000 - tn: 1055.0000 - fn: 134.0000 - accuracy: 0.6517 - precision: 0.3162 - recall: 0.6633 - auc: 0.7199 - prc: 0.4277 - val_loss: 0.6804 - val_tp: 62.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 29.0000 - val_accuracy: 0.5810 - val_precision: 0.2531 - val_recall: 0.6813 - val_auc: 0.6894 - val_prc: 0.3942\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0356 - tp: 264.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 134.0000 - accuracy: 0.6680 - precision: 0.3292 - recall: 0.6633 - auc: 0.7168 - prc: 0.4302 - val_loss: 0.6836 - val_tp: 65.0000 - val_fp: 186.0000 - val_tn: 229.0000 - val_fn: 26.0000 - val_accuracy: 0.5810 - val_precision: 0.2590 - val_recall: 0.7143 - val_auc: 0.6888 - val_prc: 0.3936\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0353 - tp: 265.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 133.0000 - accuracy: 0.6556 - precision: 0.3197 - recall: 0.6658 - auc: 0.7169 - prc: 0.4272 - val_loss: 0.6763 - val_tp: 61.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 30.0000 - val_accuracy: 0.5929 - val_precision: 0.2574 - val_recall: 0.6703 - val_auc: 0.6885 - val_prc: 0.3929\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0327 - tp: 266.0000 - fp: 566.0000 - tn: 1060.0000 - fn: 132.0000 - accuracy: 0.6551 - precision: 0.3197 - recall: 0.6683 - auc: 0.7201 - prc: 0.4271 - val_loss: 0.6789 - val_tp: 62.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 29.0000 - val_accuracy: 0.5870 - val_precision: 0.2562 - val_recall: 0.6813 - val_auc: 0.6891 - val_prc: 0.3941\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0364 - tp: 253.0000 - fp: 562.0000 - tn: 1064.0000 - fn: 145.0000 - accuracy: 0.6507 - precision: 0.3104 - recall: 0.6357 - auc: 0.7167 - prc: 0.4308 - val_loss: 0.6605 - val_tp: 61.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 30.0000 - val_accuracy: 0.6126 - val_precision: 0.2687 - val_recall: 0.6703 - val_auc: 0.6896 - val_prc: 0.4040\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0373 - tp: 264.0000 - fp: 563.0000 - tn: 1063.0000 - fn: 134.0000 - accuracy: 0.6556 - precision: 0.3192 - recall: 0.6633 - auc: 0.7151 - prc: 0.4230 - val_loss: 0.7032 - val_tp: 69.0000 - val_fp: 198.0000 - val_tn: 217.0000 - val_fn: 22.0000 - val_accuracy: 0.5652 - val_precision: 0.2584 - val_recall: 0.7582 - val_auc: 0.6891 - val_prc: 0.3904\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0334 - tp: 252.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 146.0000 - accuracy: 0.6640 - precision: 0.3206 - recall: 0.6332 - auc: 0.7174 - prc: 0.4369 - val_loss: 0.6987 - val_tp: 69.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 22.0000 - val_accuracy: 0.5692 - val_precision: 0.2604 - val_recall: 0.7582 - val_auc: 0.6896 - val_prc: 0.3966\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0379 - tp: 260.0000 - fp: 559.0000 - tn: 1067.0000 - fn: 138.0000 - accuracy: 0.6556 - precision: 0.3175 - recall: 0.6533 - auc: 0.7145 - prc: 0.4304 - val_loss: 0.6715 - val_tp: 62.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 29.0000 - val_accuracy: 0.6008 - val_precision: 0.2638 - val_recall: 0.6813 - val_auc: 0.6893 - val_prc: 0.3960\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0341 - tp: 256.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 142.0000 - accuracy: 0.6650 - precision: 0.3232 - recall: 0.6432 - auc: 0.7170 - prc: 0.4320 - val_loss: 0.7515 - val_tp: 71.0000 - val_fp: 239.0000 - val_tn: 176.0000 - val_fn: 20.0000 - val_accuracy: 0.4881 - val_precision: 0.2290 - val_recall: 0.7802 - val_auc: 0.6875 - val_prc: 0.3890\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0360 - tp: 262.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 136.0000 - accuracy: 0.6512 - precision: 0.3149 - recall: 0.6583 - auc: 0.7161 - prc: 0.4257 - val_loss: 0.6355 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6897 - val_prc: 0.4012\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0370 - tp: 268.0000 - fp: 587.0000 - tn: 1039.0000 - fn: 130.0000 - accuracy: 0.6458 - precision: 0.3135 - recall: 0.6734 - auc: 0.7172 - prc: 0.4154 - val_loss: 0.5938 - val_tp: 47.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 44.0000 - val_accuracy: 0.7016 - val_precision: 0.3052 - val_recall: 0.5165 - val_auc: 0.6886 - val_prc: 0.4103\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0407 - tp: 241.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 157.0000 - accuracy: 0.6601 - precision: 0.3122 - recall: 0.6055 - auc: 0.7106 - prc: 0.4247 - val_loss: 0.7061 - val_tp: 69.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 22.0000 - val_accuracy: 0.5613 - val_precision: 0.2565 - val_recall: 0.7582 - val_auc: 0.6896 - val_prc: 0.3900\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0345 - tp: 268.0000 - fp: 567.0000 - tn: 1059.0000 - fn: 130.0000 - accuracy: 0.6556 - precision: 0.3210 - recall: 0.6734 - auc: 0.7177 - prc: 0.4286 - val_loss: 0.7081 - val_tp: 69.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 22.0000 - val_accuracy: 0.5613 - val_precision: 0.2565 - val_recall: 0.7582 - val_auc: 0.6893 - val_prc: 0.3918\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0370 - tp: 255.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 143.0000 - accuracy: 0.6690 - precision: 0.3261 - recall: 0.6407 - auc: 0.7148 - prc: 0.4313 - val_loss: 0.7010 - val_tp: 68.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 23.0000 - val_accuracy: 0.5731 - val_precision: 0.2605 - val_recall: 0.7473 - val_auc: 0.6889 - val_prc: 0.3899\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0358 - tp: 270.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 128.0000 - accuracy: 0.6433 - precision: 0.3125 - recall: 0.6784 - auc: 0.7168 - prc: 0.4262 - val_loss: 0.5445 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6874 - val_prc: 0.4115\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0401 - tp: 254.0000 - fp: 524.0000 - tn: 1102.0000 - fn: 144.0000 - accuracy: 0.6700 - precision: 0.3265 - recall: 0.6382 - auc: 0.7124 - prc: 0.4094 - val_loss: 0.7465 - val_tp: 71.0000 - val_fp: 226.0000 - val_tn: 189.0000 - val_fn: 20.0000 - val_accuracy: 0.5138 - val_precision: 0.2391 - val_recall: 0.7802 - val_auc: 0.6882 - val_prc: 0.3891\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0407 - tp: 258.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 140.0000 - accuracy: 0.6586 - precision: 0.3189 - recall: 0.6482 - auc: 0.7141 - prc: 0.4232 - val_loss: 0.6193 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6889 - val_prc: 0.4011\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0387 - tp: 249.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 149.0000 - accuracy: 0.6616 - precision: 0.3172 - recall: 0.6256 - auc: 0.7152 - prc: 0.4231 - val_loss: 0.6764 - val_tp: 62.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 29.0000 - val_accuracy: 0.5988 - val_precision: 0.2627 - val_recall: 0.6813 - val_auc: 0.6891 - val_prc: 0.3998\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0326 - tp: 261.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 137.0000 - accuracy: 0.6621 - precision: 0.3230 - recall: 0.6558 - auc: 0.7186 - prc: 0.4270 - val_loss: 0.6617 - val_tp: 61.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 30.0000 - val_accuracy: 0.5929 - val_precision: 0.2574 - val_recall: 0.6703 - val_auc: 0.6865 - val_prc: 0.4038\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0285 - tp: 263.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 135.0000 - accuracy: 0.6714 - precision: 0.3317 - recall: 0.6608 - auc: 0.7250 - prc: 0.4249 - val_loss: 0.8672 - val_tp: 74.0000 - val_fp: 282.0000 - val_tn: 133.0000 - val_fn: 17.0000 - val_accuracy: 0.4091 - val_precision: 0.2079 - val_recall: 0.8132 - val_auc: 0.6798 - val_prc: 0.3328\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0345 - tp: 268.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 130.0000 - accuracy: 0.6487 - precision: 0.3157 - recall: 0.6734 - auc: 0.7178 - prc: 0.4158 - val_loss: 0.5961 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6892 - val_prc: 0.4093\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0350 - tp: 249.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 149.0000 - accuracy: 0.6690 - precision: 0.3234 - recall: 0.6256 - auc: 0.7172 - prc: 0.4286 - val_loss: 0.7008 - val_tp: 68.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 23.0000 - val_accuracy: 0.5731 - val_precision: 0.2605 - val_recall: 0.7473 - val_auc: 0.6893 - val_prc: 0.3949\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0385 - tp: 253.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 145.0000 - accuracy: 0.6467 - precision: 0.3074 - recall: 0.6357 - auc: 0.7132 - prc: 0.4283 - val_loss: 0.7220 - val_tp: 71.0000 - val_fp: 223.0000 - val_tn: 192.0000 - val_fn: 20.0000 - val_accuracy: 0.5198 - val_precision: 0.2415 - val_recall: 0.7802 - val_auc: 0.6886 - val_prc: 0.3907\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0421 - tp: 265.0000 - fp: 598.0000 - tn: 1028.0000 - fn: 133.0000 - accuracy: 0.6388 - precision: 0.3071 - recall: 0.6658 - auc: 0.7116 - prc: 0.4235 - val_loss: 0.5779 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6879 - val_prc: 0.4104\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0386 - tp: 253.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 145.0000 - accuracy: 0.6789 - precision: 0.3338 - recall: 0.6357 - auc: 0.7171 - prc: 0.4168 - val_loss: 0.7104 - val_tp: 70.0000 - val_fp: 198.0000 - val_tn: 217.0000 - val_fn: 21.0000 - val_accuracy: 0.5672 - val_precision: 0.2612 - val_recall: 0.7692 - val_auc: 0.6887 - val_prc: 0.3896\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0320 - tp: 267.0000 - fp: 557.0000 - tn: 1069.0000 - fn: 131.0000 - accuracy: 0.6601 - precision: 0.3240 - recall: 0.6709 - auc: 0.7205 - prc: 0.4289 - val_loss: 0.6437 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6897 - val_prc: 0.4034\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0326 - tp: 262.0000 - fp: 550.0000 - tn: 1076.0000 - fn: 136.0000 - accuracy: 0.6611 - precision: 0.3227 - recall: 0.6583 - auc: 0.7199 - prc: 0.4275 - val_loss: 0.6838 - val_tp: 63.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 28.0000 - val_accuracy: 0.5870 - val_precision: 0.2582 - val_recall: 0.6923 - val_auc: 0.6901 - val_prc: 0.4002\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0357 - tp: 267.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 131.0000 - accuracy: 0.6537 - precision: 0.3190 - recall: 0.6709 - auc: 0.7160 - prc: 0.4288 - val_loss: 0.6843 - val_tp: 63.0000 - val_fp: 182.0000 - val_tn: 233.0000 - val_fn: 28.0000 - val_accuracy: 0.5850 - val_precision: 0.2571 - val_recall: 0.6923 - val_auc: 0.6898 - val_prc: 0.3939\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0321 - tp: 259.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 139.0000 - accuracy: 0.6571 - precision: 0.3182 - recall: 0.6508 - auc: 0.7192 - prc: 0.4282 - val_loss: 0.5885 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6894 - val_prc: 0.4104\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0379 - tp: 262.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 136.0000 - accuracy: 0.6650 - precision: 0.3259 - recall: 0.6583 - auc: 0.7152 - prc: 0.4138 - val_loss: 0.6455 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6896 - val_prc: 0.4031\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0333 - tp: 254.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 144.0000 - accuracy: 0.6665 - precision: 0.3236 - recall: 0.6382 - auc: 0.7187 - prc: 0.4287 - val_loss: 0.6401 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6906 - val_prc: 0.4027\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0323 - tp: 264.0000 - fp: 571.0000 - tn: 1055.0000 - fn: 134.0000 - accuracy: 0.6517 - precision: 0.3162 - recall: 0.6633 - auc: 0.7183 - prc: 0.4397 - val_loss: 0.6573 - val_tp: 61.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 30.0000 - val_accuracy: 0.6225 - val_precision: 0.2748 - val_recall: 0.6703 - val_auc: 0.6899 - val_prc: 0.4022\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0313 - tp: 255.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 143.0000 - accuracy: 0.6685 - precision: 0.3257 - recall: 0.6407 - auc: 0.7209 - prc: 0.4257 - val_loss: 0.6667 - val_tp: 62.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 29.0000 - val_accuracy: 0.6126 - val_precision: 0.2707 - val_recall: 0.6813 - val_auc: 0.6900 - val_prc: 0.4043\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0349 - tp: 271.0000 - fp: 588.0000 - tn: 1038.0000 - fn: 127.0000 - accuracy: 0.6467 - precision: 0.3155 - recall: 0.6809 - auc: 0.7169 - prc: 0.4176 - val_loss: 0.6498 - val_tp: 58.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 33.0000 - val_accuracy: 0.6285 - val_precision: 0.2723 - val_recall: 0.6374 - val_auc: 0.6897 - val_prc: 0.4016\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0329 - tp: 257.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 141.0000 - accuracy: 0.6695 - precision: 0.3274 - recall: 0.6457 - auc: 0.7175 - prc: 0.4351 - val_loss: 0.6523 - val_tp: 60.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 31.0000 - val_accuracy: 0.6265 - val_precision: 0.2752 - val_recall: 0.6593 - val_auc: 0.6884 - val_prc: 0.4013\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0328 - tp: 258.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 140.0000 - accuracy: 0.6630 - precision: 0.3225 - recall: 0.6482 - auc: 0.7186 - prc: 0.4271 - val_loss: 0.6469 - val_tp: 56.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 35.0000 - val_accuracy: 0.6304 - val_precision: 0.2692 - val_recall: 0.6154 - val_auc: 0.6897 - val_prc: 0.4033\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0332 - tp: 260.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 138.0000 - accuracy: 0.6561 - precision: 0.3178 - recall: 0.6533 - auc: 0.7192 - prc: 0.4328 - val_loss: 0.6332 - val_tp: 56.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 35.0000 - val_accuracy: 0.6561 - val_precision: 0.2872 - val_recall: 0.6154 - val_auc: 0.6901 - val_prc: 0.4015\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0370 - tp: 256.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 142.0000 - accuracy: 0.6660 - precision: 0.3241 - recall: 0.6432 - auc: 0.7154 - prc: 0.4261 - val_loss: 0.6477 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6902 - val_prc: 0.4027\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0346 - tp: 266.0000 - fp: 584.0000 - tn: 1042.0000 - fn: 132.0000 - accuracy: 0.6462 - precision: 0.3129 - recall: 0.6683 - auc: 0.7173 - prc: 0.4266 - val_loss: 0.6832 - val_tp: 64.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 27.0000 - val_accuracy: 0.5889 - val_precision: 0.2612 - val_recall: 0.7033 - val_auc: 0.6898 - val_prc: 0.3975\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0323 - tp: 260.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 138.0000 - accuracy: 0.6655 - precision: 0.3254 - recall: 0.6533 - auc: 0.7215 - prc: 0.4257 - val_loss: 0.7324 - val_tp: 71.0000 - val_fp: 225.0000 - val_tn: 190.0000 - val_fn: 20.0000 - val_accuracy: 0.5158 - val_precision: 0.2399 - val_recall: 0.7802 - val_auc: 0.6891 - val_prc: 0.3925\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0317 - tp: 263.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 135.0000 - accuracy: 0.6546 - precision: 0.3180 - recall: 0.6608 - auc: 0.7199 - prc: 0.4307 - val_loss: 0.6745 - val_tp: 62.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 29.0000 - val_accuracy: 0.5988 - val_precision: 0.2627 - val_recall: 0.6813 - val_auc: 0.6903 - val_prc: 0.4036\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0356 - tp: 271.0000 - fp: 607.0000 - tn: 1019.0000 - fn: 127.0000 - accuracy: 0.6374 - precision: 0.3087 - recall: 0.6809 - auc: 0.7163 - prc: 0.4176 - val_loss: 0.6465 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6904 - val_prc: 0.4022\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0332 - tp: 255.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 143.0000 - accuracy: 0.6606 - precision: 0.3191 - recall: 0.6407 - auc: 0.7184 - prc: 0.4349 - val_loss: 0.6314 - val_tp: 58.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 33.0000 - val_accuracy: 0.6719 - val_precision: 0.3037 - val_recall: 0.6374 - val_auc: 0.6902 - val_prc: 0.4112\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0309 - tp: 265.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 133.0000 - accuracy: 0.6769 - precision: 0.3372 - recall: 0.6658 - auc: 0.7221 - prc: 0.4178 - val_loss: 0.6535 - val_tp: 59.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 32.0000 - val_accuracy: 0.6225 - val_precision: 0.2706 - val_recall: 0.6484 - val_auc: 0.6907 - val_prc: 0.4034\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0326 - tp: 269.0000 - fp: 565.0000 - tn: 1061.0000 - fn: 129.0000 - accuracy: 0.6571 - precision: 0.3225 - recall: 0.6759 - auc: 0.7188 - prc: 0.4302 - val_loss: 0.6775 - val_tp: 63.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 28.0000 - val_accuracy: 0.5988 - val_precision: 0.2647 - val_recall: 0.6923 - val_auc: 0.6899 - val_prc: 0.4058\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0364 - tp: 251.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 147.0000 - accuracy: 0.6546 - precision: 0.3126 - recall: 0.6307 - auc: 0.7154 - prc: 0.4270 - val_loss: 0.6764 - val_tp: 62.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 29.0000 - val_accuracy: 0.5889 - val_precision: 0.2573 - val_recall: 0.6813 - val_auc: 0.6899 - val_prc: 0.4042\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0316 - tp: 260.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 138.0000 - accuracy: 0.6625 - precision: 0.3230 - recall: 0.6533 - auc: 0.7204 - prc: 0.4327 - val_loss: 0.6431 - val_tp: 58.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 33.0000 - val_accuracy: 0.6403 - val_precision: 0.2802 - val_recall: 0.6374 - val_auc: 0.6902 - val_prc: 0.4026\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0372 - tp: 273.0000 - fp: 572.0000 - tn: 1054.0000 - fn: 125.0000 - accuracy: 0.6556 - precision: 0.3231 - recall: 0.6859 - auc: 0.7151 - prc: 0.4187 - val_loss: 0.5899 - val_tp: 47.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 44.0000 - val_accuracy: 0.7075 - val_precision: 0.3113 - val_recall: 0.5165 - val_auc: 0.6901 - val_prc: 0.4109\n",
      "Epoch 265/500\n",
      "101/102 [============================>.] - ETA: 0s - loss: 1.0320 - tp: 260.0000 - fp: 527.0000 - tn: 1095.0000 - fn: 138.0000 - accuracy: 0.6708 - precision: 0.3304 - recall: 0.6533 - auc: 0.7213 - prc: 0.4236Restoring model weights from the end of the best epoch: 215.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0309 - tp: 260.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 138.0000 - accuracy: 0.6709 - precision: 0.3299 - recall: 0.6533 - auc: 0.7215 - prc: 0.4235 - val_loss: 0.6373 - val_tp: 58.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 33.0000 - val_accuracy: 0.6522 - val_precision: 0.2886 - val_recall: 0.6374 - val_auc: 0.6906 - val_prc: 0.4020\n",
      "Epoch 265: early stopping\n",
      "26/26 [==============================] - 0s 568us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.9126 - tp: 58.0000 - fp: 143.0000 - tn: 1898.0000 - fn: 431.0000 - accuracy: 0.7731 - precision: 0.2886 - recall: 0.1186 - auc: 0.5132 - prc: 0.2322 - val_loss: 0.4738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5489 - prc: 0.2235 - val_loss: 0.4768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8642 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4999 - prc: 0.1970 - val_loss: 0.4811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8434 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5299 - prc: 0.2143 - val_loss: 0.4861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8246 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5136 - prc: 0.2072 - val_loss: 0.4921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8077 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4835 - prc: 0.1895 - val_loss: 0.4988 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7924 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5071 - prc: 0.2000 - val_loss: 0.5062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7784 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4964 - prc: 0.1916 - val_loss: 0.5143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7662 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4975 - prc: 0.1967 - val_loss: 0.5228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7556 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4851 - prc: 0.1900 - val_loss: 0.5316 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7459 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4830 - prc: 0.1900 - val_loss: 0.5405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7374 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4969 - prc: 0.1934 - val_loss: 0.5500 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7302 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - prc: 0.1888 - val_loss: 0.5591 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5222 - prc: 0.2057 - val_loss: 0.5683 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7185 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4932 - prc: 0.1948 - val_loss: 0.5775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4994 - val_prc: 0.1796\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7140 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5054 - prc: 0.2017 - val_loss: 0.5868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7100 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5120 - prc: 0.2019 - val_loss: 0.5960 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5144 - prc: 0.2032 - val_loss: 0.6043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7041 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5108 - prc: 0.2032 - val_loss: 0.6122 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7016 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4942 - prc: 0.1925 - val_loss: 0.6205 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6998 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4981 - prc: 0.1958 - val_loss: 0.6283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6983 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - prc: 0.1921 - val_loss: 0.6345 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4869 - prc: 0.1921 - val_loss: 0.6413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6962 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4946 - prc: 0.1948 - val_loss: 0.6465 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6954 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5128 - prc: 0.2017 - val_loss: 0.6511 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6949 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4956 - prc: 0.1945 - val_loss: 0.6565 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4967 - prc: 0.1951 - val_loss: 0.6604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.6643 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6935 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.6682 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6932 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - prc: 0.1922 - val_loss: 0.6714 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6931 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4859 - prc: 0.1919 - val_loss: 0.6732 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6933 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4840 - prc: 0.1878 - val_loss: 0.6771 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - prc: 0.1922 - val_loss: 0.6793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5025 - prc: 0.1974 - val_loss: 0.6801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5027 - prc: 0.1975 - val_loss: 0.6814 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5168 - prc: 0.2023 - val_loss: 0.6857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5006 - val_prc: 0.1800\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6923 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5046 - prc: 0.1981 - val_loss: 0.6857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5054 - val_prc: 0.1814\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6915 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - prc: 0.1898 - val_loss: 0.6824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5151 - val_prc: 0.1845\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6834 - tp: 106.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 292.0000 - accuracy: 0.6719 - precision: 0.2218 - recall: 0.2663 - auc: 0.5788 - prc: 0.2297 - val_loss: 0.6741 - val_tp: 84.0000 - val_fp: 342.0000 - val_tn: 73.0000 - val_fn: 7.0000 - val_accuracy: 0.3103 - val_precision: 0.1972 - val_recall: 0.9231 - val_auc: 0.5555 - val_prc: 0.1985\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6761 - tp: 256.0000 - fp: 672.0000 - tn: 954.0000 - fn: 142.0000 - accuracy: 0.5978 - precision: 0.2759 - recall: 0.6432 - auc: 0.6320 - prc: 0.2699 - val_loss: 0.5594 - val_tp: 32.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 59.0000 - val_accuracy: 0.7628 - val_precision: 0.3441 - val_recall: 0.3516 - val_auc: 0.6513 - val_prc: 0.2952\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6696 - tp: 259.0000 - fp: 667.0000 - tn: 959.0000 - fn: 139.0000 - accuracy: 0.6018 - precision: 0.2797 - recall: 0.6508 - auc: 0.6457 - prc: 0.2766 - val_loss: 0.5303 - val_tp: 20.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 71.0000 - val_accuracy: 0.8024 - val_precision: 0.4082 - val_recall: 0.2198 - val_auc: 0.6579 - val_prc: 0.3179\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6675 - tp: 221.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 177.0000 - accuracy: 0.6650 - precision: 0.3061 - recall: 0.5553 - auc: 0.6682 - prc: 0.3336 - val_loss: 0.5668 - val_tp: 36.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 55.0000 - val_accuracy: 0.7767 - val_precision: 0.3830 - val_recall: 0.3956 - val_auc: 0.6582 - val_prc: 0.3106\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6633 - tp: 227.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 171.0000 - accuracy: 0.6680 - precision: 0.3118 - recall: 0.5704 - auc: 0.6558 - prc: 0.2786 - val_loss: 0.5354 - val_tp: 21.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 70.0000 - val_accuracy: 0.8024 - val_precision: 0.4118 - val_recall: 0.2308 - val_auc: 0.6623 - val_prc: 0.3382\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6585 - tp: 206.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 192.0000 - accuracy: 0.7391 - precision: 0.3801 - recall: 0.5176 - auc: 0.6877 - prc: 0.3500 - val_loss: 0.6027 - val_tp: 53.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 38.0000 - val_accuracy: 0.7075 - val_precision: 0.3252 - val_recall: 0.5824 - val_auc: 0.6582 - val_prc: 0.3012\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6603 - tp: 260.0000 - fp: 616.0000 - tn: 1010.0000 - fn: 138.0000 - accuracy: 0.6275 - precision: 0.2968 - recall: 0.6533 - auc: 0.6712 - prc: 0.3227 - val_loss: 0.5883 - val_tp: 47.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 44.0000 - val_accuracy: 0.7372 - val_precision: 0.3456 - val_recall: 0.5165 - val_auc: 0.6615 - val_prc: 0.3112\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6537 - tp: 213.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 185.0000 - accuracy: 0.7115 - precision: 0.3480 - recall: 0.5352 - auc: 0.6874 - prc: 0.3268 - val_loss: 0.6191 - val_tp: 56.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 35.0000 - val_accuracy: 0.6601 - val_precision: 0.2902 - val_recall: 0.6154 - val_auc: 0.6545 - val_prc: 0.2880\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6523 - tp: 229.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 169.0000 - accuracy: 0.7189 - precision: 0.3641 - recall: 0.5754 - auc: 0.6904 - prc: 0.3448 - val_loss: 0.6277 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6542 - val_prc: 0.2869\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6491 - tp: 226.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 172.0000 - accuracy: 0.7090 - precision: 0.3515 - recall: 0.5678 - auc: 0.6928 - prc: 0.3374 - val_loss: 0.5975 - val_tp: 53.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 38.0000 - val_accuracy: 0.7134 - val_precision: 0.3313 - val_recall: 0.5824 - val_auc: 0.6633 - val_prc: 0.3119\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6493 - tp: 238.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 160.0000 - accuracy: 0.6937 - precision: 0.3410 - recall: 0.5980 - auc: 0.6912 - prc: 0.3511 - val_loss: 0.6446 - val_tp: 60.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 31.0000 - val_accuracy: 0.5968 - val_precision: 0.2575 - val_recall: 0.6593 - val_auc: 0.6579 - val_prc: 0.2920\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6463 - tp: 236.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 162.0000 - accuracy: 0.6942 - precision: 0.3405 - recall: 0.5930 - auc: 0.6952 - prc: 0.3426 - val_loss: 0.5883 - val_tp: 51.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 40.0000 - val_accuracy: 0.7194 - val_precision: 0.3333 - val_recall: 0.5604 - val_auc: 0.6667 - val_prc: 0.3211\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6460 - tp: 239.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 159.0000 - accuracy: 0.6952 - precision: 0.3429 - recall: 0.6005 - auc: 0.6913 - prc: 0.3282 - val_loss: 0.6715 - val_tp: 64.0000 - val_fp: 214.0000 - val_tn: 201.0000 - val_fn: 27.0000 - val_accuracy: 0.5237 - val_precision: 0.2302 - val_recall: 0.7033 - val_auc: 0.6557 - val_prc: 0.2879\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6437 - tp: 232.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 166.0000 - accuracy: 0.7115 - precision: 0.3569 - recall: 0.5829 - auc: 0.6982 - prc: 0.3619 - val_loss: 0.6234 - val_tp: 56.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 35.0000 - val_accuracy: 0.6581 - val_precision: 0.2887 - val_recall: 0.6154 - val_auc: 0.6650 - val_prc: 0.3094\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6492 - tp: 241.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 157.0000 - accuracy: 0.6502 - precision: 0.3043 - recall: 0.6055 - auc: 0.6780 - prc: 0.3198 - val_loss: 0.5728 - val_tp: 42.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 49.0000 - val_accuracy: 0.7510 - val_precision: 0.3529 - val_recall: 0.4615 - val_auc: 0.6716 - val_prc: 0.3408\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6435 - tp: 246.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 152.0000 - accuracy: 0.6808 - precision: 0.3324 - recall: 0.6181 - auc: 0.6931 - prc: 0.3416 - val_loss: 0.5557 - val_tp: 39.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 52.0000 - val_accuracy: 0.7688 - val_precision: 0.3750 - val_recall: 0.4286 - val_auc: 0.6729 - val_prc: 0.3525\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6406 - tp: 231.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 167.0000 - accuracy: 0.6917 - precision: 0.3358 - recall: 0.5804 - auc: 0.6988 - prc: 0.3565 - val_loss: 0.5983 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6705 - val_prc: 0.3265\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6455 - tp: 236.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 162.0000 - accuracy: 0.6591 - precision: 0.3089 - recall: 0.5930 - auc: 0.6852 - prc: 0.3365 - val_loss: 0.6161 - val_tp: 55.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 36.0000 - val_accuracy: 0.6858 - val_precision: 0.3090 - val_recall: 0.6044 - val_auc: 0.6706 - val_prc: 0.3272\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6396 - tp: 231.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 167.0000 - accuracy: 0.7105 - precision: 0.3554 - recall: 0.5804 - auc: 0.7038 - prc: 0.3974 - val_loss: 0.6660 - val_tp: 64.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 27.0000 - val_accuracy: 0.5652 - val_precision: 0.2490 - val_recall: 0.7033 - val_auc: 0.6650 - val_prc: 0.3070\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6374 - tp: 234.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 164.0000 - accuracy: 0.6957 - precision: 0.3411 - recall: 0.5879 - auc: 0.7055 - prc: 0.3813 - val_loss: 0.6302 - val_tp: 57.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 34.0000 - val_accuracy: 0.6423 - val_precision: 0.2794 - val_recall: 0.6264 - val_auc: 0.6697 - val_prc: 0.3200\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6388 - tp: 246.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 152.0000 - accuracy: 0.6714 - precision: 0.3241 - recall: 0.6181 - auc: 0.6998 - prc: 0.3721 - val_loss: 0.5989 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6716 - val_prc: 0.3290\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6378 - tp: 230.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 168.0000 - accuracy: 0.6937 - precision: 0.3372 - recall: 0.5779 - auc: 0.6987 - prc: 0.3724 - val_loss: 0.6610 - val_tp: 64.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 27.0000 - val_accuracy: 0.5850 - val_precision: 0.2591 - val_recall: 0.7033 - val_auc: 0.6672 - val_prc: 0.3109\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6372 - tp: 250.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 148.0000 - accuracy: 0.6966 - precision: 0.3492 - recall: 0.6281 - auc: 0.7018 - prc: 0.3666 - val_loss: 0.7022 - val_tp: 67.0000 - val_fp: 230.0000 - val_tn: 185.0000 - val_fn: 24.0000 - val_accuracy: 0.4980 - val_precision: 0.2256 - val_recall: 0.7363 - val_auc: 0.6550 - val_prc: 0.2812\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6363 - tp: 254.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 144.0000 - accuracy: 0.6690 - precision: 0.3256 - recall: 0.6382 - auc: 0.6988 - prc: 0.3531 - val_loss: 0.6019 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6741 - val_prc: 0.3450\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6345 - tp: 243.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 155.0000 - accuracy: 0.6789 - precision: 0.3293 - recall: 0.6106 - auc: 0.7034 - prc: 0.3669 - val_loss: 0.6346 - val_tp: 58.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 33.0000 - val_accuracy: 0.6423 - val_precision: 0.2816 - val_recall: 0.6374 - val_auc: 0.6730 - val_prc: 0.3306\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6321 - tp: 249.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 149.0000 - accuracy: 0.6818 - precision: 0.3347 - recall: 0.6256 - auc: 0.7075 - prc: 0.3815 - val_loss: 0.5787 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6751 - val_prc: 0.3468\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6320 - tp: 249.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 149.0000 - accuracy: 0.6759 - precision: 0.3294 - recall: 0.6256 - auc: 0.7058 - prc: 0.3696 - val_loss: 0.5650 - val_tp: 41.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 50.0000 - val_accuracy: 0.7372 - val_precision: 0.3306 - val_recall: 0.4505 - val_auc: 0.6768 - val_prc: 0.3568\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6334 - tp: 248.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 150.0000 - accuracy: 0.6744 - precision: 0.3276 - recall: 0.6231 - auc: 0.7033 - prc: 0.3665 - val_loss: 0.6715 - val_tp: 64.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 27.0000 - val_accuracy: 0.5672 - val_precision: 0.2500 - val_recall: 0.7033 - val_auc: 0.6689 - val_prc: 0.3153\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6321 - tp: 246.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 152.0000 - accuracy: 0.6779 - precision: 0.3298 - recall: 0.6181 - auc: 0.7040 - prc: 0.3681 - val_loss: 0.6512 - val_tp: 63.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 28.0000 - val_accuracy: 0.6126 - val_precision: 0.2727 - val_recall: 0.6923 - val_auc: 0.6728 - val_prc: 0.3258\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6287 - tp: 244.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 154.0000 - accuracy: 0.6818 - precision: 0.3324 - recall: 0.6131 - auc: 0.7075 - prc: 0.3673 - val_loss: 0.5758 - val_tp: 43.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 48.0000 - val_accuracy: 0.7292 - val_precision: 0.3258 - val_recall: 0.4725 - val_auc: 0.6766 - val_prc: 0.3580\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6299 - tp: 231.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 167.0000 - accuracy: 0.7110 - precision: 0.3559 - recall: 0.5804 - auc: 0.7090 - prc: 0.3848 - val_loss: 0.6581 - val_tp: 63.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 28.0000 - val_accuracy: 0.5929 - val_precision: 0.2614 - val_recall: 0.6923 - val_auc: 0.6742 - val_prc: 0.3270\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6321 - tp: 259.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 139.0000 - accuracy: 0.6546 - precision: 0.3162 - recall: 0.6508 - auc: 0.7027 - prc: 0.3559 - val_loss: 0.6603 - val_tp: 63.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 28.0000 - val_accuracy: 0.5889 - val_precision: 0.2593 - val_recall: 0.6923 - val_auc: 0.6732 - val_prc: 0.3267\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6316 - tp: 242.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 156.0000 - accuracy: 0.6848 - precision: 0.3343 - recall: 0.6080 - auc: 0.7044 - prc: 0.3910 - val_loss: 0.6626 - val_tp: 64.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 27.0000 - val_accuracy: 0.5929 - val_precision: 0.2634 - val_recall: 0.7033 - val_auc: 0.6740 - val_prc: 0.3239\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6301 - tp: 246.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 152.0000 - accuracy: 0.6828 - precision: 0.3342 - recall: 0.6181 - auc: 0.7055 - prc: 0.3821 - val_loss: 0.5797 - val_tp: 44.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 47.0000 - val_accuracy: 0.7174 - val_precision: 0.3143 - val_recall: 0.4835 - val_auc: 0.6785 - val_prc: 0.3623\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6285 - tp: 239.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 159.0000 - accuracy: 0.6996 - precision: 0.3474 - recall: 0.6005 - auc: 0.7095 - prc: 0.4047 - val_loss: 0.6283 - val_tp: 57.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 34.0000 - val_accuracy: 0.6581 - val_precision: 0.2908 - val_recall: 0.6264 - val_auc: 0.6777 - val_prc: 0.3455\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6263 - tp: 246.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 152.0000 - accuracy: 0.6828 - precision: 0.3342 - recall: 0.6181 - auc: 0.7115 - prc: 0.3874 - val_loss: 0.6018 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6793 - val_prc: 0.3558\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6277 - tp: 241.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 157.0000 - accuracy: 0.6957 - precision: 0.3443 - recall: 0.6055 - auc: 0.7097 - prc: 0.3908 - val_loss: 0.6851 - val_tp: 66.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 25.0000 - val_accuracy: 0.5553 - val_precision: 0.2481 - val_recall: 0.7253 - val_auc: 0.6756 - val_prc: 0.3275\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6295 - tp: 250.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 148.0000 - accuracy: 0.6695 - precision: 0.3243 - recall: 0.6281 - auc: 0.7048 - prc: 0.3717 - val_loss: 0.7035 - val_tp: 67.0000 - val_fp: 216.0000 - val_tn: 199.0000 - val_fn: 24.0000 - val_accuracy: 0.5257 - val_precision: 0.2367 - val_recall: 0.7363 - val_auc: 0.6715 - val_prc: 0.3129\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6253 - tp: 247.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 151.0000 - accuracy: 0.6818 - precision: 0.3338 - recall: 0.6206 - auc: 0.7110 - prc: 0.3819 - val_loss: 0.6321 - val_tp: 58.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 33.0000 - val_accuracy: 0.6542 - val_precision: 0.2900 - val_recall: 0.6374 - val_auc: 0.6788 - val_prc: 0.3408\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6257 - tp: 244.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 154.0000 - accuracy: 0.6976 - precision: 0.3476 - recall: 0.6131 - auc: 0.7113 - prc: 0.3862 - val_loss: 0.6749 - val_tp: 65.0000 - val_fp: 190.0000 - val_tn: 225.0000 - val_fn: 26.0000 - val_accuracy: 0.5731 - val_precision: 0.2549 - val_recall: 0.7143 - val_auc: 0.6767 - val_prc: 0.3328\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6253 - tp: 249.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 149.0000 - accuracy: 0.6843 - precision: 0.3369 - recall: 0.6256 - auc: 0.7113 - prc: 0.3950 - val_loss: 0.6097 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6798 - val_prc: 0.3558\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6278 - tp: 240.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 158.0000 - accuracy: 0.6887 - precision: 0.3371 - recall: 0.6030 - auc: 0.7070 - prc: 0.3791 - val_loss: 0.6639 - val_tp: 64.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 27.0000 - val_accuracy: 0.5889 - val_precision: 0.2612 - val_recall: 0.7033 - val_auc: 0.6780 - val_prc: 0.3344\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6257 - tp: 250.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 148.0000 - accuracy: 0.6754 - precision: 0.3294 - recall: 0.6281 - auc: 0.7088 - prc: 0.3757 - val_loss: 0.5990 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6808 - val_prc: 0.3613\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6246 - tp: 254.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 144.0000 - accuracy: 0.6779 - precision: 0.3333 - recall: 0.6382 - auc: 0.7111 - prc: 0.3826 - val_loss: 0.5825 - val_tp: 45.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 46.0000 - val_accuracy: 0.7115 - val_precision: 0.3103 - val_recall: 0.4945 - val_auc: 0.6807 - val_prc: 0.3726\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6268 - tp: 241.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 157.0000 - accuracy: 0.6739 - precision: 0.3239 - recall: 0.6055 - auc: 0.7076 - prc: 0.3761 - val_loss: 0.6272 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6802 - val_prc: 0.3496\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6233 - tp: 243.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 155.0000 - accuracy: 0.6932 - precision: 0.3427 - recall: 0.6106 - auc: 0.7125 - prc: 0.3856 - val_loss: 0.6152 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6800 - val_prc: 0.3553\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6267 - tp: 243.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 155.0000 - accuracy: 0.6734 - precision: 0.3244 - recall: 0.6106 - auc: 0.7059 - prc: 0.3539 - val_loss: 0.6663 - val_tp: 64.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 27.0000 - val_accuracy: 0.5929 - val_precision: 0.2634 - val_recall: 0.7033 - val_auc: 0.6781 - val_prc: 0.3322\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6242 - tp: 242.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 156.0000 - accuracy: 0.6749 - precision: 0.3253 - recall: 0.6080 - auc: 0.7101 - prc: 0.3918 - val_loss: 0.5996 - val_tp: 48.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 43.0000 - val_accuracy: 0.7036 - val_precision: 0.3097 - val_recall: 0.5275 - val_auc: 0.6819 - val_prc: 0.3699\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6216 - tp: 247.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 151.0000 - accuracy: 0.6868 - precision: 0.3384 - recall: 0.6206 - auc: 0.7158 - prc: 0.3886 - val_loss: 0.6076 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6810 - val_prc: 0.3600\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6263 - tp: 243.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 155.0000 - accuracy: 0.6808 - precision: 0.3311 - recall: 0.6106 - auc: 0.7072 - prc: 0.3883 - val_loss: 0.6488 - val_tp: 61.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 30.0000 - val_accuracy: 0.6245 - val_precision: 0.2760 - val_recall: 0.6703 - val_auc: 0.6802 - val_prc: 0.3442\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6233 - tp: 253.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 145.0000 - accuracy: 0.6774 - precision: 0.3325 - recall: 0.6357 - auc: 0.7129 - prc: 0.3873 - val_loss: 0.6270 - val_tp: 57.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 34.0000 - val_accuracy: 0.6522 - val_precision: 0.2864 - val_recall: 0.6264 - val_auc: 0.6808 - val_prc: 0.3491\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6245 - tp: 234.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 164.0000 - accuracy: 0.6843 - precision: 0.3300 - recall: 0.5879 - auc: 0.7095 - prc: 0.3729 - val_loss: 0.6454 - val_tp: 60.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 31.0000 - val_accuracy: 0.6285 - val_precision: 0.2765 - val_recall: 0.6593 - val_auc: 0.6807 - val_prc: 0.3443\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6213 - tp: 244.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 154.0000 - accuracy: 0.6813 - precision: 0.3320 - recall: 0.6131 - auc: 0.7149 - prc: 0.4066 - val_loss: 0.5906 - val_tp: 46.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 45.0000 - val_accuracy: 0.7075 - val_precision: 0.3087 - val_recall: 0.5055 - val_auc: 0.6823 - val_prc: 0.3756\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6204 - tp: 252.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 146.0000 - accuracy: 0.6947 - precision: 0.3481 - recall: 0.6332 - auc: 0.7170 - prc: 0.4010 - val_loss: 0.6527 - val_tp: 61.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 30.0000 - val_accuracy: 0.6186 - val_precision: 0.2723 - val_recall: 0.6703 - val_auc: 0.6809 - val_prc: 0.3423\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6218 - tp: 244.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 154.0000 - accuracy: 0.6843 - precision: 0.3347 - recall: 0.6131 - auc: 0.7148 - prc: 0.3943 - val_loss: 0.5868 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6827 - val_prc: 0.3783\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6255 - tp: 234.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 164.0000 - accuracy: 0.6705 - precision: 0.3175 - recall: 0.5879 - auc: 0.7046 - prc: 0.3763 - val_loss: 0.5713 - val_tp: 43.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 48.0000 - val_accuracy: 0.7312 - val_precision: 0.3282 - val_recall: 0.4725 - val_auc: 0.6804 - val_prc: 0.3739\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6215 - tp: 239.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 159.0000 - accuracy: 0.7006 - precision: 0.3484 - recall: 0.6005 - auc: 0.7150 - prc: 0.3986 - val_loss: 0.6916 - val_tp: 67.0000 - val_fp: 205.0000 - val_tn: 210.0000 - val_fn: 24.0000 - val_accuracy: 0.5474 - val_precision: 0.2463 - val_recall: 0.7363 - val_auc: 0.6807 - val_prc: 0.3367\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6225 - tp: 244.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 154.0000 - accuracy: 0.6808 - precision: 0.3315 - recall: 0.6131 - auc: 0.7114 - prc: 0.3969 - val_loss: 0.6566 - val_tp: 62.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 29.0000 - val_accuracy: 0.6146 - val_precision: 0.2719 - val_recall: 0.6813 - val_auc: 0.6813 - val_prc: 0.3420\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6210 - tp: 251.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 147.0000 - accuracy: 0.6877 - precision: 0.3410 - recall: 0.6307 - auc: 0.7157 - prc: 0.3848 - val_loss: 0.6608 - val_tp: 62.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 29.0000 - val_accuracy: 0.6067 - val_precision: 0.2672 - val_recall: 0.6813 - val_auc: 0.6802 - val_prc: 0.3369\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6237 - tp: 247.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 151.0000 - accuracy: 0.6882 - precision: 0.3398 - recall: 0.6206 - auc: 0.7080 - prc: 0.3776 - val_loss: 0.6187 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6831 - val_prc: 0.3679\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6202 - tp: 244.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 154.0000 - accuracy: 0.6764 - precision: 0.3275 - recall: 0.6131 - auc: 0.7145 - prc: 0.4000 - val_loss: 0.6311 - val_tp: 58.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 33.0000 - val_accuracy: 0.6522 - val_precision: 0.2886 - val_recall: 0.6374 - val_auc: 0.6838 - val_prc: 0.3644\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6247 - tp: 243.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 155.0000 - accuracy: 0.6798 - precision: 0.3302 - recall: 0.6106 - auc: 0.7073 - prc: 0.3816 - val_loss: 0.6327 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.6832 - val_prc: 0.3635\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6208 - tp: 243.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 155.0000 - accuracy: 0.6759 - precision: 0.3266 - recall: 0.6106 - auc: 0.7142 - prc: 0.4014 - val_loss: 0.6635 - val_tp: 62.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 29.0000 - val_accuracy: 0.6028 - val_precision: 0.2650 - val_recall: 0.6813 - val_auc: 0.6819 - val_prc: 0.3445\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6255 - tp: 243.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 155.0000 - accuracy: 0.6779 - precision: 0.3284 - recall: 0.6106 - auc: 0.7046 - prc: 0.3785 - val_loss: 0.6032 - val_tp: 48.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 43.0000 - val_accuracy: 0.6937 - val_precision: 0.3000 - val_recall: 0.5275 - val_auc: 0.6836 - val_prc: 0.3772\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6203 - tp: 256.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 142.0000 - accuracy: 0.6877 - precision: 0.3432 - recall: 0.6432 - auc: 0.7136 - prc: 0.3987 - val_loss: 0.5913 - val_tp: 45.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 46.0000 - val_accuracy: 0.7036 - val_precision: 0.3020 - val_recall: 0.4945 - val_auc: 0.6834 - val_prc: 0.3802\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6213 - tp: 242.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 156.0000 - accuracy: 0.6793 - precision: 0.3293 - recall: 0.6080 - auc: 0.7122 - prc: 0.4021 - val_loss: 0.6293 - val_tp: 58.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 33.0000 - val_accuracy: 0.6522 - val_precision: 0.2886 - val_recall: 0.6374 - val_auc: 0.6838 - val_prc: 0.3641\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6211 - tp: 247.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 151.0000 - accuracy: 0.6907 - precision: 0.3421 - recall: 0.6206 - auc: 0.7149 - prc: 0.3969 - val_loss: 0.5906 - val_tp: 45.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 46.0000 - val_accuracy: 0.7036 - val_precision: 0.3020 - val_recall: 0.4945 - val_auc: 0.6837 - val_prc: 0.3796\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6192 - tp: 255.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 143.0000 - accuracy: 0.6808 - precision: 0.3364 - recall: 0.6407 - auc: 0.7166 - prc: 0.3945 - val_loss: 0.5848 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6846 - val_prc: 0.3865\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6199 - tp: 235.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 163.0000 - accuracy: 0.6966 - precision: 0.3426 - recall: 0.5905 - auc: 0.7147 - prc: 0.4092 - val_loss: 0.6363 - val_tp: 58.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 33.0000 - val_accuracy: 0.6443 - val_precision: 0.2829 - val_recall: 0.6374 - val_auc: 0.6837 - val_prc: 0.3707\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6223 - tp: 253.0000 - fp: 524.0000 - tn: 1102.0000 - fn: 145.0000 - accuracy: 0.6695 - precision: 0.3256 - recall: 0.6357 - auc: 0.7103 - prc: 0.3919 - val_loss: 0.6046 - val_tp: 48.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 43.0000 - val_accuracy: 0.6838 - val_precision: 0.2909 - val_recall: 0.5275 - val_auc: 0.6828 - val_prc: 0.3824\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6194 - tp: 248.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 150.0000 - accuracy: 0.6803 - precision: 0.3329 - recall: 0.6231 - auc: 0.7146 - prc: 0.3917 - val_loss: 0.6455 - val_tp: 58.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 33.0000 - val_accuracy: 0.6364 - val_precision: 0.2775 - val_recall: 0.6374 - val_auc: 0.6845 - val_prc: 0.3643\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6210 - tp: 248.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 150.0000 - accuracy: 0.6882 - precision: 0.3402 - recall: 0.6231 - auc: 0.7119 - prc: 0.3991 - val_loss: 0.5887 - val_tp: 45.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 46.0000 - val_accuracy: 0.7016 - val_precision: 0.3000 - val_recall: 0.4945 - val_auc: 0.6844 - val_prc: 0.3774\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6213 - tp: 244.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 154.0000 - accuracy: 0.6858 - precision: 0.3361 - recall: 0.6131 - auc: 0.7136 - prc: 0.4021 - val_loss: 0.6065 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6846 - val_prc: 0.3794\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6208 - tp: 236.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 162.0000 - accuracy: 0.6932 - precision: 0.3396 - recall: 0.5930 - auc: 0.7130 - prc: 0.4004 - val_loss: 0.6916 - val_tp: 66.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 25.0000 - val_accuracy: 0.5692 - val_precision: 0.2548 - val_recall: 0.7253 - val_auc: 0.6813 - val_prc: 0.3428\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6206 - tp: 254.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 144.0000 - accuracy: 0.6695 - precision: 0.3261 - recall: 0.6382 - auc: 0.7141 - prc: 0.4037 - val_loss: 0.5756 - val_tp: 45.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 46.0000 - val_accuracy: 0.7174 - val_precision: 0.3169 - val_recall: 0.4945 - val_auc: 0.6852 - val_prc: 0.3887\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6221 - tp: 249.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 149.0000 - accuracy: 0.6838 - precision: 0.3365 - recall: 0.6256 - auc: 0.7111 - prc: 0.3939 - val_loss: 0.5594 - val_tp: 43.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 48.0000 - val_accuracy: 0.7431 - val_precision: 0.3440 - val_recall: 0.4725 - val_auc: 0.6844 - val_prc: 0.3877\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6234 - tp: 246.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 152.0000 - accuracy: 0.6714 - precision: 0.3241 - recall: 0.6181 - auc: 0.7080 - prc: 0.3866 - val_loss: 0.5930 - val_tp: 46.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 45.0000 - val_accuracy: 0.7016 - val_precision: 0.3026 - val_recall: 0.5055 - val_auc: 0.6852 - val_prc: 0.3865\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6215 - tp: 240.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 158.0000 - accuracy: 0.6813 - precision: 0.3301 - recall: 0.6030 - auc: 0.7119 - prc: 0.3905 - val_loss: 0.6917 - val_tp: 66.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 25.0000 - val_accuracy: 0.5731 - val_precision: 0.2568 - val_recall: 0.7253 - val_auc: 0.6810 - val_prc: 0.3400\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6184 - tp: 240.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 158.0000 - accuracy: 0.6957 - precision: 0.3438 - recall: 0.6030 - auc: 0.7158 - prc: 0.4055 - val_loss: 0.6752 - val_tp: 64.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 27.0000 - val_accuracy: 0.5988 - val_precision: 0.2667 - val_recall: 0.7033 - val_auc: 0.6829 - val_prc: 0.3499\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6173 - tp: 240.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 158.0000 - accuracy: 0.6947 - precision: 0.3429 - recall: 0.6030 - auc: 0.7171 - prc: 0.4116 - val_loss: 0.7489 - val_tp: 68.0000 - val_fp: 236.0000 - val_tn: 179.0000 - val_fn: 23.0000 - val_accuracy: 0.4881 - val_precision: 0.2237 - val_recall: 0.7473 - val_auc: 0.6799 - val_prc: 0.3360\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6200 - tp: 255.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 143.0000 - accuracy: 0.6729 - precision: 0.3295 - recall: 0.6407 - auc: 0.7142 - prc: 0.3967 - val_loss: 0.6191 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6856 - val_prc: 0.3801\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6225 - tp: 245.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 153.0000 - accuracy: 0.6793 - precision: 0.3306 - recall: 0.6156 - auc: 0.7089 - prc: 0.4043 - val_loss: 0.5856 - val_tp: 45.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 46.0000 - val_accuracy: 0.7055 - val_precision: 0.3041 - val_recall: 0.4945 - val_auc: 0.6858 - val_prc: 0.3781\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6172 - tp: 246.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 152.0000 - accuracy: 0.6838 - precision: 0.3351 - recall: 0.6181 - auc: 0.7171 - prc: 0.4106 - val_loss: 0.6089 - val_tp: 50.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 41.0000 - val_accuracy: 0.6818 - val_precision: 0.2941 - val_recall: 0.5495 - val_auc: 0.6848 - val_prc: 0.3886\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6202 - tp: 239.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 159.0000 - accuracy: 0.6838 - precision: 0.3319 - recall: 0.6005 - auc: 0.7113 - prc: 0.4206 - val_loss: 0.6564 - val_tp: 59.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 32.0000 - val_accuracy: 0.6126 - val_precision: 0.2646 - val_recall: 0.6484 - val_auc: 0.6858 - val_prc: 0.3821\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6199 - tp: 247.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 151.0000 - accuracy: 0.6868 - precision: 0.3384 - recall: 0.6206 - auc: 0.7151 - prc: 0.4014 - val_loss: 0.6371 - val_tp: 58.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 33.0000 - val_accuracy: 0.6443 - val_precision: 0.2829 - val_recall: 0.6374 - val_auc: 0.6853 - val_prc: 0.3791\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6172 - tp: 243.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 155.0000 - accuracy: 0.6917 - precision: 0.3413 - recall: 0.6106 - auc: 0.7161 - prc: 0.4063 - val_loss: 0.6469 - val_tp: 59.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 32.0000 - val_accuracy: 0.6383 - val_precision: 0.2810 - val_recall: 0.6484 - val_auc: 0.6858 - val_prc: 0.3846\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6186 - tp: 245.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 153.0000 - accuracy: 0.6823 - precision: 0.3333 - recall: 0.6156 - auc: 0.7140 - prc: 0.4078 - val_loss: 0.5816 - val_tp: 45.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 46.0000 - val_accuracy: 0.7095 - val_precision: 0.3082 - val_recall: 0.4945 - val_auc: 0.6850 - val_prc: 0.3890\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6179 - tp: 241.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 157.0000 - accuracy: 0.6873 - precision: 0.3361 - recall: 0.6055 - auc: 0.7154 - prc: 0.3988 - val_loss: 0.6657 - val_tp: 62.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 29.0000 - val_accuracy: 0.6047 - val_precision: 0.2661 - val_recall: 0.6813 - val_auc: 0.6845 - val_prc: 0.3684\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6202 - tp: 234.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 164.0000 - accuracy: 0.6714 - precision: 0.3184 - recall: 0.5879 - auc: 0.7096 - prc: 0.4083 - val_loss: 0.7333 - val_tp: 68.0000 - val_fp: 227.0000 - val_tn: 188.0000 - val_fn: 23.0000 - val_accuracy: 0.5059 - val_precision: 0.2305 - val_recall: 0.7473 - val_auc: 0.6807 - val_prc: 0.3336\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6198 - tp: 245.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 153.0000 - accuracy: 0.6818 - precision: 0.3329 - recall: 0.6156 - auc: 0.7124 - prc: 0.3972 - val_loss: 0.6493 - val_tp: 59.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 32.0000 - val_accuracy: 0.6344 - val_precision: 0.2783 - val_recall: 0.6484 - val_auc: 0.6851 - val_prc: 0.3792\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6229 - tp: 243.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 155.0000 - accuracy: 0.6739 - precision: 0.3249 - recall: 0.6106 - auc: 0.7079 - prc: 0.3992 - val_loss: 0.6520 - val_tp: 59.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 32.0000 - val_accuracy: 0.6225 - val_precision: 0.2706 - val_recall: 0.6484 - val_auc: 0.6849 - val_prc: 0.3818\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6245 - tp: 235.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 163.0000 - accuracy: 0.6897 - precision: 0.3357 - recall: 0.5905 - auc: 0.7069 - prc: 0.3941 - val_loss: 0.6445 - val_tp: 59.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 32.0000 - val_accuracy: 0.6423 - val_precision: 0.2837 - val_recall: 0.6484 - val_auc: 0.6853 - val_prc: 0.3819\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6219 - tp: 257.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 141.0000 - accuracy: 0.6621 - precision: 0.3212 - recall: 0.6457 - auc: 0.7120 - prc: 0.3871 - val_loss: 0.6432 - val_tp: 58.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 33.0000 - val_accuracy: 0.6403 - val_precision: 0.2802 - val_recall: 0.6374 - val_auc: 0.6865 - val_prc: 0.3824\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6177 - tp: 241.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 157.0000 - accuracy: 0.6823 - precision: 0.3315 - recall: 0.6055 - auc: 0.7150 - prc: 0.4122 - val_loss: 0.7139 - val_tp: 68.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 23.0000 - val_accuracy: 0.5474 - val_precision: 0.2482 - val_recall: 0.7473 - val_auc: 0.6804 - val_prc: 0.3369\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6182 - tp: 252.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 146.0000 - accuracy: 0.6759 - precision: 0.3307 - recall: 0.6332 - auc: 0.7164 - prc: 0.4014 - val_loss: 0.6755 - val_tp: 64.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 27.0000 - val_accuracy: 0.5949 - val_precision: 0.2645 - val_recall: 0.7033 - val_auc: 0.6834 - val_prc: 0.3560\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6158 - tp: 252.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 146.0000 - accuracy: 0.6828 - precision: 0.3369 - recall: 0.6332 - auc: 0.7192 - prc: 0.4124 - val_loss: 0.7377 - val_tp: 68.0000 - val_fp: 223.0000 - val_tn: 192.0000 - val_fn: 23.0000 - val_accuracy: 0.5138 - val_precision: 0.2337 - val_recall: 0.7473 - val_auc: 0.6793 - val_prc: 0.3294\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6178 - tp: 243.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 155.0000 - accuracy: 0.6981 - precision: 0.3476 - recall: 0.6106 - auc: 0.7147 - prc: 0.4172 - val_loss: 0.6281 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6856 - val_prc: 0.3830\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6204 - tp: 239.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 159.0000 - accuracy: 0.6833 - precision: 0.3315 - recall: 0.6005 - auc: 0.7102 - prc: 0.4075 - val_loss: 0.6699 - val_tp: 64.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 27.0000 - val_accuracy: 0.6087 - val_precision: 0.2723 - val_recall: 0.7033 - val_auc: 0.6852 - val_prc: 0.3715\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6192 - tp: 251.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 147.0000 - accuracy: 0.6749 - precision: 0.3294 - recall: 0.6307 - auc: 0.7114 - prc: 0.3964 - val_loss: 0.6205 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6860 - val_prc: 0.3879\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6184 - tp: 247.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 151.0000 - accuracy: 0.6892 - precision: 0.3407 - recall: 0.6206 - auc: 0.7178 - prc: 0.3984 - val_loss: 0.7326 - val_tp: 68.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 23.0000 - val_accuracy: 0.5356 - val_precision: 0.2429 - val_recall: 0.7473 - val_auc: 0.6803 - val_prc: 0.3370\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6161 - tp: 254.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 144.0000 - accuracy: 0.6882 - precision: 0.3428 - recall: 0.6382 - auc: 0.7177 - prc: 0.4087 - val_loss: 0.5836 - val_tp: 45.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 46.0000 - val_accuracy: 0.7075 - val_precision: 0.3061 - val_recall: 0.4945 - val_auc: 0.6870 - val_prc: 0.3909\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6231 - tp: 238.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 160.0000 - accuracy: 0.6823 - precision: 0.3301 - recall: 0.5980 - auc: 0.7098 - prc: 0.3916 - val_loss: 0.6586 - val_tp: 61.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 30.0000 - val_accuracy: 0.6107 - val_precision: 0.2675 - val_recall: 0.6703 - val_auc: 0.6859 - val_prc: 0.3825\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6170 - tp: 237.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 161.0000 - accuracy: 0.6882 - precision: 0.3352 - recall: 0.5955 - auc: 0.7153 - prc: 0.4099 - val_loss: 0.6914 - val_tp: 66.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 25.0000 - val_accuracy: 0.5771 - val_precision: 0.2588 - val_recall: 0.7253 - val_auc: 0.6839 - val_prc: 0.3536\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6160 - tp: 243.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 155.0000 - accuracy: 0.6863 - precision: 0.3361 - recall: 0.6106 - auc: 0.7191 - prc: 0.4143 - val_loss: 0.7091 - val_tp: 68.0000 - val_fp: 204.0000 - val_tn: 211.0000 - val_fn: 23.0000 - val_accuracy: 0.5514 - val_precision: 0.2500 - val_recall: 0.7473 - val_auc: 0.6835 - val_prc: 0.3489\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6190 - tp: 247.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 151.0000 - accuracy: 0.6818 - precision: 0.3338 - recall: 0.6206 - auc: 0.7113 - prc: 0.4189 - val_loss: 0.6841 - val_tp: 65.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 26.0000 - val_accuracy: 0.5870 - val_precision: 0.2621 - val_recall: 0.7143 - val_auc: 0.6844 - val_prc: 0.3603\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6166 - tp: 242.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 156.0000 - accuracy: 0.6892 - precision: 0.3385 - recall: 0.6080 - auc: 0.7154 - prc: 0.4104 - val_loss: 0.6452 - val_tp: 57.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 34.0000 - val_accuracy: 0.6364 - val_precision: 0.2754 - val_recall: 0.6264 - val_auc: 0.6869 - val_prc: 0.3855\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6157 - tp: 239.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 159.0000 - accuracy: 0.6932 - precision: 0.3409 - recall: 0.6005 - auc: 0.7192 - prc: 0.4210 - val_loss: 0.5437 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6853 - val_prc: 0.4043\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6199 - tp: 246.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 152.0000 - accuracy: 0.6749 - precision: 0.3271 - recall: 0.6181 - auc: 0.7133 - prc: 0.4016 - val_loss: 0.5692 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6858 - val_prc: 0.3887\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6215 - tp: 236.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 162.0000 - accuracy: 0.6798 - precision: 0.3269 - recall: 0.5930 - auc: 0.7092 - prc: 0.4070 - val_loss: 0.5306 - val_tp: 39.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 52.0000 - val_accuracy: 0.7787 - val_precision: 0.3939 - val_recall: 0.4286 - val_auc: 0.6857 - val_prc: 0.4051\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6171 - tp: 243.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 155.0000 - accuracy: 0.6882 - precision: 0.3380 - recall: 0.6106 - auc: 0.7177 - prc: 0.4052 - val_loss: 0.7174 - val_tp: 68.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 23.0000 - val_accuracy: 0.5395 - val_precision: 0.2446 - val_recall: 0.7473 - val_auc: 0.6828 - val_prc: 0.3486\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6145 - tp: 257.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 141.0000 - accuracy: 0.6877 - precision: 0.3436 - recall: 0.6457 - auc: 0.7210 - prc: 0.4331 - val_loss: 0.5937 - val_tp: 46.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 45.0000 - val_accuracy: 0.7036 - val_precision: 0.3046 - val_recall: 0.5055 - val_auc: 0.6862 - val_prc: 0.3914\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6197 - tp: 234.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 164.0000 - accuracy: 0.6873 - precision: 0.3329 - recall: 0.5879 - auc: 0.7118 - prc: 0.4092 - val_loss: 0.6421 - val_tp: 56.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 35.0000 - val_accuracy: 0.6423 - val_precision: 0.2772 - val_recall: 0.6154 - val_auc: 0.6869 - val_prc: 0.3892\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6168 - tp: 245.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 153.0000 - accuracy: 0.6833 - precision: 0.3342 - recall: 0.6156 - auc: 0.7164 - prc: 0.4194 - val_loss: 0.5966 - val_tp: 47.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 44.0000 - val_accuracy: 0.7036 - val_precision: 0.3072 - val_recall: 0.5165 - val_auc: 0.6868 - val_prc: 0.3923\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6182 - tp: 245.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 153.0000 - accuracy: 0.6823 - precision: 0.3333 - recall: 0.6156 - auc: 0.7129 - prc: 0.4210 - val_loss: 0.7016 - val_tp: 67.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 24.0000 - val_accuracy: 0.5632 - val_precision: 0.2538 - val_recall: 0.7363 - val_auc: 0.6848 - val_prc: 0.3706\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6170 - tp: 247.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 151.0000 - accuracy: 0.6833 - precision: 0.3351 - recall: 0.6206 - auc: 0.7171 - prc: 0.4080 - val_loss: 0.6673 - val_tp: 62.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 29.0000 - val_accuracy: 0.6028 - val_precision: 0.2650 - val_recall: 0.6813 - val_auc: 0.6862 - val_prc: 0.3827\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6169 - tp: 242.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 156.0000 - accuracy: 0.6749 - precision: 0.3253 - recall: 0.6080 - auc: 0.7162 - prc: 0.4135 - val_loss: 0.5852 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6873 - val_prc: 0.3925\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6174 - tp: 237.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 161.0000 - accuracy: 0.6873 - precision: 0.3343 - recall: 0.5955 - auc: 0.7129 - prc: 0.4157 - val_loss: 0.6156 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6875 - val_prc: 0.3883\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6169 - tp: 250.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 148.0000 - accuracy: 0.6902 - precision: 0.3429 - recall: 0.6281 - auc: 0.7161 - prc: 0.4203 - val_loss: 0.6449 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6870 - val_prc: 0.3868\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6159 - tp: 246.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 152.0000 - accuracy: 0.6942 - precision: 0.3450 - recall: 0.6181 - auc: 0.7168 - prc: 0.4235 - val_loss: 0.6315 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6863 - val_prc: 0.3878\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6163 - tp: 245.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 153.0000 - accuracy: 0.6887 - precision: 0.3393 - recall: 0.6156 - auc: 0.7166 - prc: 0.4188 - val_loss: 0.7046 - val_tp: 67.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 24.0000 - val_accuracy: 0.5632 - val_precision: 0.2538 - val_recall: 0.7363 - val_auc: 0.6847 - val_prc: 0.3674\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6155 - tp: 249.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 149.0000 - accuracy: 0.6858 - precision: 0.3383 - recall: 0.6256 - auc: 0.7185 - prc: 0.4206 - val_loss: 0.6091 - val_tp: 50.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 41.0000 - val_accuracy: 0.6858 - val_precision: 0.2976 - val_recall: 0.5495 - val_auc: 0.6876 - val_prc: 0.3917\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6152 - tp: 239.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 159.0000 - accuracy: 0.6863 - precision: 0.3343 - recall: 0.6005 - auc: 0.7186 - prc: 0.4161 - val_loss: 0.6545 - val_tp: 57.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 34.0000 - val_accuracy: 0.6146 - val_precision: 0.2615 - val_recall: 0.6264 - val_auc: 0.6868 - val_prc: 0.3868\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6169 - tp: 239.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 159.0000 - accuracy: 0.6961 - precision: 0.3439 - recall: 0.6005 - auc: 0.7155 - prc: 0.4157 - val_loss: 0.7101 - val_tp: 67.0000 - val_fp: 204.0000 - val_tn: 211.0000 - val_fn: 24.0000 - val_accuracy: 0.5494 - val_precision: 0.2472 - val_recall: 0.7363 - val_auc: 0.6845 - val_prc: 0.3625\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6171 - tp: 254.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 144.0000 - accuracy: 0.6843 - precision: 0.3391 - recall: 0.6382 - auc: 0.7153 - prc: 0.4244 - val_loss: 0.6166 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6870 - val_prc: 0.3892\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6167 - tp: 245.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 153.0000 - accuracy: 0.6848 - precision: 0.3356 - recall: 0.6156 - auc: 0.7141 - prc: 0.4156 - val_loss: 0.6355 - val_tp: 57.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 34.0000 - val_accuracy: 0.6680 - val_precision: 0.2984 - val_recall: 0.6264 - val_auc: 0.6855 - val_prc: 0.3896\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6153 - tp: 229.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 169.0000 - accuracy: 0.6912 - precision: 0.3343 - recall: 0.5754 - auc: 0.7193 - prc: 0.4139 - val_loss: 0.6885 - val_tp: 65.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 26.0000 - val_accuracy: 0.5850 - val_precision: 0.2610 - val_recall: 0.7143 - val_auc: 0.6861 - val_prc: 0.3794\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6169 - tp: 243.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 155.0000 - accuracy: 0.6892 - precision: 0.3389 - recall: 0.6106 - auc: 0.7146 - prc: 0.4062 - val_loss: 0.7431 - val_tp: 69.0000 - val_fp: 219.0000 - val_tn: 196.0000 - val_fn: 22.0000 - val_accuracy: 0.5237 - val_precision: 0.2396 - val_recall: 0.7582 - val_auc: 0.6816 - val_prc: 0.3402\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6163 - tp: 241.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 157.0000 - accuracy: 0.6892 - precision: 0.3380 - recall: 0.6055 - auc: 0.7162 - prc: 0.4140 - val_loss: 0.7181 - val_tp: 68.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 23.0000 - val_accuracy: 0.5415 - val_precision: 0.2455 - val_recall: 0.7473 - val_auc: 0.6850 - val_prc: 0.3652\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6160 - tp: 245.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 153.0000 - accuracy: 0.6808 - precision: 0.3320 - recall: 0.6156 - auc: 0.7162 - prc: 0.4302 - val_loss: 0.5329 - val_tp: 38.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 53.0000 - val_accuracy: 0.7806 - val_precision: 0.3958 - val_recall: 0.4176 - val_auc: 0.6854 - val_prc: 0.4092\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6165 - tp: 239.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 159.0000 - accuracy: 0.6739 - precision: 0.3230 - recall: 0.6005 - auc: 0.7165 - prc: 0.4138 - val_loss: 0.6049 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6877 - val_prc: 0.3936\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6147 - tp: 242.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 156.0000 - accuracy: 0.6877 - precision: 0.3370 - recall: 0.6080 - auc: 0.7178 - prc: 0.4194 - val_loss: 0.5867 - val_tp: 46.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 45.0000 - val_accuracy: 0.7075 - val_precision: 0.3087 - val_recall: 0.5055 - val_auc: 0.6879 - val_prc: 0.3924\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6176 - tp: 232.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 166.0000 - accuracy: 0.7006 - precision: 0.3452 - recall: 0.5829 - auc: 0.7153 - prc: 0.4215 - val_loss: 0.5806 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6871 - val_prc: 0.3978\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6162 - tp: 236.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 162.0000 - accuracy: 0.6961 - precision: 0.3425 - recall: 0.5930 - auc: 0.7162 - prc: 0.4276 - val_loss: 0.6994 - val_tp: 67.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 24.0000 - val_accuracy: 0.5731 - val_precision: 0.2587 - val_recall: 0.7363 - val_auc: 0.6864 - val_prc: 0.3833\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6165 - tp: 248.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 150.0000 - accuracy: 0.6863 - precision: 0.3383 - recall: 0.6231 - auc: 0.7151 - prc: 0.4251 - val_loss: 0.6204 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6879 - val_prc: 0.3939\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6140 - tp: 248.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 150.0000 - accuracy: 0.6873 - precision: 0.3393 - recall: 0.6231 - auc: 0.7196 - prc: 0.4223 - val_loss: 0.6016 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6873 - val_prc: 0.3939\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6170 - tp: 253.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 145.0000 - accuracy: 0.6670 - precision: 0.3235 - recall: 0.6357 - auc: 0.7169 - prc: 0.4156 - val_loss: 0.5428 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6882 - val_prc: 0.4068\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6185 - tp: 237.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 161.0000 - accuracy: 0.6976 - precision: 0.3445 - recall: 0.5955 - auc: 0.7134 - prc: 0.4201 - val_loss: 0.6254 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.6882 - val_prc: 0.3905\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6150 - tp: 231.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 167.0000 - accuracy: 0.6986 - precision: 0.3427 - recall: 0.5804 - auc: 0.7196 - prc: 0.4220 - val_loss: 0.6941 - val_tp: 65.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 26.0000 - val_accuracy: 0.5791 - val_precision: 0.2579 - val_recall: 0.7143 - val_auc: 0.6864 - val_prc: 0.3802\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6151 - tp: 246.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 152.0000 - accuracy: 0.6868 - precision: 0.3379 - recall: 0.6181 - auc: 0.7179 - prc: 0.4250 - val_loss: 0.6364 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6882 - val_prc: 0.3902\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6172 - tp: 241.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 157.0000 - accuracy: 0.6873 - precision: 0.3361 - recall: 0.6055 - auc: 0.7142 - prc: 0.4170 - val_loss: 0.5918 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6875 - val_prc: 0.3993\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6160 - tp: 241.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 157.0000 - accuracy: 0.6838 - precision: 0.3329 - recall: 0.6055 - auc: 0.7154 - prc: 0.4144 - val_loss: 0.5732 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6876 - val_prc: 0.4061\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6142 - tp: 244.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 154.0000 - accuracy: 0.6927 - precision: 0.3427 - recall: 0.6131 - auc: 0.7186 - prc: 0.4274 - val_loss: 0.6082 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6889 - val_prc: 0.3952\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6160 - tp: 220.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 178.0000 - accuracy: 0.7006 - precision: 0.3395 - recall: 0.5528 - auc: 0.7172 - prc: 0.4207 - val_loss: 0.7853 - val_tp: 69.0000 - val_fp: 246.0000 - val_tn: 169.0000 - val_fn: 22.0000 - val_accuracy: 0.4704 - val_precision: 0.2190 - val_recall: 0.7582 - val_auc: 0.6802 - val_prc: 0.3318\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6212 - tp: 258.0000 - fp: 584.0000 - tn: 1042.0000 - fn: 140.0000 - accuracy: 0.6423 - precision: 0.3064 - recall: 0.6482 - auc: 0.7086 - prc: 0.4096 - val_loss: 0.5709 - val_tp: 44.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 47.0000 - val_accuracy: 0.7352 - val_precision: 0.3359 - val_recall: 0.4835 - val_auc: 0.6878 - val_prc: 0.4077\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6140 - tp: 237.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 161.0000 - accuracy: 0.6892 - precision: 0.3362 - recall: 0.5955 - auc: 0.7182 - prc: 0.4256 - val_loss: 0.6707 - val_tp: 62.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 29.0000 - val_accuracy: 0.6028 - val_precision: 0.2650 - val_recall: 0.6813 - val_auc: 0.6873 - val_prc: 0.3984\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6144 - tp: 248.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 150.0000 - accuracy: 0.6971 - precision: 0.3488 - recall: 0.6231 - auc: 0.7185 - prc: 0.4258 - val_loss: 0.6632 - val_tp: 60.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 31.0000 - val_accuracy: 0.6126 - val_precision: 0.2667 - val_recall: 0.6593 - val_auc: 0.6880 - val_prc: 0.3915\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6165 - tp: 239.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 159.0000 - accuracy: 0.6754 - precision: 0.3243 - recall: 0.6005 - auc: 0.7154 - prc: 0.4180 - val_loss: 0.6065 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6885 - val_prc: 0.4005\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6195 - tp: 241.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 157.0000 - accuracy: 0.6764 - precision: 0.3261 - recall: 0.6055 - auc: 0.7097 - prc: 0.4160 - val_loss: 0.6051 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6893 - val_prc: 0.4011\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6156 - tp: 237.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 161.0000 - accuracy: 0.6892 - precision: 0.3362 - recall: 0.5955 - auc: 0.7163 - prc: 0.4263 - val_loss: 0.6129 - val_tp: 52.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 39.0000 - val_accuracy: 0.6818 - val_precision: 0.2989 - val_recall: 0.5714 - val_auc: 0.6883 - val_prc: 0.3947\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6182 - tp: 245.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 153.0000 - accuracy: 0.6858 - precision: 0.3365 - recall: 0.6156 - auc: 0.7135 - prc: 0.4097 - val_loss: 0.6910 - val_tp: 65.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 26.0000 - val_accuracy: 0.5830 - val_precision: 0.2600 - val_recall: 0.7143 - val_auc: 0.6867 - val_prc: 0.3851\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6155 - tp: 250.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 148.0000 - accuracy: 0.6764 - precision: 0.3303 - recall: 0.6281 - auc: 0.7167 - prc: 0.4224 - val_loss: 0.6030 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6887 - val_prc: 0.4001\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6185 - tp: 235.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 163.0000 - accuracy: 0.6818 - precision: 0.3282 - recall: 0.5905 - auc: 0.7124 - prc: 0.4131 - val_loss: 0.6416 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6884 - val_prc: 0.3959\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6156 - tp: 243.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 155.0000 - accuracy: 0.6848 - precision: 0.3347 - recall: 0.6106 - auc: 0.7174 - prc: 0.4173 - val_loss: 0.6484 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6875 - val_prc: 0.3924\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6141 - tp: 235.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 163.0000 - accuracy: 0.6853 - precision: 0.3315 - recall: 0.5905 - auc: 0.7192 - prc: 0.4261 - val_loss: 0.6006 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6876 - val_prc: 0.4013\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6134 - tp: 249.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 149.0000 - accuracy: 0.6838 - precision: 0.3365 - recall: 0.6256 - auc: 0.7192 - prc: 0.4274 - val_loss: 0.6298 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6884 - val_prc: 0.3969\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6180 - tp: 239.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 159.0000 - accuracy: 0.6971 - precision: 0.3449 - recall: 0.6005 - auc: 0.7116 - prc: 0.4225 - val_loss: 0.6213 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6869 - val_prc: 0.3946\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6135 - tp: 246.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 152.0000 - accuracy: 0.6863 - precision: 0.3374 - recall: 0.6181 - auc: 0.7211 - prc: 0.4206 - val_loss: 0.6567 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6877 - val_prc: 0.3895\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6132 - tp: 244.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 154.0000 - accuracy: 0.6873 - precision: 0.3375 - recall: 0.6131 - auc: 0.7190 - prc: 0.4236 - val_loss: 0.6494 - val_tp: 57.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 34.0000 - val_accuracy: 0.6245 - val_precision: 0.2676 - val_recall: 0.6264 - val_auc: 0.6884 - val_prc: 0.3894\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6135 - tp: 246.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 152.0000 - accuracy: 0.6868 - precision: 0.3379 - recall: 0.6181 - auc: 0.7188 - prc: 0.4265 - val_loss: 0.6259 - val_tp: 55.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 36.0000 - val_accuracy: 0.6739 - val_precision: 0.2989 - val_recall: 0.6044 - val_auc: 0.6885 - val_prc: 0.3924\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6148 - tp: 232.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 166.0000 - accuracy: 0.6927 - precision: 0.3372 - recall: 0.5829 - auc: 0.7168 - prc: 0.4253 - val_loss: 0.6174 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6874 - val_prc: 0.4012\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6178 - tp: 255.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 143.0000 - accuracy: 0.6645 - precision: 0.3224 - recall: 0.6407 - auc: 0.7121 - prc: 0.4240 - val_loss: 0.5951 - val_tp: 47.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 44.0000 - val_accuracy: 0.6976 - val_precision: 0.3013 - val_recall: 0.5165 - val_auc: 0.6866 - val_prc: 0.3990\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6139 - tp: 256.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 142.0000 - accuracy: 0.6922 - precision: 0.3474 - recall: 0.6432 - auc: 0.7187 - prc: 0.4352 - val_loss: 0.5478 - val_tp: 41.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 50.0000 - val_accuracy: 0.7530 - val_precision: 0.3534 - val_recall: 0.4505 - val_auc: 0.6874 - val_prc: 0.4081\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6173 - tp: 232.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 166.0000 - accuracy: 0.6922 - precision: 0.3367 - recall: 0.5829 - auc: 0.7133 - prc: 0.4166 - val_loss: 0.6568 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6874 - val_prc: 0.3885\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6138 - tp: 242.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 156.0000 - accuracy: 0.6843 - precision: 0.3338 - recall: 0.6080 - auc: 0.7186 - prc: 0.4139 - val_loss: 0.7413 - val_tp: 69.0000 - val_fp: 224.0000 - val_tn: 191.0000 - val_fn: 22.0000 - val_accuracy: 0.5138 - val_precision: 0.2355 - val_recall: 0.7582 - val_auc: 0.6863 - val_prc: 0.3705\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6154 - tp: 241.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 157.0000 - accuracy: 0.6942 - precision: 0.3428 - recall: 0.6055 - auc: 0.7186 - prc: 0.4197 - val_loss: 0.6425 - val_tp: 56.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 35.0000 - val_accuracy: 0.6443 - val_precision: 0.2786 - val_recall: 0.6154 - val_auc: 0.6880 - val_prc: 0.3953\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6140 - tp: 248.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 150.0000 - accuracy: 0.6734 - precision: 0.3267 - recall: 0.6231 - auc: 0.7194 - prc: 0.4238 - val_loss: 0.5143 - val_tp: 36.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 55.0000 - val_accuracy: 0.7885 - val_precision: 0.4091 - val_recall: 0.3956 - val_auc: 0.6859 - val_prc: 0.4107\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6186 - tp: 238.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 160.0000 - accuracy: 0.6961 - precision: 0.3434 - recall: 0.5980 - auc: 0.7150 - prc: 0.4053 - val_loss: 0.6556 - val_tp: 59.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 32.0000 - val_accuracy: 0.6245 - val_precision: 0.2719 - val_recall: 0.6484 - val_auc: 0.6866 - val_prc: 0.3887\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6153 - tp: 238.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 160.0000 - accuracy: 0.6966 - precision: 0.3439 - recall: 0.5980 - auc: 0.7149 - prc: 0.4364 - val_loss: 0.7513 - val_tp: 70.0000 - val_fp: 239.0000 - val_tn: 176.0000 - val_fn: 21.0000 - val_accuracy: 0.4862 - val_precision: 0.2265 - val_recall: 0.7692 - val_auc: 0.6862 - val_prc: 0.3707\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6149 - tp: 243.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 155.0000 - accuracy: 0.6828 - precision: 0.3329 - recall: 0.6106 - auc: 0.7170 - prc: 0.4201 - val_loss: 0.6564 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6884 - val_prc: 0.3905\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6186 - tp: 244.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 154.0000 - accuracy: 0.6665 - precision: 0.3190 - recall: 0.6131 - auc: 0.7110 - prc: 0.3950 - val_loss: 0.7272 - val_tp: 69.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 22.0000 - val_accuracy: 0.5375 - val_precision: 0.2456 - val_recall: 0.7582 - val_auc: 0.6860 - val_prc: 0.3751\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6168 - tp: 241.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 157.0000 - accuracy: 0.6858 - precision: 0.3347 - recall: 0.6055 - auc: 0.7133 - prc: 0.4210 - val_loss: 0.6805 - val_tp: 61.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 30.0000 - val_accuracy: 0.5889 - val_precision: 0.2552 - val_recall: 0.6703 - val_auc: 0.6873 - val_prc: 0.3905\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6132 - tp: 239.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 159.0000 - accuracy: 0.6907 - precision: 0.3385 - recall: 0.6005 - auc: 0.7194 - prc: 0.4299 - val_loss: 0.7250 - val_tp: 68.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 23.0000 - val_accuracy: 0.5415 - val_precision: 0.2455 - val_recall: 0.7473 - val_auc: 0.6854 - val_prc: 0.3773\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6141 - tp: 245.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 153.0000 - accuracy: 0.6868 - precision: 0.3375 - recall: 0.6156 - auc: 0.7195 - prc: 0.4175 - val_loss: 0.6549 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6884 - val_prc: 0.3953\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6129 - tp: 247.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 151.0000 - accuracy: 0.6922 - precision: 0.3435 - recall: 0.6206 - auc: 0.7193 - prc: 0.4352 - val_loss: 0.6332 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6877 - val_prc: 0.3951\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6142 - tp: 237.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 161.0000 - accuracy: 0.6882 - precision: 0.3352 - recall: 0.5955 - auc: 0.7171 - prc: 0.4256 - val_loss: 0.6406 - val_tp: 56.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 35.0000 - val_accuracy: 0.6443 - val_precision: 0.2786 - val_recall: 0.6154 - val_auc: 0.6886 - val_prc: 0.3994\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6151 - tp: 247.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 151.0000 - accuracy: 0.6902 - precision: 0.3416 - recall: 0.6206 - auc: 0.7177 - prc: 0.4199 - val_loss: 0.6372 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6883 - val_prc: 0.3986\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - tp: 249.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 149.0000 - accuracy: 0.6833 - precision: 0.3360 - recall: 0.6256 - auc: 0.7188 - prc: 0.4263 - val_loss: 0.5746 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6888 - val_prc: 0.4086\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6151 - tp: 239.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 159.0000 - accuracy: 0.7016 - precision: 0.3494 - recall: 0.6005 - auc: 0.7166 - prc: 0.4204 - val_loss: 0.6370 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6887 - val_prc: 0.3987\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6150 - tp: 241.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 157.0000 - accuracy: 0.6789 - precision: 0.3283 - recall: 0.6055 - auc: 0.7162 - prc: 0.4165 - val_loss: 0.6921 - val_tp: 63.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 28.0000 - val_accuracy: 0.5711 - val_precision: 0.2500 - val_recall: 0.6923 - val_auc: 0.6876 - val_prc: 0.3942\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6149 - tp: 246.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 152.0000 - accuracy: 0.6808 - precision: 0.3324 - recall: 0.6181 - auc: 0.7150 - prc: 0.4340 - val_loss: 0.6425 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.6870 - val_prc: 0.3982\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6142 - tp: 240.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 158.0000 - accuracy: 0.6863 - precision: 0.3347 - recall: 0.6030 - auc: 0.7171 - prc: 0.4386 - val_loss: 0.6075 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6878 - val_prc: 0.4006\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - tp: 241.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 157.0000 - accuracy: 0.6937 - precision: 0.3423 - recall: 0.6055 - auc: 0.7180 - prc: 0.4352 - val_loss: 0.6094 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6885 - val_prc: 0.4002\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - tp: 231.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 167.0000 - accuracy: 0.6947 - precision: 0.3387 - recall: 0.5804 - auc: 0.7183 - prc: 0.4360 - val_loss: 0.5967 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6879 - val_prc: 0.4011\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6137 - tp: 239.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 159.0000 - accuracy: 0.6843 - precision: 0.3324 - recall: 0.6005 - auc: 0.7182 - prc: 0.4234 - val_loss: 0.6412 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6889 - val_prc: 0.3982\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6156 - tp: 243.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 155.0000 - accuracy: 0.6887 - precision: 0.3384 - recall: 0.6106 - auc: 0.7140 - prc: 0.4167 - val_loss: 0.6480 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6885 - val_prc: 0.3997\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6135 - tp: 245.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 153.0000 - accuracy: 0.6981 - precision: 0.3485 - recall: 0.6156 - auc: 0.7188 - prc: 0.4266 - val_loss: 0.5979 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6884 - val_prc: 0.4004\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6163 - tp: 249.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 149.0000 - accuracy: 0.6655 - precision: 0.3205 - recall: 0.6256 - auc: 0.7156 - prc: 0.4148 - val_loss: 0.5694 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6873 - val_prc: 0.4096\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6164 - tp: 233.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 165.0000 - accuracy: 0.6873 - precision: 0.3324 - recall: 0.5854 - auc: 0.7136 - prc: 0.4262 - val_loss: 0.6097 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6885 - val_prc: 0.4014\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6151 - tp: 246.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 152.0000 - accuracy: 0.6863 - precision: 0.3374 - recall: 0.6181 - auc: 0.7148 - prc: 0.4180 - val_loss: 0.6442 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6878 - val_prc: 0.3933\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6135 - tp: 242.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 156.0000 - accuracy: 0.6868 - precision: 0.3361 - recall: 0.6080 - auc: 0.7194 - prc: 0.4251 - val_loss: 0.6537 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.6879 - val_prc: 0.3938\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6145 - tp: 247.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 151.0000 - accuracy: 0.6813 - precision: 0.3333 - recall: 0.6206 - auc: 0.7158 - prc: 0.4242 - val_loss: 0.6081 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6883 - val_prc: 0.4016\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6131 - tp: 245.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 153.0000 - accuracy: 0.6912 - precision: 0.3417 - recall: 0.6156 - auc: 0.7187 - prc: 0.4233 - val_loss: 0.6218 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6881 - val_prc: 0.4029\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6121 - tp: 240.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 158.0000 - accuracy: 0.6976 - precision: 0.3458 - recall: 0.6030 - auc: 0.7204 - prc: 0.4276 - val_loss: 0.6409 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6881 - val_prc: 0.3990\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6129 - tp: 246.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 152.0000 - accuracy: 0.6877 - precision: 0.3388 - recall: 0.6181 - auc: 0.7208 - prc: 0.4307 - val_loss: 0.6851 - val_tp: 61.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 30.0000 - val_accuracy: 0.5830 - val_precision: 0.2521 - val_recall: 0.6703 - val_auc: 0.6881 - val_prc: 0.3933\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6115 - tp: 240.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 158.0000 - accuracy: 0.6853 - precision: 0.3338 - recall: 0.6030 - auc: 0.7204 - prc: 0.4318 - val_loss: 0.5717 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6880 - val_prc: 0.4086\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6141 - tp: 225.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 173.0000 - accuracy: 0.7100 - precision: 0.3521 - recall: 0.5653 - auc: 0.7179 - prc: 0.4150 - val_loss: 0.8174 - val_tp: 72.0000 - val_fp: 259.0000 - val_tn: 156.0000 - val_fn: 19.0000 - val_accuracy: 0.4506 - val_precision: 0.2175 - val_recall: 0.7912 - val_auc: 0.6811 - val_prc: 0.3327\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6193 - tp: 254.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 144.0000 - accuracy: 0.6621 - precision: 0.3199 - recall: 0.6382 - auc: 0.7089 - prc: 0.3973 - val_loss: 0.6273 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6870 - val_prc: 0.4032\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6174 - tp: 240.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 158.0000 - accuracy: 0.6823 - precision: 0.3310 - recall: 0.6030 - auc: 0.7137 - prc: 0.4072 - val_loss: 0.6740 - val_tp: 60.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 31.0000 - val_accuracy: 0.5909 - val_precision: 0.2542 - val_recall: 0.6593 - val_auc: 0.6869 - val_prc: 0.3951\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6151 - tp: 236.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 162.0000 - accuracy: 0.6912 - precision: 0.3376 - recall: 0.5930 - auc: 0.7153 - prc: 0.4279 - val_loss: 0.6428 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6878 - val_prc: 0.4001\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6120 - tp: 249.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 149.0000 - accuracy: 0.6917 - precision: 0.3439 - recall: 0.6256 - auc: 0.7214 - prc: 0.4296 - val_loss: 0.5880 - val_tp: 47.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.3133 - val_recall: 0.5165 - val_auc: 0.6880 - val_prc: 0.4099\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6125 - tp: 240.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 158.0000 - accuracy: 0.6892 - precision: 0.3376 - recall: 0.6030 - auc: 0.7201 - prc: 0.4269 - val_loss: 0.6332 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6884 - val_prc: 0.3974\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6140 - tp: 236.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 162.0000 - accuracy: 0.6902 - precision: 0.3367 - recall: 0.5930 - auc: 0.7164 - prc: 0.4347 - val_loss: 0.6178 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6887 - val_prc: 0.4016\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6137 - tp: 237.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 161.0000 - accuracy: 0.6882 - precision: 0.3352 - recall: 0.5955 - auc: 0.7171 - prc: 0.4283 - val_loss: 0.5936 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6881 - val_prc: 0.3994\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6123 - tp: 237.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 161.0000 - accuracy: 0.6957 - precision: 0.3425 - recall: 0.5955 - auc: 0.7195 - prc: 0.4288 - val_loss: 0.6647 - val_tp: 59.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 32.0000 - val_accuracy: 0.6126 - val_precision: 0.2646 - val_recall: 0.6484 - val_auc: 0.6887 - val_prc: 0.3949\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6131 - tp: 235.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 163.0000 - accuracy: 0.6858 - precision: 0.3319 - recall: 0.5905 - auc: 0.7186 - prc: 0.4244 - val_loss: 0.5762 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6884 - val_prc: 0.4090\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6125 - tp: 241.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 157.0000 - accuracy: 0.6961 - precision: 0.3448 - recall: 0.6055 - auc: 0.7195 - prc: 0.4299 - val_loss: 0.7079 - val_tp: 67.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 24.0000 - val_accuracy: 0.5751 - val_precision: 0.2597 - val_recall: 0.7363 - val_auc: 0.6869 - val_prc: 0.3862\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6147 - tp: 248.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 150.0000 - accuracy: 0.6798 - precision: 0.3324 - recall: 0.6231 - auc: 0.7147 - prc: 0.4264 - val_loss: 0.5709 - val_tp: 44.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 47.0000 - val_accuracy: 0.7352 - val_precision: 0.3359 - val_recall: 0.4835 - val_auc: 0.6869 - val_prc: 0.4108\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6111 - tp: 242.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 156.0000 - accuracy: 0.6868 - precision: 0.3361 - recall: 0.6080 - auc: 0.7192 - prc: 0.4331 - val_loss: 0.5976 - val_tp: 50.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 41.0000 - val_accuracy: 0.7075 - val_precision: 0.3185 - val_recall: 0.5495 - val_auc: 0.6874 - val_prc: 0.4010\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6133 - tp: 243.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 155.0000 - accuracy: 0.6932 - precision: 0.3427 - recall: 0.6106 - auc: 0.7172 - prc: 0.4296 - val_loss: 0.6418 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6871 - val_prc: 0.3970\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6127 - tp: 237.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 161.0000 - accuracy: 0.6897 - precision: 0.3366 - recall: 0.5955 - auc: 0.7196 - prc: 0.4270 - val_loss: 0.6674 - val_tp: 60.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 31.0000 - val_accuracy: 0.6107 - val_precision: 0.2655 - val_recall: 0.6593 - val_auc: 0.6885 - val_prc: 0.3905\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6130 - tp: 246.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 152.0000 - accuracy: 0.6966 - precision: 0.3475 - recall: 0.6181 - auc: 0.7168 - prc: 0.4325 - val_loss: 0.6581 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6889 - val_prc: 0.4006\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6124 - tp: 244.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 154.0000 - accuracy: 0.6882 - precision: 0.3384 - recall: 0.6131 - auc: 0.7199 - prc: 0.4282 - val_loss: 0.6199 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6888 - val_prc: 0.4033\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6126 - tp: 231.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 167.0000 - accuracy: 0.6971 - precision: 0.3412 - recall: 0.5804 - auc: 0.7183 - prc: 0.4327 - val_loss: 0.6308 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6886 - val_prc: 0.4032\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6125 - tp: 245.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 153.0000 - accuracy: 0.6981 - precision: 0.3485 - recall: 0.6156 - auc: 0.7195 - prc: 0.4312 - val_loss: 0.6644 - val_tp: 59.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 32.0000 - val_accuracy: 0.6087 - val_precision: 0.2622 - val_recall: 0.6484 - val_auc: 0.6883 - val_prc: 0.3999\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6155 - tp: 248.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 150.0000 - accuracy: 0.6808 - precision: 0.3333 - recall: 0.6231 - auc: 0.7163 - prc: 0.4221 - val_loss: 0.5951 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6869 - val_prc: 0.4093\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6128 - tp: 242.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 156.0000 - accuracy: 0.6892 - precision: 0.3385 - recall: 0.6080 - auc: 0.7186 - prc: 0.4279 - val_loss: 0.5761 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6873 - val_prc: 0.4116\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - tp: 244.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 154.0000 - accuracy: 0.6986 - precision: 0.3486 - recall: 0.6131 - auc: 0.7185 - prc: 0.4297 - val_loss: 0.6304 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6881 - val_prc: 0.4034\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6118 - tp: 241.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 157.0000 - accuracy: 0.6932 - precision: 0.3418 - recall: 0.6055 - auc: 0.7196 - prc: 0.4316 - val_loss: 0.5910 - val_tp: 47.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 44.0000 - val_accuracy: 0.7115 - val_precision: 0.3154 - val_recall: 0.5165 - val_auc: 0.6871 - val_prc: 0.4107\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6096 - tp: 249.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 149.0000 - accuracy: 0.6848 - precision: 0.3374 - recall: 0.6256 - auc: 0.7222 - prc: 0.4237 - val_loss: 0.5402 - val_tp: 39.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 52.0000 - val_accuracy: 0.7688 - val_precision: 0.3750 - val_recall: 0.4286 - val_auc: 0.6864 - val_prc: 0.4140\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6134 - tp: 247.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 151.0000 - accuracy: 0.6858 - precision: 0.3374 - recall: 0.6206 - auc: 0.7190 - prc: 0.4246 - val_loss: 0.6013 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6891 - val_prc: 0.4036\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6126 - tp: 243.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 155.0000 - accuracy: 0.6838 - precision: 0.3338 - recall: 0.6106 - auc: 0.7182 - prc: 0.4310 - val_loss: 0.5639 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6879 - val_prc: 0.4099\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6127 - tp: 242.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 156.0000 - accuracy: 0.6966 - precision: 0.3457 - recall: 0.6080 - auc: 0.7187 - prc: 0.4307 - val_loss: 0.6120 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6885 - val_prc: 0.4026\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6148 - tp: 247.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 151.0000 - accuracy: 0.6922 - precision: 0.3435 - recall: 0.6206 - auc: 0.7139 - prc: 0.4264 - val_loss: 0.6255 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6873 - val_prc: 0.4035\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6164 - tp: 234.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 164.0000 - accuracy: 0.6873 - precision: 0.3329 - recall: 0.5879 - auc: 0.7122 - prc: 0.4241 - val_loss: 0.6793 - val_tp: 60.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 31.0000 - val_accuracy: 0.5909 - val_precision: 0.2542 - val_recall: 0.6593 - val_auc: 0.6882 - val_prc: 0.3960\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6145 - tp: 244.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 154.0000 - accuracy: 0.6833 - precision: 0.3338 - recall: 0.6131 - auc: 0.7151 - prc: 0.4247 - val_loss: 0.5921 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6878 - val_prc: 0.4100\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6115 - tp: 233.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 165.0000 - accuracy: 0.7045 - precision: 0.3498 - recall: 0.5854 - auc: 0.7200 - prc: 0.4330 - val_loss: 0.6446 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6893 - val_prc: 0.4008\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6130 - tp: 249.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 149.0000 - accuracy: 0.6808 - precision: 0.3338 - recall: 0.6256 - auc: 0.7193 - prc: 0.4244 - val_loss: 0.5958 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6884 - val_prc: 0.4109\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6126 - tp: 236.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 162.0000 - accuracy: 0.6813 - precision: 0.3282 - recall: 0.5930 - auc: 0.7172 - prc: 0.4248 - val_loss: 0.5939 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6885 - val_prc: 0.4025\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6142 - tp: 244.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 154.0000 - accuracy: 0.6774 - precision: 0.3284 - recall: 0.6131 - auc: 0.7160 - prc: 0.4209 - val_loss: 0.6013 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6886 - val_prc: 0.4011\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6141 - tp: 232.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 166.0000 - accuracy: 0.6927 - precision: 0.3372 - recall: 0.5829 - auc: 0.7172 - prc: 0.4258 - val_loss: 0.6127 - val_tp: 52.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 39.0000 - val_accuracy: 0.6937 - val_precision: 0.3095 - val_recall: 0.5714 - val_auc: 0.6896 - val_prc: 0.4012\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6157 - tp: 227.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 171.0000 - accuracy: 0.6927 - precision: 0.3348 - recall: 0.5704 - auc: 0.7141 - prc: 0.4303 - val_loss: 0.6452 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6892 - val_prc: 0.4050\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6129 - tp: 244.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 154.0000 - accuracy: 0.6833 - precision: 0.3338 - recall: 0.6131 - auc: 0.7182 - prc: 0.4241 - val_loss: 0.6060 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6886 - val_prc: 0.4013\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6181 - tp: 237.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 161.0000 - accuracy: 0.6739 - precision: 0.3220 - recall: 0.5955 - auc: 0.7099 - prc: 0.4230 - val_loss: 0.6556 - val_tp: 57.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 34.0000 - val_accuracy: 0.6166 - val_precision: 0.2627 - val_recall: 0.6264 - val_auc: 0.6889 - val_prc: 0.4084\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6119 - tp: 247.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 151.0000 - accuracy: 0.6853 - precision: 0.3370 - recall: 0.6206 - auc: 0.7211 - prc: 0.4165 - val_loss: 0.6122 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6890 - val_prc: 0.4021\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6127 - tp: 238.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 160.0000 - accuracy: 0.6922 - precision: 0.3395 - recall: 0.5980 - auc: 0.7183 - prc: 0.4325 - val_loss: 0.6366 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6890 - val_prc: 0.4039\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - tp: 243.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 155.0000 - accuracy: 0.6700 - precision: 0.3214 - recall: 0.6106 - auc: 0.7170 - prc: 0.4256 - val_loss: 0.5647 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6887 - val_prc: 0.4108\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6142 - tp: 237.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 161.0000 - accuracy: 0.7006 - precision: 0.3475 - recall: 0.5955 - auc: 0.7166 - prc: 0.4262 - val_loss: 0.6595 - val_tp: 59.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 32.0000 - val_accuracy: 0.6166 - val_precision: 0.2670 - val_recall: 0.6484 - val_auc: 0.6892 - val_prc: 0.4090\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6113 - tp: 236.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 162.0000 - accuracy: 0.6937 - precision: 0.3401 - recall: 0.5930 - auc: 0.7212 - prc: 0.4322 - val_loss: 0.6509 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6892 - val_prc: 0.4058\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6157 - tp: 243.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 155.0000 - accuracy: 0.6902 - precision: 0.3399 - recall: 0.6106 - auc: 0.7142 - prc: 0.4281 - val_loss: 0.6152 - val_tp: 53.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 38.0000 - val_accuracy: 0.6877 - val_precision: 0.3064 - val_recall: 0.5824 - val_auc: 0.6885 - val_prc: 0.4017\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6126 - tp: 240.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 158.0000 - accuracy: 0.6892 - precision: 0.3376 - recall: 0.6030 - auc: 0.7186 - prc: 0.4327 - val_loss: 0.6164 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6893 - val_prc: 0.4021\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6131 - tp: 252.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 146.0000 - accuracy: 0.6868 - precision: 0.3405 - recall: 0.6332 - auc: 0.7164 - prc: 0.4352 - val_loss: 0.6580 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6894 - val_prc: 0.4073\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6113 - tp: 241.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 157.0000 - accuracy: 0.6798 - precision: 0.3292 - recall: 0.6055 - auc: 0.7194 - prc: 0.4393 - val_loss: 0.5711 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6897 - val_prc: 0.4101\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6113 - tp: 232.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 166.0000 - accuracy: 0.7090 - precision: 0.3542 - recall: 0.5829 - auc: 0.7217 - prc: 0.4316 - val_loss: 0.7271 - val_tp: 70.0000 - val_fp: 215.0000 - val_tn: 200.0000 - val_fn: 21.0000 - val_accuracy: 0.5336 - val_precision: 0.2456 - val_recall: 0.7692 - val_auc: 0.6885 - val_prc: 0.3956\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6151 - tp: 244.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 154.0000 - accuracy: 0.6808 - precision: 0.3315 - recall: 0.6131 - auc: 0.7145 - prc: 0.4294 - val_loss: 0.5784 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6876 - val_prc: 0.4102\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6113 - tp: 236.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 162.0000 - accuracy: 0.6947 - precision: 0.3410 - recall: 0.5930 - auc: 0.7208 - prc: 0.4349 - val_loss: 0.6350 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6894 - val_prc: 0.4039\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6137 - tp: 246.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 152.0000 - accuracy: 0.6892 - precision: 0.3402 - recall: 0.6181 - auc: 0.7174 - prc: 0.4161 - val_loss: 0.6729 - val_tp: 60.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 31.0000 - val_accuracy: 0.6028 - val_precision: 0.2609 - val_recall: 0.6593 - val_auc: 0.6891 - val_prc: 0.4087\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6101 - tp: 240.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 158.0000 - accuracy: 0.7006 - precision: 0.3488 - recall: 0.6030 - auc: 0.7217 - prc: 0.4367 - val_loss: 0.7018 - val_tp: 66.0000 - val_fp: 190.0000 - val_tn: 225.0000 - val_fn: 25.0000 - val_accuracy: 0.5751 - val_precision: 0.2578 - val_recall: 0.7253 - val_auc: 0.6881 - val_prc: 0.3951\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6140 - tp: 242.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 156.0000 - accuracy: 0.6769 - precision: 0.3270 - recall: 0.6080 - auc: 0.7163 - prc: 0.4285 - val_loss: 0.6358 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6894 - val_prc: 0.4044\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6106 - tp: 251.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 147.0000 - accuracy: 0.6833 - precision: 0.3369 - recall: 0.6307 - auc: 0.7214 - prc: 0.4341 - val_loss: 0.5791 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6895 - val_prc: 0.4108\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6104 - tp: 235.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 163.0000 - accuracy: 0.7036 - precision: 0.3497 - recall: 0.5905 - auc: 0.7234 - prc: 0.4357 - val_loss: 0.8372 - val_tp: 72.0000 - val_fp: 262.0000 - val_tn: 153.0000 - val_fn: 19.0000 - val_accuracy: 0.4447 - val_precision: 0.2156 - val_recall: 0.7912 - val_auc: 0.6810 - val_prc: 0.3356\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6192 - tp: 245.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 153.0000 - accuracy: 0.6719 - precision: 0.3241 - recall: 0.6156 - auc: 0.7098 - prc: 0.4154 - val_loss: 0.6186 - val_tp: 54.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 37.0000 - val_accuracy: 0.6838 - val_precision: 0.3051 - val_recall: 0.5934 - val_auc: 0.6897 - val_prc: 0.4031\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6111 - tp: 238.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 160.0000 - accuracy: 0.7041 - precision: 0.3516 - recall: 0.5980 - auc: 0.7209 - prc: 0.4378 - val_loss: 0.6495 - val_tp: 56.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 35.0000 - val_accuracy: 0.6245 - val_precision: 0.2654 - val_recall: 0.6154 - val_auc: 0.6886 - val_prc: 0.4048\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6123 - tp: 248.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 150.0000 - accuracy: 0.6858 - precision: 0.3379 - recall: 0.6231 - auc: 0.7186 - prc: 0.4249 - val_loss: 0.6615 - val_tp: 60.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 31.0000 - val_accuracy: 0.6186 - val_precision: 0.2703 - val_recall: 0.6593 - val_auc: 0.6889 - val_prc: 0.4048\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6127 - tp: 246.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 152.0000 - accuracy: 0.6907 - precision: 0.3417 - recall: 0.6181 - auc: 0.7183 - prc: 0.4301 - val_loss: 0.6491 - val_tp: 56.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 35.0000 - val_accuracy: 0.6265 - val_precision: 0.2667 - val_recall: 0.6154 - val_auc: 0.6889 - val_prc: 0.4049\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6121 - tp: 236.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 162.0000 - accuracy: 0.6932 - precision: 0.3396 - recall: 0.5930 - auc: 0.7180 - prc: 0.4367 - val_loss: 0.6701 - val_tp: 60.0000 - val_fp: 169.0000 - val_tn: 246.0000 - val_fn: 31.0000 - val_accuracy: 0.6047 - val_precision: 0.2620 - val_recall: 0.6593 - val_auc: 0.6888 - val_prc: 0.4094\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6153 - tp: 252.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 146.0000 - accuracy: 0.6724 - precision: 0.3277 - recall: 0.6332 - auc: 0.7147 - prc: 0.4269 - val_loss: 0.6368 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6893 - val_prc: 0.4045\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6176 - tp: 235.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 163.0000 - accuracy: 0.6779 - precision: 0.3246 - recall: 0.5905 - auc: 0.7128 - prc: 0.4199 - val_loss: 0.6043 - val_tp: 52.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 39.0000 - val_accuracy: 0.6957 - val_precision: 0.3114 - val_recall: 0.5714 - val_auc: 0.6884 - val_prc: 0.4133\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6141 - tp: 248.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 150.0000 - accuracy: 0.6937 - precision: 0.3454 - recall: 0.6231 - auc: 0.7172 - prc: 0.4316 - val_loss: 0.6029 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6889 - val_prc: 0.4119\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6132 - tp: 230.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 168.0000 - accuracy: 0.7006 - precision: 0.3443 - recall: 0.5779 - auc: 0.7171 - prc: 0.4421 - val_loss: 0.6642 - val_tp: 61.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 30.0000 - val_accuracy: 0.6186 - val_precision: 0.2723 - val_recall: 0.6703 - val_auc: 0.6888 - val_prc: 0.4050\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6133 - tp: 247.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 151.0000 - accuracy: 0.6838 - precision: 0.3356 - recall: 0.6206 - auc: 0.7174 - prc: 0.4297 - val_loss: 0.6135 - val_tp: 53.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 38.0000 - val_accuracy: 0.6877 - val_precision: 0.3064 - val_recall: 0.5824 - val_auc: 0.6890 - val_prc: 0.4127\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6118 - tp: 250.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 148.0000 - accuracy: 0.6912 - precision: 0.3439 - recall: 0.6281 - auc: 0.7195 - prc: 0.4303 - val_loss: 0.6147 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6894 - val_prc: 0.4045\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6145 - tp: 231.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 167.0000 - accuracy: 0.6947 - precision: 0.3387 - recall: 0.5804 - auc: 0.7138 - prc: 0.4326 - val_loss: 0.6151 - val_tp: 53.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 38.0000 - val_accuracy: 0.6877 - val_precision: 0.3064 - val_recall: 0.5824 - val_auc: 0.6889 - val_prc: 0.4138\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6126 - tp: 240.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 158.0000 - accuracy: 0.6789 - precision: 0.3279 - recall: 0.6030 - auc: 0.7185 - prc: 0.4306 - val_loss: 0.5731 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6885 - val_prc: 0.4122\n",
      "Epoch 302/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6131 - tp: 236.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 162.0000 - accuracy: 0.6971 - precision: 0.3435 - recall: 0.5930 - auc: 0.7171 - prc: 0.4393 - val_loss: 0.6610 - val_tp: 58.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 33.0000 - val_accuracy: 0.6107 - val_precision: 0.2613 - val_recall: 0.6374 - val_auc: 0.6893 - val_prc: 0.4046\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6120 - tp: 236.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 162.0000 - accuracy: 0.6922 - precision: 0.3386 - recall: 0.5930 - auc: 0.7194 - prc: 0.4319 - val_loss: 0.6570 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6898 - val_prc: 0.4059\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6124 - tp: 240.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 158.0000 - accuracy: 0.6828 - precision: 0.3315 - recall: 0.6030 - auc: 0.7209 - prc: 0.4198 - val_loss: 0.5890 - val_tp: 49.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 42.0000 - val_accuracy: 0.7134 - val_precision: 0.3224 - val_recall: 0.5385 - val_auc: 0.6904 - val_prc: 0.4135\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6131 - tp: 252.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 146.0000 - accuracy: 0.6927 - precision: 0.3462 - recall: 0.6332 - auc: 0.7181 - prc: 0.4306 - val_loss: 0.6810 - val_tp: 62.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 29.0000 - val_accuracy: 0.5889 - val_precision: 0.2573 - val_recall: 0.6813 - val_auc: 0.6882 - val_prc: 0.4080\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6113 - tp: 247.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 151.0000 - accuracy: 0.6828 - precision: 0.3347 - recall: 0.6206 - auc: 0.7199 - prc: 0.4370 - val_loss: 0.6041 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6903 - val_prc: 0.4136\n",
      "Epoch 307/500\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 0.6021 - tp: 221.0000 - fp: 422.0000 - tn: 1111.0000 - fn: 146.0000 - accuracy: 0.7011 - precision: 0.3437 - recall: 0.6022 - auc: 0.7280 - prc: 0.4379Restoring model weights from the end of the best epoch: 257.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6118 - tp: 233.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 165.0000 - accuracy: 0.6981 - precision: 0.3432 - recall: 0.5854 - auc: 0.7199 - prc: 0.4316 - val_loss: 0.6593 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6890 - val_prc: 0.4059\n",
      "Epoch 307: early stopping\n",
      "26/26 [==============================] - 0s 546us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "# Create a dictionary mapping the class indices to their respective weights\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_values = [{0: 1, 1: 1+i/2} for i in range(1, 8)]  # list of class_weights dictionary\n",
    "class_weights_values.append(class_weights_dict)\n",
    "\n",
    "# Hyperparameter tuning for class weight\n",
    "coordinates = [[0,0]]\n",
    "for i in range(len(class_weights_values)):\n",
    "    class_weight = class_weights_values[i]\n",
    "    model = make_model()\n",
    "    model.load_weights(initial_weights)\n",
    "    baseline_history = model.fit(X_train,\n",
    "                                y_train,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                class_weight=class_weight)\n",
    "    y_pred = (model.predict(X_val, batch_size=BATCH_SIZE) > 0.5).astype(int)\n",
    "    c_mat = confusion_matrix(y_val, y_pred)\n",
    "    # save the values of sensitivity and 1-specificity for ROC curve\n",
    "    sensitivity = c_mat[1,1]/np.sum(c_mat[1,:])\n",
    "    specificity = c_mat[0,0]/np.sum(c_mat[0,:])\n",
    "    coordinates.append([1-specificity,sensitivity])\n",
    "coordinates.append([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1386a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot roc curve\n",
    "coordinates_np = np.array(sorted(coordinates, key=lambda x: x[0]))  # first column: FP, second column: TP\n",
    "plt.plot(coordinates_np[:,0], coordinates_np[:,1], linewidth=2, marker='o')\n",
    "diag = np.linspace(0,1,20)\n",
    "plt.plot(diag, diag)\n",
    "plt.xlabel('False positives')\n",
    "plt.ylabel('True positives')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.grid(True)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38d4ceff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6223862238622386, 1: 2.542713567839196}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use youden index to find the best class weight\n",
    "youden_np = (coordinates_np[:,1]-coordinates_np[:,0])\n",
    "optimal = coordinates_np[youden_np.argmax(), :]\n",
    "best_class_weight_idx = coordinates.index([optimal[0], optimal[1]])\n",
    "\n",
    "# -1 is needed because coordinates list began with [0,0]\n",
    "best_class_weight = class_weights_values[best_class_weight_idx-1]\n",
    "best_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d101bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.9116 - tp: 58.0000 - fp: 162.0000 - tn: 1879.0000 - fn: 431.0000 - accuracy: 0.7656 - precision: 0.2636 - recall: 0.1186 - auc: 0.5095 - prc: 0.2328 - val_loss: 0.4739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8867 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4632 - prc: 0.1802 - val_loss: 0.4770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8640 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4895 - prc: 0.1945 - val_loss: 0.4811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8428 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5134 - prc: 0.2084 - val_loss: 0.4863 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8238 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4980 - prc: 0.1943 - val_loss: 0.4924 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - prc: 0.2026 - val_loss: 0.4992 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7917 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5295 - prc: 0.2085 - val_loss: 0.5068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7775 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - prc: 0.1962 - val_loss: 0.5149 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7653 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4901 - prc: 0.1902 - val_loss: 0.5234 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7545 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5097 - prc: 0.2019 - val_loss: 0.5325 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5055 - prc: 0.2053 - val_loss: 0.5413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7372 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1994 - val_loss: 0.5501 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7302 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007 - prc: 0.1912 - val_loss: 0.5599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5164 - prc: 0.2094 - val_loss: 0.5683 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7187 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5019 - prc: 0.1941 - val_loss: 0.5778 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7143 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4776 - prc: 0.1863 - val_loss: 0.5866 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7104 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4962 - prc: 0.1938 - val_loss: 0.5954 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4901 - prc: 0.1924 - val_loss: 0.6040 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7044 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - prc: 0.1887 - val_loss: 0.6120 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7022 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - prc: 0.1958 - val_loss: 0.6197 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7003 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4888 - prc: 0.1926 - val_loss: 0.6263 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4862 - prc: 0.1901 - val_loss: 0.6330 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6975 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4985 - prc: 0.1960 - val_loss: 0.6397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6965 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4911 - prc: 0.1933 - val_loss: 0.6453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6956 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4975 - prc: 0.1956 - val_loss: 0.6515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - prc: 0.1957 - val_loss: 0.6563 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6945 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1954 - val_loss: 0.6596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6941 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1973 - val_loss: 0.6650 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6938 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6693 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4927 - prc: 0.1919 - val_loss: 0.6719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6934 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.6751 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6932 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - prc: 0.1893 - val_loss: 0.6777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6931 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4903 - prc: 0.1935 - val_loss: 0.6788 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6931 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.6823 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6929 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4808 - prc: 0.1874 - val_loss: 0.6836 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6929 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - prc: 0.1906 - val_loss: 0.6837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6929 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4734 - prc: 0.1853 - val_loss: 0.6887 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4907 - prc: 0.1924 - val_loss: 0.6906 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4958 - prc: 0.1926 - val_loss: 0.6896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6926 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4852 - prc: 0.1910 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6927 - tp: 36.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 362.0000 - accuracy: 0.7204 - precision: 0.1500 - recall: 0.0905 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6926 - tp: 278.0000 - fp: 1161.0000 - tn: 465.0000 - fn: 120.0000 - accuracy: 0.3671 - precision: 0.1932 - recall: 0.6985 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6926 - tp: 78.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 320.0000 - accuracy: 0.6537 - precision: 0.1699 - recall: 0.1960 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6929 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6927 - tp: 368.0000 - fp: 1512.0000 - tn: 114.0000 - fn: 30.0000 - accuracy: 0.2381 - precision: 0.1957 - recall: 0.9246 - auc: 0.4867 - prc: 0.1866 - val_loss: 0.6940 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6926 - tp: 207.0000 - fp: 894.0000 - tn: 732.0000 - fn: 191.0000 - accuracy: 0.4639 - precision: 0.1880 - recall: 0.5201 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6935 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 205.0000 - fp: 916.0000 - tn: 710.0000 - fn: 193.0000 - accuracy: 0.4521 - precision: 0.1829 - recall: 0.5151 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6928 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6927 - tp: 397.0000 - fp: 1621.0000 - tn: 5.0000 - fn: 1.0000 - accuracy: 0.1986 - precision: 0.1967 - recall: 0.9975 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.6948 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 398.0000 - fp: 1622.0000 - tn: 4.0000 - fn: 0.0000e+00 - accuracy: 0.1986 - precision: 0.1970 - recall: 1.0000 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6942 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 370.0000 - fp: 1549.0000 - tn: 77.0000 - fn: 28.0000 - accuracy: 0.2208 - precision: 0.1928 - recall: 0.9296 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6928 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 336.0000 - fp: 1406.0000 - tn: 220.0000 - fn: 62.0000 - accuracy: 0.2747 - precision: 0.1929 - recall: 0.8442 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6939 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 397.0000 - fp: 1622.0000 - tn: 4.0000 - fn: 1.0000 - accuracy: 0.1981 - precision: 0.1966 - recall: 0.9975 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.6933 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 398.0000 - fp: 1622.0000 - tn: 4.0000 - fn: 0.0000e+00 - accuracy: 0.1986 - precision: 0.1970 - recall: 1.0000 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.6934 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "100/102 [============================>.] - ETA: 0s - loss: 0.6923 - tp: 393.0000 - fp: 1603.0000 - tn: 4.0000 - fn: 0.0000e+00 - accuracy: 0.1985 - precision: 0.1969 - recall: 1.0000 - auc: 0.4854 - prc: 0.1859Restoring model weights from the end of the best epoch: 6.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6925 - tp: 398.0000 - fp: 1622.0000 - tn: 4.0000 - fn: 0.0000e+00 - accuracy: 0.1986 - precision: 0.1970 - recall: 1.0000 - auc: 0.4856 - prc: 0.1861 - val_loss: 0.6933 - val_tp: 91.0000 - val_fp: 414.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.1818 - val_precision: 0.1802 - val_recall: 1.0000 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 56: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train a NN model based on the best class weight found\n",
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=best_class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d5fb7b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ecbd243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 519us/step\n",
      "32/32 [==============================] - 0s 527us/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5024e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5186923742294312\n",
      "tp :  0.0\n",
      "fp :  0.0\n",
      "tn :  506.0\n",
      "fn :  127.0\n",
      "accuracy :  0.7993680834770203\n",
      "precision :  0.0\n",
      "recall :  0.0\n",
      "auc :  0.5\n",
      "prc :  0.20063191652297974\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  506\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  0\n",
      "Fraudulent Transactions Missed (False Negatives):  127\n",
      "Fraudulent Transactions Detected (True Positives):  0\n",
      "Total Fraudulent Transactions:  127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performance report\n",
    "weighted_results = weighted_model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f116354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Slope ',\n",
       " 'Hurst Exponent ',\n",
       " 'Left Slope ',\n",
       " 'Right Slope ',\n",
       " 'Left Tangent ',\n",
       " 'Left Tangent Point',\n",
       " 'Right Tangent Point']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using all features in the data\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [col_name for col_name in data.columns[1:11]]  # predictor features name\n",
    "features.pop(features.index('ID'))  # remove patient ID from feature names list\n",
    "features.pop(features.index('Broadness'))\n",
    "features.pop(features.index('Right Tangent'))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7131dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "362f36d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "'''\n",
    "model = make_model(output_bias=initial_bias)\n",
    "model.predict(X_train[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5273cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.6551 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2132.0000 - fn: 525.0000 - accuracy: 0.8024 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - prc: 0.1972 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6511 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4860 - prc: 0.1911 - val_loss: 0.4742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6482 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007 - prc: 0.1984 - val_loss: 0.4756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6457 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5043 - prc: 0.1984 - val_loss: 0.4773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6440 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5017 - prc: 0.1973 - val_loss: 0.4789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6427 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4985 - prc: 0.1961 - val_loss: 0.4804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6418 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5036 - prc: 0.1978 - val_loss: 0.4819 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6410 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4987 - prc: 0.1962 - val_loss: 0.4832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6405 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4985 - prc: 0.1958 - val_loss: 0.4845 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6401 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4729 - prc: 0.1838 - val_loss: 0.4856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6398 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4945 - prc: 0.1948 - val_loss: 0.4862 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5108 - val_prc: 0.1831\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6395 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5023 - prc: 0.1974 - val_loss: 0.4868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5157 - val_prc: 0.1846\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6380 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5717 - prc: 0.2302 - val_loss: 0.4832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6349 - val_prc: 0.2502\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6344 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6304 - prc: 0.2825 - val_loss: 0.4742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6542 - val_prc: 0.3124\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6304 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6300 - prc: 0.2578 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6265 - val_prc: 0.2370\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6264 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6579 - prc: 0.2953 - val_loss: 0.4659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6707 - val_prc: 0.3278\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6219 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6832 - prc: 0.3625 - val_loss: 0.4654 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6696 - val_prc: 0.2965\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6179 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6875 - prc: 0.3669 - val_loss: 0.4637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6747 - val_prc: 0.3072\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6882 - prc: 0.3757 - val_loss: 0.4618 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6751 - val_prc: 0.3061\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6142 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6801 - prc: 0.3352 - val_loss: 0.4541 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6823 - val_prc: 0.3360\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6949 - prc: 0.3475 - val_loss: 0.4499 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6860 - val_prc: 0.3440\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6898 - prc: 0.3524 - val_loss: 0.4480 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6845 - val_prc: 0.3453\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6055 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6959 - prc: 0.3645 - val_loss: 0.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6819 - val_prc: 0.3272\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6027 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6977 - prc: 0.3505 - val_loss: 0.4512 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6832 - val_prc: 0.3329\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6016 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6984 - prc: 0.3652 - val_loss: 0.4489 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6832 - val_prc: 0.3348\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5991 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7023 - prc: 0.3683 - val_loss: 0.4506 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6808 - val_prc: 0.3294\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6986 - prc: 0.3543 - val_loss: 0.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6806 - val_prc: 0.3352\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5955 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7058 - prc: 0.3832 - val_loss: 0.4532 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6825 - val_prc: 0.3383\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5965 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6956 - prc: 0.3448 - val_loss: 0.4679 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6771 - val_prc: 0.3145\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7057 - prc: 0.3696 - val_loss: 0.4459 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6834 - val_prc: 0.3451\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5915 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7069 - prc: 0.3781 - val_loss: 0.4491 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6826 - val_prc: 0.3369\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5900 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7092 - prc: 0.3835 - val_loss: 0.4475 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6815 - val_prc: 0.3367\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5901 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7068 - prc: 0.3844 - val_loss: 0.4471 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.3526\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7085 - prc: 0.4004 - val_loss: 0.4478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6856 - val_prc: 0.3480\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5866 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7108 - prc: 0.3799 - val_loss: 0.4545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6830 - val_prc: 0.3389\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5864 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7097 - prc: 0.3950 - val_loss: 0.4550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6821 - val_prc: 0.3404\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5844 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7122 - prc: 0.3862 - val_loss: 0.4431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6868 - val_prc: 0.3551\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5849 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7099 - prc: 0.3839 - val_loss: 0.4453 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6893 - val_prc: 0.3640\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7128 - prc: 0.3959 - val_loss: 0.4478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6877 - val_prc: 0.3547\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7150 - prc: 0.4079 - val_loss: 0.4411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6901 - val_prc: 0.3631\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7116 - prc: 0.3875 - val_loss: 0.4547 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6865 - val_prc: 0.3464\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5824 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7100 - prc: 0.3958 - val_loss: 0.4399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6896 - val_prc: 0.3596\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5798 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7153 - prc: 0.4007 - val_loss: 0.4418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6891 - val_prc: 0.3585\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7158 - prc: 0.3995 - val_loss: 0.4604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6862 - val_prc: 0.3476\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5781 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7157 - prc: 0.3976 - val_loss: 0.4416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6912 - val_prc: 0.3547\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5770 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7174 - prc: 0.4081 - val_loss: 0.4421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6900 - val_prc: 0.3559\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5753 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7184 - prc: 0.4011 - val_loss: 0.4551 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6888 - val_prc: 0.3635\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5773 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7155 - prc: 0.4108 - val_loss: 0.4504 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6911 - val_prc: 0.3644\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7238 - prc: 0.4014 - val_loss: 0.4401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6930 - val_prc: 0.3679\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5785 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7128 - prc: 0.4185 - val_loss: 0.4375 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6938 - val_prc: 0.3691\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5751 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7184 - prc: 0.4149 - val_loss: 0.4579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6922 - val_prc: 0.3663\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5748 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7171 - prc: 0.4139 - val_loss: 0.4421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6941 - val_prc: 0.3735\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5726 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7217 - prc: 0.4256 - val_loss: 0.4477 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6924 - val_prc: 0.3567\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5740 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7176 - prc: 0.4239 - val_loss: 0.4428 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6943 - val_prc: 0.3698\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5721 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7212 - prc: 0.4184 - val_loss: 0.4367 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6963 - val_prc: 0.3745\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7174 - prc: 0.3935 - val_loss: 0.4389 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6942 - val_prc: 0.3686\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5720 - tp: 61.0000 - fp: 41.0000 - tn: 1585.0000 - fn: 337.0000 - accuracy: 0.8132 - precision: 0.5980 - recall: 0.1533 - auc: 0.7195 - prc: 0.4141 - val_loss: 0.4420 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 74.0000 - val_accuracy: 0.8241 - val_precision: 0.5312 - val_recall: 0.1868 - val_auc: 0.6950 - val_prc: 0.3632\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5714 - tp: 89.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 309.0000 - accuracy: 0.8197 - precision: 0.6138 - recall: 0.2236 - auc: 0.7216 - prc: 0.4230 - val_loss: 0.4360 - val_tp: 15.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 76.0000 - val_accuracy: 0.8281 - val_precision: 0.5769 - val_recall: 0.1648 - val_auc: 0.6969 - val_prc: 0.3751\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5714 - tp: 84.0000 - fp: 50.0000 - tn: 1576.0000 - fn: 314.0000 - accuracy: 0.8202 - precision: 0.6269 - recall: 0.2111 - auc: 0.7205 - prc: 0.4227 - val_loss: 0.4534 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6912 - val_prc: 0.3602\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5741 - tp: 99.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 299.0000 - accuracy: 0.8142 - precision: 0.5625 - recall: 0.2487 - auc: 0.7134 - prc: 0.4011 - val_loss: 0.4451 - val_tp: 17.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 74.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1868 - val_auc: 0.6939 - val_prc: 0.3626\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5673 - tp: 102.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 296.0000 - accuracy: 0.8177 - precision: 0.5829 - recall: 0.2563 - auc: 0.7263 - prc: 0.4248 - val_loss: 0.4304 - val_tp: 11.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 80.0000 - val_accuracy: 0.8281 - val_precision: 0.6111 - val_recall: 0.1209 - val_auc: 0.6946 - val_prc: 0.3743\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5702 - tp: 88.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 310.0000 - accuracy: 0.8162 - precision: 0.5867 - recall: 0.2211 - auc: 0.7208 - prc: 0.4149 - val_loss: 0.4455 - val_tp: 17.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 74.0000 - val_accuracy: 0.8182 - val_precision: 0.4857 - val_recall: 0.1868 - val_auc: 0.6935 - val_prc: 0.3663\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5694 - tp: 88.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 310.0000 - accuracy: 0.8162 - precision: 0.5867 - recall: 0.2211 - auc: 0.7222 - prc: 0.4100 - val_loss: 0.4457 - val_tp: 18.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 73.0000 - val_accuracy: 0.8182 - val_precision: 0.4865 - val_recall: 0.1978 - val_auc: 0.6923 - val_prc: 0.3656\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5685 - tp: 96.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 302.0000 - accuracy: 0.8147 - precision: 0.5680 - recall: 0.2412 - auc: 0.7236 - prc: 0.4175 - val_loss: 0.4446 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6931 - val_prc: 0.3666\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5679 - tp: 92.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 306.0000 - accuracy: 0.8187 - precision: 0.6013 - recall: 0.2312 - auc: 0.7232 - prc: 0.4246 - val_loss: 0.4432 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6950 - val_prc: 0.3667\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5680 - tp: 103.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 295.0000 - accuracy: 0.8132 - precision: 0.5538 - recall: 0.2588 - auc: 0.7230 - prc: 0.4198 - val_loss: 0.4392 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 74.0000 - val_accuracy: 0.8241 - val_precision: 0.5312 - val_recall: 0.1868 - val_auc: 0.6944 - val_prc: 0.3740\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5671 - tp: 94.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 304.0000 - accuracy: 0.8187 - precision: 0.5987 - recall: 0.2362 - auc: 0.7242 - prc: 0.4220 - val_loss: 0.4770 - val_tp: 32.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 59.0000 - val_accuracy: 0.7984 - val_precision: 0.4267 - val_recall: 0.3516 - val_auc: 0.6890 - val_prc: 0.3517\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5677 - tp: 106.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 292.0000 - accuracy: 0.8172 - precision: 0.5761 - recall: 0.2663 - auc: 0.7203 - prc: 0.4117 - val_loss: 0.4455 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6931 - val_prc: 0.3694\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5666 - tp: 95.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 303.0000 - accuracy: 0.8187 - precision: 0.5975 - recall: 0.2387 - auc: 0.7247 - prc: 0.4296 - val_loss: 0.4411 - val_tp: 17.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 74.0000 - val_accuracy: 0.8182 - val_precision: 0.4857 - val_recall: 0.1868 - val_auc: 0.6958 - val_prc: 0.3754\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5657 - tp: 91.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 307.0000 - accuracy: 0.8152 - precision: 0.5759 - recall: 0.2286 - auc: 0.7267 - prc: 0.4271 - val_loss: 0.4514 - val_tp: 27.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 64.0000 - val_accuracy: 0.8300 - val_precision: 0.5510 - val_recall: 0.2967 - val_auc: 0.6945 - val_prc: 0.3680\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5674 - tp: 99.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 299.0000 - accuracy: 0.8142 - precision: 0.5625 - recall: 0.2487 - auc: 0.7222 - prc: 0.4280 - val_loss: 0.4352 - val_tp: 16.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 75.0000 - val_accuracy: 0.8281 - val_precision: 0.5714 - val_recall: 0.1758 - val_auc: 0.6962 - val_prc: 0.3819\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5657 - tp: 93.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 305.0000 - accuracy: 0.8182 - precision: 0.5962 - recall: 0.2337 - auc: 0.7253 - prc: 0.4430 - val_loss: 0.4412 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6958 - val_prc: 0.3834\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5657 - tp: 89.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 309.0000 - accuracy: 0.8182 - precision: 0.6014 - recall: 0.2236 - auc: 0.7245 - prc: 0.4428 - val_loss: 0.4475 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6946 - val_prc: 0.3817\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5666 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7233 - prc: 0.4218 - val_loss: 0.4384 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6951 - val_prc: 0.3853\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5656 - tp: 93.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 305.0000 - accuracy: 0.8172 - precision: 0.5886 - recall: 0.2337 - auc: 0.7238 - prc: 0.4291 - val_loss: 0.4479 - val_tp: 25.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 66.0000 - val_accuracy: 0.8281 - val_precision: 0.5435 - val_recall: 0.2747 - val_auc: 0.6952 - val_prc: 0.3831\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5662 - tp: 102.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 296.0000 - accuracy: 0.8177 - precision: 0.5829 - recall: 0.2563 - auc: 0.7234 - prc: 0.4333 - val_loss: 0.4505 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6936 - val_prc: 0.3753\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5630 - tp: 111.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 287.0000 - accuracy: 0.8172 - precision: 0.5722 - recall: 0.2789 - auc: 0.7279 - prc: 0.4224 - val_loss: 0.4315 - val_tp: 15.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 76.0000 - val_accuracy: 0.8261 - val_precision: 0.5556 - val_recall: 0.1648 - val_auc: 0.6969 - val_prc: 0.3754\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5690 - tp: 106.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 292.0000 - accuracy: 0.8177 - precision: 0.5792 - recall: 0.2663 - auc: 0.7163 - prc: 0.4353 - val_loss: 0.4388 - val_tp: 17.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 74.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1868 - val_auc: 0.6937 - val_prc: 0.3757\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5642 - tp: 92.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 306.0000 - accuracy: 0.8162 - precision: 0.5823 - recall: 0.2312 - auc: 0.7256 - prc: 0.4443 - val_loss: 0.4484 - val_tp: 25.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 66.0000 - val_accuracy: 0.8281 - val_precision: 0.5435 - val_recall: 0.2747 - val_auc: 0.6942 - val_prc: 0.3836\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5641 - tp: 113.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 285.0000 - accuracy: 0.8177 - precision: 0.5736 - recall: 0.2839 - auc: 0.7260 - prc: 0.4264 - val_loss: 0.4430 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6946 - val_prc: 0.3821\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5631 - tp: 103.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 295.0000 - accuracy: 0.8152 - precision: 0.5659 - recall: 0.2588 - auc: 0.7271 - prc: 0.4335 - val_loss: 0.4468 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6954 - val_prc: 0.3830\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5626 - tp: 108.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 290.0000 - accuracy: 0.8142 - precision: 0.5567 - recall: 0.2714 - auc: 0.7277 - prc: 0.4403 - val_loss: 0.4441 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6942 - val_prc: 0.3806\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5627 - tp: 101.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 297.0000 - accuracy: 0.8162 - precision: 0.5739 - recall: 0.2538 - auc: 0.7262 - prc: 0.4467 - val_loss: 0.4397 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 72.0000 - val_accuracy: 0.8241 - val_precision: 0.5278 - val_recall: 0.2088 - val_auc: 0.6961 - val_prc: 0.3792\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5636 - tp: 101.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 297.0000 - accuracy: 0.8192 - precision: 0.5941 - recall: 0.2538 - auc: 0.7252 - prc: 0.4450 - val_loss: 0.4470 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6943 - val_prc: 0.3843\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5612 - tp: 97.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 301.0000 - accuracy: 0.8187 - precision: 0.5951 - recall: 0.2437 - auc: 0.7282 - prc: 0.4433 - val_loss: 0.4585 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 62.0000 - val_accuracy: 0.8221 - val_precision: 0.5088 - val_recall: 0.3187 - val_auc: 0.6921 - val_prc: 0.3769\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5607 - tp: 108.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 290.0000 - accuracy: 0.8182 - precision: 0.5806 - recall: 0.2714 - auc: 0.7303 - prc: 0.4451 - val_loss: 0.4754 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6901 - val_prc: 0.3658\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5652 - tp: 121.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 277.0000 - accuracy: 0.8157 - precision: 0.5576 - recall: 0.3040 - auc: 0.7222 - prc: 0.4330 - val_loss: 0.4431 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6948 - val_prc: 0.3837\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5619 - tp: 109.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 289.0000 - accuracy: 0.8177 - precision: 0.5767 - recall: 0.2739 - auc: 0.7273 - prc: 0.4419 - val_loss: 0.4419 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6937 - val_prc: 0.3769\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5615 - tp: 101.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 297.0000 - accuracy: 0.8187 - precision: 0.5906 - recall: 0.2538 - auc: 0.7284 - prc: 0.4414 - val_loss: 0.4427 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6944 - val_prc: 0.3758\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5620 - tp: 100.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 298.0000 - accuracy: 0.8192 - precision: 0.5952 - recall: 0.2513 - auc: 0.7261 - prc: 0.4517 - val_loss: 0.4446 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6941 - val_prc: 0.3802\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5615 - tp: 106.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 292.0000 - accuracy: 0.8162 - precision: 0.5699 - recall: 0.2663 - auc: 0.7267 - prc: 0.4457 - val_loss: 0.4442 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6937 - val_prc: 0.3750\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5626 - tp: 103.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 295.0000 - accuracy: 0.8162 - precision: 0.5722 - recall: 0.2588 - auc: 0.7267 - prc: 0.4428 - val_loss: 0.4325 - val_tp: 17.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 74.0000 - val_accuracy: 0.8281 - val_precision: 0.5667 - val_recall: 0.1868 - val_auc: 0.6927 - val_prc: 0.3842\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5602 - tp: 95.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 303.0000 - accuracy: 0.8167 - precision: 0.5828 - recall: 0.2387 - auc: 0.7291 - prc: 0.4596 - val_loss: 0.4530 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6940 - val_prc: 0.3817\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5611 - tp: 101.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 297.0000 - accuracy: 0.8162 - precision: 0.5739 - recall: 0.2538 - auc: 0.7277 - prc: 0.4525 - val_loss: 0.4422 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6952 - val_prc: 0.3804\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5614 - tp: 100.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 298.0000 - accuracy: 0.8142 - precision: 0.5618 - recall: 0.2513 - auc: 0.7271 - prc: 0.4529 - val_loss: 0.4434 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6958 - val_prc: 0.3780\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5598 - tp: 103.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 295.0000 - accuracy: 0.8162 - precision: 0.5722 - recall: 0.2588 - auc: 0.7305 - prc: 0.4426 - val_loss: 0.4337 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6977 - val_prc: 0.3871\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5609 - tp: 101.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 297.0000 - accuracy: 0.8162 - precision: 0.5739 - recall: 0.2538 - auc: 0.7280 - prc: 0.4485 - val_loss: 0.4369 - val_tp: 17.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 74.0000 - val_accuracy: 0.8221 - val_precision: 0.5152 - val_recall: 0.1868 - val_auc: 0.6956 - val_prc: 0.3882\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5625 - tp: 96.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 302.0000 - accuracy: 0.8177 - precision: 0.5890 - recall: 0.2412 - auc: 0.7242 - prc: 0.4400 - val_loss: 0.4556 - val_tp: 30.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 61.0000 - val_accuracy: 0.8281 - val_precision: 0.5357 - val_recall: 0.3297 - val_auc: 0.6926 - val_prc: 0.3819\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5593 - tp: 108.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 290.0000 - accuracy: 0.8152 - precision: 0.5625 - recall: 0.2714 - auc: 0.7306 - prc: 0.4474 - val_loss: 0.4430 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6920 - val_prc: 0.3763\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5597 - tp: 105.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 293.0000 - accuracy: 0.8211 - precision: 0.6034 - recall: 0.2638 - auc: 0.7293 - prc: 0.4558 - val_loss: 0.4335 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6926 - val_prc: 0.3861\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5589 - tp: 101.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 297.0000 - accuracy: 0.8177 - precision: 0.5838 - recall: 0.2538 - auc: 0.7303 - prc: 0.4538 - val_loss: 0.4588 - val_tp: 31.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 60.0000 - val_accuracy: 0.8241 - val_precision: 0.5167 - val_recall: 0.3407 - val_auc: 0.6912 - val_prc: 0.3857\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5583 - tp: 112.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 286.0000 - accuracy: 0.8162 - precision: 0.5657 - recall: 0.2814 - auc: 0.7333 - prc: 0.4553 - val_loss: 0.4351 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 74.0000 - val_accuracy: 0.8241 - val_precision: 0.5312 - val_recall: 0.1868 - val_auc: 0.6940 - val_prc: 0.3797\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5596 - tp: 110.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 288.0000 - accuracy: 0.8221 - precision: 0.6044 - recall: 0.2764 - auc: 0.7289 - prc: 0.4528 - val_loss: 0.4394 - val_tp: 20.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 71.0000 - val_accuracy: 0.8281 - val_precision: 0.5556 - val_recall: 0.2198 - val_auc: 0.6940 - val_prc: 0.3815\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5603 - tp: 110.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 288.0000 - accuracy: 0.8192 - precision: 0.5851 - recall: 0.2764 - auc: 0.7280 - prc: 0.4455 - val_loss: 0.4460 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6943 - val_prc: 0.3755\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5581 - tp: 104.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 294.0000 - accuracy: 0.8172 - precision: 0.5778 - recall: 0.2613 - auc: 0.7317 - prc: 0.4532 - val_loss: 0.4453 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6937 - val_prc: 0.3745\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5590 - tp: 99.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 299.0000 - accuracy: 0.8162 - precision: 0.5756 - recall: 0.2487 - auc: 0.7300 - prc: 0.4451 - val_loss: 0.4480 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6903 - val_prc: 0.3757\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5589 - tp: 111.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 287.0000 - accuracy: 0.8207 - precision: 0.5936 - recall: 0.2789 - auc: 0.7292 - prc: 0.4541 - val_loss: 0.4292 - val_tp: 16.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 75.0000 - val_accuracy: 0.8320 - val_precision: 0.6154 - val_recall: 0.1758 - val_auc: 0.6958 - val_prc: 0.3833\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5591 - tp: 104.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 294.0000 - accuracy: 0.8152 - precision: 0.5652 - recall: 0.2613 - auc: 0.7284 - prc: 0.4561 - val_loss: 0.4394 - val_tp: 20.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 71.0000 - val_accuracy: 0.8281 - val_precision: 0.5556 - val_recall: 0.2198 - val_auc: 0.6938 - val_prc: 0.3797\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5569 - tp: 98.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 300.0000 - accuracy: 0.8177 - precision: 0.5868 - recall: 0.2462 - auc: 0.7312 - prc: 0.4658 - val_loss: 0.4606 - val_tp: 31.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 60.0000 - val_accuracy: 0.8241 - val_precision: 0.5167 - val_recall: 0.3407 - val_auc: 0.6915 - val_prc: 0.3807\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5580 - tp: 111.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 287.0000 - accuracy: 0.8182 - precision: 0.5781 - recall: 0.2789 - auc: 0.7296 - prc: 0.4562 - val_loss: 0.4347 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6931 - val_prc: 0.3799\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5573 - tp: 104.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 294.0000 - accuracy: 0.8167 - precision: 0.5746 - recall: 0.2613 - auc: 0.7309 - prc: 0.4590 - val_loss: 0.4352 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6921 - val_prc: 0.3855\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5580 - tp: 98.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 300.0000 - accuracy: 0.8187 - precision: 0.5939 - recall: 0.2462 - auc: 0.7311 - prc: 0.4608 - val_loss: 0.4403 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6902 - val_prc: 0.3814\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5582 - tp: 106.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 292.0000 - accuracy: 0.8192 - precision: 0.5889 - recall: 0.2663 - auc: 0.7297 - prc: 0.4592 - val_loss: 0.4395 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6890 - val_prc: 0.3793\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5563 - tp: 101.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 297.0000 - accuracy: 0.8177 - precision: 0.5838 - recall: 0.2538 - auc: 0.7340 - prc: 0.4492 - val_loss: 0.4517 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6910 - val_prc: 0.3758\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5576 - tp: 107.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 291.0000 - accuracy: 0.8172 - precision: 0.5753 - recall: 0.2688 - auc: 0.7329 - prc: 0.4527 - val_loss: 0.4481 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6902 - val_prc: 0.3734\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5560 - tp: 100.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 298.0000 - accuracy: 0.8197 - precision: 0.5988 - recall: 0.2513 - auc: 0.7328 - prc: 0.4577 - val_loss: 0.4599 - val_tp: 30.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 61.0000 - val_accuracy: 0.8221 - val_precision: 0.5085 - val_recall: 0.3297 - val_auc: 0.6880 - val_prc: 0.3741\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5575 - tp: 104.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 294.0000 - accuracy: 0.8162 - precision: 0.5714 - recall: 0.2613 - auc: 0.7333 - prc: 0.4481 - val_loss: 0.4402 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6906 - val_prc: 0.3781\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5571 - tp: 106.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 292.0000 - accuracy: 0.8142 - precision: 0.5579 - recall: 0.2663 - auc: 0.7298 - prc: 0.4592 - val_loss: 0.4426 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6905 - val_prc: 0.3740\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5569 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7309 - prc: 0.4591 - val_loss: 0.4375 - val_tp: 20.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 71.0000 - val_accuracy: 0.8300 - val_precision: 0.5714 - val_recall: 0.2198 - val_auc: 0.6929 - val_prc: 0.3743\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5563 - tp: 104.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 294.0000 - accuracy: 0.8216 - precision: 0.6082 - recall: 0.2613 - auc: 0.7333 - prc: 0.4511 - val_loss: 0.4385 - val_tp: 20.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 71.0000 - val_accuracy: 0.8281 - val_precision: 0.5556 - val_recall: 0.2198 - val_auc: 0.6903 - val_prc: 0.3765\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5551 - tp: 101.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 297.0000 - accuracy: 0.8207 - precision: 0.6048 - recall: 0.2538 - auc: 0.7333 - prc: 0.4594 - val_loss: 0.4586 - val_tp: 30.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 61.0000 - val_accuracy: 0.8241 - val_precision: 0.5172 - val_recall: 0.3297 - val_auc: 0.6872 - val_prc: 0.3721\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5557 - tp: 105.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 293.0000 - accuracy: 0.8172 - precision: 0.5769 - recall: 0.2638 - auc: 0.7327 - prc: 0.4625 - val_loss: 0.4442 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6918 - val_prc: 0.3778\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5565 - tp: 101.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 297.0000 - accuracy: 0.8162 - precision: 0.5739 - recall: 0.2538 - auc: 0.7318 - prc: 0.4562 - val_loss: 0.4446 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6927 - val_prc: 0.3789\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5559 - tp: 107.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 291.0000 - accuracy: 0.8197 - precision: 0.5912 - recall: 0.2688 - auc: 0.7323 - prc: 0.4726 - val_loss: 0.4489 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6870 - val_prc: 0.3724\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5557 - tp: 108.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 290.0000 - accuracy: 0.8192 - precision: 0.5870 - recall: 0.2714 - auc: 0.7326 - prc: 0.4644 - val_loss: 0.4360 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6926 - val_prc: 0.3753\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5548 - tp: 99.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 299.0000 - accuracy: 0.8167 - precision: 0.5789 - recall: 0.2487 - auc: 0.7344 - prc: 0.4611 - val_loss: 0.4490 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6907 - val_prc: 0.3727\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5572 - tp: 115.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 283.0000 - accuracy: 0.8192 - precision: 0.5808 - recall: 0.2889 - auc: 0.7298 - prc: 0.4534 - val_loss: 0.4393 - val_tp: 20.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 71.0000 - val_accuracy: 0.8300 - val_precision: 0.5714 - val_recall: 0.2198 - val_auc: 0.6899 - val_prc: 0.3753\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5546 - tp: 102.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 296.0000 - accuracy: 0.8216 - precision: 0.6108 - recall: 0.2563 - auc: 0.7358 - prc: 0.4642 - val_loss: 0.4609 - val_tp: 30.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 61.0000 - val_accuracy: 0.8241 - val_precision: 0.5172 - val_recall: 0.3297 - val_auc: 0.6893 - val_prc: 0.3753\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5554 - tp: 109.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 289.0000 - accuracy: 0.8202 - precision: 0.5924 - recall: 0.2739 - auc: 0.7326 - prc: 0.4596 - val_loss: 0.4555 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6897 - val_prc: 0.3711\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5573 - tp: 117.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 281.0000 - accuracy: 0.8182 - precision: 0.5735 - recall: 0.2940 - auc: 0.7305 - prc: 0.4599 - val_loss: 0.4346 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6912 - val_prc: 0.3754\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5542 - tp: 109.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 289.0000 - accuracy: 0.8202 - precision: 0.5924 - recall: 0.2739 - auc: 0.7352 - prc: 0.4587 - val_loss: 0.4465 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6878 - val_prc: 0.3738\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5552 - tp: 100.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 298.0000 - accuracy: 0.8211 - precision: 0.6098 - recall: 0.2513 - auc: 0.7324 - prc: 0.4630 - val_loss: 0.4606 - val_tp: 30.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 61.0000 - val_accuracy: 0.8241 - val_precision: 0.5172 - val_recall: 0.3297 - val_auc: 0.6865 - val_prc: 0.3743\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5554 - tp: 111.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 287.0000 - accuracy: 0.8187 - precision: 0.5812 - recall: 0.2789 - auc: 0.7314 - prc: 0.4647 - val_loss: 0.4486 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6881 - val_prc: 0.3747\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5551 - tp: 115.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 283.0000 - accuracy: 0.8182 - precision: 0.5750 - recall: 0.2889 - auc: 0.7324 - prc: 0.4616 - val_loss: 0.4306 - val_tp: 16.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 75.0000 - val_accuracy: 0.8281 - val_precision: 0.5714 - val_recall: 0.1758 - val_auc: 0.6898 - val_prc: 0.3778\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5538 - tp: 101.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 297.0000 - accuracy: 0.8192 - precision: 0.5941 - recall: 0.2538 - auc: 0.7340 - prc: 0.4653 - val_loss: 0.4424 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6913 - val_prc: 0.3743\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5552 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7314 - prc: 0.4592 - val_loss: 0.4455 - val_tp: 20.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 71.0000 - val_accuracy: 0.8162 - val_precision: 0.4762 - val_recall: 0.2198 - val_auc: 0.6917 - val_prc: 0.3710\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5559 - tp: 108.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 290.0000 - accuracy: 0.8197 - precision: 0.5902 - recall: 0.2714 - auc: 0.7314 - prc: 0.4615 - val_loss: 0.4478 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6908 - val_prc: 0.3762\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5532 - tp: 107.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 291.0000 - accuracy: 0.8202 - precision: 0.5944 - recall: 0.2688 - auc: 0.7359 - prc: 0.4620 - val_loss: 0.4654 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6896 - val_prc: 0.3699\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5587 - tp: 131.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 267.0000 - accuracy: 0.8207 - precision: 0.5771 - recall: 0.3291 - auc: 0.7281 - prc: 0.4513 - val_loss: 0.4350 - val_tp: 17.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 74.0000 - val_accuracy: 0.8241 - val_precision: 0.5312 - val_recall: 0.1868 - val_auc: 0.6932 - val_prc: 0.3814\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5545 - tp: 104.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 294.0000 - accuracy: 0.8172 - precision: 0.5778 - recall: 0.2613 - auc: 0.7349 - prc: 0.4596 - val_loss: 0.4538 - val_tp: 28.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 63.0000 - val_accuracy: 0.8261 - val_precision: 0.5283 - val_recall: 0.3077 - val_auc: 0.6898 - val_prc: 0.3723\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5537 - tp: 116.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 282.0000 - accuracy: 0.8167 - precision: 0.5659 - recall: 0.2915 - auc: 0.7356 - prc: 0.4593 - val_loss: 0.4330 - val_tp: 17.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 74.0000 - val_accuracy: 0.8281 - val_precision: 0.5667 - val_recall: 0.1868 - val_auc: 0.6913 - val_prc: 0.3834\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5552 - tp: 104.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 294.0000 - accuracy: 0.8187 - precision: 0.5876 - recall: 0.2613 - auc: 0.7327 - prc: 0.4645 - val_loss: 0.4468 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6905 - val_prc: 0.3766\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5543 - tp: 105.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 293.0000 - accuracy: 0.8192 - precision: 0.5899 - recall: 0.2638 - auc: 0.7344 - prc: 0.4654 - val_loss: 0.4600 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 61.0000 - val_accuracy: 0.8261 - val_precision: 0.5263 - val_recall: 0.3297 - val_auc: 0.6896 - val_prc: 0.3760\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5532 - tp: 110.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 288.0000 - accuracy: 0.8172 - precision: 0.5729 - recall: 0.2764 - auc: 0.7366 - prc: 0.4636 - val_loss: 0.4424 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6911 - val_prc: 0.3760\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5547 - tp: 106.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 292.0000 - accuracy: 0.8172 - precision: 0.5761 - recall: 0.2663 - auc: 0.7333 - prc: 0.4598 - val_loss: 0.4497 - val_tp: 22.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 69.0000 - val_accuracy: 0.8142 - val_precision: 0.4681 - val_recall: 0.2418 - val_auc: 0.6904 - val_prc: 0.3679\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5532 - tp: 107.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 291.0000 - accuracy: 0.8211 - precision: 0.6011 - recall: 0.2688 - auc: 0.7337 - prc: 0.4637 - val_loss: 0.4488 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6889 - val_prc: 0.3737\n",
      "Epoch 147/500\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 0.5597 - tp: 100.0000 - fp: 77.0000 - tn: 1396.0000 - fn: 267.0000 - accuracy: 0.8130 - precision: 0.5650 - recall: 0.2725 - auc: 0.7349 - prc: 0.4516Restoring model weights from the end of the best epoch: 97.\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5534 - tp: 109.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 289.0000 - accuracy: 0.8172 - precision: 0.5737 - recall: 0.2739 - auc: 0.7366 - prc: 0.4574 - val_loss: 0.4352 - val_tp: 17.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 74.0000 - val_accuracy: 0.8261 - val_precision: 0.5484 - val_recall: 0.1868 - val_auc: 0.6913 - val_prc: 0.3836\n",
      "Epoch 147: early stopping\n",
      "26/26 [==============================] - 0s 543us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.8124 - tp: 17.0000 - fp: 14.0000 - tn: 2027.0000 - fn: 472.0000 - accuracy: 0.8079 - precision: 0.5484 - recall: 0.0348 - auc: 0.5333 - prc: 0.2393 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8020 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4845 - prc: 0.1868 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7937 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5019 - prc: 0.1974 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7866 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4856 - prc: 0.1914 - val_loss: 0.4809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5298 - prc: 0.2095 - val_loss: 0.4840 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5096 - val_prc: 0.1827\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7757 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5158 - prc: 0.2039 - val_loss: 0.4874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7717 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5011 - prc: 0.1973 - val_loss: 0.4908 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5086 - prc: 0.2041 - val_loss: 0.4944 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7658 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4915 - prc: 0.1926 - val_loss: 0.4981 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7639 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4964 - prc: 0.1953 - val_loss: 0.5009 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5084 - val_prc: 0.1824\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7624 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5041 - prc: 0.1981 - val_loss: 0.5031 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5228 - val_prc: 0.1948\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7603 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5614 - prc: 0.2237 - val_loss: 0.5006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6326 - val_prc: 0.2750\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7571 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6250 - prc: 0.2706 - val_loss: 0.5020 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6240 - val_prc: 0.2400\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7529 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6476 - prc: 0.2987 - val_loss: 0.4966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6486 - val_prc: 0.2665\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7480 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6650 - prc: 0.3207 - val_loss: 0.4861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6665 - val_prc: 0.3080\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7440 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6635 - prc: 0.3215 - val_loss: 0.4850 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6700 - val_prc: 0.3087\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7400 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6750 - prc: 0.3391 - val_loss: 0.5056 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6302 - val_prc: 0.2397\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7363 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6724 - prc: 0.3358 - val_loss: 0.4883 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6757 - val_prc: 0.2969\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6835 - prc: 0.3414 - val_loss: 0.4616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6849 - val_prc: 0.3577\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7270 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6890 - prc: 0.3350 - val_loss: 0.4706 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6818 - val_prc: 0.3257\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7242 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6864 - prc: 0.3387 - val_loss: 0.4766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6801 - val_prc: 0.3176\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7198 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6949 - prc: 0.3487 - val_loss: 0.4687 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6823 - val_prc: 0.3211\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7163 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6948 - prc: 0.3452 - val_loss: 0.4505 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6873 - val_prc: 0.3644\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7150 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6956 - prc: 0.3430 - val_loss: 0.4702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6809 - val_prc: 0.3169\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7133 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6927 - prc: 0.3347 - val_loss: 0.4903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6708 - val_prc: 0.2893\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7141 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6841 - prc: 0.3195 - val_loss: 0.4912 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6700 - val_prc: 0.2904\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7094 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7007 - prc: 0.3698 - val_loss: 0.5153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6613 - val_prc: 0.2748\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6863 - prc: 0.3199 - val_loss: 0.4685 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6848 - val_prc: 0.3283\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7036 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7043 - prc: 0.3568 - val_loss: 0.4749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6829 - val_prc: 0.3286\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7030 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7058 - prc: 0.3837 - val_loss: 0.4749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6808 - val_prc: 0.3231\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7023 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7017 - prc: 0.3461 - val_loss: 0.4983 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6736 - val_prc: 0.2983\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7004 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7019 - prc: 0.3484 - val_loss: 0.4575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6873 - val_prc: 0.3508\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6996 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7071 - prc: 0.3813 - val_loss: 0.4925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6800 - val_prc: 0.3122\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6974 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7042 - prc: 0.3583 - val_loss: 0.4763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6841 - val_prc: 0.3323\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6963 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7056 - prc: 0.3630 - val_loss: 0.4673 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6860 - val_prc: 0.3393\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7138 - prc: 0.3850 - val_loss: 0.4570 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6871 - val_prc: 0.3496\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7071 - prc: 0.3775 - val_loss: 0.4592 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6907 - val_prc: 0.3521\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6923 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7124 - prc: 0.3836 - val_loss: 0.4757 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6887 - val_prc: 0.3396\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6894 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7145 - prc: 0.3867 - val_loss: 0.4597 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6954 - val_prc: 0.3601\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7127 - prc: 0.3931 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6924 - val_prc: 0.3565\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6892 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7130 - prc: 0.4021 - val_loss: 0.4663 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6923 - val_prc: 0.3526\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6880 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7143 - prc: 0.4088 - val_loss: 0.5000 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6897 - val_prc: 0.3317\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6856 - tp: 32.0000 - fp: 21.0000 - tn: 1605.0000 - fn: 366.0000 - accuracy: 0.8088 - precision: 0.6038 - recall: 0.0804 - auc: 0.7172 - prc: 0.4025 - val_loss: 0.4893 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6905 - val_prc: 0.3403\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6841 - tp: 133.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 265.0000 - accuracy: 0.8098 - precision: 0.5257 - recall: 0.3342 - auc: 0.7194 - prc: 0.3981 - val_loss: 0.4481 - val_tp: 16.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 75.0000 - val_accuracy: 0.8261 - val_precision: 0.5517 - val_recall: 0.1758 - val_auc: 0.6991 - val_prc: 0.3746\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6847 - tp: 105.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 293.0000 - accuracy: 0.8162 - precision: 0.5707 - recall: 0.2638 - auc: 0.7174 - prc: 0.4094 - val_loss: 0.4687 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6948 - val_prc: 0.3600\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6821 - tp: 111.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 287.0000 - accuracy: 0.8063 - precision: 0.5139 - recall: 0.2789 - auc: 0.7190 - prc: 0.3968 - val_loss: 0.4696 - val_tp: 27.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 64.0000 - val_accuracy: 0.8261 - val_precision: 0.5294 - val_recall: 0.2967 - val_auc: 0.6979 - val_prc: 0.3647\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6820 - tp: 125.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 273.0000 - accuracy: 0.8182 - precision: 0.5682 - recall: 0.3141 - auc: 0.7182 - prc: 0.4193 - val_loss: 0.4566 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.6990 - val_prc: 0.3729\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6797 - tp: 116.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 282.0000 - accuracy: 0.8137 - precision: 0.5498 - recall: 0.2915 - auc: 0.7218 - prc: 0.4164 - val_loss: 0.4700 - val_tp: 27.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 64.0000 - val_accuracy: 0.8241 - val_precision: 0.5192 - val_recall: 0.2967 - val_auc: 0.6967 - val_prc: 0.3645\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6813 - tp: 114.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 284.0000 - accuracy: 0.8098 - precision: 0.5302 - recall: 0.2864 - auc: 0.7189 - prc: 0.4055 - val_loss: 0.4890 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6970 - val_prc: 0.3662\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6799 - tp: 111.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 287.0000 - accuracy: 0.8152 - precision: 0.5606 - recall: 0.2789 - auc: 0.7202 - prc: 0.4145 - val_loss: 0.4831 - val_tp: 29.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 62.0000 - val_accuracy: 0.8083 - val_precision: 0.4531 - val_recall: 0.3187 - val_auc: 0.6965 - val_prc: 0.3657\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6788 - tp: 116.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 282.0000 - accuracy: 0.8118 - precision: 0.5395 - recall: 0.2915 - auc: 0.7212 - prc: 0.4188 - val_loss: 0.4760 - val_tp: 30.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 61.0000 - val_accuracy: 0.8221 - val_precision: 0.5085 - val_recall: 0.3297 - val_auc: 0.6979 - val_prc: 0.3656\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6791 - tp: 121.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 277.0000 - accuracy: 0.8103 - precision: 0.5307 - recall: 0.3040 - auc: 0.7197 - prc: 0.4098 - val_loss: 0.4782 - val_tp: 29.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 62.0000 - val_accuracy: 0.8162 - val_precision: 0.4833 - val_recall: 0.3187 - val_auc: 0.6953 - val_prc: 0.3622\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6792 - tp: 123.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 275.0000 - accuracy: 0.8132 - precision: 0.5442 - recall: 0.3090 - auc: 0.7175 - prc: 0.4159 - val_loss: 0.4521 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.7004 - val_prc: 0.3717\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6776 - tp: 122.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 276.0000 - accuracy: 0.8078 - precision: 0.5191 - recall: 0.3065 - auc: 0.7201 - prc: 0.4092 - val_loss: 0.4781 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6954 - val_prc: 0.3578\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6756 - tp: 128.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 270.0000 - accuracy: 0.8078 - precision: 0.5182 - recall: 0.3216 - auc: 0.7221 - prc: 0.4066 - val_loss: 0.4664 - val_tp: 29.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 62.0000 - val_accuracy: 0.8241 - val_precision: 0.5179 - val_recall: 0.3187 - val_auc: 0.6961 - val_prc: 0.3641\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6747 - tp: 115.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 283.0000 - accuracy: 0.8103 - precision: 0.5324 - recall: 0.2889 - auc: 0.7251 - prc: 0.3994 - val_loss: 0.4931 - val_tp: 35.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 56.0000 - val_accuracy: 0.7925 - val_precision: 0.4167 - val_recall: 0.3846 - val_auc: 0.6964 - val_prc: 0.3609\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6745 - tp: 138.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 260.0000 - accuracy: 0.8108 - precision: 0.5287 - recall: 0.3467 - auc: 0.7234 - prc: 0.4033 - val_loss: 0.4759 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6986 - val_prc: 0.3686\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6729 - tp: 133.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 265.0000 - accuracy: 0.8132 - precision: 0.5407 - recall: 0.3342 - auc: 0.7237 - prc: 0.4074 - val_loss: 0.4889 - val_tp: 33.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 58.0000 - val_accuracy: 0.7964 - val_precision: 0.4231 - val_recall: 0.3626 - val_auc: 0.6971 - val_prc: 0.3641\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6738 - tp: 142.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 256.0000 - accuracy: 0.8078 - precision: 0.5164 - recall: 0.3568 - auc: 0.7237 - prc: 0.4257 - val_loss: 0.4619 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6987 - val_prc: 0.3723\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6716 - tp: 135.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 263.0000 - accuracy: 0.8063 - precision: 0.5114 - recall: 0.3392 - auc: 0.7280 - prc: 0.4192 - val_loss: 0.4415 - val_tp: 18.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 73.0000 - val_accuracy: 0.8261 - val_precision: 0.5455 - val_recall: 0.1978 - val_auc: 0.7016 - val_prc: 0.3870\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6722 - tp: 123.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 275.0000 - accuracy: 0.8088 - precision: 0.5234 - recall: 0.3090 - auc: 0.7253 - prc: 0.4170 - val_loss: 0.5016 - val_tp: 38.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 53.0000 - val_accuracy: 0.7925 - val_precision: 0.4222 - val_recall: 0.4176 - val_auc: 0.6968 - val_prc: 0.3587\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6688 - tp: 142.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 256.0000 - accuracy: 0.8073 - precision: 0.5145 - recall: 0.3568 - auc: 0.7299 - prc: 0.4267 - val_loss: 0.4440 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6999 - val_prc: 0.3875\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6714 - tp: 131.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 267.0000 - accuracy: 0.8123 - precision: 0.5369 - recall: 0.3291 - auc: 0.7245 - prc: 0.4214 - val_loss: 0.4721 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6965 - val_prc: 0.3564\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6715 - tp: 136.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 262.0000 - accuracy: 0.8118 - precision: 0.5333 - recall: 0.3417 - auc: 0.7255 - prc: 0.4286 - val_loss: 0.4711 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6987 - val_prc: 0.3639\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6704 - tp: 137.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 261.0000 - accuracy: 0.8142 - precision: 0.5437 - recall: 0.3442 - auc: 0.7249 - prc: 0.4241 - val_loss: 0.4800 - val_tp: 33.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 58.0000 - val_accuracy: 0.8024 - val_precision: 0.4400 - val_recall: 0.3626 - val_auc: 0.6992 - val_prc: 0.3670\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6696 - tp: 148.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 250.0000 - accuracy: 0.8068 - precision: 0.5121 - recall: 0.3719 - auc: 0.7263 - prc: 0.4246 - val_loss: 0.4598 - val_tp: 29.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 62.0000 - val_accuracy: 0.8241 - val_precision: 0.5179 - val_recall: 0.3187 - val_auc: 0.6986 - val_prc: 0.3738\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6691 - tp: 141.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 257.0000 - accuracy: 0.8113 - precision: 0.5301 - recall: 0.3543 - auc: 0.7260 - prc: 0.4177 - val_loss: 0.4820 - val_tp: 34.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 57.0000 - val_accuracy: 0.7964 - val_precision: 0.4250 - val_recall: 0.3736 - val_auc: 0.6970 - val_prc: 0.3651\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6705 - tp: 130.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 268.0000 - accuracy: 0.8053 - precision: 0.5078 - recall: 0.3266 - auc: 0.7247 - prc: 0.4214 - val_loss: 0.4676 - val_tp: 30.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 61.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3297 - val_auc: 0.6964 - val_prc: 0.3649\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6706 - tp: 148.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 250.0000 - accuracy: 0.8073 - precision: 0.5139 - recall: 0.3719 - auc: 0.7242 - prc: 0.4101 - val_loss: 0.4728 - val_tp: 31.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 60.0000 - val_accuracy: 0.8083 - val_precision: 0.4559 - val_recall: 0.3407 - val_auc: 0.6982 - val_prc: 0.3667\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6679 - tp: 139.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 259.0000 - accuracy: 0.8068 - precision: 0.5129 - recall: 0.3492 - auc: 0.7279 - prc: 0.4223 - val_loss: 0.4748 - val_tp: 32.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 59.0000 - val_accuracy: 0.8083 - val_precision: 0.4571 - val_recall: 0.3516 - val_auc: 0.6972 - val_prc: 0.3627\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6671 - tp: 145.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 253.0000 - accuracy: 0.8098 - precision: 0.5235 - recall: 0.3643 - auc: 0.7290 - prc: 0.4226 - val_loss: 0.5056 - val_tp: 39.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 52.0000 - val_accuracy: 0.7885 - val_precision: 0.4149 - val_recall: 0.4286 - val_auc: 0.6956 - val_prc: 0.3609\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6690 - tp: 145.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 253.0000 - accuracy: 0.8073 - precision: 0.5142 - recall: 0.3643 - auc: 0.7257 - prc: 0.4209 - val_loss: 0.4708 - val_tp: 31.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 60.0000 - val_accuracy: 0.8103 - val_precision: 0.4627 - val_recall: 0.3407 - val_auc: 0.6995 - val_prc: 0.3741\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6679 - tp: 143.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 255.0000 - accuracy: 0.8123 - precision: 0.5336 - recall: 0.3593 - auc: 0.7270 - prc: 0.4276 - val_loss: 0.4620 - val_tp: 30.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 61.0000 - val_accuracy: 0.8241 - val_precision: 0.5172 - val_recall: 0.3297 - val_auc: 0.6998 - val_prc: 0.3800\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6655 - tp: 142.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 256.0000 - accuracy: 0.8132 - precision: 0.5379 - recall: 0.3568 - auc: 0.7310 - prc: 0.4230 - val_loss: 0.4957 - val_tp: 36.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 55.0000 - val_accuracy: 0.7925 - val_precision: 0.4186 - val_recall: 0.3956 - val_auc: 0.6958 - val_prc: 0.3702\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6671 - tp: 151.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 247.0000 - accuracy: 0.7999 - precision: 0.4887 - recall: 0.3794 - auc: 0.7278 - prc: 0.4171 - val_loss: 0.4635 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6993 - val_prc: 0.3754\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6657 - tp: 144.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 254.0000 - accuracy: 0.8103 - precision: 0.5255 - recall: 0.3618 - auc: 0.7293 - prc: 0.4332 - val_loss: 0.4647 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6971 - val_prc: 0.3723\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6646 - tp: 145.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 253.0000 - accuracy: 0.8063 - precision: 0.5106 - recall: 0.3643 - auc: 0.7301 - prc: 0.4246 - val_loss: 0.4520 - val_tp: 26.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 65.0000 - val_accuracy: 0.8261 - val_precision: 0.5306 - val_recall: 0.2857 - val_auc: 0.7005 - val_prc: 0.3870\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6649 - tp: 150.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 248.0000 - accuracy: 0.8118 - precision: 0.5300 - recall: 0.3769 - auc: 0.7300 - prc: 0.4262 - val_loss: 0.4561 - val_tp: 30.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 61.0000 - val_accuracy: 0.8281 - val_precision: 0.5357 - val_recall: 0.3297 - val_auc: 0.6976 - val_prc: 0.3793\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6643 - tp: 137.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 261.0000 - accuracy: 0.8024 - precision: 0.4964 - recall: 0.3442 - auc: 0.7332 - prc: 0.4344 - val_loss: 0.4544 - val_tp: 30.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 61.0000 - val_accuracy: 0.8300 - val_precision: 0.5455 - val_recall: 0.3297 - val_auc: 0.6987 - val_prc: 0.3814\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6643 - tp: 148.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 250.0000 - accuracy: 0.8088 - precision: 0.5193 - recall: 0.3719 - auc: 0.7322 - prc: 0.4297 - val_loss: 0.4651 - val_tp: 32.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 59.0000 - val_accuracy: 0.8182 - val_precision: 0.4923 - val_recall: 0.3516 - val_auc: 0.6983 - val_prc: 0.3759\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6641 - tp: 149.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 249.0000 - accuracy: 0.8048 - precision: 0.5051 - recall: 0.3744 - auc: 0.7309 - prc: 0.4160 - val_loss: 0.4643 - val_tp: 32.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 59.0000 - val_accuracy: 0.8221 - val_precision: 0.5079 - val_recall: 0.3516 - val_auc: 0.6960 - val_prc: 0.3759\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6656 - tp: 150.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 248.0000 - accuracy: 0.8108 - precision: 0.5263 - recall: 0.3769 - auc: 0.7280 - prc: 0.4326 - val_loss: 0.4764 - val_tp: 33.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 58.0000 - val_accuracy: 0.8024 - val_precision: 0.4400 - val_recall: 0.3626 - val_auc: 0.6973 - val_prc: 0.3677\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6612 - tp: 151.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 247.0000 - accuracy: 0.8123 - precision: 0.5317 - recall: 0.3794 - auc: 0.7328 - prc: 0.4286 - val_loss: 0.4468 - val_tp: 22.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 69.0000 - val_accuracy: 0.8221 - val_precision: 0.5116 - val_recall: 0.2418 - val_auc: 0.7003 - val_prc: 0.3777\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6643 - tp: 140.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 258.0000 - accuracy: 0.8098 - precision: 0.5243 - recall: 0.3518 - auc: 0.7304 - prc: 0.4205 - val_loss: 0.4937 - val_tp: 37.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 54.0000 - val_accuracy: 0.7945 - val_precision: 0.4253 - val_recall: 0.4066 - val_auc: 0.6972 - val_prc: 0.3666\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6638 - tp: 146.0000 - fp: 152.0000 - tn: 1474.0000 - fn: 252.0000 - accuracy: 0.8004 - precision: 0.4899 - recall: 0.3668 - auc: 0.7326 - prc: 0.4316 - val_loss: 0.4422 - val_tp: 21.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 70.0000 - val_accuracy: 0.8241 - val_precision: 0.5250 - val_recall: 0.2308 - val_auc: 0.7011 - val_prc: 0.3842\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6659 - tp: 142.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 256.0000 - accuracy: 0.8073 - precision: 0.5145 - recall: 0.3568 - auc: 0.7270 - prc: 0.4296 - val_loss: 0.4574 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 61.0000 - val_accuracy: 0.8261 - val_precision: 0.5263 - val_recall: 0.3297 - val_auc: 0.6966 - val_prc: 0.3792\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6633 - tp: 145.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 253.0000 - accuracy: 0.8202 - precision: 0.5664 - recall: 0.3643 - auc: 0.7296 - prc: 0.4414 - val_loss: 0.4771 - val_tp: 34.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 57.0000 - val_accuracy: 0.8083 - val_precision: 0.4595 - val_recall: 0.3736 - val_auc: 0.6978 - val_prc: 0.3746\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6628 - tp: 139.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 259.0000 - accuracy: 0.8078 - precision: 0.5167 - recall: 0.3492 - auc: 0.7311 - prc: 0.4398 - val_loss: 0.4651 - val_tp: 32.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 59.0000 - val_accuracy: 0.8221 - val_precision: 0.5079 - val_recall: 0.3516 - val_auc: 0.6961 - val_prc: 0.3782\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6630 - tp: 149.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 249.0000 - accuracy: 0.8083 - precision: 0.5174 - recall: 0.3744 - auc: 0.7302 - prc: 0.4399 - val_loss: 0.4532 - val_tp: 26.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 65.0000 - val_accuracy: 0.8241 - val_precision: 0.5200 - val_recall: 0.2857 - val_auc: 0.6996 - val_prc: 0.3828\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6632 - tp: 139.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 259.0000 - accuracy: 0.8137 - precision: 0.5409 - recall: 0.3492 - auc: 0.7299 - prc: 0.4434 - val_loss: 0.4660 - val_tp: 33.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 58.0000 - val_accuracy: 0.8221 - val_precision: 0.5077 - val_recall: 0.3626 - val_auc: 0.6966 - val_prc: 0.3807\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6612 - tp: 142.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 256.0000 - accuracy: 0.8063 - precision: 0.5108 - recall: 0.3568 - auc: 0.7333 - prc: 0.4343 - val_loss: 0.4676 - val_tp: 33.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 58.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3626 - val_auc: 0.6984 - val_prc: 0.3836\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6605 - tp: 150.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 248.0000 - accuracy: 0.8132 - precision: 0.5357 - recall: 0.3769 - auc: 0.7326 - prc: 0.4397 - val_loss: 0.4572 - val_tp: 30.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 61.0000 - val_accuracy: 0.8241 - val_precision: 0.5172 - val_recall: 0.3297 - val_auc: 0.6995 - val_prc: 0.3849\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6623 - tp: 139.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 259.0000 - accuracy: 0.8113 - precision: 0.5305 - recall: 0.3492 - auc: 0.7300 - prc: 0.4419 - val_loss: 0.4695 - val_tp: 33.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 58.0000 - val_accuracy: 0.8182 - val_precision: 0.4925 - val_recall: 0.3626 - val_auc: 0.6963 - val_prc: 0.3829\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6607 - tp: 147.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 251.0000 - accuracy: 0.8147 - precision: 0.5424 - recall: 0.3693 - auc: 0.7320 - prc: 0.4490 - val_loss: 0.4587 - val_tp: 28.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 63.0000 - val_accuracy: 0.8241 - val_precision: 0.5185 - val_recall: 0.3077 - val_auc: 0.7001 - val_prc: 0.3822\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6617 - tp: 137.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 261.0000 - accuracy: 0.8073 - precision: 0.5150 - recall: 0.3442 - auc: 0.7330 - prc: 0.4437 - val_loss: 0.4837 - val_tp: 34.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 57.0000 - val_accuracy: 0.8004 - val_precision: 0.4359 - val_recall: 0.3736 - val_auc: 0.6975 - val_prc: 0.3788\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6597 - tp: 147.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 251.0000 - accuracy: 0.8118 - precision: 0.5307 - recall: 0.3693 - auc: 0.7330 - prc: 0.4487 - val_loss: 0.4784 - val_tp: 34.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 57.0000 - val_accuracy: 0.8103 - val_precision: 0.4658 - val_recall: 0.3736 - val_auc: 0.6965 - val_prc: 0.3780\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6598 - tp: 142.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 256.0000 - accuracy: 0.8088 - precision: 0.5201 - recall: 0.3568 - auc: 0.7342 - prc: 0.4424 - val_loss: 0.4697 - val_tp: 33.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 58.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3626 - val_auc: 0.6958 - val_prc: 0.3808\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6601 - tp: 134.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 264.0000 - accuracy: 0.8108 - precision: 0.5296 - recall: 0.3367 - auc: 0.7340 - prc: 0.4570 - val_loss: 0.5008 - val_tp: 36.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 55.0000 - val_accuracy: 0.7846 - val_precision: 0.4000 - val_recall: 0.3956 - val_auc: 0.6961 - val_prc: 0.3704\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6604 - tp: 141.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 257.0000 - accuracy: 0.8068 - precision: 0.5127 - recall: 0.3543 - auc: 0.7344 - prc: 0.4456 - val_loss: 0.4875 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6953 - val_prc: 0.3801\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6595 - tp: 153.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 245.0000 - accuracy: 0.8093 - precision: 0.5204 - recall: 0.3844 - auc: 0.7346 - prc: 0.4550 - val_loss: 0.4576 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 62.0000 - val_accuracy: 0.8221 - val_precision: 0.5088 - val_recall: 0.3187 - val_auc: 0.6959 - val_prc: 0.3793\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6624 - tp: 132.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 266.0000 - accuracy: 0.8098 - precision: 0.5259 - recall: 0.3317 - auc: 0.7328 - prc: 0.4413 - val_loss: 0.4677 - val_tp: 33.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 58.0000 - val_accuracy: 0.8221 - val_precision: 0.5077 - val_recall: 0.3626 - val_auc: 0.6949 - val_prc: 0.3818\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6614 - tp: 144.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 254.0000 - accuracy: 0.8078 - precision: 0.5161 - recall: 0.3618 - auc: 0.7317 - prc: 0.4425 - val_loss: 0.4781 - val_tp: 34.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 57.0000 - val_accuracy: 0.8123 - val_precision: 0.4722 - val_recall: 0.3736 - val_auc: 0.6958 - val_prc: 0.3792\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6605 - tp: 141.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 257.0000 - accuracy: 0.8098 - precision: 0.5242 - recall: 0.3543 - auc: 0.7339 - prc: 0.4405 - val_loss: 0.4713 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6975 - val_prc: 0.3855\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6580 - tp: 140.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 258.0000 - accuracy: 0.8137 - precision: 0.5405 - recall: 0.3518 - auc: 0.7362 - prc: 0.4520 - val_loss: 0.4902 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6960 - val_prc: 0.3740\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6586 - tp: 141.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 257.0000 - accuracy: 0.8103 - precision: 0.5261 - recall: 0.3543 - auc: 0.7343 - prc: 0.4510 - val_loss: 0.4870 - val_tp: 34.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 57.0000 - val_accuracy: 0.8004 - val_precision: 0.4359 - val_recall: 0.3736 - val_auc: 0.6968 - val_prc: 0.3809\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6574 - tp: 148.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 250.0000 - accuracy: 0.8137 - precision: 0.5382 - recall: 0.3719 - auc: 0.7360 - prc: 0.4554 - val_loss: 0.4614 - val_tp: 31.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 60.0000 - val_accuracy: 0.8261 - val_precision: 0.5254 - val_recall: 0.3407 - val_auc: 0.6969 - val_prc: 0.3801\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6591 - tp: 149.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 249.0000 - accuracy: 0.8113 - precision: 0.5284 - recall: 0.3744 - auc: 0.7349 - prc: 0.4443 - val_loss: 0.4727 - val_tp: 33.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 58.0000 - val_accuracy: 0.8142 - val_precision: 0.4783 - val_recall: 0.3626 - val_auc: 0.6974 - val_prc: 0.3859\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6607 - tp: 152.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 246.0000 - accuracy: 0.8048 - precision: 0.5050 - recall: 0.3819 - auc: 0.7335 - prc: 0.4307 - val_loss: 0.4763 - val_tp: 34.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 57.0000 - val_accuracy: 0.8123 - val_precision: 0.4722 - val_recall: 0.3736 - val_auc: 0.6967 - val_prc: 0.3791\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6573 - tp: 143.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 255.0000 - accuracy: 0.8103 - precision: 0.5257 - recall: 0.3593 - auc: 0.7363 - prc: 0.4474 - val_loss: 0.4778 - val_tp: 34.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 57.0000 - val_accuracy: 0.8103 - val_precision: 0.4658 - val_recall: 0.3736 - val_auc: 0.6968 - val_prc: 0.3789\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6565 - tp: 143.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 255.0000 - accuracy: 0.8118 - precision: 0.5316 - recall: 0.3593 - auc: 0.7369 - prc: 0.4523 - val_loss: 0.5122 - val_tp: 39.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 52.0000 - val_accuracy: 0.7747 - val_precision: 0.3861 - val_recall: 0.4286 - val_auc: 0.6950 - val_prc: 0.3746\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6591 - tp: 159.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 239.0000 - accuracy: 0.8083 - precision: 0.5162 - recall: 0.3995 - auc: 0.7358 - prc: 0.4344 - val_loss: 0.4612 - val_tp: 32.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 59.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3516 - val_auc: 0.6952 - val_prc: 0.3781\n",
      "Epoch 112/500\n",
      " 93/102 [==========================>...] - ETA: 0s - loss: 0.6604 - tp: 131.0000 - fp: 114.0000 - tn: 1382.0000 - fn: 233.0000 - accuracy: 0.8134 - precision: 0.5347 - recall: 0.3599 - auc: 0.7297 - prc: 0.4484Restoring model weights from the end of the best epoch: 62.\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6583 - tp: 145.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 253.0000 - accuracy: 0.8152 - precision: 0.5451 - recall: 0.3643 - auc: 0.7342 - prc: 0.4615 - val_loss: 0.4771 - val_tp: 35.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 56.0000 - val_accuracy: 0.8123 - val_precision: 0.4730 - val_recall: 0.3846 - val_auc: 0.6965 - val_prc: 0.3845\n",
      "Epoch 112: early stopping\n",
      "26/26 [==============================] - 0s 584us/step\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 4ms/step - loss: 0.9723 - tp: 35.0000 - fp: 39.0000 - tn: 2002.0000 - fn: 454.0000 - accuracy: 0.8051 - precision: 0.4730 - recall: 0.0716 - auc: 0.4961 - prc: 0.2269 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4926 - val_prc: 0.1777\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9545 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5170 - prc: 0.2041 - val_loss: 0.4756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4909 - prc: 0.1925 - val_loss: 0.4787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9263 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5147 - prc: 0.2063 - val_loss: 0.4823 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9148 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.2024 - val_loss: 0.4865 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9052 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4903 - prc: 0.1945 - val_loss: 0.4911 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4843 - prc: 0.1873 - val_loss: 0.4959 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8900 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5072 - prc: 0.2036 - val_loss: 0.5007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8840 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5125 - prc: 0.2015 - val_loss: 0.5058 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5053 - prc: 0.1988 - val_loss: 0.5110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8747 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5104 - prc: 0.1971 - val_loss: 0.5165 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8715 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5141 - prc: 0.2049 - val_loss: 0.5211 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4937 - prc: 0.1933 - val_loss: 0.5256 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8668 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5024 - prc: 0.1973 - val_loss: 0.5298 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8652 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5190 - prc: 0.2143 - val_loss: 0.5332 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8639 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5050 - prc: 0.1986 - val_loss: 0.5376 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8629 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5024 - prc: 0.1970 - val_loss: 0.5406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5157 - val_prc: 0.1846\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8620 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5047 - prc: 0.1961 - val_loss: 0.5439 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5248 - val_prc: 0.1876\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8607 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5361 - prc: 0.2097 - val_loss: 0.5412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5709 - val_prc: 0.2061\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8591 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5621 - prc: 0.2245 - val_loss: 0.5425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5981 - val_prc: 0.2190\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8550 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6146 - prc: 0.2764 - val_loss: 0.5343 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6283 - val_prc: 0.2427\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8496 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6367 - prc: 0.2787 - val_loss: 0.5252 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6505 - val_prc: 0.2654\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8432 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6593 - prc: 0.3179 - val_loss: 0.5049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6683 - val_prc: 0.3379\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6535 - prc: 0.3024 - val_loss: 0.5189 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6653 - val_prc: 0.2811\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8323 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6740 - prc: 0.3282 - val_loss: 0.5044 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6784 - val_prc: 0.3146\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8286 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6687 - prc: 0.3014 - val_loss: 0.5114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6771 - val_prc: 0.3043\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8243 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6793 - prc: 0.3176 - val_loss: 0.5127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6691 - val_prc: 0.2836\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8201 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6800 - prc: 0.3149 - val_loss: 0.5025 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6816 - val_prc: 0.3122\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8167 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6835 - prc: 0.3186 - val_loss: 0.5033 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6766 - val_prc: 0.2989\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8134 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6811 - prc: 0.3104 - val_loss: 0.4961 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6824 - val_prc: 0.3122\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8122 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6833 - prc: 0.3189 - val_loss: 0.4755 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3304\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8104 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6877 - prc: 0.3294 - val_loss: 0.5145 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6753 - val_prc: 0.2986\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6917 - prc: 0.3377 - val_loss: 0.5004 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6806 - val_prc: 0.3080\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8039 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6892 - prc: 0.3194 - val_loss: 0.4853 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6830 - val_prc: 0.3230\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8053 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6892 - prc: 0.3393 - val_loss: 0.4850 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3284\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8027 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6881 - prc: 0.3268 - val_loss: 0.5016 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6835 - val_prc: 0.3232\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6967 - prc: 0.3454 - val_loss: 0.4892 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6857 - val_prc: 0.3330\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6898 - prc: 0.3153 - val_loss: 0.5236 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6750 - val_prc: 0.2956\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7958 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7000 - prc: 0.3460 - val_loss: 0.5279 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6719 - val_prc: 0.2924\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7962 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6948 - prc: 0.3386 - val_loss: 0.4873 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6856 - val_prc: 0.3408\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7923 - tp: 4.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 394.0000 - accuracy: 0.8039 - precision: 0.5714 - recall: 0.0101 - auc: 0.7039 - prc: 0.3658 - val_loss: 0.4975 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6833 - val_prc: 0.3264\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7913 - tp: 134.0000 - fp: 192.0000 - tn: 1434.0000 - fn: 264.0000 - accuracy: 0.7747 - precision: 0.4110 - recall: 0.3367 - auc: 0.6997 - prc: 0.3386 - val_loss: 0.4738 - val_tp: 22.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 69.0000 - val_accuracy: 0.8221 - val_precision: 0.5116 - val_recall: 0.2418 - val_auc: 0.6860 - val_prc: 0.3448\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7909 - tp: 133.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 265.0000 - accuracy: 0.7915 - precision: 0.4586 - recall: 0.3342 - auc: 0.7018 - prc: 0.3577 - val_loss: 0.4958 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6853 - val_prc: 0.3355\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7898 - tp: 134.0000 - fp: 161.0000 - tn: 1465.0000 - fn: 264.0000 - accuracy: 0.7900 - precision: 0.4542 - recall: 0.3367 - auc: 0.7028 - prc: 0.3595 - val_loss: 0.5124 - val_tp: 34.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 57.0000 - val_accuracy: 0.7806 - val_precision: 0.3864 - val_recall: 0.3736 - val_auc: 0.6819 - val_prc: 0.3129\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7866 - tp: 149.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 249.0000 - accuracy: 0.7801 - precision: 0.4319 - recall: 0.3744 - auc: 0.7043 - prc: 0.3540 - val_loss: 0.5014 - val_tp: 30.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 61.0000 - val_accuracy: 0.7866 - val_precision: 0.3896 - val_recall: 0.3297 - val_auc: 0.6865 - val_prc: 0.3347\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7903 - tp: 143.0000 - fp: 161.0000 - tn: 1465.0000 - fn: 255.0000 - accuracy: 0.7945 - precision: 0.4704 - recall: 0.3593 - auc: 0.6998 - prc: 0.3717 - val_loss: 0.5058 - val_tp: 33.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 58.0000 - val_accuracy: 0.7925 - val_precision: 0.4125 - val_recall: 0.3626 - val_auc: 0.6840 - val_prc: 0.3306\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7851 - tp: 136.0000 - fp: 172.0000 - tn: 1454.0000 - fn: 262.0000 - accuracy: 0.7856 - precision: 0.4416 - recall: 0.3417 - auc: 0.7089 - prc: 0.3715 - val_loss: 0.5106 - val_tp: 35.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 56.0000 - val_accuracy: 0.7905 - val_precision: 0.4118 - val_recall: 0.3846 - val_auc: 0.6872 - val_prc: 0.3387\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7815 - tp: 150.0000 - fp: 176.0000 - tn: 1450.0000 - fn: 248.0000 - accuracy: 0.7905 - precision: 0.4601 - recall: 0.3769 - auc: 0.7123 - prc: 0.3757 - val_loss: 0.4796 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6893 - val_prc: 0.3493\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7822 - tp: 142.0000 - fp: 152.0000 - tn: 1474.0000 - fn: 256.0000 - accuracy: 0.7984 - precision: 0.4830 - recall: 0.3568 - auc: 0.7101 - prc: 0.3768 - val_loss: 0.5167 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6871 - val_prc: 0.3297\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7823 - tp: 157.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 241.0000 - accuracy: 0.7767 - precision: 0.4266 - recall: 0.3945 - auc: 0.7075 - prc: 0.3642 - val_loss: 0.5154 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6875 - val_prc: 0.3357\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7795 - tp: 159.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 239.0000 - accuracy: 0.7866 - precision: 0.4517 - recall: 0.3995 - auc: 0.7116 - prc: 0.3739 - val_loss: 0.5024 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6889 - val_prc: 0.3387\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7795 - tp: 149.0000 - fp: 180.0000 - tn: 1446.0000 - fn: 249.0000 - accuracy: 0.7880 - precision: 0.4529 - recall: 0.3744 - auc: 0.7131 - prc: 0.4008 - val_loss: 0.5018 - val_tp: 32.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 59.0000 - val_accuracy: 0.7905 - val_precision: 0.4051 - val_recall: 0.3516 - val_auc: 0.6882 - val_prc: 0.3357\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7769 - tp: 149.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 249.0000 - accuracy: 0.7856 - precision: 0.4461 - recall: 0.3744 - auc: 0.7155 - prc: 0.3841 - val_loss: 0.4736 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6921 - val_prc: 0.3643\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7768 - tp: 147.0000 - fp: 166.0000 - tn: 1460.0000 - fn: 251.0000 - accuracy: 0.7940 - precision: 0.4696 - recall: 0.3693 - auc: 0.7141 - prc: 0.3971 - val_loss: 0.4838 - val_tp: 28.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 63.0000 - val_accuracy: 0.8083 - val_precision: 0.4516 - val_recall: 0.3077 - val_auc: 0.6907 - val_prc: 0.3550\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7767 - tp: 150.0000 - fp: 162.0000 - tn: 1464.0000 - fn: 248.0000 - accuracy: 0.7974 - precision: 0.4808 - recall: 0.3769 - auc: 0.7128 - prc: 0.3865 - val_loss: 0.5075 - val_tp: 32.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 59.0000 - val_accuracy: 0.7826 - val_precision: 0.3855 - val_recall: 0.3516 - val_auc: 0.6904 - val_prc: 0.3479\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7736 - tp: 142.0000 - fp: 165.0000 - tn: 1461.0000 - fn: 256.0000 - accuracy: 0.7920 - precision: 0.4625 - recall: 0.3568 - auc: 0.7190 - prc: 0.3943 - val_loss: 0.5467 - val_tp: 48.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 43.0000 - val_accuracy: 0.7530 - val_precision: 0.3692 - val_recall: 0.5275 - val_auc: 0.6880 - val_prc: 0.3303\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7777 - tp: 167.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 231.0000 - accuracy: 0.7772 - precision: 0.4315 - recall: 0.4196 - auc: 0.7115 - prc: 0.3899 - val_loss: 0.5001 - val_tp: 32.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 59.0000 - val_accuracy: 0.7925 - val_precision: 0.4103 - val_recall: 0.3516 - val_auc: 0.6921 - val_prc: 0.3486\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7733 - tp: 162.0000 - fp: 190.0000 - tn: 1436.0000 - fn: 236.0000 - accuracy: 0.7895 - precision: 0.4602 - recall: 0.4070 - auc: 0.7144 - prc: 0.3754 - val_loss: 0.4967 - val_tp: 30.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 61.0000 - val_accuracy: 0.7905 - val_precision: 0.4000 - val_recall: 0.3297 - val_auc: 0.6926 - val_prc: 0.3522\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7737 - tp: 148.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 250.0000 - accuracy: 0.7861 - precision: 0.4471 - recall: 0.3719 - auc: 0.7159 - prc: 0.3973 - val_loss: 0.4953 - val_tp: 30.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 61.0000 - val_accuracy: 0.7945 - val_precision: 0.4110 - val_recall: 0.3297 - val_auc: 0.6930 - val_prc: 0.3599\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7721 - tp: 167.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 231.0000 - accuracy: 0.7831 - precision: 0.4453 - recall: 0.4196 - auc: 0.7158 - prc: 0.3824 - val_loss: 0.4986 - val_tp: 32.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 59.0000 - val_accuracy: 0.7885 - val_precision: 0.4000 - val_recall: 0.3516 - val_auc: 0.6922 - val_prc: 0.3514\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7716 - tp: 161.0000 - fp: 189.0000 - tn: 1437.0000 - fn: 237.0000 - accuracy: 0.7895 - precision: 0.4600 - recall: 0.4045 - auc: 0.7176 - prc: 0.4064 - val_loss: 0.4991 - val_tp: 31.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 60.0000 - val_accuracy: 0.7885 - val_precision: 0.3974 - val_recall: 0.3407 - val_auc: 0.6924 - val_prc: 0.3520\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7693 - tp: 161.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 237.0000 - accuracy: 0.7945 - precision: 0.4735 - recall: 0.4045 - auc: 0.7198 - prc: 0.3940 - val_loss: 0.5341 - val_tp: 46.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 45.0000 - val_accuracy: 0.7648 - val_precision: 0.3833 - val_recall: 0.5055 - val_auc: 0.6897 - val_prc: 0.3412\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7692 - tp: 165.0000 - fp: 203.0000 - tn: 1423.0000 - fn: 233.0000 - accuracy: 0.7846 - precision: 0.4484 - recall: 0.4146 - auc: 0.7201 - prc: 0.3979 - val_loss: 0.5099 - val_tp: 36.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 55.0000 - val_accuracy: 0.7866 - val_precision: 0.4045 - val_recall: 0.3956 - val_auc: 0.6923 - val_prc: 0.3453\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7679 - tp: 165.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 233.0000 - accuracy: 0.7836 - precision: 0.4459 - recall: 0.4146 - auc: 0.7218 - prc: 0.4037 - val_loss: 0.4949 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6928 - val_prc: 0.3576\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7673 - tp: 164.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 234.0000 - accuracy: 0.7900 - precision: 0.4620 - recall: 0.4121 - auc: 0.7207 - prc: 0.3928 - val_loss: 0.4996 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6914 - val_prc: 0.3492\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7674 - tp: 166.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 232.0000 - accuracy: 0.7900 - precision: 0.4624 - recall: 0.4171 - auc: 0.7208 - prc: 0.4101 - val_loss: 0.4954 - val_tp: 31.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 60.0000 - val_accuracy: 0.7945 - val_precision: 0.4133 - val_recall: 0.3407 - val_auc: 0.6927 - val_prc: 0.3579\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7638 - tp: 168.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 230.0000 - accuracy: 0.8004 - precision: 0.4912 - recall: 0.4221 - auc: 0.7254 - prc: 0.4038 - val_loss: 0.5378 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6913 - val_prc: 0.3436\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7664 - tp: 171.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 227.0000 - accuracy: 0.7846 - precision: 0.4500 - recall: 0.4296 - auc: 0.7209 - prc: 0.3995 - val_loss: 0.5106 - val_tp: 38.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 53.0000 - val_accuracy: 0.7885 - val_precision: 0.4130 - val_recall: 0.4176 - val_auc: 0.6934 - val_prc: 0.3461\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7635 - tp: 163.0000 - fp: 180.0000 - tn: 1446.0000 - fn: 235.0000 - accuracy: 0.7950 - precision: 0.4752 - recall: 0.4095 - auc: 0.7252 - prc: 0.4095 - val_loss: 0.5294 - val_tp: 46.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 45.0000 - val_accuracy: 0.7727 - val_precision: 0.3966 - val_recall: 0.5055 - val_auc: 0.6916 - val_prc: 0.3436\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7629 - tp: 171.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 227.0000 - accuracy: 0.7851 - precision: 0.4512 - recall: 0.4296 - auc: 0.7253 - prc: 0.4095 - val_loss: 0.5063 - val_tp: 34.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 57.0000 - val_accuracy: 0.7826 - val_precision: 0.3908 - val_recall: 0.3736 - val_auc: 0.6910 - val_prc: 0.3542\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7636 - tp: 159.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 239.0000 - accuracy: 0.7935 - precision: 0.4704 - recall: 0.3995 - auc: 0.7251 - prc: 0.4166 - val_loss: 0.5185 - val_tp: 41.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 50.0000 - val_accuracy: 0.7846 - val_precision: 0.4100 - val_recall: 0.4505 - val_auc: 0.6920 - val_prc: 0.3513\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7631 - tp: 171.0000 - fp: 207.0000 - tn: 1419.0000 - fn: 227.0000 - accuracy: 0.7856 - precision: 0.4524 - recall: 0.4296 - auc: 0.7251 - prc: 0.4076 - val_loss: 0.5128 - val_tp: 38.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 53.0000 - val_accuracy: 0.7866 - val_precision: 0.4086 - val_recall: 0.4176 - val_auc: 0.6887 - val_prc: 0.3482\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7609 - tp: 170.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 228.0000 - accuracy: 0.7945 - precision: 0.4749 - recall: 0.4271 - auc: 0.7270 - prc: 0.4035 - val_loss: 0.5030 - val_tp: 33.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 58.0000 - val_accuracy: 0.7846 - val_precision: 0.3929 - val_recall: 0.3626 - val_auc: 0.6924 - val_prc: 0.3709\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7621 - tp: 164.0000 - fp: 190.0000 - tn: 1436.0000 - fn: 234.0000 - accuracy: 0.7905 - precision: 0.4633 - recall: 0.4121 - auc: 0.7247 - prc: 0.4137 - val_loss: 0.4991 - val_tp: 31.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 60.0000 - val_accuracy: 0.7866 - val_precision: 0.3924 - val_recall: 0.3407 - val_auc: 0.6915 - val_prc: 0.3704\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7593 - tp: 172.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 226.0000 - accuracy: 0.7871 - precision: 0.4562 - recall: 0.4322 - auc: 0.7271 - prc: 0.4028 - val_loss: 0.5141 - val_tp: 41.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 50.0000 - val_accuracy: 0.7925 - val_precision: 0.4271 - val_recall: 0.4505 - val_auc: 0.6907 - val_prc: 0.3484\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7610 - tp: 178.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 220.0000 - accuracy: 0.7915 - precision: 0.4684 - recall: 0.4472 - auc: 0.7246 - prc: 0.4052 - val_loss: 0.5102 - val_tp: 39.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 52.0000 - val_accuracy: 0.7885 - val_precision: 0.4149 - val_recall: 0.4286 - val_auc: 0.6912 - val_prc: 0.3493\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7580 - tp: 176.0000 - fp: 198.0000 - tn: 1428.0000 - fn: 222.0000 - accuracy: 0.7925 - precision: 0.4706 - recall: 0.4422 - auc: 0.7291 - prc: 0.4140 - val_loss: 0.4924 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6912 - val_prc: 0.3732\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7583 - tp: 170.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 228.0000 - accuracy: 0.7905 - precision: 0.4645 - recall: 0.4271 - auc: 0.7285 - prc: 0.4166 - val_loss: 0.4948 - val_tp: 34.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 57.0000 - val_accuracy: 0.7984 - val_precision: 0.4304 - val_recall: 0.3736 - val_auc: 0.6925 - val_prc: 0.3711\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7574 - tp: 179.0000 - fp: 198.0000 - tn: 1428.0000 - fn: 219.0000 - accuracy: 0.7940 - precision: 0.4748 - recall: 0.4497 - auc: 0.7287 - prc: 0.4133 - val_loss: 0.5093 - val_tp: 41.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 50.0000 - val_accuracy: 0.7925 - val_precision: 0.4271 - val_recall: 0.4505 - val_auc: 0.6928 - val_prc: 0.3660\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7576 - tp: 177.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 221.0000 - accuracy: 0.7910 - precision: 0.4670 - recall: 0.4447 - auc: 0.7268 - prc: 0.4123 - val_loss: 0.4990 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6915 - val_prc: 0.3539\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7589 - tp: 170.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 228.0000 - accuracy: 0.7900 - precision: 0.4632 - recall: 0.4271 - auc: 0.7286 - prc: 0.4160 - val_loss: 0.4865 - val_tp: 32.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 59.0000 - val_accuracy: 0.8063 - val_precision: 0.4507 - val_recall: 0.3516 - val_auc: 0.6919 - val_prc: 0.3721\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7592 - tp: 180.0000 - fp: 210.0000 - tn: 1416.0000 - fn: 218.0000 - accuracy: 0.7885 - precision: 0.4615 - recall: 0.4523 - auc: 0.7272 - prc: 0.4136 - val_loss: 0.5428 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.6895 - val_prc: 0.3506\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7582 - tp: 170.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 228.0000 - accuracy: 0.7861 - precision: 0.4533 - recall: 0.4271 - auc: 0.7271 - prc: 0.4102 - val_loss: 0.5289 - val_tp: 45.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 46.0000 - val_accuracy: 0.7747 - val_precision: 0.3982 - val_recall: 0.4945 - val_auc: 0.6891 - val_prc: 0.3492\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7578 - tp: 174.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 224.0000 - accuracy: 0.7880 - precision: 0.4591 - recall: 0.4372 - auc: 0.7267 - prc: 0.4108 - val_loss: 0.4990 - val_tp: 34.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 57.0000 - val_accuracy: 0.7945 - val_precision: 0.4198 - val_recall: 0.3736 - val_auc: 0.6920 - val_prc: 0.3761\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7563 - tp: 161.0000 - fp: 198.0000 - tn: 1428.0000 - fn: 237.0000 - accuracy: 0.7851 - precision: 0.4485 - recall: 0.4045 - auc: 0.7305 - prc: 0.4246 - val_loss: 0.4980 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6943 - val_prc: 0.3711\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7568 - tp: 181.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 217.0000 - accuracy: 0.7811 - precision: 0.4447 - recall: 0.4548 - auc: 0.7286 - prc: 0.4035 - val_loss: 0.4863 - val_tp: 34.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 57.0000 - val_accuracy: 0.8083 - val_precision: 0.4595 - val_recall: 0.3736 - val_auc: 0.6933 - val_prc: 0.3717\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7555 - tp: 177.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 221.0000 - accuracy: 0.7895 - precision: 0.4634 - recall: 0.4447 - auc: 0.7292 - prc: 0.4198 - val_loss: 0.5122 - val_tp: 42.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 49.0000 - val_accuracy: 0.7905 - val_precision: 0.4242 - val_recall: 0.4615 - val_auc: 0.6915 - val_prc: 0.3655\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7553 - tp: 169.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 229.0000 - accuracy: 0.7955 - precision: 0.4774 - recall: 0.4246 - auc: 0.7309 - prc: 0.4181 - val_loss: 0.5189 - val_tp: 42.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 49.0000 - val_accuracy: 0.7787 - val_precision: 0.4000 - val_recall: 0.4615 - val_auc: 0.6907 - val_prc: 0.3584\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7556 - tp: 176.0000 - fp: 200.0000 - tn: 1426.0000 - fn: 222.0000 - accuracy: 0.7915 - precision: 0.4681 - recall: 0.4422 - auc: 0.7282 - prc: 0.4219 - val_loss: 0.5207 - val_tp: 44.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 47.0000 - val_accuracy: 0.7787 - val_precision: 0.4037 - val_recall: 0.4835 - val_auc: 0.6903 - val_prc: 0.3600\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7594 - tp: 191.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 207.0000 - accuracy: 0.7826 - precision: 0.4505 - recall: 0.4799 - auc: 0.7253 - prc: 0.4088 - val_loss: 0.4840 - val_tp: 33.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 58.0000 - val_accuracy: 0.8024 - val_precision: 0.4400 - val_recall: 0.3626 - val_auc: 0.6903 - val_prc: 0.3702\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7525 - tp: 183.0000 - fp: 230.0000 - tn: 1396.0000 - fn: 215.0000 - accuracy: 0.7801 - precision: 0.4431 - recall: 0.4598 - auc: 0.7345 - prc: 0.4130 - val_loss: 0.4534 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6917 - val_prc: 0.3763\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7545 - tp: 170.0000 - fp: 198.0000 - tn: 1428.0000 - fn: 228.0000 - accuracy: 0.7895 - precision: 0.4620 - recall: 0.4271 - auc: 0.7299 - prc: 0.4203 - val_loss: 0.5064 - val_tp: 40.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 51.0000 - val_accuracy: 0.7964 - val_precision: 0.4348 - val_recall: 0.4396 - val_auc: 0.6909 - val_prc: 0.3680\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7558 - tp: 177.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 221.0000 - accuracy: 0.7910 - precision: 0.4670 - recall: 0.4447 - auc: 0.7289 - prc: 0.4195 - val_loss: 0.5078 - val_tp: 40.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 51.0000 - val_accuracy: 0.7885 - val_precision: 0.4167 - val_recall: 0.4396 - val_auc: 0.6900 - val_prc: 0.3687\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7537 - tp: 178.0000 - fp: 206.0000 - tn: 1420.0000 - fn: 220.0000 - accuracy: 0.7895 - precision: 0.4635 - recall: 0.4472 - auc: 0.7317 - prc: 0.4302 - val_loss: 0.5012 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 54.0000 - val_accuracy: 0.7905 - val_precision: 0.4157 - val_recall: 0.4066 - val_auc: 0.6903 - val_prc: 0.3660\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7569 - tp: 178.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 220.0000 - accuracy: 0.7846 - precision: 0.4518 - recall: 0.4472 - auc: 0.7284 - prc: 0.4185 - val_loss: 0.5135 - val_tp: 41.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 50.0000 - val_accuracy: 0.7826 - val_precision: 0.4059 - val_recall: 0.4505 - val_auc: 0.6895 - val_prc: 0.3700\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7531 - tp: 181.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 217.0000 - accuracy: 0.7826 - precision: 0.4480 - recall: 0.4548 - auc: 0.7315 - prc: 0.4230 - val_loss: 0.4763 - val_tp: 32.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 59.0000 - val_accuracy: 0.8083 - val_precision: 0.4571 - val_recall: 0.3516 - val_auc: 0.6895 - val_prc: 0.3761\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7561 - tp: 173.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 225.0000 - accuracy: 0.7920 - precision: 0.4688 - recall: 0.4347 - auc: 0.7270 - prc: 0.4305 - val_loss: 0.5015 - val_tp: 37.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 54.0000 - val_accuracy: 0.7984 - val_precision: 0.4353 - val_recall: 0.4066 - val_auc: 0.6894 - val_prc: 0.3665\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7514 - tp: 173.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 225.0000 - accuracy: 0.7959 - precision: 0.4792 - recall: 0.4347 - auc: 0.7326 - prc: 0.4272 - val_loss: 0.5095 - val_tp: 41.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 50.0000 - val_accuracy: 0.7964 - val_precision: 0.4362 - val_recall: 0.4505 - val_auc: 0.6911 - val_prc: 0.3752\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7508 - tp: 174.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 224.0000 - accuracy: 0.7979 - precision: 0.4847 - recall: 0.4372 - auc: 0.7343 - prc: 0.4267 - val_loss: 0.5491 - val_tp: 48.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 43.0000 - val_accuracy: 0.7589 - val_precision: 0.3780 - val_recall: 0.5275 - val_auc: 0.6885 - val_prc: 0.3496\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7526 - tp: 178.0000 - fp: 218.0000 - tn: 1408.0000 - fn: 220.0000 - accuracy: 0.7836 - precision: 0.4495 - recall: 0.4472 - auc: 0.7311 - prc: 0.4136 - val_loss: 0.5003 - val_tp: 36.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 55.0000 - val_accuracy: 0.7905 - val_precision: 0.4138 - val_recall: 0.3956 - val_auc: 0.6922 - val_prc: 0.3711\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7539 - tp: 185.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 213.0000 - accuracy: 0.7841 - precision: 0.4523 - recall: 0.4648 - auc: 0.7294 - prc: 0.4251 - val_loss: 0.4875 - val_tp: 35.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 56.0000 - val_accuracy: 0.8063 - val_precision: 0.4545 - val_recall: 0.3846 - val_auc: 0.6917 - val_prc: 0.3614\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7525 - tp: 169.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 229.0000 - accuracy: 0.7955 - precision: 0.4774 - recall: 0.4246 - auc: 0.7304 - prc: 0.4235 - val_loss: 0.4965 - val_tp: 36.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 55.0000 - val_accuracy: 0.7964 - val_precision: 0.4286 - val_recall: 0.3956 - val_auc: 0.6886 - val_prc: 0.3633\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7489 - tp: 176.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 222.0000 - accuracy: 0.7935 - precision: 0.4731 - recall: 0.4422 - auc: 0.7341 - prc: 0.4292 - val_loss: 0.5036 - val_tp: 36.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 55.0000 - val_accuracy: 0.7846 - val_precision: 0.4000 - val_recall: 0.3956 - val_auc: 0.6926 - val_prc: 0.3684\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7500 - tp: 176.0000 - fp: 198.0000 - tn: 1428.0000 - fn: 222.0000 - accuracy: 0.7925 - precision: 0.4706 - recall: 0.4422 - auc: 0.7329 - prc: 0.4315 - val_loss: 0.5375 - val_tp: 44.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 47.0000 - val_accuracy: 0.7589 - val_precision: 0.3697 - val_recall: 0.4835 - val_auc: 0.6892 - val_prc: 0.3653\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7545 - tp: 173.0000 - fp: 203.0000 - tn: 1423.0000 - fn: 225.0000 - accuracy: 0.7885 - precision: 0.4601 - recall: 0.4347 - auc: 0.7270 - prc: 0.4253 - val_loss: 0.5142 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6920 - val_prc: 0.3733\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7489 - tp: 181.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 217.0000 - accuracy: 0.7861 - precision: 0.4559 - recall: 0.4548 - auc: 0.7352 - prc: 0.4307 - val_loss: 0.5246 - val_tp: 42.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 49.0000 - val_accuracy: 0.7767 - val_precision: 0.3962 - val_recall: 0.4615 - val_auc: 0.6914 - val_prc: 0.3768\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7508 - tp: 172.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 226.0000 - accuracy: 0.7920 - precision: 0.4687 - recall: 0.4322 - auc: 0.7319 - prc: 0.4303 - val_loss: 0.5175 - val_tp: 37.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 54.0000 - val_accuracy: 0.7708 - val_precision: 0.3737 - val_recall: 0.4066 - val_auc: 0.6880 - val_prc: 0.3690\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7490 - tp: 179.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 219.0000 - accuracy: 0.7959 - precision: 0.4799 - recall: 0.4497 - auc: 0.7334 - prc: 0.4303 - val_loss: 0.5258 - val_tp: 39.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 52.0000 - val_accuracy: 0.7628 - val_precision: 0.3645 - val_recall: 0.4286 - val_auc: 0.6938 - val_prc: 0.3785\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7507 - tp: 180.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 218.0000 - accuracy: 0.7930 - precision: 0.4724 - recall: 0.4523 - auc: 0.7311 - prc: 0.4377 - val_loss: 0.5149 - val_tp: 37.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 54.0000 - val_accuracy: 0.7806 - val_precision: 0.3936 - val_recall: 0.4066 - val_auc: 0.6927 - val_prc: 0.3759\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7503 - tp: 172.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 226.0000 - accuracy: 0.7974 - precision: 0.4831 - recall: 0.4322 - auc: 0.7307 - prc: 0.4447 - val_loss: 0.5265 - val_tp: 40.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 51.0000 - val_accuracy: 0.7727 - val_precision: 0.3846 - val_recall: 0.4396 - val_auc: 0.6904 - val_prc: 0.3738\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7479 - tp: 172.0000 - fp: 186.0000 - tn: 1440.0000 - fn: 226.0000 - accuracy: 0.7964 - precision: 0.4804 - recall: 0.4322 - auc: 0.7344 - prc: 0.4349 - val_loss: 0.5053 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6936 - val_prc: 0.3738\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7513 - tp: 185.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 213.0000 - accuracy: 0.7875 - precision: 0.4602 - recall: 0.4648 - auc: 0.7295 - prc: 0.4368 - val_loss: 0.5062 - val_tp: 35.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 56.0000 - val_accuracy: 0.7846 - val_precision: 0.3977 - val_recall: 0.3846 - val_auc: 0.6937 - val_prc: 0.3740\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7507 - tp: 164.0000 - fp: 178.0000 - tn: 1448.0000 - fn: 234.0000 - accuracy: 0.7964 - precision: 0.4795 - recall: 0.4121 - auc: 0.7325 - prc: 0.4370 - val_loss: 0.5155 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6916 - val_prc: 0.3691\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7504 - tp: 182.0000 - fp: 205.0000 - tn: 1421.0000 - fn: 216.0000 - accuracy: 0.7920 - precision: 0.4703 - recall: 0.4573 - auc: 0.7294 - prc: 0.4371 - val_loss: 0.5079 - val_tp: 36.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 55.0000 - val_accuracy: 0.7826 - val_precision: 0.3956 - val_recall: 0.3956 - val_auc: 0.6909 - val_prc: 0.3744\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7470 - tp: 172.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 226.0000 - accuracy: 0.7979 - precision: 0.4845 - recall: 0.4322 - auc: 0.7349 - prc: 0.4429 - val_loss: 0.4999 - val_tp: 35.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 56.0000 - val_accuracy: 0.7885 - val_precision: 0.4070 - val_recall: 0.3846 - val_auc: 0.6904 - val_prc: 0.3672\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7489 - tp: 178.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 220.0000 - accuracy: 0.7920 - precision: 0.4697 - recall: 0.4472 - auc: 0.7324 - prc: 0.4174 - val_loss: 0.5126 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6900 - val_prc: 0.3627\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7477 - tp: 177.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 221.0000 - accuracy: 0.7915 - precision: 0.4683 - recall: 0.4447 - auc: 0.7341 - prc: 0.4353 - val_loss: 0.5170 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6951 - val_prc: 0.3762\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7460 - tp: 179.0000 - fp: 182.0000 - tn: 1444.0000 - fn: 219.0000 - accuracy: 0.8019 - precision: 0.4958 - recall: 0.4497 - auc: 0.7357 - prc: 0.4468 - val_loss: 0.5243 - val_tp: 42.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 49.0000 - val_accuracy: 0.7767 - val_precision: 0.3962 - val_recall: 0.4615 - val_auc: 0.6914 - val_prc: 0.3755\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7448 - tp: 181.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 217.0000 - accuracy: 0.7969 - precision: 0.4827 - recall: 0.4548 - auc: 0.7356 - prc: 0.4532 - val_loss: 0.5392 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6959 - val_prc: 0.3757\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7501 - tp: 184.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 214.0000 - accuracy: 0.7910 - precision: 0.4682 - recall: 0.4623 - auc: 0.7306 - prc: 0.4332 - val_loss: 0.4955 - val_tp: 35.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 56.0000 - val_accuracy: 0.8024 - val_precision: 0.4430 - val_recall: 0.3846 - val_auc: 0.6959 - val_prc: 0.3666\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7444 - tp: 169.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 229.0000 - accuracy: 0.7895 - precision: 0.4617 - recall: 0.4246 - auc: 0.7383 - prc: 0.4449 - val_loss: 0.5284 - val_tp: 42.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 49.0000 - val_accuracy: 0.7767 - val_precision: 0.3962 - val_recall: 0.4615 - val_auc: 0.6867 - val_prc: 0.3646\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7467 - tp: 177.0000 - fp: 207.0000 - tn: 1419.0000 - fn: 221.0000 - accuracy: 0.7885 - precision: 0.4609 - recall: 0.4447 - auc: 0.7340 - prc: 0.4433 - val_loss: 0.4929 - val_tp: 35.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 56.0000 - val_accuracy: 0.8063 - val_precision: 0.4545 - val_recall: 0.3846 - val_auc: 0.6933 - val_prc: 0.3661\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7448 - tp: 169.0000 - fp: 175.0000 - tn: 1451.0000 - fn: 229.0000 - accuracy: 0.8004 - precision: 0.4913 - recall: 0.4246 - auc: 0.7365 - prc: 0.4386 - val_loss: 0.5284 - val_tp: 42.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 49.0000 - val_accuracy: 0.7767 - val_precision: 0.3962 - val_recall: 0.4615 - val_auc: 0.6903 - val_prc: 0.3679\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7466 - tp: 187.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 211.0000 - accuracy: 0.7905 - precision: 0.4675 - recall: 0.4698 - auc: 0.7343 - prc: 0.4353 - val_loss: 0.4977 - val_tp: 35.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 56.0000 - val_accuracy: 0.7964 - val_precision: 0.4268 - val_recall: 0.3846 - val_auc: 0.6935 - val_prc: 0.3702\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7468 - tp: 180.0000 - fp: 194.0000 - tn: 1432.0000 - fn: 218.0000 - accuracy: 0.7964 - precision: 0.4813 - recall: 0.4523 - auc: 0.7348 - prc: 0.4421 - val_loss: 0.4758 - val_tp: 35.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 56.0000 - val_accuracy: 0.8162 - val_precision: 0.4861 - val_recall: 0.3846 - val_auc: 0.6907 - val_prc: 0.3663\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7464 - tp: 169.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 229.0000 - accuracy: 0.7915 - precision: 0.4669 - recall: 0.4246 - auc: 0.7343 - prc: 0.4448 - val_loss: 0.4764 - val_tp: 34.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 57.0000 - val_accuracy: 0.8162 - val_precision: 0.4857 - val_recall: 0.3736 - val_auc: 0.6892 - val_prc: 0.3655\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7423 - tp: 174.0000 - fp: 181.0000 - tn: 1445.0000 - fn: 224.0000 - accuracy: 0.7999 - precision: 0.4901 - recall: 0.4372 - auc: 0.7397 - prc: 0.4526 - val_loss: 0.5349 - val_tp: 44.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 47.0000 - val_accuracy: 0.7688 - val_precision: 0.3860 - val_recall: 0.4835 - val_auc: 0.6879 - val_prc: 0.3640\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7443 - tp: 176.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 222.0000 - accuracy: 0.7935 - precision: 0.4731 - recall: 0.4422 - auc: 0.7364 - prc: 0.4409 - val_loss: 0.5539 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6876 - val_prc: 0.3677\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7454 - tp: 180.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 218.0000 - accuracy: 0.7895 - precision: 0.4639 - recall: 0.4523 - auc: 0.7360 - prc: 0.4422 - val_loss: 0.4810 - val_tp: 34.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 57.0000 - val_accuracy: 0.8142 - val_precision: 0.4789 - val_recall: 0.3736 - val_auc: 0.6890 - val_prc: 0.3659\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7430 - tp: 181.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 217.0000 - accuracy: 0.7880 - precision: 0.4606 - recall: 0.4548 - auc: 0.7384 - prc: 0.4336 - val_loss: 0.4538 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6908 - val_prc: 0.3753\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7452 - tp: 159.0000 - fp: 173.0000 - tn: 1453.0000 - fn: 239.0000 - accuracy: 0.7964 - precision: 0.4789 - recall: 0.3995 - auc: 0.7370 - prc: 0.4522 - val_loss: 0.5085 - val_tp: 35.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 56.0000 - val_accuracy: 0.7787 - val_precision: 0.3846 - val_recall: 0.3846 - val_auc: 0.6923 - val_prc: 0.3654\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7468 - tp: 167.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 231.0000 - accuracy: 0.7890 - precision: 0.4601 - recall: 0.4196 - auc: 0.7357 - prc: 0.4468 - val_loss: 0.5019 - val_tp: 34.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 57.0000 - val_accuracy: 0.7846 - val_precision: 0.3953 - val_recall: 0.3736 - val_auc: 0.6866 - val_prc: 0.3645\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7429 - tp: 180.0000 - fp: 192.0000 - tn: 1434.0000 - fn: 218.0000 - accuracy: 0.7974 - precision: 0.4839 - recall: 0.4523 - auc: 0.7380 - prc: 0.4505 - val_loss: 0.5166 - val_tp: 37.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 54.0000 - val_accuracy: 0.7708 - val_precision: 0.3737 - val_recall: 0.4066 - val_auc: 0.6919 - val_prc: 0.3663\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7436 - tp: 178.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 220.0000 - accuracy: 0.7999 - precision: 0.4904 - recall: 0.4472 - auc: 0.7367 - prc: 0.4453 - val_loss: 0.5344 - val_tp: 43.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 48.0000 - val_accuracy: 0.7727 - val_precision: 0.3909 - val_recall: 0.4725 - val_auc: 0.6932 - val_prc: 0.3708\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7449 - tp: 173.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 225.0000 - accuracy: 0.7945 - precision: 0.4753 - recall: 0.4347 - auc: 0.7354 - prc: 0.4489 - val_loss: 0.5360 - val_tp: 45.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 46.0000 - val_accuracy: 0.7747 - val_precision: 0.3982 - val_recall: 0.4945 - val_auc: 0.6898 - val_prc: 0.3651\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7429 - tp: 179.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 219.0000 - accuracy: 0.7974 - precision: 0.4838 - recall: 0.4497 - auc: 0.7397 - prc: 0.4487 - val_loss: 0.5277 - val_tp: 42.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 49.0000 - val_accuracy: 0.7747 - val_precision: 0.3925 - val_recall: 0.4615 - val_auc: 0.6892 - val_prc: 0.3702\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7450 - tp: 192.0000 - fp: 237.0000 - tn: 1389.0000 - fn: 206.0000 - accuracy: 0.7811 - precision: 0.4476 - recall: 0.4824 - auc: 0.7363 - prc: 0.4425 - val_loss: 0.4831 - val_tp: 35.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 56.0000 - val_accuracy: 0.8142 - val_precision: 0.4795 - val_recall: 0.3846 - val_auc: 0.6916 - val_prc: 0.3738\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7435 - tp: 170.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 228.0000 - accuracy: 0.8014 - precision: 0.4942 - recall: 0.4271 - auc: 0.7387 - prc: 0.4438 - val_loss: 0.5170 - val_tp: 39.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 52.0000 - val_accuracy: 0.7747 - val_precision: 0.3861 - val_recall: 0.4286 - val_auc: 0.6892 - val_prc: 0.3705\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7419 - tp: 188.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 210.0000 - accuracy: 0.7969 - precision: 0.4833 - recall: 0.4724 - auc: 0.7388 - prc: 0.4525 - val_loss: 0.4950 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6874 - val_prc: 0.3625\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7424 - tp: 188.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 210.0000 - accuracy: 0.7905 - precision: 0.4677 - recall: 0.4724 - auc: 0.7367 - prc: 0.4460 - val_loss: 0.4679 - val_tp: 30.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 61.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3297 - val_auc: 0.6943 - val_prc: 0.3690\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7428 - tp: 177.0000 - fp: 175.0000 - tn: 1451.0000 - fn: 221.0000 - accuracy: 0.8043 - precision: 0.5028 - recall: 0.4447 - auc: 0.7371 - prc: 0.4521 - val_loss: 0.4673 - val_tp: 31.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 60.0000 - val_accuracy: 0.8261 - val_precision: 0.5254 - val_recall: 0.3407 - val_auc: 0.6894 - val_prc: 0.3753\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7447 - tp: 165.0000 - fp: 168.0000 - tn: 1458.0000 - fn: 233.0000 - accuracy: 0.8019 - precision: 0.4955 - recall: 0.4146 - auc: 0.7360 - prc: 0.4526 - val_loss: 0.5143 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6871 - val_prc: 0.3593\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7413 - tp: 176.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 222.0000 - accuracy: 0.7940 - precision: 0.4744 - recall: 0.4422 - auc: 0.7396 - prc: 0.4592 - val_loss: 0.5293 - val_tp: 41.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 50.0000 - val_accuracy: 0.7708 - val_precision: 0.3832 - val_recall: 0.4505 - val_auc: 0.6863 - val_prc: 0.3647\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7442 - tp: 178.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 220.0000 - accuracy: 0.8004 - precision: 0.4917 - recall: 0.4472 - auc: 0.7350 - prc: 0.4465 - val_loss: 0.5167 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6909 - val_prc: 0.3635\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7427 - tp: 174.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 224.0000 - accuracy: 0.7964 - precision: 0.4807 - recall: 0.4372 - auc: 0.7369 - prc: 0.4533 - val_loss: 0.5006 - val_tp: 35.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 56.0000 - val_accuracy: 0.7866 - val_precision: 0.4023 - val_recall: 0.3846 - val_auc: 0.6873 - val_prc: 0.3674\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7417 - tp: 178.0000 - fp: 182.0000 - tn: 1444.0000 - fn: 220.0000 - accuracy: 0.8014 - precision: 0.4944 - recall: 0.4472 - auc: 0.7373 - prc: 0.4532 - val_loss: 0.5251 - val_tp: 40.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 51.0000 - val_accuracy: 0.7708 - val_precision: 0.3810 - val_recall: 0.4396 - val_auc: 0.6875 - val_prc: 0.3656\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7397 - tp: 173.0000 - fp: 177.0000 - tn: 1449.0000 - fn: 225.0000 - accuracy: 0.8014 - precision: 0.4943 - recall: 0.4347 - auc: 0.7402 - prc: 0.4575 - val_loss: 0.5285 - val_tp: 41.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 50.0000 - val_accuracy: 0.7688 - val_precision: 0.3796 - val_recall: 0.4505 - val_auc: 0.6933 - val_prc: 0.3657\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7461 - tp: 184.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 214.0000 - accuracy: 0.7950 - precision: 0.4779 - recall: 0.4623 - auc: 0.7317 - prc: 0.4490 - val_loss: 0.5236 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6882 - val_prc: 0.3669\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7418 - tp: 180.0000 - fp: 177.0000 - tn: 1449.0000 - fn: 218.0000 - accuracy: 0.8048 - precision: 0.5042 - recall: 0.4523 - auc: 0.7369 - prc: 0.4567 - val_loss: 0.5183 - val_tp: 40.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 51.0000 - val_accuracy: 0.7787 - val_precision: 0.3960 - val_recall: 0.4396 - val_auc: 0.6907 - val_prc: 0.3642\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7413 - tp: 173.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 225.0000 - accuracy: 0.7979 - precision: 0.4846 - recall: 0.4347 - auc: 0.7380 - prc: 0.4563 - val_loss: 0.5134 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6901 - val_prc: 0.3647\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7423 - tp: 174.0000 - fp: 198.0000 - tn: 1428.0000 - fn: 224.0000 - accuracy: 0.7915 - precision: 0.4677 - recall: 0.4372 - auc: 0.7384 - prc: 0.4580 - val_loss: 0.5108 - val_tp: 39.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 52.0000 - val_accuracy: 0.7826 - val_precision: 0.4021 - val_recall: 0.4286 - val_auc: 0.6876 - val_prc: 0.3698\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7436 - tp: 180.0000 - fp: 192.0000 - tn: 1434.0000 - fn: 218.0000 - accuracy: 0.7974 - precision: 0.4839 - recall: 0.4523 - auc: 0.7358 - prc: 0.4461 - val_loss: 0.5253 - val_tp: 41.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 50.0000 - val_accuracy: 0.7787 - val_precision: 0.3981 - val_recall: 0.4505 - val_auc: 0.6861 - val_prc: 0.3624\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7406 - tp: 183.0000 - fp: 190.0000 - tn: 1436.0000 - fn: 215.0000 - accuracy: 0.7999 - precision: 0.4906 - recall: 0.4598 - auc: 0.7388 - prc: 0.4592 - val_loss: 0.4982 - val_tp: 35.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 56.0000 - val_accuracy: 0.7984 - val_precision: 0.4321 - val_recall: 0.3846 - val_auc: 0.6865 - val_prc: 0.3624\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7392 - tp: 181.0000 - fp: 199.0000 - tn: 1427.0000 - fn: 217.0000 - accuracy: 0.7945 - precision: 0.4763 - recall: 0.4548 - auc: 0.7399 - prc: 0.4646 - val_loss: 0.4985 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6900 - val_prc: 0.3693\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7424 - tp: 175.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 223.0000 - accuracy: 0.7989 - precision: 0.4875 - recall: 0.4397 - auc: 0.7358 - prc: 0.4561 - val_loss: 0.5066 - val_tp: 35.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 56.0000 - val_accuracy: 0.7846 - val_precision: 0.3977 - val_recall: 0.3846 - val_auc: 0.6871 - val_prc: 0.3612\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7414 - tp: 179.0000 - fp: 190.0000 - tn: 1436.0000 - fn: 219.0000 - accuracy: 0.7979 - precision: 0.4851 - recall: 0.4497 - auc: 0.7372 - prc: 0.4472 - val_loss: 0.5150 - val_tp: 38.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 53.0000 - val_accuracy: 0.7787 - val_precision: 0.3918 - val_recall: 0.4176 - val_auc: 0.6873 - val_prc: 0.3674\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7403 - tp: 177.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 221.0000 - accuracy: 0.8004 - precision: 0.4917 - recall: 0.4447 - auc: 0.7380 - prc: 0.4571 - val_loss: 0.5103 - val_tp: 37.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 54.0000 - val_accuracy: 0.7826 - val_precision: 0.3978 - val_recall: 0.4066 - val_auc: 0.6913 - val_prc: 0.3686\n",
      "Epoch 158/500\n",
      " 98/102 [===========================>..] - ETA: 0s - loss: 0.7450 - tp: 182.0000 - fp: 202.0000 - tn: 1368.0000 - fn: 208.0000 - accuracy: 0.7908 - precision: 0.4740 - recall: 0.4667 - auc: 0.7398 - prc: 0.4600Restoring model weights from the end of the best epoch: 108.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7397 - tp: 186.0000 - fp: 206.0000 - tn: 1420.0000 - fn: 212.0000 - accuracy: 0.7935 - precision: 0.4745 - recall: 0.4673 - auc: 0.7413 - prc: 0.4562 - val_loss: 0.4675 - val_tp: 31.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 60.0000 - val_accuracy: 0.8221 - val_precision: 0.5082 - val_recall: 0.3407 - val_auc: 0.6924 - val_prc: 0.3785\n",
      "Epoch 158: early stopping\n",
      "26/26 [==============================] - 0s 602us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.1283 - tp: 31.0000 - fp: 30.0000 - tn: 2011.0000 - fn: 458.0000 - accuracy: 0.8071 - precision: 0.5082 - recall: 0.0634 - auc: 0.5212 - prc: 0.2334 - val_loss: 0.4736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5125 - prc: 0.2001 - val_loss: 0.4763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0810 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5112 - prc: 0.2031 - val_loss: 0.4799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0616 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5326 - prc: 0.2129 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0449 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - prc: 0.1930 - val_loss: 0.4892 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0300 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5196 - prc: 0.2114 - val_loss: 0.4945 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4885 - prc: 0.1933 - val_loss: 0.5007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0051 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4784 - prc: 0.1831 - val_loss: 0.5073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5099 - prc: 0.2062 - val_loss: 0.5134 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9867 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5220 - prc: 0.2106 - val_loss: 0.5202 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9799 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4749 - prc: 0.1883 - val_loss: 0.5269 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5200 - prc: 0.2008 - val_loss: 0.5335 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5319 - prc: 0.2100 - val_loss: 0.5397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5084 - val_prc: 0.1824\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9650 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5120 - prc: 0.2028 - val_loss: 0.5458 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9617 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4834 - prc: 0.1899 - val_loss: 0.5519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4935 - prc: 0.1933 - val_loss: 0.5571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9570 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4882 - prc: 0.1918 - val_loss: 0.5620 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9552 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4780 - prc: 0.1831 - val_loss: 0.5680 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9539 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1971 - val_loss: 0.5720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9527 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4983 - prc: 0.1961 - val_loss: 0.5760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9516 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.5779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5218 - val_prc: 0.1866\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9505 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5386 - prc: 0.2126 - val_loss: 0.5777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5653 - val_prc: 0.2035\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9480 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5729 - prc: 0.2434 - val_loss: 0.5658 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6331 - val_prc: 0.2604\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9405 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6271 - prc: 0.2747 - val_loss: 0.5699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6218 - val_prc: 0.2349\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9357 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6388 - prc: 0.2840 - val_loss: 0.5740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6364 - val_prc: 0.2449\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9287 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6617 - prc: 0.3114 - val_loss: 0.5502 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6716 - val_prc: 0.2931\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9219 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6790 - prc: 0.3279 - val_loss: 0.5452 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6768 - val_prc: 0.3021\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9173 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6737 - prc: 0.3131 - val_loss: 0.5198 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6848 - val_prc: 0.3305\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6895 - prc: 0.3314 - val_loss: 0.5440 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6760 - val_prc: 0.2991\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9052 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6844 - prc: 0.3150 - val_loss: 0.5046 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6856 - val_prc: 0.3411\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9044 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6855 - prc: 0.3421 - val_loss: 0.5019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6860 - val_prc: 0.3384\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6911 - prc: 0.3437 - val_loss: 0.5764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6537 - val_prc: 0.2624\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8971 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6887 - prc: 0.3362 - val_loss: 0.5585 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6721 - val_prc: 0.2920\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8911 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6994 - prc: 0.3470 - val_loss: 0.5002 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6857 - val_prc: 0.3482\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8927 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6952 - prc: 0.3553 - val_loss: 0.5125 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6842 - val_prc: 0.3376\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8896 - tp: 29.0000 - fp: 54.0000 - tn: 1572.0000 - fn: 369.0000 - accuracy: 0.7910 - precision: 0.3494 - recall: 0.0729 - auc: 0.6919 - prc: 0.3392 - val_loss: 0.5338 - val_tp: 36.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 55.0000 - val_accuracy: 0.7925 - val_precision: 0.4186 - val_recall: 0.3956 - val_auc: 0.6831 - val_prc: 0.3281\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8856 - tp: 146.0000 - fp: 218.0000 - tn: 1408.0000 - fn: 252.0000 - accuracy: 0.7678 - precision: 0.4011 - recall: 0.3668 - auc: 0.6945 - prc: 0.3323 - val_loss: 0.5276 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6832 - val_prc: 0.3351\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8867 - tp: 151.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 247.0000 - accuracy: 0.7658 - precision: 0.3995 - recall: 0.3794 - auc: 0.6902 - prc: 0.3362 - val_loss: 0.5287 - val_tp: 38.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 53.0000 - val_accuracy: 0.7945 - val_precision: 0.4270 - val_recall: 0.4176 - val_auc: 0.6838 - val_prc: 0.3374\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8860 - tp: 168.0000 - fp: 274.0000 - tn: 1352.0000 - fn: 230.0000 - accuracy: 0.7510 - precision: 0.3801 - recall: 0.4221 - auc: 0.6894 - prc: 0.3323 - val_loss: 0.5287 - val_tp: 37.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 54.0000 - val_accuracy: 0.7925 - val_precision: 0.4205 - val_recall: 0.4066 - val_auc: 0.6824 - val_prc: 0.3321\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8789 - tp: 165.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 233.0000 - accuracy: 0.7703 - precision: 0.4156 - recall: 0.4146 - auc: 0.7029 - prc: 0.3620 - val_loss: 0.5056 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6887 - val_prc: 0.3546\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8769 - tp: 165.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 233.0000 - accuracy: 0.7703 - precision: 0.4156 - recall: 0.4146 - auc: 0.7019 - prc: 0.3519 - val_loss: 0.5297 - val_tp: 38.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 53.0000 - val_accuracy: 0.7905 - val_precision: 0.4176 - val_recall: 0.4176 - val_auc: 0.6815 - val_prc: 0.3291\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8755 - tp: 164.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 234.0000 - accuracy: 0.7653 - precision: 0.4049 - recall: 0.4121 - auc: 0.6990 - prc: 0.3382 - val_loss: 0.5214 - val_tp: 37.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 54.0000 - val_accuracy: 0.7925 - val_precision: 0.4205 - val_recall: 0.4066 - val_auc: 0.6831 - val_prc: 0.3358\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8750 - tp: 165.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 233.0000 - accuracy: 0.7648 - precision: 0.4044 - recall: 0.4146 - auc: 0.7019 - prc: 0.3577 - val_loss: 0.5168 - val_tp: 36.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 55.0000 - val_accuracy: 0.7925 - val_precision: 0.4186 - val_recall: 0.3956 - val_auc: 0.6854 - val_prc: 0.3388\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8733 - tp: 168.0000 - fp: 239.0000 - tn: 1387.0000 - fn: 230.0000 - accuracy: 0.7683 - precision: 0.4128 - recall: 0.4221 - auc: 0.7053 - prc: 0.3675 - val_loss: 0.5673 - val_tp: 47.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 44.0000 - val_accuracy: 0.7352 - val_precision: 0.3431 - val_recall: 0.5165 - val_auc: 0.6766 - val_prc: 0.3095\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8716 - tp: 187.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 211.0000 - accuracy: 0.7633 - precision: 0.4110 - recall: 0.4698 - auc: 0.7035 - prc: 0.3511 - val_loss: 0.5525 - val_tp: 45.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 46.0000 - val_accuracy: 0.7490 - val_precision: 0.3571 - val_recall: 0.4945 - val_auc: 0.6842 - val_prc: 0.3296\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8692 - tp: 181.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 217.0000 - accuracy: 0.7633 - precision: 0.4086 - recall: 0.4548 - auc: 0.7078 - prc: 0.3761 - val_loss: 0.5191 - val_tp: 38.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 53.0000 - val_accuracy: 0.7945 - val_precision: 0.4270 - val_recall: 0.4176 - val_auc: 0.6835 - val_prc: 0.3324\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8695 - tp: 176.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 222.0000 - accuracy: 0.7708 - precision: 0.4211 - recall: 0.4422 - auc: 0.7050 - prc: 0.3641 - val_loss: 0.5097 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6839 - val_prc: 0.3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8628 - tp: 170.0000 - fp: 246.0000 - tn: 1380.0000 - fn: 228.0000 - accuracy: 0.7658 - precision: 0.4087 - recall: 0.4271 - auc: 0.7141 - prc: 0.3749 - val_loss: 0.5917 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6742 - val_prc: 0.3006\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8705 - tp: 181.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 217.0000 - accuracy: 0.7451 - precision: 0.3771 - recall: 0.4548 - auc: 0.7019 - prc: 0.3576 - val_loss: 0.5787 - val_tp: 49.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 42.0000 - val_accuracy: 0.6957 - val_precision: 0.3043 - val_recall: 0.5385 - val_auc: 0.6795 - val_prc: 0.3139\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8678 - tp: 180.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 218.0000 - accuracy: 0.7589 - precision: 0.4000 - recall: 0.4523 - auc: 0.7044 - prc: 0.3656 - val_loss: 0.5699 - val_tp: 49.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 42.0000 - val_accuracy: 0.7233 - val_precision: 0.3333 - val_recall: 0.5385 - val_auc: 0.6824 - val_prc: 0.3266\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8627 - tp: 183.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 215.0000 - accuracy: 0.7638 - precision: 0.4103 - recall: 0.4598 - auc: 0.7131 - prc: 0.3837 - val_loss: 0.5236 - val_tp: 38.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 53.0000 - val_accuracy: 0.7866 - val_precision: 0.4086 - val_recall: 0.4176 - val_auc: 0.6835 - val_prc: 0.3375\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8630 - tp: 175.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 223.0000 - accuracy: 0.7673 - precision: 0.4137 - recall: 0.4397 - auc: 0.7111 - prc: 0.3822 - val_loss: 0.5745 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6832 - val_prc: 0.3246\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8588 - tp: 195.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 203.0000 - accuracy: 0.7500 - precision: 0.3916 - recall: 0.4899 - auc: 0.7142 - prc: 0.3772 - val_loss: 0.4988 - val_tp: 30.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 61.0000 - val_accuracy: 0.7984 - val_precision: 0.4225 - val_recall: 0.3297 - val_auc: 0.6898 - val_prc: 0.3641\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8625 - tp: 183.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 215.0000 - accuracy: 0.7693 - precision: 0.4207 - recall: 0.4598 - auc: 0.7103 - prc: 0.3883 - val_loss: 0.5200 - val_tp: 36.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 55.0000 - val_accuracy: 0.7866 - val_precision: 0.4045 - val_recall: 0.3956 - val_auc: 0.6907 - val_prc: 0.3604\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8603 - tp: 183.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 215.0000 - accuracy: 0.7742 - precision: 0.4306 - recall: 0.4598 - auc: 0.7126 - prc: 0.3898 - val_loss: 0.5427 - val_tp: 44.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 47.0000 - val_accuracy: 0.7609 - val_precision: 0.3729 - val_recall: 0.4835 - val_auc: 0.6871 - val_prc: 0.3409\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8580 - tp: 186.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 212.0000 - accuracy: 0.7693 - precision: 0.4218 - recall: 0.4673 - auc: 0.7151 - prc: 0.4067 - val_loss: 0.5267 - val_tp: 36.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 55.0000 - val_accuracy: 0.7806 - val_precision: 0.3913 - val_recall: 0.3956 - val_auc: 0.6923 - val_prc: 0.3619\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8557 - tp: 199.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 199.0000 - accuracy: 0.7698 - precision: 0.4270 - recall: 0.5000 - auc: 0.7167 - prc: 0.3904 - val_loss: 0.5175 - val_tp: 33.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 58.0000 - val_accuracy: 0.7866 - val_precision: 0.3976 - val_recall: 0.3626 - val_auc: 0.6940 - val_prc: 0.3726\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8556 - tp: 180.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 218.0000 - accuracy: 0.7796 - precision: 0.4412 - recall: 0.4523 - auc: 0.7163 - prc: 0.4065 - val_loss: 0.5336 - val_tp: 43.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 48.0000 - val_accuracy: 0.7846 - val_precision: 0.4135 - val_recall: 0.4725 - val_auc: 0.6932 - val_prc: 0.3581\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8537 - tp: 189.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 209.0000 - accuracy: 0.7722 - precision: 0.4286 - recall: 0.4749 - auc: 0.7181 - prc: 0.3967 - val_loss: 0.5577 - val_tp: 48.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 43.0000 - val_accuracy: 0.7273 - val_precision: 0.3357 - val_recall: 0.5275 - val_auc: 0.6905 - val_prc: 0.3507\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8552 - tp: 199.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 199.0000 - accuracy: 0.7549 - precision: 0.4012 - recall: 0.5000 - auc: 0.7146 - prc: 0.3965 - val_loss: 0.5771 - val_tp: 48.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 43.0000 - val_accuracy: 0.7055 - val_precision: 0.3117 - val_recall: 0.5275 - val_auc: 0.6881 - val_prc: 0.3378\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8533 - tp: 189.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 209.0000 - accuracy: 0.7619 - precision: 0.4091 - recall: 0.4749 - auc: 0.7162 - prc: 0.3967 - val_loss: 0.5487 - val_tp: 47.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 44.0000 - val_accuracy: 0.7530 - val_precision: 0.3672 - val_recall: 0.5165 - val_auc: 0.6926 - val_prc: 0.3547\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8520 - tp: 186.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 212.0000 - accuracy: 0.7594 - precision: 0.4035 - recall: 0.4673 - auc: 0.7169 - prc: 0.3892 - val_loss: 0.5459 - val_tp: 47.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 44.0000 - val_accuracy: 0.7628 - val_precision: 0.3821 - val_recall: 0.5165 - val_auc: 0.6930 - val_prc: 0.3557\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8496 - tp: 188.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 210.0000 - accuracy: 0.7772 - precision: 0.4382 - recall: 0.4724 - auc: 0.7195 - prc: 0.4100 - val_loss: 0.5479 - val_tp: 47.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 44.0000 - val_accuracy: 0.7628 - val_precision: 0.3821 - val_recall: 0.5165 - val_auc: 0.6908 - val_prc: 0.3545\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8485 - tp: 190.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 208.0000 - accuracy: 0.7747 - precision: 0.4338 - recall: 0.4774 - auc: 0.7210 - prc: 0.4133 - val_loss: 0.5292 - val_tp: 43.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 48.0000 - val_accuracy: 0.7905 - val_precision: 0.4257 - val_recall: 0.4725 - val_auc: 0.6944 - val_prc: 0.3736\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8468 - tp: 200.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 198.0000 - accuracy: 0.7747 - precision: 0.4367 - recall: 0.5025 - auc: 0.7215 - prc: 0.3992 - val_loss: 0.4993 - val_tp: 30.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 61.0000 - val_accuracy: 0.7945 - val_precision: 0.4110 - val_recall: 0.3297 - val_auc: 0.6940 - val_prc: 0.3727\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8473 - tp: 188.0000 - fp: 245.0000 - tn: 1381.0000 - fn: 210.0000 - accuracy: 0.7752 - precision: 0.4342 - recall: 0.4724 - auc: 0.7210 - prc: 0.4020 - val_loss: 0.4944 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6956 - val_prc: 0.3823\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8468 - tp: 187.0000 - fp: 246.0000 - tn: 1380.0000 - fn: 211.0000 - accuracy: 0.7742 - precision: 0.4319 - recall: 0.4698 - auc: 0.7211 - prc: 0.4129 - val_loss: 0.5309 - val_tp: 42.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 49.0000 - val_accuracy: 0.7806 - val_precision: 0.4038 - val_recall: 0.4615 - val_auc: 0.6942 - val_prc: 0.3679\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8439 - tp: 187.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 211.0000 - accuracy: 0.7708 - precision: 0.4250 - recall: 0.4698 - auc: 0.7232 - prc: 0.4142 - val_loss: 0.5729 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6920 - val_prc: 0.3552\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8437 - tp: 200.0000 - fp: 264.0000 - tn: 1362.0000 - fn: 198.0000 - accuracy: 0.7717 - precision: 0.4310 - recall: 0.5025 - auc: 0.7223 - prc: 0.4030 - val_loss: 0.5627 - val_tp: 47.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 44.0000 - val_accuracy: 0.7213 - val_precision: 0.3264 - val_recall: 0.5165 - val_auc: 0.6927 - val_prc: 0.3584\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8455 - tp: 194.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 204.0000 - accuracy: 0.7658 - precision: 0.4181 - recall: 0.4874 - auc: 0.7210 - prc: 0.4195 - val_loss: 0.5405 - val_tp: 45.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 46.0000 - val_accuracy: 0.7628 - val_precision: 0.3782 - val_recall: 0.4945 - val_auc: 0.6941 - val_prc: 0.3645\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8418 - tp: 188.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 210.0000 - accuracy: 0.7678 - precision: 0.4196 - recall: 0.4724 - auc: 0.7249 - prc: 0.4217 - val_loss: 0.5257 - val_tp: 43.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 48.0000 - val_accuracy: 0.7866 - val_precision: 0.4175 - val_recall: 0.4725 - val_auc: 0.6969 - val_prc: 0.3743\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8424 - tp: 200.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 198.0000 - accuracy: 0.7584 - precision: 0.4073 - recall: 0.5025 - auc: 0.7238 - prc: 0.3986 - val_loss: 0.5534 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6928 - val_prc: 0.3524\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8419 - tp: 194.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 204.0000 - accuracy: 0.7732 - precision: 0.4321 - recall: 0.4874 - auc: 0.7236 - prc: 0.4169 - val_loss: 0.5135 - val_tp: 35.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 56.0000 - val_accuracy: 0.7905 - val_precision: 0.4118 - val_recall: 0.3846 - val_auc: 0.6962 - val_prc: 0.3759\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8414 - tp: 189.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 209.0000 - accuracy: 0.7693 - precision: 0.4228 - recall: 0.4749 - auc: 0.7253 - prc: 0.4217 - val_loss: 0.5597 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6909 - val_prc: 0.3538\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8408 - tp: 197.0000 - fp: 244.0000 - tn: 1382.0000 - fn: 201.0000 - accuracy: 0.7801 - precision: 0.4467 - recall: 0.4950 - auc: 0.7247 - prc: 0.4208 - val_loss: 0.5565 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6909 - val_prc: 0.3534\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8365 - tp: 189.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 209.0000 - accuracy: 0.7683 - precision: 0.4209 - recall: 0.4749 - auc: 0.7297 - prc: 0.4235 - val_loss: 0.5893 - val_tp: 53.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 38.0000 - val_accuracy: 0.6917 - val_precision: 0.3099 - val_recall: 0.5824 - val_auc: 0.6909 - val_prc: 0.3517\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8397 - tp: 206.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 192.0000 - accuracy: 0.7633 - precision: 0.4178 - recall: 0.5176 - auc: 0.7267 - prc: 0.4188 - val_loss: 0.5278 - val_tp: 43.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 48.0000 - val_accuracy: 0.7846 - val_precision: 0.4135 - val_recall: 0.4725 - val_auc: 0.6948 - val_prc: 0.3780\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8377 - tp: 204.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 194.0000 - accuracy: 0.7762 - precision: 0.4406 - recall: 0.5126 - auc: 0.7269 - prc: 0.4300 - val_loss: 0.5614 - val_tp: 47.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 44.0000 - val_accuracy: 0.7233 - val_precision: 0.3287 - val_recall: 0.5165 - val_auc: 0.6914 - val_prc: 0.3565\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8374 - tp: 198.0000 - fp: 284.0000 - tn: 1342.0000 - fn: 200.0000 - accuracy: 0.7609 - precision: 0.4108 - recall: 0.4975 - auc: 0.7270 - prc: 0.4260 - val_loss: 0.5104 - val_tp: 35.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 56.0000 - val_accuracy: 0.7905 - val_precision: 0.4118 - val_recall: 0.3846 - val_auc: 0.6957 - val_prc: 0.3790\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8374 - tp: 196.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 202.0000 - accuracy: 0.7678 - precision: 0.4224 - recall: 0.4925 - auc: 0.7264 - prc: 0.4292 - val_loss: 0.5153 - val_tp: 38.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 53.0000 - val_accuracy: 0.7905 - val_precision: 0.4176 - val_recall: 0.4176 - val_auc: 0.6955 - val_prc: 0.3814\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8375 - tp: 189.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 209.0000 - accuracy: 0.7772 - precision: 0.4385 - recall: 0.4749 - auc: 0.7269 - prc: 0.4335 - val_loss: 0.5306 - val_tp: 43.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 48.0000 - val_accuracy: 0.7826 - val_precision: 0.4095 - val_recall: 0.4725 - val_auc: 0.6962 - val_prc: 0.3795\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8359 - tp: 207.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 191.0000 - accuracy: 0.7604 - precision: 0.4132 - recall: 0.5201 - auc: 0.7290 - prc: 0.4338 - val_loss: 0.5130 - val_tp: 36.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 55.0000 - val_accuracy: 0.7945 - val_precision: 0.4235 - val_recall: 0.3956 - val_auc: 0.6966 - val_prc: 0.3807\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8363 - tp: 190.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 208.0000 - accuracy: 0.7772 - precision: 0.4388 - recall: 0.4774 - auc: 0.7279 - prc: 0.4405 - val_loss: 0.5602 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6901 - val_prc: 0.3611\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8367 - tp: 200.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 198.0000 - accuracy: 0.7624 - precision: 0.4141 - recall: 0.5025 - auc: 0.7271 - prc: 0.4349 - val_loss: 0.5258 - val_tp: 43.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 48.0000 - val_accuracy: 0.7866 - val_precision: 0.4175 - val_recall: 0.4725 - val_auc: 0.6966 - val_prc: 0.3842\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8360 - tp: 206.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 192.0000 - accuracy: 0.7624 - precision: 0.4162 - recall: 0.5176 - auc: 0.7267 - prc: 0.4321 - val_loss: 0.5380 - val_tp: 46.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 45.0000 - val_accuracy: 0.7688 - val_precision: 0.3898 - val_recall: 0.5055 - val_auc: 0.6956 - val_prc: 0.3788\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8374 - tp: 197.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 201.0000 - accuracy: 0.7693 - precision: 0.4255 - recall: 0.4950 - auc: 0.7257 - prc: 0.4318 - val_loss: 0.5773 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6904 - val_prc: 0.3610\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8332 - tp: 201.0000 - fp: 280.0000 - tn: 1346.0000 - fn: 197.0000 - accuracy: 0.7643 - precision: 0.4179 - recall: 0.5050 - auc: 0.7306 - prc: 0.4324 - val_loss: 0.5183 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 54.0000 - val_accuracy: 0.7905 - val_precision: 0.4157 - val_recall: 0.4066 - val_auc: 0.6960 - val_prc: 0.3776\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8350 - tp: 200.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 198.0000 - accuracy: 0.7762 - precision: 0.4396 - recall: 0.5025 - auc: 0.7271 - prc: 0.4201 - val_loss: 0.5302 - val_tp: 43.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 48.0000 - val_accuracy: 0.7806 - val_precision: 0.4057 - val_recall: 0.4725 - val_auc: 0.6965 - val_prc: 0.3867\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8346 - tp: 206.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 192.0000 - accuracy: 0.7717 - precision: 0.4328 - recall: 0.5176 - auc: 0.7263 - prc: 0.4336 - val_loss: 0.5530 - val_tp: 48.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 43.0000 - val_accuracy: 0.7510 - val_precision: 0.3664 - val_recall: 0.5275 - val_auc: 0.6944 - val_prc: 0.3767\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8333 - tp: 207.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 191.0000 - accuracy: 0.7727 - precision: 0.4349 - recall: 0.5201 - auc: 0.7294 - prc: 0.4418 - val_loss: 0.5155 - val_tp: 38.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 53.0000 - val_accuracy: 0.7905 - val_precision: 0.4176 - val_recall: 0.4176 - val_auc: 0.6965 - val_prc: 0.3859\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8353 - tp: 195.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 203.0000 - accuracy: 0.7722 - precision: 0.4305 - recall: 0.4899 - auc: 0.7271 - prc: 0.4392 - val_loss: 0.5343 - val_tp: 44.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 47.0000 - val_accuracy: 0.7767 - val_precision: 0.4000 - val_recall: 0.4835 - val_auc: 0.6956 - val_prc: 0.3813\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8323 - tp: 190.0000 - fp: 246.0000 - tn: 1380.0000 - fn: 208.0000 - accuracy: 0.7757 - precision: 0.4358 - recall: 0.4774 - auc: 0.7311 - prc: 0.4449 - val_loss: 0.5682 - val_tp: 48.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 43.0000 - val_accuracy: 0.7273 - val_precision: 0.3357 - val_recall: 0.5275 - val_auc: 0.6936 - val_prc: 0.3717\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8329 - tp: 202.0000 - fp: 280.0000 - tn: 1346.0000 - fn: 196.0000 - accuracy: 0.7648 - precision: 0.4191 - recall: 0.5075 - auc: 0.7286 - prc: 0.4241 - val_loss: 0.5501 - val_tp: 48.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 43.0000 - val_accuracy: 0.7569 - val_precision: 0.3750 - val_recall: 0.5275 - val_auc: 0.6941 - val_prc: 0.3834\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8310 - tp: 200.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 198.0000 - accuracy: 0.7693 - precision: 0.4264 - recall: 0.5025 - auc: 0.7304 - prc: 0.4443 - val_loss: 0.5725 - val_tp: 48.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 43.0000 - val_accuracy: 0.7253 - val_precision: 0.3333 - val_recall: 0.5275 - val_auc: 0.6922 - val_prc: 0.3659\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8311 - tp: 199.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 199.0000 - accuracy: 0.7737 - precision: 0.4345 - recall: 0.5000 - auc: 0.7304 - prc: 0.4374 - val_loss: 0.5739 - val_tp: 48.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 43.0000 - val_accuracy: 0.7016 - val_precision: 0.3077 - val_recall: 0.5275 - val_auc: 0.6927 - val_prc: 0.3718\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8307 - tp: 207.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 191.0000 - accuracy: 0.7658 - precision: 0.4224 - recall: 0.5201 - auc: 0.7293 - prc: 0.4352 - val_loss: 0.5588 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.6937 - val_prc: 0.3724\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8294 - tp: 200.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 198.0000 - accuracy: 0.7742 - precision: 0.4357 - recall: 0.5025 - auc: 0.7324 - prc: 0.4494 - val_loss: 0.5984 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6912 - val_prc: 0.3560\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8314 - tp: 210.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 188.0000 - accuracy: 0.7564 - precision: 0.4078 - recall: 0.5276 - auc: 0.7291 - prc: 0.4321 - val_loss: 0.5316 - val_tp: 43.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 48.0000 - val_accuracy: 0.7688 - val_precision: 0.3839 - val_recall: 0.4725 - val_auc: 0.6935 - val_prc: 0.3787\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8365 - tp: 187.0000 - fp: 257.0000 - tn: 1369.0000 - fn: 211.0000 - accuracy: 0.7688 - precision: 0.4212 - recall: 0.4698 - auc: 0.7247 - prc: 0.4441 - val_loss: 0.5214 - val_tp: 40.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 51.0000 - val_accuracy: 0.7885 - val_precision: 0.4167 - val_recall: 0.4396 - val_auc: 0.6954 - val_prc: 0.3817\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8285 - tp: 210.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 188.0000 - accuracy: 0.7579 - precision: 0.4102 - recall: 0.5276 - auc: 0.7335 - prc: 0.4358 - val_loss: 0.5189 - val_tp: 40.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 51.0000 - val_accuracy: 0.7885 - val_precision: 0.4167 - val_recall: 0.4396 - val_auc: 0.6956 - val_prc: 0.3797\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8280 - tp: 200.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 198.0000 - accuracy: 0.7782 - precision: 0.4435 - recall: 0.5025 - auc: 0.7326 - prc: 0.4448 - val_loss: 0.5472 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6935 - val_prc: 0.3818\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8301 - tp: 204.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 194.0000 - accuracy: 0.7668 - precision: 0.4232 - recall: 0.5126 - auc: 0.7300 - prc: 0.4395 - val_loss: 0.5304 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6954 - val_prc: 0.3819\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8310 - tp: 203.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 195.0000 - accuracy: 0.7703 - precision: 0.4292 - recall: 0.5101 - auc: 0.7298 - prc: 0.4399 - val_loss: 0.5208 - val_tp: 42.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 49.0000 - val_accuracy: 0.7885 - val_precision: 0.4200 - val_recall: 0.4615 - val_auc: 0.6952 - val_prc: 0.3789\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8289 - tp: 194.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 204.0000 - accuracy: 0.7846 - precision: 0.4554 - recall: 0.4874 - auc: 0.7306 - prc: 0.4453 - val_loss: 0.5638 - val_tp: 48.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 43.0000 - val_accuracy: 0.7233 - val_precision: 0.3310 - val_recall: 0.5275 - val_auc: 0.6930 - val_prc: 0.3752\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8291 - tp: 204.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 194.0000 - accuracy: 0.7530 - precision: 0.4000 - recall: 0.5126 - auc: 0.7329 - prc: 0.4437 - val_loss: 0.5310 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6946 - val_prc: 0.3775\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8284 - tp: 199.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 199.0000 - accuracy: 0.7742 - precision: 0.4354 - recall: 0.5000 - auc: 0.7314 - prc: 0.4469 - val_loss: 0.5417 - val_tp: 46.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 45.0000 - val_accuracy: 0.7708 - val_precision: 0.3932 - val_recall: 0.5055 - val_auc: 0.6929 - val_prc: 0.3784\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8290 - tp: 202.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 196.0000 - accuracy: 0.7747 - precision: 0.4372 - recall: 0.5075 - auc: 0.7309 - prc: 0.4452 - val_loss: 0.5852 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6908 - val_prc: 0.3704\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8289 - tp: 207.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 191.0000 - accuracy: 0.7643 - precision: 0.4199 - recall: 0.5201 - auc: 0.7307 - prc: 0.4338 - val_loss: 0.5516 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6928 - val_prc: 0.3805\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8258 - tp: 208.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 190.0000 - accuracy: 0.7653 - precision: 0.4219 - recall: 0.5226 - auc: 0.7343 - prc: 0.4509 - val_loss: 0.5260 - val_tp: 44.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 47.0000 - val_accuracy: 0.7846 - val_precision: 0.4151 - val_recall: 0.4835 - val_auc: 0.6945 - val_prc: 0.3771\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8254 - tp: 203.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 195.0000 - accuracy: 0.7643 - precision: 0.4186 - recall: 0.5101 - auc: 0.7343 - prc: 0.4433 - val_loss: 0.4999 - val_tp: 33.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 58.0000 - val_accuracy: 0.7925 - val_precision: 0.4125 - val_recall: 0.3626 - val_auc: 0.6956 - val_prc: 0.3820\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8274 - tp: 205.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 193.0000 - accuracy: 0.7668 - precision: 0.4236 - recall: 0.5151 - auc: 0.7317 - prc: 0.4412 - val_loss: 0.4878 - val_tp: 32.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 59.0000 - val_accuracy: 0.8063 - val_precision: 0.4507 - val_recall: 0.3516 - val_auc: 0.6958 - val_prc: 0.3797\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8260 - tp: 202.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 196.0000 - accuracy: 0.7772 - precision: 0.4420 - recall: 0.5075 - auc: 0.7337 - prc: 0.4484 - val_loss: 0.5225 - val_tp: 43.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 48.0000 - val_accuracy: 0.7806 - val_precision: 0.4057 - val_recall: 0.4725 - val_auc: 0.6950 - val_prc: 0.3738\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8273 - tp: 199.0000 - fp: 261.0000 - tn: 1365.0000 - fn: 199.0000 - accuracy: 0.7727 - precision: 0.4326 - recall: 0.5000 - auc: 0.7335 - prc: 0.4479 - val_loss: 0.5433 - val_tp: 47.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 44.0000 - val_accuracy: 0.7708 - val_precision: 0.3950 - val_recall: 0.5165 - val_auc: 0.6927 - val_prc: 0.3814\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8263 - tp: 203.0000 - fp: 265.0000 - tn: 1361.0000 - fn: 195.0000 - accuracy: 0.7727 - precision: 0.4338 - recall: 0.5101 - auc: 0.7334 - prc: 0.4448 - val_loss: 0.5208 - val_tp: 43.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 48.0000 - val_accuracy: 0.7866 - val_precision: 0.4175 - val_recall: 0.4725 - val_auc: 0.6936 - val_prc: 0.3740\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8252 - tp: 202.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 196.0000 - accuracy: 0.7708 - precision: 0.4298 - recall: 0.5075 - auc: 0.7344 - prc: 0.4494 - val_loss: 0.5216 - val_tp: 43.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 48.0000 - val_accuracy: 0.7806 - val_precision: 0.4057 - val_recall: 0.4725 - val_auc: 0.6945 - val_prc: 0.3752\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8244 - tp: 212.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 186.0000 - accuracy: 0.7663 - precision: 0.4248 - recall: 0.5327 - auc: 0.7351 - prc: 0.4464 - val_loss: 0.4950 - val_tp: 33.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 58.0000 - val_accuracy: 0.8004 - val_precision: 0.4342 - val_recall: 0.3626 - val_auc: 0.6931 - val_prc: 0.3735\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8310 - tp: 207.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 191.0000 - accuracy: 0.7594 - precision: 0.4115 - recall: 0.5201 - auc: 0.7294 - prc: 0.4418 - val_loss: 0.5233 - val_tp: 42.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 49.0000 - val_accuracy: 0.7787 - val_precision: 0.4000 - val_recall: 0.4615 - val_auc: 0.6914 - val_prc: 0.3708\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8263 - tp: 197.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 201.0000 - accuracy: 0.7782 - precision: 0.4427 - recall: 0.4950 - auc: 0.7328 - prc: 0.4579 - val_loss: 0.5554 - val_tp: 47.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 44.0000 - val_accuracy: 0.7490 - val_precision: 0.3615 - val_recall: 0.5165 - val_auc: 0.6920 - val_prc: 0.3752\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8228 - tp: 211.0000 - fp: 271.0000 - tn: 1355.0000 - fn: 187.0000 - accuracy: 0.7737 - precision: 0.4378 - recall: 0.5302 - auc: 0.7356 - prc: 0.4488 - val_loss: 0.4852 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6943 - val_prc: 0.3802\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8247 - tp: 203.0000 - fp: 249.0000 - tn: 1377.0000 - fn: 195.0000 - accuracy: 0.7806 - precision: 0.4491 - recall: 0.5101 - auc: 0.7342 - prc: 0.4529 - val_loss: 0.5202 - val_tp: 40.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 51.0000 - val_accuracy: 0.7787 - val_precision: 0.3960 - val_recall: 0.4396 - val_auc: 0.6929 - val_prc: 0.3733\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8290 - tp: 201.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 197.0000 - accuracy: 0.7727 - precision: 0.4332 - recall: 0.5050 - auc: 0.7289 - prc: 0.4528 - val_loss: 0.5614 - val_tp: 48.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 43.0000 - val_accuracy: 0.7391 - val_precision: 0.3504 - val_recall: 0.5275 - val_auc: 0.6912 - val_prc: 0.3771\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8239 - tp: 209.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 189.0000 - accuracy: 0.7638 - precision: 0.4197 - recall: 0.5251 - auc: 0.7349 - prc: 0.4465 - val_loss: 0.5413 - val_tp: 45.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 46.0000 - val_accuracy: 0.7668 - val_precision: 0.3846 - val_recall: 0.4945 - val_auc: 0.6924 - val_prc: 0.3712\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8219 - tp: 197.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 201.0000 - accuracy: 0.7727 - precision: 0.4320 - recall: 0.4950 - auc: 0.7377 - prc: 0.4466 - val_loss: 0.5658 - val_tp: 49.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 42.0000 - val_accuracy: 0.7352 - val_precision: 0.3475 - val_recall: 0.5385 - val_auc: 0.6912 - val_prc: 0.3732\n",
      "Epoch 124/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8219 - tp: 211.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 187.0000 - accuracy: 0.7599 - precision: 0.4137 - recall: 0.5302 - auc: 0.7369 - prc: 0.4505 - val_loss: 0.4980 - val_tp: 33.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 58.0000 - val_accuracy: 0.8004 - val_precision: 0.4342 - val_recall: 0.3626 - val_auc: 0.6929 - val_prc: 0.3740\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8236 - tp: 198.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 200.0000 - accuracy: 0.7717 - precision: 0.4304 - recall: 0.4975 - auc: 0.7345 - prc: 0.4571 - val_loss: 0.5224 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6937 - val_prc: 0.3719\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8215 - tp: 201.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 197.0000 - accuracy: 0.7777 - precision: 0.4427 - recall: 0.5050 - auc: 0.7372 - prc: 0.4449 - val_loss: 0.5966 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6901 - val_prc: 0.3738\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8286 - tp: 208.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 190.0000 - accuracy: 0.7594 - precision: 0.4119 - recall: 0.5226 - auc: 0.7304 - prc: 0.4423 - val_loss: 0.5417 - val_tp: 45.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 46.0000 - val_accuracy: 0.7727 - val_precision: 0.3947 - val_recall: 0.4945 - val_auc: 0.6912 - val_prc: 0.3709\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8223 - tp: 205.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 193.0000 - accuracy: 0.7717 - precision: 0.4325 - recall: 0.5151 - auc: 0.7371 - prc: 0.4539 - val_loss: 0.5639 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.6905 - val_prc: 0.3725\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8235 - tp: 195.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 203.0000 - accuracy: 0.7663 - precision: 0.4194 - recall: 0.4899 - auc: 0.7335 - prc: 0.4574 - val_loss: 0.5366 - val_tp: 45.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 46.0000 - val_accuracy: 0.7767 - val_precision: 0.4018 - val_recall: 0.4945 - val_auc: 0.6914 - val_prc: 0.3744\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8222 - tp: 207.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 191.0000 - accuracy: 0.7678 - precision: 0.4259 - recall: 0.5201 - auc: 0.7358 - prc: 0.4514 - val_loss: 0.5175 - val_tp: 40.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 51.0000 - val_accuracy: 0.7787 - val_precision: 0.3960 - val_recall: 0.4396 - val_auc: 0.6938 - val_prc: 0.3723\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8228 - tp: 210.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 188.0000 - accuracy: 0.7811 - precision: 0.4516 - recall: 0.5276 - auc: 0.7347 - prc: 0.4369 - val_loss: 0.5465 - val_tp: 46.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 45.0000 - val_accuracy: 0.7648 - val_precision: 0.3833 - val_recall: 0.5055 - val_auc: 0.6920 - val_prc: 0.3711\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8227 - tp: 204.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 194.0000 - accuracy: 0.7712 - precision: 0.4313 - recall: 0.5126 - auc: 0.7352 - prc: 0.4594 - val_loss: 0.5233 - val_tp: 43.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 48.0000 - val_accuracy: 0.7806 - val_precision: 0.4057 - val_recall: 0.4725 - val_auc: 0.6931 - val_prc: 0.3743\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8218 - tp: 201.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 197.0000 - accuracy: 0.7787 - precision: 0.4447 - recall: 0.5050 - auc: 0.7371 - prc: 0.4567 - val_loss: 0.5615 - val_tp: 49.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 42.0000 - val_accuracy: 0.7391 - val_precision: 0.3525 - val_recall: 0.5385 - val_auc: 0.6920 - val_prc: 0.3756\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8247 - tp: 199.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 199.0000 - accuracy: 0.7658 - precision: 0.4198 - recall: 0.5000 - auc: 0.7322 - prc: 0.4616 - val_loss: 0.5191 - val_tp: 40.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 51.0000 - val_accuracy: 0.7806 - val_precision: 0.4000 - val_recall: 0.4396 - val_auc: 0.6941 - val_prc: 0.3770\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8208 - tp: 201.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 197.0000 - accuracy: 0.7732 - precision: 0.4341 - recall: 0.5050 - auc: 0.7375 - prc: 0.4582 - val_loss: 0.5387 - val_tp: 45.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 46.0000 - val_accuracy: 0.7708 - val_precision: 0.3913 - val_recall: 0.4945 - val_auc: 0.6946 - val_prc: 0.3752\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8246 - tp: 208.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 190.0000 - accuracy: 0.7747 - precision: 0.4388 - recall: 0.5226 - auc: 0.7336 - prc: 0.4567 - val_loss: 0.4935 - val_tp: 33.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 58.0000 - val_accuracy: 0.8083 - val_precision: 0.4583 - val_recall: 0.3626 - val_auc: 0.6925 - val_prc: 0.3846\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8223 - tp: 198.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 200.0000 - accuracy: 0.7747 - precision: 0.4361 - recall: 0.4975 - auc: 0.7347 - prc: 0.4604 - val_loss: 0.5196 - val_tp: 43.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 48.0000 - val_accuracy: 0.7826 - val_precision: 0.4095 - val_recall: 0.4725 - val_auc: 0.6952 - val_prc: 0.3787\n",
      "Epoch 138/500\n",
      " 95/102 [==========================>...] - ETA: 0s - loss: 0.8155 - tp: 184.0000 - fp: 228.0000 - tn: 1302.0000 - fn: 186.0000 - accuracy: 0.7821 - precision: 0.4466 - recall: 0.4973 - auc: 0.7385 - prc: 0.4653       Restoring model weights from the end of the best epoch: 88.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8213 - tp: 195.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 203.0000 - accuracy: 0.7796 - precision: 0.4452 - recall: 0.4899 - auc: 0.7362 - prc: 0.4612 - val_loss: 0.5612 - val_tp: 48.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 43.0000 - val_accuracy: 0.7352 - val_precision: 0.3453 - val_recall: 0.5275 - val_auc: 0.6923 - val_prc: 0.3756\n",
      "Epoch 138: early stopping\n",
      "26/26 [==============================] - 0s 567us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.2856 - tp: 48.0000 - fp: 91.0000 - tn: 1950.0000 - fn: 441.0000 - accuracy: 0.7897 - precision: 0.3453 - recall: 0.0982 - auc: 0.5098 - prc: 0.2283 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2530 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5148 - prc: 0.2075 - val_loss: 0.4765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2247 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5261 - prc: 0.2076 - val_loss: 0.4803 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5093 - prc: 0.2030 - val_loss: 0.4849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1758 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4809 - prc: 0.1891 - val_loss: 0.4903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1554 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5031 - prc: 0.1981 - val_loss: 0.4964 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1367 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5092 - prc: 0.2017 - val_loss: 0.5030 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1206 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4785 - prc: 0.1861 - val_loss: 0.5102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5133 - val_prc: 0.1838\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1066 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5016 - prc: 0.1937 - val_loss: 0.5175 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4987 - prc: 0.1964 - val_loss: 0.5251 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0833 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5098 - prc: 0.2027 - val_loss: 0.5326 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5233 - prc: 0.2127 - val_loss: 0.5410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5056 - prc: 0.2019 - val_loss: 0.5486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0591 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1954 - val_loss: 0.5570 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0535 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5031 - prc: 0.1946 - val_loss: 0.5647 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0485 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4918 - prc: 0.1934 - val_loss: 0.5720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0448 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5166 - prc: 0.2056 - val_loss: 0.5786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0418 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4879 - prc: 0.1910 - val_loss: 0.5852 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5132 - val_prc: 0.1838\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0388 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5122 - prc: 0.2040 - val_loss: 0.5920 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0368 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4759 - prc: 0.1878 - val_loss: 0.5982 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5120 - val_prc: 0.1835\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0349 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5069 - prc: 0.1989 - val_loss: 0.6024 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5177 - val_prc: 0.1852\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4964 - prc: 0.1953 - val_loss: 0.6061 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5374 - val_prc: 0.1920\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5625 - prc: 0.2265 - val_loss: 0.6051 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5966 - val_prc: 0.2188\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0259 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6112 - prc: 0.2581 - val_loss: 0.5972 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6213 - val_prc: 0.2330\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0189 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6449 - prc: 0.3001 - val_loss: 0.5947 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6334 - val_prc: 0.2447\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0139 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6465 - prc: 0.3037 - val_loss: 0.5662 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6715 - val_prc: 0.3034\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0082 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6321 - prc: 0.2571 - val_loss: 0.6169 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5935 - val_prc: 0.2147\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0040 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6411 - prc: 0.2719 - val_loss: 0.5669 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6730 - val_prc: 0.2945\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9948 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6728 - prc: 0.3085 - val_loss: 0.5615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6745 - val_prc: 0.3015\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9929 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6618 - prc: 0.2939 - val_loss: 0.5549 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6781 - val_prc: 0.3141\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9849 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6843 - prc: 0.3349 - val_loss: 0.5674 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6711 - val_prc: 0.2926\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9805 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6765 - prc: 0.3013 - val_loss: 0.6072 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6410 - val_prc: 0.2484\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9801 - tp: 21.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 377.0000 - accuracy: 0.7856 - precision: 0.2692 - recall: 0.0528 - auc: 0.6713 - prc: 0.3002 - val_loss: 0.5970 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6514 - val_prc: 0.2599\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9780 - tp: 198.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 200.0000 - accuracy: 0.7100 - precision: 0.3385 - recall: 0.4975 - auc: 0.6732 - prc: 0.3038 - val_loss: 0.5519 - val_tp: 38.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 53.0000 - val_accuracy: 0.7727 - val_precision: 0.3800 - val_recall: 0.4176 - val_auc: 0.6778 - val_prc: 0.3138\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9716 - tp: 163.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 235.0000 - accuracy: 0.7574 - precision: 0.3890 - recall: 0.4095 - auc: 0.6908 - prc: 0.3418 - val_loss: 0.5683 - val_tp: 42.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 49.0000 - val_accuracy: 0.7391 - val_precision: 0.3360 - val_recall: 0.4615 - val_auc: 0.6704 - val_prc: 0.2943\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9711 - tp: 201.0000 - fp: 375.0000 - tn: 1251.0000 - fn: 197.0000 - accuracy: 0.7174 - precision: 0.3490 - recall: 0.5050 - auc: 0.6843 - prc: 0.3225 - val_loss: 0.5778 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6675 - val_prc: 0.2882\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9653 - tp: 193.0000 - fp: 343.0000 - tn: 1283.0000 - fn: 205.0000 - accuracy: 0.7292 - precision: 0.3601 - recall: 0.4849 - auc: 0.6914 - prc: 0.3345 - val_loss: 0.5410 - val_tp: 38.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 53.0000 - val_accuracy: 0.7806 - val_precision: 0.3958 - val_recall: 0.4176 - val_auc: 0.6802 - val_prc: 0.3277\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9651 - tp: 199.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 199.0000 - accuracy: 0.7263 - precision: 0.3592 - recall: 0.5000 - auc: 0.6858 - prc: 0.3210 - val_loss: 0.5591 - val_tp: 40.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 51.0000 - val_accuracy: 0.7451 - val_precision: 0.3390 - val_recall: 0.4396 - val_auc: 0.6767 - val_prc: 0.3181\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9636 - tp: 197.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 201.0000 - accuracy: 0.7288 - precision: 0.3615 - recall: 0.4950 - auc: 0.6876 - prc: 0.3257 - val_loss: 0.5443 - val_tp: 39.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 52.0000 - val_accuracy: 0.7668 - val_precision: 0.3714 - val_recall: 0.4286 - val_auc: 0.6797 - val_prc: 0.3241\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9581 - tp: 193.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 205.0000 - accuracy: 0.7268 - precision: 0.3567 - recall: 0.4849 - auc: 0.6940 - prc: 0.3320 - val_loss: 0.5904 - val_tp: 50.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 41.0000 - val_accuracy: 0.6818 - val_precision: 0.2941 - val_recall: 0.5495 - val_auc: 0.6666 - val_prc: 0.2870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9595 - tp: 213.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 185.0000 - accuracy: 0.7139 - precision: 0.3509 - recall: 0.5352 - auc: 0.6916 - prc: 0.3417 - val_loss: 0.5453 - val_tp: 39.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 52.0000 - val_accuracy: 0.7589 - val_precision: 0.3578 - val_recall: 0.4286 - val_auc: 0.6821 - val_prc: 0.3282\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9545 - tp: 214.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 184.0000 - accuracy: 0.7194 - precision: 0.3579 - recall: 0.5377 - auc: 0.6967 - prc: 0.3403 - val_loss: 0.5633 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6799 - val_prc: 0.3239\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9532 - tp: 202.0000 - fp: 361.0000 - tn: 1265.0000 - fn: 196.0000 - accuracy: 0.7248 - precision: 0.3588 - recall: 0.5075 - auc: 0.6976 - prc: 0.3469 - val_loss: 0.5862 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6706 - val_prc: 0.2978\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9531 - tp: 202.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 196.0000 - accuracy: 0.7184 - precision: 0.3507 - recall: 0.5075 - auc: 0.6963 - prc: 0.3453 - val_loss: 0.5689 - val_tp: 48.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 43.0000 - val_accuracy: 0.7253 - val_precision: 0.3333 - val_recall: 0.5275 - val_auc: 0.6799 - val_prc: 0.3253\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9492 - tp: 212.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 186.0000 - accuracy: 0.7189 - precision: 0.3563 - recall: 0.5327 - auc: 0.7006 - prc: 0.3525 - val_loss: 0.5493 - val_tp: 39.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 52.0000 - val_accuracy: 0.7470 - val_precision: 0.3391 - val_recall: 0.4286 - val_auc: 0.6813 - val_prc: 0.3295\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9475 - tp: 199.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 199.0000 - accuracy: 0.7337 - precision: 0.3692 - recall: 0.5000 - auc: 0.7056 - prc: 0.3794 - val_loss: 0.5407 - val_tp: 39.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 52.0000 - val_accuracy: 0.7648 - val_precision: 0.3679 - val_recall: 0.4286 - val_auc: 0.6818 - val_prc: 0.3338\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9497 - tp: 204.0000 - fp: 342.0000 - tn: 1284.0000 - fn: 194.0000 - accuracy: 0.7352 - precision: 0.3736 - recall: 0.5126 - auc: 0.6980 - prc: 0.3552 - val_loss: 0.5637 - val_tp: 46.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 45.0000 - val_accuracy: 0.7372 - val_precision: 0.3433 - val_recall: 0.5055 - val_auc: 0.6826 - val_prc: 0.3322\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9421 - tp: 222.0000 - fp: 401.0000 - tn: 1225.0000 - fn: 176.0000 - accuracy: 0.7149 - precision: 0.3563 - recall: 0.5578 - auc: 0.7059 - prc: 0.3585 - val_loss: 0.5203 - val_tp: 34.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 57.0000 - val_accuracy: 0.7885 - val_precision: 0.4048 - val_recall: 0.3736 - val_auc: 0.6888 - val_prc: 0.3566\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9448 - tp: 202.0000 - fp: 325.0000 - tn: 1301.0000 - fn: 196.0000 - accuracy: 0.7426 - precision: 0.3833 - recall: 0.5075 - auc: 0.7036 - prc: 0.3579 - val_loss: 0.5514 - val_tp: 42.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 49.0000 - val_accuracy: 0.7451 - val_precision: 0.3443 - val_recall: 0.4615 - val_auc: 0.6842 - val_prc: 0.3373\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9433 - tp: 211.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 187.0000 - accuracy: 0.7372 - precision: 0.3795 - recall: 0.5302 - auc: 0.7042 - prc: 0.3655 - val_loss: 0.5488 - val_tp: 41.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 50.0000 - val_accuracy: 0.7530 - val_precision: 0.3534 - val_recall: 0.4505 - val_auc: 0.6814 - val_prc: 0.3297\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9434 - tp: 215.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 183.0000 - accuracy: 0.7288 - precision: 0.3701 - recall: 0.5402 - auc: 0.7027 - prc: 0.3607 - val_loss: 0.5891 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6815 - val_prc: 0.3257\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9394 - tp: 211.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 187.0000 - accuracy: 0.7283 - precision: 0.3676 - recall: 0.5302 - auc: 0.7083 - prc: 0.3747 - val_loss: 0.5644 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6840 - val_prc: 0.3373\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9410 - tp: 214.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 184.0000 - accuracy: 0.7263 - precision: 0.3664 - recall: 0.5377 - auc: 0.7050 - prc: 0.3671 - val_loss: 0.5685 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6867 - val_prc: 0.3409\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9362 - tp: 193.0000 - fp: 337.0000 - tn: 1289.0000 - fn: 205.0000 - accuracy: 0.7322 - precision: 0.3642 - recall: 0.4849 - auc: 0.7104 - prc: 0.3837 - val_loss: 0.5923 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6847 - val_prc: 0.3345\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9377 - tp: 224.0000 - fp: 427.0000 - tn: 1199.0000 - fn: 174.0000 - accuracy: 0.7031 - precision: 0.3441 - recall: 0.5628 - auc: 0.7064 - prc: 0.3699 - val_loss: 0.5686 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6873 - val_prc: 0.3453\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9369 - tp: 208.0000 - fp: 376.0000 - tn: 1250.0000 - fn: 190.0000 - accuracy: 0.7204 - precision: 0.3562 - recall: 0.5226 - auc: 0.7062 - prc: 0.3695 - val_loss: 0.5686 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6875 - val_prc: 0.3456\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9341 - tp: 213.0000 - fp: 341.0000 - tn: 1285.0000 - fn: 185.0000 - accuracy: 0.7401 - precision: 0.3845 - recall: 0.5352 - auc: 0.7113 - prc: 0.3869 - val_loss: 0.5547 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6862 - val_prc: 0.3516\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9338 - tp: 218.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 180.0000 - accuracy: 0.7288 - precision: 0.3714 - recall: 0.5477 - auc: 0.7107 - prc: 0.3848 - val_loss: 0.5800 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6858 - val_prc: 0.3434\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9362 - tp: 217.0000 - fp: 367.0000 - tn: 1259.0000 - fn: 181.0000 - accuracy: 0.7292 - precision: 0.3716 - recall: 0.5452 - auc: 0.7064 - prc: 0.3873 - val_loss: 0.6070 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6844 - val_prc: 0.3312\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9292 - tp: 207.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 191.0000 - accuracy: 0.7337 - precision: 0.3730 - recall: 0.5201 - auc: 0.7149 - prc: 0.3952 - val_loss: 0.5965 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6858 - val_prc: 0.3380\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9317 - tp: 230.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 168.0000 - accuracy: 0.7125 - precision: 0.3571 - recall: 0.5779 - auc: 0.7111 - prc: 0.3782 - val_loss: 0.6024 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6865 - val_prc: 0.3401\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9280 - tp: 222.0000 - fp: 368.0000 - tn: 1258.0000 - fn: 176.0000 - accuracy: 0.7312 - precision: 0.3763 - recall: 0.5578 - auc: 0.7139 - prc: 0.3773 - val_loss: 0.5510 - val_tp: 44.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 47.0000 - val_accuracy: 0.7648 - val_precision: 0.3793 - val_recall: 0.4835 - val_auc: 0.6886 - val_prc: 0.3549\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9291 - tp: 210.0000 - fp: 332.0000 - tn: 1294.0000 - fn: 188.0000 - accuracy: 0.7431 - precision: 0.3875 - recall: 0.5276 - auc: 0.7132 - prc: 0.3933 - val_loss: 0.5554 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.6925 - val_prc: 0.3654\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9278 - tp: 213.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 185.0000 - accuracy: 0.7347 - precision: 0.3770 - recall: 0.5352 - auc: 0.7132 - prc: 0.3867 - val_loss: 0.5793 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6881 - val_prc: 0.3521\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9282 - tp: 218.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 180.0000 - accuracy: 0.7288 - precision: 0.3714 - recall: 0.5477 - auc: 0.7139 - prc: 0.3938 - val_loss: 0.5539 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.6898 - val_prc: 0.3594\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9233 - tp: 220.0000 - fp: 347.0000 - tn: 1279.0000 - fn: 178.0000 - accuracy: 0.7406 - precision: 0.3880 - recall: 0.5528 - auc: 0.7179 - prc: 0.4046 - val_loss: 0.5480 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6954 - val_prc: 0.3746\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9225 - tp: 226.0000 - fp: 360.0000 - tn: 1266.0000 - fn: 172.0000 - accuracy: 0.7372 - precision: 0.3857 - recall: 0.5678 - auc: 0.7198 - prc: 0.4083 - val_loss: 0.5626 - val_tp: 47.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 44.0000 - val_accuracy: 0.7332 - val_precision: 0.3406 - val_recall: 0.5165 - val_auc: 0.6937 - val_prc: 0.3696\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9255 - tp: 217.0000 - fp: 379.0000 - tn: 1247.0000 - fn: 181.0000 - accuracy: 0.7233 - precision: 0.3641 - recall: 0.5452 - auc: 0.7156 - prc: 0.3961 - val_loss: 0.5787 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6901 - val_prc: 0.3595\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9232 - tp: 214.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 184.0000 - accuracy: 0.7515 - precision: 0.4015 - recall: 0.5377 - auc: 0.7178 - prc: 0.4139 - val_loss: 0.5959 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6898 - val_prc: 0.3539\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9224 - tp: 212.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 186.0000 - accuracy: 0.7426 - precision: 0.3876 - recall: 0.5327 - auc: 0.7173 - prc: 0.4078 - val_loss: 0.5831 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6909 - val_prc: 0.3572\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9205 - tp: 219.0000 - fp: 361.0000 - tn: 1265.0000 - fn: 179.0000 - accuracy: 0.7332 - precision: 0.3776 - recall: 0.5503 - auc: 0.7194 - prc: 0.4102 - val_loss: 0.5464 - val_tp: 45.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 46.0000 - val_accuracy: 0.7668 - val_precision: 0.3846 - val_recall: 0.4945 - val_auc: 0.6947 - val_prc: 0.3714\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9234 - tp: 215.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 183.0000 - accuracy: 0.7273 - precision: 0.3682 - recall: 0.5402 - auc: 0.7148 - prc: 0.4030 - val_loss: 0.5695 - val_tp: 47.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 44.0000 - val_accuracy: 0.7332 - val_precision: 0.3406 - val_recall: 0.5165 - val_auc: 0.6925 - val_prc: 0.3667\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9189 - tp: 213.0000 - fp: 333.0000 - tn: 1293.0000 - fn: 185.0000 - accuracy: 0.7441 - precision: 0.3901 - recall: 0.5352 - auc: 0.7187 - prc: 0.4187 - val_loss: 0.6072 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6923 - val_prc: 0.3630\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9156 - tp: 212.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 186.0000 - accuracy: 0.7540 - precision: 0.4046 - recall: 0.5327 - auc: 0.7224 - prc: 0.4144 - val_loss: 0.6365 - val_tp: 58.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 33.0000 - val_accuracy: 0.6245 - val_precision: 0.2698 - val_recall: 0.6374 - val_auc: 0.6871 - val_prc: 0.3371\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9197 - tp: 232.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 166.0000 - accuracy: 0.7218 - precision: 0.3688 - recall: 0.5829 - auc: 0.7190 - prc: 0.4040 - val_loss: 0.5321 - val_tp: 40.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 51.0000 - val_accuracy: 0.7787 - val_precision: 0.3960 - val_recall: 0.4396 - val_auc: 0.6945 - val_prc: 0.3811\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9178 - tp: 222.0000 - fp: 361.0000 - tn: 1265.0000 - fn: 176.0000 - accuracy: 0.7347 - precision: 0.3808 - recall: 0.5578 - auc: 0.7196 - prc: 0.4152 - val_loss: 0.5595 - val_tp: 46.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 45.0000 - val_accuracy: 0.7451 - val_precision: 0.3538 - val_recall: 0.5055 - val_auc: 0.6940 - val_prc: 0.3768\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9159 - tp: 205.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 193.0000 - accuracy: 0.7530 - precision: 0.4004 - recall: 0.5151 - auc: 0.7215 - prc: 0.4334 - val_loss: 0.6001 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6895 - val_prc: 0.3541\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9151 - tp: 216.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 182.0000 - accuracy: 0.7327 - precision: 0.3757 - recall: 0.5427 - auc: 0.7210 - prc: 0.4167 - val_loss: 0.5618 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6941 - val_prc: 0.3758\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9150 - tp: 222.0000 - fp: 353.0000 - tn: 1273.0000 - fn: 176.0000 - accuracy: 0.7386 - precision: 0.3861 - recall: 0.5578 - auc: 0.7216 - prc: 0.4170 - val_loss: 0.5749 - val_tp: 48.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 43.0000 - val_accuracy: 0.7253 - val_precision: 0.3333 - val_recall: 0.5275 - val_auc: 0.6918 - val_prc: 0.3641\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9136 - tp: 219.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 179.0000 - accuracy: 0.7446 - precision: 0.3932 - recall: 0.5503 - auc: 0.7220 - prc: 0.4224 - val_loss: 0.5604 - val_tp: 44.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 47.0000 - val_accuracy: 0.7391 - val_precision: 0.3411 - val_recall: 0.4835 - val_auc: 0.6935 - val_prc: 0.3751\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9159 - tp: 219.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 179.0000 - accuracy: 0.7342 - precision: 0.3789 - recall: 0.5503 - auc: 0.7197 - prc: 0.4205 - val_loss: 0.5935 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6909 - val_prc: 0.3651\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9143 - tp: 223.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 175.0000 - accuracy: 0.7372 - precision: 0.3845 - recall: 0.5603 - auc: 0.7211 - prc: 0.4105 - val_loss: 0.5315 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6947 - val_prc: 0.3779\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9128 - tp: 220.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 178.0000 - accuracy: 0.7460 - precision: 0.3957 - recall: 0.5528 - auc: 0.7222 - prc: 0.4107 - val_loss: 0.5711 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6922 - val_prc: 0.3704\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9112 - tp: 219.0000 - fp: 351.0000 - tn: 1275.0000 - fn: 179.0000 - accuracy: 0.7381 - precision: 0.3842 - recall: 0.5503 - auc: 0.7233 - prc: 0.4252 - val_loss: 0.5556 - val_tp: 45.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 46.0000 - val_accuracy: 0.7530 - val_precision: 0.3629 - val_recall: 0.4945 - val_auc: 0.6944 - val_prc: 0.3715\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9116 - tp: 221.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 177.0000 - accuracy: 0.7495 - precision: 0.4011 - recall: 0.5553 - auc: 0.7223 - prc: 0.4142 - val_loss: 0.5377 - val_tp: 41.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 50.0000 - val_accuracy: 0.7747 - val_precision: 0.3905 - val_recall: 0.4505 - val_auc: 0.6947 - val_prc: 0.3744\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9101 - tp: 227.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 171.0000 - accuracy: 0.7391 - precision: 0.3887 - recall: 0.5704 - auc: 0.7232 - prc: 0.4096 - val_loss: 0.5879 - val_tp: 51.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 40.0000 - val_accuracy: 0.6976 - val_precision: 0.3110 - val_recall: 0.5604 - val_auc: 0.6906 - val_prc: 0.3647\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9115 - tp: 216.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 182.0000 - accuracy: 0.7426 - precision: 0.3892 - recall: 0.5427 - auc: 0.7216 - prc: 0.4260 - val_loss: 0.5711 - val_tp: 47.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 44.0000 - val_accuracy: 0.7273 - val_precision: 0.3333 - val_recall: 0.5165 - val_auc: 0.6932 - val_prc: 0.3716\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9101 - tp: 224.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 174.0000 - accuracy: 0.7421 - precision: 0.3916 - recall: 0.5628 - auc: 0.7228 - prc: 0.4068 - val_loss: 0.5643 - val_tp: 47.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 44.0000 - val_accuracy: 0.7451 - val_precision: 0.3561 - val_recall: 0.5165 - val_auc: 0.6938 - val_prc: 0.3706\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9091 - tp: 217.0000 - fp: 343.0000 - tn: 1283.0000 - fn: 181.0000 - accuracy: 0.7411 - precision: 0.3875 - recall: 0.5452 - auc: 0.7244 - prc: 0.4237 - val_loss: 0.6102 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6912 - val_prc: 0.3621\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9087 - tp: 213.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 185.0000 - accuracy: 0.7470 - precision: 0.3944 - recall: 0.5352 - auc: 0.7225 - prc: 0.4265 - val_loss: 0.5853 - val_tp: 49.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 42.0000 - val_accuracy: 0.7154 - val_precision: 0.3245 - val_recall: 0.5385 - val_auc: 0.6918 - val_prc: 0.3642\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9098 - tp: 232.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 166.0000 - accuracy: 0.7297 - precision: 0.3785 - recall: 0.5829 - auc: 0.7220 - prc: 0.4165 - val_loss: 0.5627 - val_tp: 46.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 45.0000 - val_accuracy: 0.7391 - val_precision: 0.3459 - val_recall: 0.5055 - val_auc: 0.6949 - val_prc: 0.3736\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9111 - tp: 217.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 181.0000 - accuracy: 0.7446 - precision: 0.3924 - recall: 0.5452 - auc: 0.7220 - prc: 0.4228 - val_loss: 0.5357 - val_tp: 39.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 52.0000 - val_accuracy: 0.7688 - val_precision: 0.3750 - val_recall: 0.4286 - val_auc: 0.6977 - val_prc: 0.3862\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9048 - tp: 224.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 174.0000 - accuracy: 0.7367 - precision: 0.3842 - recall: 0.5628 - auc: 0.7278 - prc: 0.4255 - val_loss: 0.5428 - val_tp: 43.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 48.0000 - val_accuracy: 0.7668 - val_precision: 0.3805 - val_recall: 0.4725 - val_auc: 0.6945 - val_prc: 0.3758\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9080 - tp: 222.0000 - fp: 349.0000 - tn: 1277.0000 - fn: 176.0000 - accuracy: 0.7406 - precision: 0.3888 - recall: 0.5578 - auc: 0.7240 - prc: 0.4292 - val_loss: 0.5509 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6954 - val_prc: 0.3758\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9066 - tp: 212.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 186.0000 - accuracy: 0.7544 - precision: 0.4054 - recall: 0.5327 - auc: 0.7259 - prc: 0.4321 - val_loss: 0.6190 - val_tp: 53.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 38.0000 - val_accuracy: 0.6581 - val_precision: 0.2819 - val_recall: 0.5824 - val_auc: 0.6907 - val_prc: 0.3680\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9073 - tp: 224.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 174.0000 - accuracy: 0.7376 - precision: 0.3855 - recall: 0.5628 - auc: 0.7244 - prc: 0.4249 - val_loss: 0.5729 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6935 - val_prc: 0.3685\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9035 - tp: 216.0000 - fp: 332.0000 - tn: 1294.0000 - fn: 182.0000 - accuracy: 0.7460 - precision: 0.3942 - recall: 0.5427 - auc: 0.7282 - prc: 0.4407 - val_loss: 0.5900 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6900 - val_prc: 0.3653\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9011 - tp: 228.0000 - fp: 378.0000 - tn: 1248.0000 - fn: 170.0000 - accuracy: 0.7292 - precision: 0.3762 - recall: 0.5729 - auc: 0.7306 - prc: 0.4165 - val_loss: 0.5608 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6922 - val_prc: 0.3680\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9057 - tp: 218.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 180.0000 - accuracy: 0.7362 - precision: 0.3811 - recall: 0.5477 - auc: 0.7252 - prc: 0.4175 - val_loss: 0.5692 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6937 - val_prc: 0.3689\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9015 - tp: 224.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 174.0000 - accuracy: 0.7485 - precision: 0.4007 - recall: 0.5628 - auc: 0.7300 - prc: 0.4294 - val_loss: 0.5917 - val_tp: 52.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 39.0000 - val_accuracy: 0.7036 - val_precision: 0.3190 - val_recall: 0.5714 - val_auc: 0.6928 - val_prc: 0.3687\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9061 - tp: 223.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 175.0000 - accuracy: 0.7218 - precision: 0.3650 - recall: 0.5603 - auc: 0.7242 - prc: 0.4231 - val_loss: 0.5622 - val_tp: 46.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 45.0000 - val_accuracy: 0.7391 - val_precision: 0.3459 - val_recall: 0.5055 - val_auc: 0.6954 - val_prc: 0.3747\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9032 - tp: 217.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 181.0000 - accuracy: 0.7480 - precision: 0.3974 - recall: 0.5452 - auc: 0.7273 - prc: 0.4320 - val_loss: 0.6048 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6909 - val_prc: 0.3666\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9049 - tp: 222.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 176.0000 - accuracy: 0.7367 - precision: 0.3834 - recall: 0.5578 - auc: 0.7234 - prc: 0.4278 - val_loss: 0.5819 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6957 - val_prc: 0.3710\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9028 - tp: 227.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 171.0000 - accuracy: 0.7347 - precision: 0.3828 - recall: 0.5704 - auc: 0.7278 - prc: 0.4333 - val_loss: 0.5874 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6947 - val_prc: 0.3700\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9014 - tp: 224.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 174.0000 - accuracy: 0.7436 - precision: 0.3937 - recall: 0.5628 - auc: 0.7291 - prc: 0.4335 - val_loss: 0.5934 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6925 - val_prc: 0.3659\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9062 - tp: 225.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 173.0000 - accuracy: 0.7381 - precision: 0.3866 - recall: 0.5653 - auc: 0.7253 - prc: 0.4181 - val_loss: 0.5761 - val_tp: 45.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 46.0000 - val_accuracy: 0.7174 - val_precision: 0.3169 - val_recall: 0.4945 - val_auc: 0.6935 - val_prc: 0.3702\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9037 - tp: 215.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 183.0000 - accuracy: 0.7426 - precision: 0.3888 - recall: 0.5402 - auc: 0.7254 - prc: 0.4293 - val_loss: 0.5604 - val_tp: 45.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 46.0000 - val_accuracy: 0.7510 - val_precision: 0.3600 - val_recall: 0.4945 - val_auc: 0.6964 - val_prc: 0.3851\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8982 - tp: 233.0000 - fp: 375.0000 - tn: 1251.0000 - fn: 165.0000 - accuracy: 0.7332 - precision: 0.3832 - recall: 0.5854 - auc: 0.7312 - prc: 0.4333 - val_loss: 0.5169 - val_tp: 36.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 55.0000 - val_accuracy: 0.7866 - val_precision: 0.4045 - val_recall: 0.3956 - val_auc: 0.7000 - val_prc: 0.3802\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9024 - tp: 212.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 186.0000 - accuracy: 0.7535 - precision: 0.4038 - recall: 0.5327 - auc: 0.7281 - prc: 0.4279 - val_loss: 0.6021 - val_tp: 53.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 38.0000 - val_accuracy: 0.6858 - val_precision: 0.3046 - val_recall: 0.5824 - val_auc: 0.6921 - val_prc: 0.3716\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9008 - tp: 233.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 165.0000 - accuracy: 0.7307 - precision: 0.3801 - recall: 0.5854 - auc: 0.7286 - prc: 0.4230 - val_loss: 0.5673 - val_tp: 47.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 44.0000 - val_accuracy: 0.7273 - val_precision: 0.3333 - val_recall: 0.5165 - val_auc: 0.6947 - val_prc: 0.3725\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9014 - tp: 217.0000 - fp: 333.0000 - tn: 1293.0000 - fn: 181.0000 - accuracy: 0.7460 - precision: 0.3945 - recall: 0.5452 - auc: 0.7277 - prc: 0.4307 - val_loss: 0.6216 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6931 - val_prc: 0.3694\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8997 - tp: 229.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 169.0000 - accuracy: 0.7357 - precision: 0.3849 - recall: 0.5754 - auc: 0.7287 - prc: 0.4283 - val_loss: 0.5775 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6949 - val_prc: 0.3778\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8988 - tp: 221.0000 - fp: 323.0000 - tn: 1303.0000 - fn: 177.0000 - accuracy: 0.7530 - precision: 0.4062 - recall: 0.5553 - auc: 0.7305 - prc: 0.4415 - val_loss: 0.5793 - val_tp: 47.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 44.0000 - val_accuracy: 0.7194 - val_precision: 0.3241 - val_recall: 0.5165 - val_auc: 0.6942 - val_prc: 0.3722\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9013 - tp: 229.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 169.0000 - accuracy: 0.7416 - precision: 0.3928 - recall: 0.5754 - auc: 0.7296 - prc: 0.4302 - val_loss: 0.5507 - val_tp: 44.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 47.0000 - val_accuracy: 0.7648 - val_precision: 0.3793 - val_recall: 0.4835 - val_auc: 0.6974 - val_prc: 0.3956\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9017 - tp: 217.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 181.0000 - accuracy: 0.7436 - precision: 0.3910 - recall: 0.5452 - auc: 0.7271 - prc: 0.4252 - val_loss: 0.5593 - val_tp: 45.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 46.0000 - val_accuracy: 0.7530 - val_precision: 0.3629 - val_recall: 0.4945 - val_auc: 0.6956 - val_prc: 0.3827\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8991 - tp: 226.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 172.0000 - accuracy: 0.7401 - precision: 0.3897 - recall: 0.5678 - auc: 0.7294 - prc: 0.4267 - val_loss: 0.6085 - val_tp: 54.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 37.0000 - val_accuracy: 0.6818 - val_precision: 0.3034 - val_recall: 0.5934 - val_auc: 0.6914 - val_prc: 0.3710\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8970 - tp: 233.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 165.0000 - accuracy: 0.7436 - precision: 0.3969 - recall: 0.5854 - auc: 0.7304 - prc: 0.4232 - val_loss: 0.5644 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6953 - val_prc: 0.3840\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8987 - tp: 221.0000 - fp: 344.0000 - tn: 1282.0000 - fn: 177.0000 - accuracy: 0.7426 - precision: 0.3912 - recall: 0.5553 - auc: 0.7307 - prc: 0.4387 - val_loss: 0.5449 - val_tp: 44.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 47.0000 - val_accuracy: 0.7589 - val_precision: 0.3697 - val_recall: 0.4835 - val_auc: 0.6975 - val_prc: 0.3908\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8958 - tp: 226.0000 - fp: 351.0000 - tn: 1275.0000 - fn: 172.0000 - accuracy: 0.7416 - precision: 0.3917 - recall: 0.5678 - auc: 0.7328 - prc: 0.4436 - val_loss: 0.5313 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6961 - val_prc: 0.3836\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8991 - tp: 233.0000 - fp: 353.0000 - tn: 1273.0000 - fn: 165.0000 - accuracy: 0.7441 - precision: 0.3976 - recall: 0.5854 - auc: 0.7288 - prc: 0.4354 - val_loss: 0.5768 - val_tp: 48.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 43.0000 - val_accuracy: 0.7233 - val_precision: 0.3310 - val_recall: 0.5275 - val_auc: 0.6939 - val_prc: 0.3727\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9029 - tp: 221.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 177.0000 - accuracy: 0.7332 - precision: 0.3784 - recall: 0.5553 - auc: 0.7264 - prc: 0.4249 - val_loss: 0.5582 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6956 - val_prc: 0.3811\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8967 - tp: 218.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 180.0000 - accuracy: 0.7540 - precision: 0.4067 - recall: 0.5477 - auc: 0.7317 - prc: 0.4381 - val_loss: 0.5825 - val_tp: 49.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 42.0000 - val_accuracy: 0.7134 - val_precision: 0.3224 - val_recall: 0.5385 - val_auc: 0.6927 - val_prc: 0.3729\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8970 - tp: 218.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 180.0000 - accuracy: 0.7554 - precision: 0.4090 - recall: 0.5477 - auc: 0.7321 - prc: 0.4401 - val_loss: 0.6170 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6940 - val_prc: 0.3723\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8966 - tp: 231.0000 - fp: 367.0000 - tn: 1259.0000 - fn: 167.0000 - accuracy: 0.7362 - precision: 0.3863 - recall: 0.5804 - auc: 0.7308 - prc: 0.4356 - val_loss: 0.5913 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6941 - val_prc: 0.3792\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8945 - tp: 226.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 172.0000 - accuracy: 0.7431 - precision: 0.3937 - recall: 0.5678 - auc: 0.7326 - prc: 0.4403 - val_loss: 0.5703 - val_tp: 49.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 42.0000 - val_accuracy: 0.7411 - val_precision: 0.3551 - val_recall: 0.5385 - val_auc: 0.6923 - val_prc: 0.3783\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8953 - tp: 216.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 182.0000 - accuracy: 0.7530 - precision: 0.4045 - recall: 0.5427 - auc: 0.7329 - prc: 0.4509 - val_loss: 0.6222 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6928 - val_prc: 0.3712\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8959 - tp: 239.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 159.0000 - accuracy: 0.7223 - precision: 0.3723 - recall: 0.6005 - auc: 0.7342 - prc: 0.4376 - val_loss: 0.5204 - val_tp: 39.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 52.0000 - val_accuracy: 0.7767 - val_precision: 0.3900 - val_recall: 0.4286 - val_auc: 0.6993 - val_prc: 0.3905\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8952 - tp: 209.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 189.0000 - accuracy: 0.7624 - precision: 0.4172 - recall: 0.5251 - auc: 0.7327 - prc: 0.4492 - val_loss: 0.6114 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6936 - val_prc: 0.3758\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8951 - tp: 227.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 171.0000 - accuracy: 0.7426 - precision: 0.3934 - recall: 0.5704 - auc: 0.7329 - prc: 0.4405 - val_loss: 0.5655 - val_tp: 46.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 45.0000 - val_accuracy: 0.7391 - val_precision: 0.3459 - val_recall: 0.5055 - val_auc: 0.6942 - val_prc: 0.3880\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8934 - tp: 221.0000 - fp: 337.0000 - tn: 1289.0000 - fn: 177.0000 - accuracy: 0.7460 - precision: 0.3961 - recall: 0.5553 - auc: 0.7348 - prc: 0.4466 - val_loss: 0.5560 - val_tp: 45.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 46.0000 - val_accuracy: 0.7549 - val_precision: 0.3659 - val_recall: 0.4945 - val_auc: 0.6954 - val_prc: 0.3907\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8942 - tp: 222.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 176.0000 - accuracy: 0.7559 - precision: 0.4111 - recall: 0.5578 - auc: 0.7337 - prc: 0.4505 - val_loss: 0.5820 - val_tp: 47.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 44.0000 - val_accuracy: 0.7194 - val_precision: 0.3241 - val_recall: 0.5165 - val_auc: 0.6938 - val_prc: 0.3840\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8960 - tp: 233.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 165.0000 - accuracy: 0.7362 - precision: 0.3870 - recall: 0.5854 - auc: 0.7315 - prc: 0.4309 - val_loss: 0.5223 - val_tp: 40.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 51.0000 - val_accuracy: 0.7747 - val_precision: 0.3883 - val_recall: 0.4396 - val_auc: 0.6986 - val_prc: 0.3964\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8942 - tp: 224.0000 - fp: 342.0000 - tn: 1284.0000 - fn: 174.0000 - accuracy: 0.7451 - precision: 0.3958 - recall: 0.5628 - auc: 0.7329 - prc: 0.4500 - val_loss: 0.5471 - val_tp: 44.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 47.0000 - val_accuracy: 0.7609 - val_precision: 0.3729 - val_recall: 0.4835 - val_auc: 0.6965 - val_prc: 0.3951\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8931 - tp: 225.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 173.0000 - accuracy: 0.7485 - precision: 0.4011 - recall: 0.5653 - auc: 0.7338 - prc: 0.4424 - val_loss: 0.5843 - val_tp: 49.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 42.0000 - val_accuracy: 0.7253 - val_precision: 0.3356 - val_recall: 0.5385 - val_auc: 0.6922 - val_prc: 0.3821\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8937 - tp: 208.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 190.0000 - accuracy: 0.7663 - precision: 0.4236 - recall: 0.5226 - auc: 0.7347 - prc: 0.4563 - val_loss: 0.6256 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6923 - val_prc: 0.3721\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9003 - tp: 235.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 163.0000 - accuracy: 0.7100 - precision: 0.3566 - recall: 0.5905 - auc: 0.7282 - prc: 0.4258 - val_loss: 0.5675 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6944 - val_prc: 0.3898\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8954 - tp: 224.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 174.0000 - accuracy: 0.7367 - precision: 0.3842 - recall: 0.5628 - auc: 0.7306 - prc: 0.4461 - val_loss: 0.5522 - val_tp: 45.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 46.0000 - val_accuracy: 0.7530 - val_precision: 0.3629 - val_recall: 0.4945 - val_auc: 0.6967 - val_prc: 0.3906\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8997 - tp: 222.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 176.0000 - accuracy: 0.7456 - precision: 0.3957 - recall: 0.5578 - auc: 0.7285 - prc: 0.4497 - val_loss: 0.5769 - val_tp: 49.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 42.0000 - val_accuracy: 0.7312 - val_precision: 0.3427 - val_recall: 0.5385 - val_auc: 0.6951 - val_prc: 0.3890\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8946 - tp: 225.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 173.0000 - accuracy: 0.7490 - precision: 0.4018 - recall: 0.5653 - auc: 0.7317 - prc: 0.4447 - val_loss: 0.5247 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6995 - val_prc: 0.3976\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8915 - tp: 220.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 178.0000 - accuracy: 0.7411 - precision: 0.3887 - recall: 0.5528 - auc: 0.7364 - prc: 0.4570 - val_loss: 0.5679 - val_tp: 46.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 45.0000 - val_accuracy: 0.7391 - val_precision: 0.3459 - val_recall: 0.5055 - val_auc: 0.6959 - val_prc: 0.3900\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8937 - tp: 221.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 177.0000 - accuracy: 0.7549 - precision: 0.4093 - recall: 0.5553 - auc: 0.7331 - prc: 0.4530 - val_loss: 0.5708 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.6945 - val_prc: 0.3897\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8924 - tp: 224.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 174.0000 - accuracy: 0.7515 - precision: 0.4051 - recall: 0.5628 - auc: 0.7342 - prc: 0.4546 - val_loss: 0.5903 - val_tp: 49.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 42.0000 - val_accuracy: 0.7253 - val_precision: 0.3356 - val_recall: 0.5385 - val_auc: 0.6915 - val_prc: 0.3826\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8955 - tp: 225.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 173.0000 - accuracy: 0.7426 - precision: 0.3927 - recall: 0.5653 - auc: 0.7319 - prc: 0.4374 - val_loss: 0.5942 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6942 - val_prc: 0.3817\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8907 - tp: 228.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 170.0000 - accuracy: 0.7574 - precision: 0.4153 - recall: 0.5729 - auc: 0.7354 - prc: 0.4524 - val_loss: 0.5872 - val_tp: 49.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 42.0000 - val_accuracy: 0.7213 - val_precision: 0.3311 - val_recall: 0.5385 - val_auc: 0.6928 - val_prc: 0.3840\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8918 - tp: 226.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 172.0000 - accuracy: 0.7470 - precision: 0.3993 - recall: 0.5678 - auc: 0.7332 - prc: 0.4365 - val_loss: 0.5908 - val_tp: 48.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 43.0000 - val_accuracy: 0.7055 - val_precision: 0.3117 - val_recall: 0.5275 - val_auc: 0.6946 - val_prc: 0.3769\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8928 - tp: 230.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 168.0000 - accuracy: 0.7490 - precision: 0.4035 - recall: 0.5779 - auc: 0.7339 - prc: 0.4513 - val_loss: 0.6077 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6933 - val_prc: 0.3749\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8914 - tp: 224.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 174.0000 - accuracy: 0.7485 - precision: 0.4007 - recall: 0.5628 - auc: 0.7346 - prc: 0.4514 - val_loss: 0.5458 - val_tp: 44.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 47.0000 - val_accuracy: 0.7628 - val_precision: 0.3761 - val_recall: 0.4835 - val_auc: 0.6961 - val_prc: 0.3973\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8920 - tp: 216.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 182.0000 - accuracy: 0.7559 - precision: 0.4091 - recall: 0.5427 - auc: 0.7344 - prc: 0.4550 - val_loss: 0.5731 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6941 - val_prc: 0.3895\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8896 - tp: 222.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 176.0000 - accuracy: 0.7470 - precision: 0.3978 - recall: 0.5578 - auc: 0.7367 - prc: 0.4485 - val_loss: 0.6197 - val_tp: 53.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 38.0000 - val_accuracy: 0.6700 - val_precision: 0.2912 - val_recall: 0.5824 - val_auc: 0.6912 - val_prc: 0.3756\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8908 - tp: 237.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 161.0000 - accuracy: 0.7376 - precision: 0.3904 - recall: 0.5955 - auc: 0.7350 - prc: 0.4476 - val_loss: 0.5245 - val_tp: 41.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 50.0000 - val_accuracy: 0.7826 - val_precision: 0.4059 - val_recall: 0.4505 - val_auc: 0.6997 - val_prc: 0.4002\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8910 - tp: 218.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 180.0000 - accuracy: 0.7569 - precision: 0.4113 - recall: 0.5477 - auc: 0.7340 - prc: 0.4487 - val_loss: 0.5791 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.6912 - val_prc: 0.3844\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8897 - tp: 216.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 182.0000 - accuracy: 0.7515 - precision: 0.4022 - recall: 0.5427 - auc: 0.7381 - prc: 0.4585 - val_loss: 0.6314 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6938 - val_prc: 0.3777\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8923 - tp: 224.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 174.0000 - accuracy: 0.7386 - precision: 0.3869 - recall: 0.5628 - auc: 0.7337 - prc: 0.4536 - val_loss: 0.5494 - val_tp: 44.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 47.0000 - val_accuracy: 0.7628 - val_precision: 0.3761 - val_recall: 0.4835 - val_auc: 0.6955 - val_prc: 0.3986\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8887 - tp: 217.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 181.0000 - accuracy: 0.7554 - precision: 0.4087 - recall: 0.5452 - auc: 0.7377 - prc: 0.4547 - val_loss: 0.6440 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6916 - val_prc: 0.3773\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8890 - tp: 226.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 172.0000 - accuracy: 0.7431 - precision: 0.3937 - recall: 0.5678 - auc: 0.7378 - prc: 0.4550 - val_loss: 0.5668 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.6935 - val_prc: 0.3971\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8913 - tp: 233.0000 - fp: 356.0000 - tn: 1270.0000 - fn: 165.0000 - accuracy: 0.7426 - precision: 0.3956 - recall: 0.5854 - auc: 0.7343 - prc: 0.4367 - val_loss: 0.5091 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6986 - val_prc: 0.3990\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8924 - tp: 217.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 181.0000 - accuracy: 0.7564 - precision: 0.4102 - recall: 0.5452 - auc: 0.7333 - prc: 0.4559 - val_loss: 0.5967 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6950 - val_prc: 0.3871\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8916 - tp: 226.0000 - fp: 342.0000 - tn: 1284.0000 - fn: 172.0000 - accuracy: 0.7460 - precision: 0.3979 - recall: 0.5678 - auc: 0.7340 - prc: 0.4510 - val_loss: 0.5734 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6930 - val_prc: 0.3930\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8891 - tp: 225.0000 - fp: 333.0000 - tn: 1293.0000 - fn: 173.0000 - accuracy: 0.7500 - precision: 0.4032 - recall: 0.5653 - auc: 0.7365 - prc: 0.4568 - val_loss: 0.5847 - val_tp: 48.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 43.0000 - val_accuracy: 0.7292 - val_precision: 0.3380 - val_recall: 0.5275 - val_auc: 0.6925 - val_prc: 0.3874\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8902 - tp: 231.0000 - fp: 358.0000 - tn: 1268.0000 - fn: 167.0000 - accuracy: 0.7406 - precision: 0.3922 - recall: 0.5804 - auc: 0.7366 - prc: 0.4441 - val_loss: 0.5772 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6940 - val_prc: 0.3921\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8884 - tp: 221.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 177.0000 - accuracy: 0.7510 - precision: 0.4033 - recall: 0.5553 - auc: 0.7363 - prc: 0.4590 - val_loss: 0.5874 - val_tp: 49.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 42.0000 - val_accuracy: 0.7194 - val_precision: 0.3289 - val_recall: 0.5385 - val_auc: 0.6960 - val_prc: 0.3956\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8909 - tp: 226.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 172.0000 - accuracy: 0.7475 - precision: 0.4000 - recall: 0.5678 - auc: 0.7340 - prc: 0.4534 - val_loss: 0.5484 - val_tp: 44.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 47.0000 - val_accuracy: 0.7609 - val_precision: 0.3729 - val_recall: 0.4835 - val_auc: 0.6951 - val_prc: 0.3972\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8873 - tp: 222.0000 - fp: 331.0000 - tn: 1295.0000 - fn: 176.0000 - accuracy: 0.7495 - precision: 0.4014 - recall: 0.5578 - auc: 0.7380 - prc: 0.4648 - val_loss: 0.5291 - val_tp: 41.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 50.0000 - val_accuracy: 0.7787 - val_precision: 0.3981 - val_recall: 0.4505 - val_auc: 0.6973 - val_prc: 0.3964\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8881 - tp: 208.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 190.0000 - accuracy: 0.7648 - precision: 0.4211 - recall: 0.5226 - auc: 0.7369 - prc: 0.4627 - val_loss: 0.6122 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6912 - val_prc: 0.3811\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8925 - tp: 234.0000 - fp: 376.0000 - tn: 1250.0000 - fn: 164.0000 - accuracy: 0.7332 - precision: 0.3836 - recall: 0.5879 - auc: 0.7326 - prc: 0.4543 - val_loss: 0.5547 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6969 - val_prc: 0.3996\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8871 - tp: 222.0000 - fp: 325.0000 - tn: 1301.0000 - fn: 176.0000 - accuracy: 0.7525 - precision: 0.4059 - recall: 0.5578 - auc: 0.7382 - prc: 0.4636 - val_loss: 0.5390 - val_tp: 44.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 47.0000 - val_accuracy: 0.7648 - val_precision: 0.3793 - val_recall: 0.4835 - val_auc: 0.6973 - val_prc: 0.3990\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8862 - tp: 224.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 174.0000 - accuracy: 0.7480 - precision: 0.4000 - recall: 0.5628 - auc: 0.7397 - prc: 0.4519 - val_loss: 0.5689 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6953 - val_prc: 0.3938\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8855 - tp: 234.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 164.0000 - accuracy: 0.7470 - precision: 0.4021 - recall: 0.5879 - auc: 0.7401 - prc: 0.4545 - val_loss: 0.5268 - val_tp: 42.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 49.0000 - val_accuracy: 0.7806 - val_precision: 0.4038 - val_recall: 0.4615 - val_auc: 0.6990 - val_prc: 0.4152\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8886 - tp: 215.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 183.0000 - accuracy: 0.7614 - precision: 0.4175 - recall: 0.5402 - auc: 0.7368 - prc: 0.4605 - val_loss: 0.5818 - val_tp: 48.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 43.0000 - val_accuracy: 0.7312 - val_precision: 0.3404 - val_recall: 0.5275 - val_auc: 0.6941 - val_prc: 0.3957\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8899 - tp: 230.0000 - fp: 332.0000 - tn: 1294.0000 - fn: 168.0000 - accuracy: 0.7530 - precision: 0.4093 - recall: 0.5779 - auc: 0.7363 - prc: 0.4519 - val_loss: 0.6199 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6917 - val_prc: 0.3842\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8904 - tp: 230.0000 - fp: 359.0000 - tn: 1267.0000 - fn: 168.0000 - accuracy: 0.7396 - precision: 0.3905 - recall: 0.5779 - auc: 0.7361 - prc: 0.4482 - val_loss: 0.5756 - val_tp: 47.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 44.0000 - val_accuracy: 0.7352 - val_precision: 0.3431 - val_recall: 0.5165 - val_auc: 0.6956 - val_prc: 0.3969\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8867 - tp: 227.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 171.0000 - accuracy: 0.7540 - precision: 0.4097 - recall: 0.5704 - auc: 0.7396 - prc: 0.4537 - val_loss: 0.5738 - val_tp: 48.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 43.0000 - val_accuracy: 0.7391 - val_precision: 0.3504 - val_recall: 0.5275 - val_auc: 0.6944 - val_prc: 0.3932\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8874 - tp: 223.0000 - fp: 323.0000 - tn: 1303.0000 - fn: 175.0000 - accuracy: 0.7540 - precision: 0.4084 - recall: 0.5603 - auc: 0.7370 - prc: 0.4589 - val_loss: 0.5958 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6941 - val_prc: 0.3966\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8894 - tp: 233.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 165.0000 - accuracy: 0.7436 - precision: 0.3969 - recall: 0.5854 - auc: 0.7379 - prc: 0.4509 - val_loss: 0.5360 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6966 - val_prc: 0.4014\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8858 - tp: 219.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 179.0000 - accuracy: 0.7574 - precision: 0.4124 - recall: 0.5503 - auc: 0.7382 - prc: 0.4681 - val_loss: 0.5869 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.6939 - val_prc: 0.3923\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8846 - tp: 224.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 174.0000 - accuracy: 0.7559 - precision: 0.4118 - recall: 0.5628 - auc: 0.7402 - prc: 0.4674 - val_loss: 0.5962 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6967 - val_prc: 0.4028\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8871 - tp: 237.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 161.0000 - accuracy: 0.7441 - precision: 0.3990 - recall: 0.5955 - auc: 0.7385 - prc: 0.4578 - val_loss: 0.5445 - val_tp: 44.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 47.0000 - val_accuracy: 0.7628 - val_precision: 0.3761 - val_recall: 0.4835 - val_auc: 0.6955 - val_prc: 0.4020\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8847 - tp: 234.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 164.0000 - accuracy: 0.7436 - precision: 0.3973 - recall: 0.5879 - auc: 0.7399 - prc: 0.4521 - val_loss: 0.5207 - val_tp: 39.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 52.0000 - val_accuracy: 0.7885 - val_precision: 0.4149 - val_recall: 0.4286 - val_auc: 0.6966 - val_prc: 0.3981\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8869 - tp: 209.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 189.0000 - accuracy: 0.7594 - precision: 0.4122 - recall: 0.5251 - auc: 0.7374 - prc: 0.4653 - val_loss: 0.5972 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6942 - val_prc: 0.3935\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8877 - tp: 230.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 168.0000 - accuracy: 0.7460 - precision: 0.3993 - recall: 0.5779 - auc: 0.7373 - prc: 0.4615 - val_loss: 0.5850 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.6955 - val_prc: 0.4062\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8870 - tp: 223.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 175.0000 - accuracy: 0.7564 - precision: 0.4122 - recall: 0.5603 - auc: 0.7378 - prc: 0.4622 - val_loss: 0.5714 - val_tp: 47.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 44.0000 - val_accuracy: 0.7372 - val_precision: 0.3456 - val_recall: 0.5165 - val_auc: 0.6960 - val_prc: 0.4025\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8840 - tp: 226.0000 - fp: 358.0000 - tn: 1268.0000 - fn: 172.0000 - accuracy: 0.7381 - precision: 0.3870 - recall: 0.5678 - auc: 0.7397 - prc: 0.4633 - val_loss: 0.5504 - val_tp: 44.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 47.0000 - val_accuracy: 0.7589 - val_precision: 0.3697 - val_recall: 0.4835 - val_auc: 0.6946 - val_prc: 0.3964\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8848 - tp: 224.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 174.0000 - accuracy: 0.7554 - precision: 0.4110 - recall: 0.5628 - auc: 0.7384 - prc: 0.4750 - val_loss: 0.5662 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.6937 - val_prc: 0.3987\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8858 - tp: 222.0000 - fp: 325.0000 - tn: 1301.0000 - fn: 176.0000 - accuracy: 0.7525 - precision: 0.4059 - recall: 0.5578 - auc: 0.7397 - prc: 0.4613 - val_loss: 0.5951 - val_tp: 50.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 41.0000 - val_accuracy: 0.7194 - val_precision: 0.3311 - val_recall: 0.5495 - val_auc: 0.6920 - val_prc: 0.3951\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8842 - tp: 219.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 179.0000 - accuracy: 0.7535 - precision: 0.4063 - recall: 0.5503 - auc: 0.7393 - prc: 0.4620 - val_loss: 0.6062 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6933 - val_prc: 0.3977\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8866 - tp: 234.0000 - fp: 362.0000 - tn: 1264.0000 - fn: 164.0000 - accuracy: 0.7401 - precision: 0.3926 - recall: 0.5879 - auc: 0.7393 - prc: 0.4595 - val_loss: 0.5858 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.6930 - val_prc: 0.4025\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8816 - tp: 224.0000 - fp: 356.0000 - tn: 1270.0000 - fn: 174.0000 - accuracy: 0.7381 - precision: 0.3862 - recall: 0.5628 - auc: 0.7439 - prc: 0.4617 - val_loss: 0.5646 - val_tp: 46.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 45.0000 - val_accuracy: 0.7372 - val_precision: 0.3433 - val_recall: 0.5055 - val_auc: 0.6993 - val_prc: 0.4089\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8855 - tp: 226.0000 - fp: 358.0000 - tn: 1268.0000 - fn: 172.0000 - accuracy: 0.7381 - precision: 0.3870 - recall: 0.5678 - auc: 0.7387 - prc: 0.4574 - val_loss: 0.5567 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.6931 - val_prc: 0.3993\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8859 - tp: 221.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 177.0000 - accuracy: 0.7564 - precision: 0.4115 - recall: 0.5553 - auc: 0.7376 - prc: 0.4597 - val_loss: 0.5599 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6966 - val_prc: 0.4026\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8836 - tp: 230.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 168.0000 - accuracy: 0.7554 - precision: 0.4129 - recall: 0.5779 - auc: 0.7381 - prc: 0.4649 - val_loss: 0.5591 - val_tp: 47.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 44.0000 - val_accuracy: 0.7589 - val_precision: 0.3760 - val_recall: 0.5165 - val_auc: 0.6936 - val_prc: 0.4030\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8832 - tp: 222.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 176.0000 - accuracy: 0.7530 - precision: 0.4066 - recall: 0.5578 - auc: 0.7397 - prc: 0.4551 - val_loss: 0.5549 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6935 - val_prc: 0.3987\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8849 - tp: 220.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 178.0000 - accuracy: 0.7574 - precision: 0.4128 - recall: 0.5528 - auc: 0.7394 - prc: 0.4669 - val_loss: 0.6009 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6973 - val_prc: 0.4065\n",
      "Epoch 193/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8832 - tp: 218.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 180.0000 - accuracy: 0.7549 - precision: 0.4082 - recall: 0.5477 - auc: 0.7405 - prc: 0.4707 - val_loss: 0.5736 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.6953 - val_prc: 0.4071\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8826 - tp: 230.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 168.0000 - accuracy: 0.7584 - precision: 0.4174 - recall: 0.5779 - auc: 0.7411 - prc: 0.4626 - val_loss: 0.5686 - val_tp: 48.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 43.0000 - val_accuracy: 0.7372 - val_precision: 0.3478 - val_recall: 0.5275 - val_auc: 0.6961 - val_prc: 0.3984\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8868 - tp: 231.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 167.0000 - accuracy: 0.7381 - precision: 0.3889 - recall: 0.5804 - auc: 0.7387 - prc: 0.4586 - val_loss: 0.5536 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6960 - val_prc: 0.4041\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8868 - tp: 223.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 175.0000 - accuracy: 0.7460 - precision: 0.3968 - recall: 0.5603 - auc: 0.7392 - prc: 0.4533 - val_loss: 0.5818 - val_tp: 48.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 43.0000 - val_accuracy: 0.7292 - val_precision: 0.3380 - val_recall: 0.5275 - val_auc: 0.6966 - val_prc: 0.4089\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8811 - tp: 225.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 173.0000 - accuracy: 0.7520 - precision: 0.4061 - recall: 0.5653 - auc: 0.7434 - prc: 0.4677 - val_loss: 0.5788 - val_tp: 48.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 43.0000 - val_accuracy: 0.7332 - val_precision: 0.3429 - val_recall: 0.5275 - val_auc: 0.6970 - val_prc: 0.4060\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8835 - tp: 219.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 179.0000 - accuracy: 0.7579 - precision: 0.4132 - recall: 0.5503 - auc: 0.7409 - prc: 0.4632 - val_loss: 0.5923 - val_tp: 49.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 42.0000 - val_accuracy: 0.7194 - val_precision: 0.3289 - val_recall: 0.5385 - val_auc: 0.6960 - val_prc: 0.4078\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8818 - tp: 230.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 168.0000 - accuracy: 0.7554 - precision: 0.4129 - recall: 0.5779 - auc: 0.7416 - prc: 0.4675 - val_loss: 0.5553 - val_tp: 45.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 46.0000 - val_accuracy: 0.7549 - val_precision: 0.3659 - val_recall: 0.4945 - val_auc: 0.6959 - val_prc: 0.4052\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8818 - tp: 219.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 179.0000 - accuracy: 0.7549 - precision: 0.4086 - recall: 0.5503 - auc: 0.7415 - prc: 0.4603 - val_loss: 0.5848 - val_tp: 49.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 42.0000 - val_accuracy: 0.7253 - val_precision: 0.3356 - val_recall: 0.5385 - val_auc: 0.6969 - val_prc: 0.4054\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8859 - tp: 230.0000 - fp: 347.0000 - tn: 1279.0000 - fn: 168.0000 - accuracy: 0.7456 - precision: 0.3986 - recall: 0.5779 - auc: 0.7379 - prc: 0.4613 - val_loss: 0.5380 - val_tp: 43.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 48.0000 - val_accuracy: 0.7727 - val_precision: 0.3909 - val_recall: 0.4725 - val_auc: 0.6975 - val_prc: 0.4135\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8854 - tp: 232.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 166.0000 - accuracy: 0.7426 - precision: 0.3952 - recall: 0.5829 - auc: 0.7404 - prc: 0.4461 - val_loss: 0.5981 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.6958 - val_prc: 0.4071\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8851 - tp: 225.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 173.0000 - accuracy: 0.7668 - precision: 0.4294 - recall: 0.5653 - auc: 0.7384 - prc: 0.4642 - val_loss: 0.5810 - val_tp: 47.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 44.0000 - val_accuracy: 0.7233 - val_precision: 0.3287 - val_recall: 0.5165 - val_auc: 0.6974 - val_prc: 0.4085\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8839 - tp: 221.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 177.0000 - accuracy: 0.7564 - precision: 0.4115 - recall: 0.5553 - auc: 0.7389 - prc: 0.4642 - val_loss: 0.6078 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6960 - val_prc: 0.3988\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8859 - tp: 231.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 167.0000 - accuracy: 0.7470 - precision: 0.4010 - recall: 0.5804 - auc: 0.7363 - prc: 0.4607 - val_loss: 0.5860 - val_tp: 50.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 41.0000 - val_accuracy: 0.7273 - val_precision: 0.3401 - val_recall: 0.5495 - val_auc: 0.6958 - val_prc: 0.4048\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8834 - tp: 222.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 176.0000 - accuracy: 0.7391 - precision: 0.3868 - recall: 0.5578 - auc: 0.7409 - prc: 0.4645 - val_loss: 0.4981 - val_tp: 38.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 53.0000 - val_accuracy: 0.8162 - val_precision: 0.4872 - val_recall: 0.4176 - val_auc: 0.7003 - val_prc: 0.4028\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8811 - tp: 222.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 176.0000 - accuracy: 0.7594 - precision: 0.4165 - recall: 0.5578 - auc: 0.7427 - prc: 0.4656 - val_loss: 0.6119 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6948 - val_prc: 0.3969\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8830 - tp: 231.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 167.0000 - accuracy: 0.7520 - precision: 0.4081 - recall: 0.5804 - auc: 0.7394 - prc: 0.4618 - val_loss: 0.5519 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6978 - val_prc: 0.4089\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8828 - tp: 227.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 171.0000 - accuracy: 0.7426 - precision: 0.3934 - recall: 0.5704 - auc: 0.7401 - prc: 0.4549 - val_loss: 0.5576 - val_tp: 46.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 45.0000 - val_accuracy: 0.7530 - val_precision: 0.3651 - val_recall: 0.5055 - val_auc: 0.6959 - val_prc: 0.4035\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8827 - tp: 225.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 173.0000 - accuracy: 0.7470 - precision: 0.3989 - recall: 0.5653 - auc: 0.7404 - prc: 0.4626 - val_loss: 0.5618 - val_tp: 48.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 43.0000 - val_accuracy: 0.7451 - val_precision: 0.3582 - val_recall: 0.5275 - val_auc: 0.6968 - val_prc: 0.4031\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8803 - tp: 224.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 174.0000 - accuracy: 0.7490 - precision: 0.4014 - recall: 0.5628 - auc: 0.7424 - prc: 0.4596 - val_loss: 0.5547 - val_tp: 45.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 46.0000 - val_accuracy: 0.7470 - val_precision: 0.3543 - val_recall: 0.4945 - val_auc: 0.6974 - val_prc: 0.4064\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8812 - tp: 224.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 174.0000 - accuracy: 0.7604 - precision: 0.4187 - recall: 0.5628 - auc: 0.7419 - prc: 0.4663 - val_loss: 0.5193 - val_tp: 41.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 50.0000 - val_accuracy: 0.7984 - val_precision: 0.4409 - val_recall: 0.4505 - val_auc: 0.6981 - val_prc: 0.4056\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8809 - tp: 226.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 172.0000 - accuracy: 0.7564 - precision: 0.4132 - recall: 0.5678 - auc: 0.7413 - prc: 0.4625 - val_loss: 0.5838 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6967 - val_prc: 0.4065\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8846 - tp: 223.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 175.0000 - accuracy: 0.7485 - precision: 0.4004 - recall: 0.5603 - auc: 0.7379 - prc: 0.4642 - val_loss: 0.6023 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6962 - val_prc: 0.4035\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8810 - tp: 237.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 161.0000 - accuracy: 0.7495 - precision: 0.4065 - recall: 0.5955 - auc: 0.7411 - prc: 0.4623 - val_loss: 0.5080 - val_tp: 38.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 53.0000 - val_accuracy: 0.7984 - val_precision: 0.4368 - val_recall: 0.4176 - val_auc: 0.6986 - val_prc: 0.4026\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8820 - tp: 220.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 178.0000 - accuracy: 0.7604 - precision: 0.4175 - recall: 0.5528 - auc: 0.7404 - prc: 0.4641 - val_loss: 0.5571 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6948 - val_prc: 0.3999\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8820 - tp: 214.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 184.0000 - accuracy: 0.7535 - precision: 0.4045 - recall: 0.5377 - auc: 0.7400 - prc: 0.4686 - val_loss: 0.5545 - val_tp: 45.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 46.0000 - val_accuracy: 0.7490 - val_precision: 0.3571 - val_recall: 0.4945 - val_auc: 0.6974 - val_prc: 0.4072\n",
      "Epoch 218/500\n",
      "100/102 [============================>.] - ETA: 0s - loss: 0.8795 - tp: 230.0000 - fp: 319.0000 - tn: 1287.0000 - fn: 164.0000 - accuracy: 0.7585 - precision: 0.4189 - recall: 0.5838 - auc: 0.7445 - prc: 0.4644Restoring model weights from the end of the best epoch: 168.\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8816 - tp: 231.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 167.0000 - accuracy: 0.7589 - precision: 0.4185 - recall: 0.5804 - auc: 0.7415 - prc: 0.4619 - val_loss: 0.5505 - val_tp: 44.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 47.0000 - val_accuracy: 0.7490 - val_precision: 0.3548 - val_recall: 0.4835 - val_auc: 0.6973 - val_prc: 0.4067\n",
      "Epoch 218: early stopping\n",
      "26/26 [==============================] - 0s 546us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.4425 - tp: 44.0000 - fp: 80.0000 - tn: 1961.0000 - fn: 445.0000 - accuracy: 0.7925 - precision: 0.3548 - recall: 0.0900 - auc: 0.5044 - prc: 0.2318 - val_loss: 0.4738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4031 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4902 - prc: 0.1914 - val_loss: 0.4766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5088 - prc: 0.1984 - val_loss: 0.4806 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3360 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5051 - prc: 0.2022 - val_loss: 0.4853 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5165 - prc: 0.2035 - val_loss: 0.4912 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4809 - prc: 0.1895 - val_loss: 0.4980 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2552 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - prc: 0.1893 - val_loss: 0.5053 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2338 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5125 - prc: 0.2010 - val_loss: 0.5130 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2145 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5025 - prc: 0.1941 - val_loss: 0.5217 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4851 - prc: 0.1931 - val_loss: 0.5304 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1826 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5150 - prc: 0.2024 - val_loss: 0.5393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1698 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4745 - prc: 0.1831 - val_loss: 0.5486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1586 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5130 - prc: 0.2042 - val_loss: 0.5573 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - prc: 0.1918 - val_loss: 0.5670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1406 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4998 - prc: 0.1950 - val_loss: 0.5761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4866 - prc: 0.1912 - val_loss: 0.5846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1276 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5112 - prc: 0.2034 - val_loss: 0.5925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5211 - val_prc: 0.1863\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1228 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4818 - prc: 0.1853 - val_loss: 0.6021 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1185 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4912 - prc: 0.1929 - val_loss: 0.6092 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5108 - val_prc: 0.1831\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1146 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5297 - prc: 0.2073 - val_loss: 0.6164 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5362 - val_prc: 0.1915\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1113 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5525 - prc: 0.2196 - val_loss: 0.6146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6206 - val_prc: 0.2346\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1061 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6205 - prc: 0.2630 - val_loss: 0.6149 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6346 - val_prc: 0.2432\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0981 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6488 - prc: 0.2875 - val_loss: 0.6059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6607 - val_prc: 0.2677\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6612 - prc: 0.2952 - val_loss: 0.6232 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6232 - val_prc: 0.2333\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6641 - prc: 0.3072 - val_loss: 0.5767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6792 - val_prc: 0.3144\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0760 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6707 - prc: 0.3071 - val_loss: 0.5769 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6814 - val_prc: 0.3193\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0665 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6770 - prc: 0.2991 - val_loss: 0.6451 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6117 - val_prc: 0.2253\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0725 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6550 - prc: 0.2936 - val_loss: 0.5712 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6807 - val_prc: 0.3169\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0613 - tp: 139.0000 - fp: 250.0000 - tn: 1376.0000 - fn: 259.0000 - accuracy: 0.7485 - precision: 0.3573 - recall: 0.3492 - auc: 0.6763 - prc: 0.3150 - val_loss: 0.5809 - val_tp: 41.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 50.0000 - val_accuracy: 0.7589 - val_precision: 0.3628 - val_recall: 0.4505 - val_auc: 0.6762 - val_prc: 0.3054\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0544 - tp: 195.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 203.0000 - accuracy: 0.7322 - precision: 0.3652 - recall: 0.4899 - auc: 0.6876 - prc: 0.3423 - val_loss: 0.5715 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6781 - val_prc: 0.3134\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0507 - tp: 201.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 197.0000 - accuracy: 0.7273 - precision: 0.3615 - recall: 0.5050 - auc: 0.6885 - prc: 0.3341 - val_loss: 0.6100 - val_tp: 51.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 40.0000 - val_accuracy: 0.6581 - val_precision: 0.2772 - val_recall: 0.5604 - val_auc: 0.6631 - val_prc: 0.2765\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0467 - tp: 208.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 190.0000 - accuracy: 0.7085 - precision: 0.3421 - recall: 0.5226 - auc: 0.6794 - prc: 0.3045 - val_loss: 0.5864 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6755 - val_prc: 0.3058\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0450 - tp: 219.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 179.0000 - accuracy: 0.6897 - precision: 0.3278 - recall: 0.5503 - auc: 0.6773 - prc: 0.3075 - val_loss: 0.5821 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6774 - val_prc: 0.3057\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0382 - tp: 225.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 173.0000 - accuracy: 0.6917 - precision: 0.3328 - recall: 0.5653 - auc: 0.6878 - prc: 0.3219 - val_loss: 0.6174 - val_tp: 53.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 38.0000 - val_accuracy: 0.6285 - val_precision: 0.2611 - val_recall: 0.5824 - val_auc: 0.6614 - val_prc: 0.2724\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0382 - tp: 224.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 174.0000 - accuracy: 0.6789 - precision: 0.3200 - recall: 0.5628 - auc: 0.6835 - prc: 0.3175 - val_loss: 0.6418 - val_tp: 61.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 30.0000 - val_accuracy: 0.5632 - val_precision: 0.2421 - val_recall: 0.6703 - val_auc: 0.6548 - val_prc: 0.2636\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0343 - tp: 230.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 168.0000 - accuracy: 0.6744 - precision: 0.3190 - recall: 0.5779 - auc: 0.6947 - prc: 0.3469 - val_loss: 0.5696 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6833 - val_prc: 0.3351\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0299 - tp: 211.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 187.0000 - accuracy: 0.7169 - precision: 0.3534 - recall: 0.5302 - auc: 0.6980 - prc: 0.3485 - val_loss: 0.6251 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6677 - val_prc: 0.2856\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0299 - tp: 230.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 168.0000 - accuracy: 0.6971 - precision: 0.3407 - recall: 0.5779 - auc: 0.6947 - prc: 0.3450 - val_loss: 0.5757 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6853 - val_prc: 0.3387\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0252 - tp: 224.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 174.0000 - accuracy: 0.6843 - precision: 0.3251 - recall: 0.5628 - auc: 0.6971 - prc: 0.3416 - val_loss: 0.5982 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6816 - val_prc: 0.3229\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0229 - tp: 230.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 168.0000 - accuracy: 0.6976 - precision: 0.3412 - recall: 0.5779 - auc: 0.6999 - prc: 0.3516 - val_loss: 0.5859 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6850 - val_prc: 0.3406\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0209 - tp: 243.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 155.0000 - accuracy: 0.6759 - precision: 0.3266 - recall: 0.6106 - auc: 0.6954 - prc: 0.3349 - val_loss: 0.5931 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6832 - val_prc: 0.3342\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0207 - tp: 227.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 171.0000 - accuracy: 0.6907 - precision: 0.3328 - recall: 0.5704 - auc: 0.6983 - prc: 0.3520 - val_loss: 0.6138 - val_tp: 55.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 36.0000 - val_accuracy: 0.6601 - val_precision: 0.2880 - val_recall: 0.6044 - val_auc: 0.6770 - val_prc: 0.3120\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0170 - tp: 234.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 164.0000 - accuracy: 0.6912 - precision: 0.3367 - recall: 0.5879 - auc: 0.7002 - prc: 0.3453 - val_loss: 0.5956 - val_tp: 51.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 40.0000 - val_accuracy: 0.6976 - val_precision: 0.3110 - val_recall: 0.5604 - val_auc: 0.6841 - val_prc: 0.3391\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0162 - tp: 227.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 171.0000 - accuracy: 0.6897 - precision: 0.3319 - recall: 0.5704 - auc: 0.7024 - prc: 0.3667 - val_loss: 0.5874 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6826 - val_prc: 0.3337\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0154 - tp: 240.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 158.0000 - accuracy: 0.6675 - precision: 0.3179 - recall: 0.6030 - auc: 0.7004 - prc: 0.3510 - val_loss: 0.6219 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6748 - val_prc: 0.3057\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0102 - tp: 238.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 160.0000 - accuracy: 0.7011 - precision: 0.3485 - recall: 0.5980 - auc: 0.7073 - prc: 0.3629 - val_loss: 0.6062 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6825 - val_prc: 0.3325\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0140 - tp: 239.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 159.0000 - accuracy: 0.6690 - precision: 0.3187 - recall: 0.6005 - auc: 0.7021 - prc: 0.3669 - val_loss: 0.6281 - val_tp: 57.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 34.0000 - val_accuracy: 0.6206 - val_precision: 0.2651 - val_recall: 0.6264 - val_auc: 0.6775 - val_prc: 0.3111\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0084 - tp: 236.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 162.0000 - accuracy: 0.6882 - precision: 0.3348 - recall: 0.5930 - auc: 0.7072 - prc: 0.3664 - val_loss: 0.6144 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6854 - val_prc: 0.3402\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0083 - tp: 243.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 155.0000 - accuracy: 0.6877 - precision: 0.3375 - recall: 0.6106 - auc: 0.7057 - prc: 0.3666 - val_loss: 0.5997 - val_tp: 53.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 38.0000 - val_accuracy: 0.6858 - val_precision: 0.3046 - val_recall: 0.5824 - val_auc: 0.6873 - val_prc: 0.3453\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0073 - tp: 248.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 150.0000 - accuracy: 0.6764 - precision: 0.3293 - recall: 0.6231 - auc: 0.7031 - prc: 0.3463 - val_loss: 0.5883 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6843 - val_prc: 0.3332\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0056 - tp: 241.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 157.0000 - accuracy: 0.6932 - precision: 0.3418 - recall: 0.6055 - auc: 0.7075 - prc: 0.3671 - val_loss: 0.5928 - val_tp: 51.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 40.0000 - val_accuracy: 0.7075 - val_precision: 0.3208 - val_recall: 0.5604 - val_auc: 0.6863 - val_prc: 0.3369\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0017 - tp: 246.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 152.0000 - accuracy: 0.6853 - precision: 0.3365 - recall: 0.6181 - auc: 0.7123 - prc: 0.3864 - val_loss: 0.5958 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6858 - val_prc: 0.3342\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0011 - tp: 247.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 151.0000 - accuracy: 0.6838 - precision: 0.3356 - recall: 0.6206 - auc: 0.7114 - prc: 0.3782 - val_loss: 0.5906 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6863 - val_prc: 0.3348\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9991 - tp: 239.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 159.0000 - accuracy: 0.6996 - precision: 0.3474 - recall: 0.6005 - auc: 0.7127 - prc: 0.3757 - val_loss: 0.6165 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6869 - val_prc: 0.3421\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0000 - tp: 246.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 152.0000 - accuracy: 0.6734 - precision: 0.3258 - recall: 0.6181 - auc: 0.7109 - prc: 0.3754 - val_loss: 0.5530 - val_tp: 44.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 47.0000 - val_accuracy: 0.7510 - val_precision: 0.3577 - val_recall: 0.4835 - val_auc: 0.6890 - val_prc: 0.3559\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9990 - tp: 233.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 165.0000 - accuracy: 0.7055 - precision: 0.3509 - recall: 0.5854 - auc: 0.7121 - prc: 0.3878 - val_loss: 0.6021 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6881 - val_prc: 0.3409\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9972 - tp: 247.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 151.0000 - accuracy: 0.6907 - precision: 0.3421 - recall: 0.6206 - auc: 0.7136 - prc: 0.3868 - val_loss: 0.5882 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6885 - val_prc: 0.3485\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9951 - tp: 241.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 157.0000 - accuracy: 0.7026 - precision: 0.3513 - recall: 0.6055 - auc: 0.7146 - prc: 0.3837 - val_loss: 0.6495 - val_tp: 60.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 31.0000 - val_accuracy: 0.5949 - val_precision: 0.2564 - val_recall: 0.6593 - val_auc: 0.6851 - val_prc: 0.3307\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9951 - tp: 252.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 146.0000 - accuracy: 0.6774 - precision: 0.3320 - recall: 0.6332 - auc: 0.7117 - prc: 0.3783 - val_loss: 0.5977 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.6887 - val_prc: 0.3427\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9923 - tp: 244.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 154.0000 - accuracy: 0.6912 - precision: 0.3413 - recall: 0.6131 - auc: 0.7158 - prc: 0.3849 - val_loss: 0.5817 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6890 - val_prc: 0.3485\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9973 - tp: 244.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 154.0000 - accuracy: 0.6937 - precision: 0.3437 - recall: 0.6131 - auc: 0.7102 - prc: 0.3917 - val_loss: 0.5963 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6902 - val_prc: 0.3477\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9924 - tp: 244.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 154.0000 - accuracy: 0.6947 - precision: 0.3446 - recall: 0.6131 - auc: 0.7152 - prc: 0.3931 - val_loss: 0.6116 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6883 - val_prc: 0.3426\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9904 - tp: 239.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 159.0000 - accuracy: 0.7065 - precision: 0.3546 - recall: 0.6005 - auc: 0.7175 - prc: 0.4094 - val_loss: 0.6197 - val_tp: 56.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 35.0000 - val_accuracy: 0.6443 - val_precision: 0.2786 - val_recall: 0.6154 - val_auc: 0.6891 - val_prc: 0.3482\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9904 - tp: 243.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 155.0000 - accuracy: 0.6981 - precision: 0.3476 - recall: 0.6106 - auc: 0.7161 - prc: 0.3994 - val_loss: 0.6271 - val_tp: 56.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 35.0000 - val_accuracy: 0.6304 - val_precision: 0.2692 - val_recall: 0.6154 - val_auc: 0.6873 - val_prc: 0.3428\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9936 - tp: 252.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 146.0000 - accuracy: 0.6759 - precision: 0.3307 - recall: 0.6332 - auc: 0.7133 - prc: 0.3859 - val_loss: 0.5512 - val_tp: 45.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 46.0000 - val_accuracy: 0.7648 - val_precision: 0.3814 - val_recall: 0.4945 - val_auc: 0.6914 - val_prc: 0.3638\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9875 - tp: 241.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 157.0000 - accuracy: 0.6922 - precision: 0.3409 - recall: 0.6055 - auc: 0.7194 - prc: 0.4065 - val_loss: 0.6109 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6907 - val_prc: 0.3445\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9862 - tp: 242.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 156.0000 - accuracy: 0.6833 - precision: 0.3329 - recall: 0.6080 - auc: 0.7177 - prc: 0.3823 - val_loss: 0.5906 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6896 - val_prc: 0.3557\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9850 - tp: 243.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 155.0000 - accuracy: 0.7011 - precision: 0.3506 - recall: 0.6106 - auc: 0.7189 - prc: 0.4019 - val_loss: 0.5647 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.6913 - val_prc: 0.3607\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9851 - tp: 238.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 160.0000 - accuracy: 0.7026 - precision: 0.3500 - recall: 0.5980 - auc: 0.7196 - prc: 0.4024 - val_loss: 0.5826 - val_tp: 48.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 43.0000 - val_accuracy: 0.7233 - val_precision: 0.3310 - val_recall: 0.5275 - val_auc: 0.6921 - val_prc: 0.3651\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9849 - tp: 245.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 153.0000 - accuracy: 0.6887 - precision: 0.3393 - recall: 0.6156 - auc: 0.7187 - prc: 0.4013 - val_loss: 0.5861 - val_tp: 49.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 42.0000 - val_accuracy: 0.7154 - val_precision: 0.3245 - val_recall: 0.5385 - val_auc: 0.6912 - val_prc: 0.3598\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9847 - tp: 237.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 161.0000 - accuracy: 0.7065 - precision: 0.3537 - recall: 0.5955 - auc: 0.7186 - prc: 0.4053 - val_loss: 0.6124 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6924 - val_prc: 0.3576\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9818 - tp: 254.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 144.0000 - accuracy: 0.6828 - precision: 0.3378 - recall: 0.6382 - auc: 0.7218 - prc: 0.4039 - val_loss: 0.5592 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.6922 - val_prc: 0.3634\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9849 - tp: 237.0000 - fp: 421.0000 - tn: 1205.0000 - fn: 161.0000 - accuracy: 0.7125 - precision: 0.3602 - recall: 0.5955 - auc: 0.7173 - prc: 0.4151 - val_loss: 0.5926 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6918 - val_prc: 0.3575\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9825 - tp: 243.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 155.0000 - accuracy: 0.7026 - precision: 0.3522 - recall: 0.6106 - auc: 0.7195 - prc: 0.3971 - val_loss: 0.6148 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6925 - val_prc: 0.3598\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9805 - tp: 244.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 154.0000 - accuracy: 0.6892 - precision: 0.3394 - recall: 0.6131 - auc: 0.7207 - prc: 0.4119 - val_loss: 0.6003 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6901 - val_prc: 0.3561\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9832 - tp: 240.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 158.0000 - accuracy: 0.6961 - precision: 0.3443 - recall: 0.6030 - auc: 0.7183 - prc: 0.4276 - val_loss: 0.6223 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6925 - val_prc: 0.3596\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9816 - tp: 239.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 159.0000 - accuracy: 0.7011 - precision: 0.3489 - recall: 0.6005 - auc: 0.7200 - prc: 0.4074 - val_loss: 0.6020 - val_tp: 52.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 39.0000 - val_accuracy: 0.6818 - val_precision: 0.2989 - val_recall: 0.5714 - val_auc: 0.6926 - val_prc: 0.3662\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9786 - tp: 235.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 163.0000 - accuracy: 0.6986 - precision: 0.3446 - recall: 0.5905 - auc: 0.7224 - prc: 0.4270 - val_loss: 0.6426 - val_tp: 57.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 34.0000 - val_accuracy: 0.6206 - val_precision: 0.2651 - val_recall: 0.6264 - val_auc: 0.6918 - val_prc: 0.3573\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9809 - tp: 252.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 146.0000 - accuracy: 0.6882 - precision: 0.3419 - recall: 0.6332 - auc: 0.7202 - prc: 0.4090 - val_loss: 0.5665 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6945 - val_prc: 0.3715\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9797 - tp: 239.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 159.0000 - accuracy: 0.7031 - precision: 0.3510 - recall: 0.6005 - auc: 0.7197 - prc: 0.4075 - val_loss: 0.5821 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6952 - val_prc: 0.3736\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9785 - tp: 246.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 152.0000 - accuracy: 0.6986 - precision: 0.3494 - recall: 0.6181 - auc: 0.7205 - prc: 0.4184 - val_loss: 0.5784 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.6942 - val_prc: 0.3759\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9753 - tp: 240.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 158.0000 - accuracy: 0.7016 - precision: 0.3499 - recall: 0.6030 - auc: 0.7247 - prc: 0.4161 - val_loss: 0.5999 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6913 - val_prc: 0.3526\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9766 - tp: 244.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 154.0000 - accuracy: 0.6966 - precision: 0.3466 - recall: 0.6131 - auc: 0.7235 - prc: 0.4264 - val_loss: 0.5743 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 44.0000 - val_accuracy: 0.7253 - val_precision: 0.3310 - val_recall: 0.5165 - val_auc: 0.6941 - val_prc: 0.3780\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9770 - tp: 234.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 164.0000 - accuracy: 0.7134 - precision: 0.3600 - recall: 0.5879 - auc: 0.7215 - prc: 0.4187 - val_loss: 0.5793 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6958 - val_prc: 0.3809\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9794 - tp: 251.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 147.0000 - accuracy: 0.6853 - precision: 0.3387 - recall: 0.6307 - auc: 0.7204 - prc: 0.4136 - val_loss: 0.5775 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 44.0000 - val_accuracy: 0.7253 - val_precision: 0.3310 - val_recall: 0.5165 - val_auc: 0.6950 - val_prc: 0.3791\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9745 - tp: 234.0000 - fp: 421.0000 - tn: 1205.0000 - fn: 164.0000 - accuracy: 0.7110 - precision: 0.3573 - recall: 0.5879 - auc: 0.7237 - prc: 0.4240 - val_loss: 0.5964 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6946 - val_prc: 0.3804\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9735 - tp: 234.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 164.0000 - accuracy: 0.7134 - precision: 0.3600 - recall: 0.5879 - auc: 0.7245 - prc: 0.4269 - val_loss: 0.6373 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6916 - val_prc: 0.3610\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9796 - tp: 248.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 150.0000 - accuracy: 0.6853 - precision: 0.3374 - recall: 0.6231 - auc: 0.7202 - prc: 0.4198 - val_loss: 0.6292 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.6926 - val_prc: 0.3679\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9732 - tp: 249.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 149.0000 - accuracy: 0.7006 - precision: 0.3527 - recall: 0.6256 - auc: 0.7242 - prc: 0.4245 - val_loss: 0.5984 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6949 - val_prc: 0.3810\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9762 - tp: 245.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 153.0000 - accuracy: 0.6917 - precision: 0.3422 - recall: 0.6156 - auc: 0.7216 - prc: 0.4150 - val_loss: 0.5817 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.6936 - val_prc: 0.3735\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9715 - tp: 244.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 154.0000 - accuracy: 0.7011 - precision: 0.3511 - recall: 0.6131 - auc: 0.7258 - prc: 0.4201 - val_loss: 0.6082 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6936 - val_prc: 0.3800\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9718 - tp: 243.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 155.0000 - accuracy: 0.7194 - precision: 0.3704 - recall: 0.6106 - auc: 0.7242 - prc: 0.4321 - val_loss: 0.5827 - val_tp: 48.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 43.0000 - val_accuracy: 0.7194 - val_precision: 0.3265 - val_recall: 0.5275 - val_auc: 0.6951 - val_prc: 0.3749\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9712 - tp: 241.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 157.0000 - accuracy: 0.7149 - precision: 0.3646 - recall: 0.6055 - auc: 0.7254 - prc: 0.4222 - val_loss: 0.6220 - val_tp: 56.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 35.0000 - val_accuracy: 0.6680 - val_precision: 0.2963 - val_recall: 0.6154 - val_auc: 0.6929 - val_prc: 0.3653\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9696 - tp: 248.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 150.0000 - accuracy: 0.7021 - precision: 0.3538 - recall: 0.6231 - auc: 0.7264 - prc: 0.4300 - val_loss: 0.5703 - val_tp: 47.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 44.0000 - val_accuracy: 0.7332 - val_precision: 0.3406 - val_recall: 0.5165 - val_auc: 0.6967 - val_prc: 0.3769\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9721 - tp: 243.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 155.0000 - accuracy: 0.7045 - precision: 0.3542 - recall: 0.6106 - auc: 0.7245 - prc: 0.4188 - val_loss: 0.6131 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6939 - val_prc: 0.3759\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9682 - tp: 234.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 164.0000 - accuracy: 0.7223 - precision: 0.3703 - recall: 0.5879 - auc: 0.7267 - prc: 0.4326 - val_loss: 0.7245 - val_tp: 67.0000 - val_fp: 217.0000 - val_tn: 198.0000 - val_fn: 24.0000 - val_accuracy: 0.5237 - val_precision: 0.2359 - val_recall: 0.7363 - val_auc: 0.6877 - val_prc: 0.3410\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9781 - tp: 239.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 159.0000 - accuracy: 0.6961 - precision: 0.3439 - recall: 0.6005 - auc: 0.7176 - prc: 0.4080 - val_loss: 0.6743 - val_tp: 64.0000 - val_fp: 182.0000 - val_tn: 233.0000 - val_fn: 27.0000 - val_accuracy: 0.5870 - val_precision: 0.2602 - val_recall: 0.7033 - val_auc: 0.6889 - val_prc: 0.3537\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9705 - tp: 247.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 151.0000 - accuracy: 0.6823 - precision: 0.3342 - recall: 0.6206 - auc: 0.7253 - prc: 0.4215 - val_loss: 0.5868 - val_tp: 48.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 43.0000 - val_accuracy: 0.7115 - val_precision: 0.3179 - val_recall: 0.5275 - val_auc: 0.6974 - val_prc: 0.3766\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9691 - tp: 246.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 152.0000 - accuracy: 0.7055 - precision: 0.3565 - recall: 0.6181 - auc: 0.7262 - prc: 0.4312 - val_loss: 0.5741 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6968 - val_prc: 0.3765\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9720 - tp: 244.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 154.0000 - accuracy: 0.7100 - precision: 0.3604 - recall: 0.6131 - auc: 0.7241 - prc: 0.4243 - val_loss: 0.5790 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6980 - val_prc: 0.3746\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9693 - tp: 245.0000 - fp: 427.0000 - tn: 1199.0000 - fn: 153.0000 - accuracy: 0.7134 - precision: 0.3646 - recall: 0.6156 - auc: 0.7265 - prc: 0.4288 - val_loss: 0.6197 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6962 - val_prc: 0.3736\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9666 - tp: 238.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 160.0000 - accuracy: 0.7189 - precision: 0.3679 - recall: 0.5980 - auc: 0.7287 - prc: 0.4338 - val_loss: 0.6672 - val_tp: 60.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 31.0000 - val_accuracy: 0.5949 - val_precision: 0.2564 - val_recall: 0.6593 - val_auc: 0.6932 - val_prc: 0.3615\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9664 - tp: 240.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 158.0000 - accuracy: 0.7085 - precision: 0.3571 - recall: 0.6030 - auc: 0.7249 - prc: 0.4185 - val_loss: 0.6439 - val_tp: 55.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 36.0000 - val_accuracy: 0.6285 - val_precision: 0.2657 - val_recall: 0.6044 - val_auc: 0.6903 - val_prc: 0.3629\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9688 - tp: 251.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 147.0000 - accuracy: 0.6947 - precision: 0.3476 - recall: 0.6307 - auc: 0.7241 - prc: 0.4207 - val_loss: 0.5671 - val_tp: 45.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 46.0000 - val_accuracy: 0.7372 - val_precision: 0.3409 - val_recall: 0.4945 - val_auc: 0.6948 - val_prc: 0.3665\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9673 - tp: 243.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 155.0000 - accuracy: 0.7194 - precision: 0.3704 - recall: 0.6106 - auc: 0.7260 - prc: 0.4334 - val_loss: 0.6090 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6970 - val_prc: 0.3736\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9661 - tp: 249.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 149.0000 - accuracy: 0.7041 - precision: 0.3562 - recall: 0.6256 - auc: 0.7279 - prc: 0.4287 - val_loss: 0.5573 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6954 - val_prc: 0.3732\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9699 - tp: 239.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 159.0000 - accuracy: 0.7243 - precision: 0.3746 - recall: 0.6005 - auc: 0.7232 - prc: 0.4305 - val_loss: 0.6039 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6942 - val_prc: 0.3776\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9653 - tp: 241.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 157.0000 - accuracy: 0.7041 - precision: 0.3529 - recall: 0.6055 - auc: 0.7276 - prc: 0.4334 - val_loss: 0.5636 - val_tp: 44.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 47.0000 - val_accuracy: 0.7530 - val_precision: 0.3607 - val_recall: 0.4835 - val_auc: 0.6966 - val_prc: 0.3737\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9661 - tp: 242.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 156.0000 - accuracy: 0.7179 - precision: 0.3683 - recall: 0.6080 - auc: 0.7271 - prc: 0.4350 - val_loss: 0.6445 - val_tp: 55.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 36.0000 - val_accuracy: 0.6324 - val_precision: 0.2683 - val_recall: 0.6044 - val_auc: 0.6922 - val_prc: 0.3612\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9667 - tp: 241.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 157.0000 - accuracy: 0.6922 - precision: 0.3409 - recall: 0.6055 - auc: 0.7265 - prc: 0.4282 - val_loss: 0.5659 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6971 - val_prc: 0.3734\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9669 - tp: 238.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 160.0000 - accuracy: 0.7144 - precision: 0.3628 - recall: 0.5980 - auc: 0.7262 - prc: 0.4262 - val_loss: 0.5519 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6963 - val_prc: 0.3766\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9655 - tp: 242.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 156.0000 - accuracy: 0.7125 - precision: 0.3623 - recall: 0.6080 - auc: 0.7279 - prc: 0.4355 - val_loss: 0.5899 - val_tp: 49.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 42.0000 - val_accuracy: 0.7134 - val_precision: 0.3224 - val_recall: 0.5385 - val_auc: 0.6955 - val_prc: 0.3739\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9640 - tp: 236.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 162.0000 - accuracy: 0.7204 - precision: 0.3688 - recall: 0.5930 - auc: 0.7289 - prc: 0.4312 - val_loss: 0.6380 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6938 - val_prc: 0.3682\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9659 - tp: 243.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 155.0000 - accuracy: 0.6917 - precision: 0.3413 - recall: 0.6106 - auc: 0.7269 - prc: 0.4269 - val_loss: 0.6377 - val_tp: 55.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 36.0000 - val_accuracy: 0.6344 - val_precision: 0.2696 - val_recall: 0.6044 - val_auc: 0.6952 - val_prc: 0.3661\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9651 - tp: 247.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 151.0000 - accuracy: 0.7006 - precision: 0.3519 - recall: 0.6206 - auc: 0.7281 - prc: 0.4214 - val_loss: 0.6162 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6957 - val_prc: 0.3834\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9646 - tp: 242.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 156.0000 - accuracy: 0.7060 - precision: 0.3554 - recall: 0.6080 - auc: 0.7268 - prc: 0.4288 - val_loss: 0.5962 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6933 - val_prc: 0.3716\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9642 - tp: 242.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 156.0000 - accuracy: 0.7144 - precision: 0.3645 - recall: 0.6080 - auc: 0.7290 - prc: 0.4284 - val_loss: 0.6293 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6959 - val_prc: 0.3820\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9639 - tp: 245.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 153.0000 - accuracy: 0.6991 - precision: 0.3495 - recall: 0.6156 - auc: 0.7287 - prc: 0.4383 - val_loss: 0.5933 - val_tp: 50.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.7174 - val_precision: 0.3289 - val_recall: 0.5495 - val_auc: 0.6960 - val_prc: 0.3751\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9640 - tp: 240.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 158.0000 - accuracy: 0.7174 - precision: 0.3670 - recall: 0.6030 - auc: 0.7281 - prc: 0.4258 - val_loss: 0.5921 - val_tp: 49.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 42.0000 - val_accuracy: 0.7134 - val_precision: 0.3224 - val_recall: 0.5385 - val_auc: 0.6963 - val_prc: 0.3748\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9631 - tp: 242.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 156.0000 - accuracy: 0.7169 - precision: 0.3672 - recall: 0.6080 - auc: 0.7295 - prc: 0.4353 - val_loss: 0.6297 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6942 - val_prc: 0.3701\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9620 - tp: 240.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 158.0000 - accuracy: 0.7189 - precision: 0.3687 - recall: 0.6030 - auc: 0.7291 - prc: 0.4268 - val_loss: 0.6073 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6944 - val_prc: 0.3766\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9606 - tp: 245.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 153.0000 - accuracy: 0.7085 - precision: 0.3592 - recall: 0.6156 - auc: 0.7312 - prc: 0.4450 - val_loss: 0.5722 - val_tp: 45.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 46.0000 - val_accuracy: 0.7372 - val_precision: 0.3409 - val_recall: 0.4945 - val_auc: 0.6955 - val_prc: 0.3764\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9639 - tp: 232.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 166.0000 - accuracy: 0.7144 - precision: 0.3602 - recall: 0.5829 - auc: 0.7268 - prc: 0.4353 - val_loss: 0.6063 - val_tp: 53.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 38.0000 - val_accuracy: 0.7016 - val_precision: 0.3193 - val_recall: 0.5824 - val_auc: 0.6962 - val_prc: 0.3777\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9632 - tp: 244.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 154.0000 - accuracy: 0.7115 - precision: 0.3620 - recall: 0.6131 - auc: 0.7292 - prc: 0.4276 - val_loss: 0.6375 - val_tp: 53.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 38.0000 - val_accuracy: 0.6443 - val_precision: 0.2718 - val_recall: 0.5824 - val_auc: 0.6920 - val_prc: 0.3662\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9611 - tp: 246.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 152.0000 - accuracy: 0.7159 - precision: 0.3677 - recall: 0.6181 - auc: 0.7305 - prc: 0.4362 - val_loss: 0.6303 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6946 - val_prc: 0.3752\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9626 - tp: 235.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 163.0000 - accuracy: 0.6986 - precision: 0.3446 - recall: 0.5905 - auc: 0.7283 - prc: 0.4260 - val_loss: 0.6082 - val_tp: 53.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 38.0000 - val_accuracy: 0.7055 - val_precision: 0.3232 - val_recall: 0.5824 - val_auc: 0.6946 - val_prc: 0.3704\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9631 - tp: 239.0000 - fp: 406.0000 - tn: 1220.0000 - fn: 159.0000 - accuracy: 0.7208 - precision: 0.3705 - recall: 0.6005 - auc: 0.7286 - prc: 0.4415 - val_loss: 0.6082 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6938 - val_prc: 0.3753\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9570 - tp: 233.0000 - fp: 396.0000 - tn: 1230.0000 - fn: 165.0000 - accuracy: 0.7228 - precision: 0.3704 - recall: 0.5854 - auc: 0.7331 - prc: 0.4372 - val_loss: 0.6683 - val_tp: 58.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 33.0000 - val_accuracy: 0.5968 - val_precision: 0.2533 - val_recall: 0.6374 - val_auc: 0.6943 - val_prc: 0.3709\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9611 - tp: 240.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 158.0000 - accuracy: 0.7179 - precision: 0.3675 - recall: 0.6030 - auc: 0.7291 - prc: 0.4364 - val_loss: 0.6411 - val_tp: 54.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 37.0000 - val_accuracy: 0.6462 - val_precision: 0.2755 - val_recall: 0.5934 - val_auc: 0.6932 - val_prc: 0.3664\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9608 - tp: 247.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 151.0000 - accuracy: 0.7021 - precision: 0.3534 - recall: 0.6206 - auc: 0.7300 - prc: 0.4332 - val_loss: 0.5263 - val_tp: 37.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 54.0000 - val_accuracy: 0.7846 - val_precision: 0.4022 - val_recall: 0.4066 - val_auc: 0.6952 - val_prc: 0.3809\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9605 - tp: 241.0000 - fp: 406.0000 - tn: 1220.0000 - fn: 157.0000 - accuracy: 0.7218 - precision: 0.3725 - recall: 0.6055 - auc: 0.7308 - prc: 0.4378 - val_loss: 0.6098 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6950 - val_prc: 0.3783\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9595 - tp: 236.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 162.0000 - accuracy: 0.7233 - precision: 0.3722 - recall: 0.5930 - auc: 0.7304 - prc: 0.4427 - val_loss: 0.5839 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.6943 - val_prc: 0.3745\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9603 - tp: 243.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 155.0000 - accuracy: 0.7050 - precision: 0.3547 - recall: 0.6106 - auc: 0.7304 - prc: 0.4342 - val_loss: 0.6425 - val_tp: 54.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 37.0000 - val_accuracy: 0.6482 - val_precision: 0.2769 - val_recall: 0.5934 - val_auc: 0.6941 - val_prc: 0.3761\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9621 - tp: 235.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 163.0000 - accuracy: 0.7134 - precision: 0.3604 - recall: 0.5905 - auc: 0.7272 - prc: 0.4342 - val_loss: 0.5949 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.6940 - val_prc: 0.3747\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9574 - tp: 247.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 151.0000 - accuracy: 0.6952 - precision: 0.3464 - recall: 0.6206 - auc: 0.7325 - prc: 0.4318 - val_loss: 0.5569 - val_tp: 45.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 46.0000 - val_accuracy: 0.7708 - val_precision: 0.3913 - val_recall: 0.4945 - val_auc: 0.6950 - val_prc: 0.3731\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9621 - tp: 242.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 156.0000 - accuracy: 0.7154 - precision: 0.3656 - recall: 0.6080 - auc: 0.7285 - prc: 0.4300 - val_loss: 0.5883 - val_tp: 50.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 41.0000 - val_accuracy: 0.7194 - val_precision: 0.3311 - val_recall: 0.5495 - val_auc: 0.6935 - val_prc: 0.3747\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9594 - tp: 231.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 167.0000 - accuracy: 0.7327 - precision: 0.3818 - recall: 0.5804 - auc: 0.7313 - prc: 0.4408 - val_loss: 0.6554 - val_tp: 55.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 36.0000 - val_accuracy: 0.6245 - val_precision: 0.2632 - val_recall: 0.6044 - val_auc: 0.6922 - val_prc: 0.3643\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9649 - tp: 250.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 148.0000 - accuracy: 0.7060 - precision: 0.3587 - recall: 0.6281 - auc: 0.7260 - prc: 0.4354 - val_loss: 0.6153 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6949 - val_prc: 0.3768\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9648 - tp: 239.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 159.0000 - accuracy: 0.7213 - precision: 0.3711 - recall: 0.6005 - auc: 0.7269 - prc: 0.4377 - val_loss: 0.6328 - val_tp: 54.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 37.0000 - val_accuracy: 0.6542 - val_precision: 0.2812 - val_recall: 0.5934 - val_auc: 0.6947 - val_prc: 0.3775\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9614 - tp: 233.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 165.0000 - accuracy: 0.7184 - precision: 0.3652 - recall: 0.5854 - auc: 0.7293 - prc: 0.4402 - val_loss: 0.6387 - val_tp: 54.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 37.0000 - val_accuracy: 0.6462 - val_precision: 0.2755 - val_recall: 0.5934 - val_auc: 0.6950 - val_prc: 0.3784\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9579 - tp: 239.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 159.0000 - accuracy: 0.7115 - precision: 0.3599 - recall: 0.6005 - auc: 0.7334 - prc: 0.4440 - val_loss: 0.5916 - val_tp: 50.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.7174 - val_precision: 0.3289 - val_recall: 0.5495 - val_auc: 0.6947 - val_prc: 0.3759\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9579 - tp: 248.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 150.0000 - accuracy: 0.7120 - precision: 0.3642 - recall: 0.6231 - auc: 0.7312 - prc: 0.4403 - val_loss: 0.5673 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6952 - val_prc: 0.3727\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9595 - tp: 231.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 167.0000 - accuracy: 0.7263 - precision: 0.3738 - recall: 0.5804 - auc: 0.7298 - prc: 0.4426 - val_loss: 0.6082 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6943 - val_prc: 0.3752\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9581 - tp: 238.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 160.0000 - accuracy: 0.7194 - precision: 0.3684 - recall: 0.5980 - auc: 0.7307 - prc: 0.4572 - val_loss: 0.6163 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6939 - val_prc: 0.3732\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9552 - tp: 252.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 146.0000 - accuracy: 0.7001 - precision: 0.3534 - recall: 0.6332 - auc: 0.7348 - prc: 0.4359 - val_loss: 0.5703 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6952 - val_prc: 0.3734\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9571 - tp: 233.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 165.0000 - accuracy: 0.7149 - precision: 0.3612 - recall: 0.5854 - auc: 0.7340 - prc: 0.4382 - val_loss: 0.6027 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.6940 - val_prc: 0.3747\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9563 - tp: 246.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 152.0000 - accuracy: 0.7223 - precision: 0.3750 - recall: 0.6181 - auc: 0.7320 - prc: 0.4420 - val_loss: 0.6063 - val_tp: 51.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 40.0000 - val_accuracy: 0.6976 - val_precision: 0.3110 - val_recall: 0.5604 - val_auc: 0.6938 - val_prc: 0.3744\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9611 - tp: 235.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 163.0000 - accuracy: 0.7045 - precision: 0.3507 - recall: 0.5905 - auc: 0.7291 - prc: 0.4347 - val_loss: 0.5400 - val_tp: 41.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 50.0000 - val_accuracy: 0.7826 - val_precision: 0.4059 - val_recall: 0.4505 - val_auc: 0.6944 - val_prc: 0.3745\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9586 - tp: 233.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 165.0000 - accuracy: 0.7169 - precision: 0.3635 - recall: 0.5854 - auc: 0.7309 - prc: 0.4395 - val_loss: 0.6030 - val_tp: 51.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 40.0000 - val_accuracy: 0.7055 - val_precision: 0.3187 - val_recall: 0.5604 - val_auc: 0.6936 - val_prc: 0.3742\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9560 - tp: 248.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 150.0000 - accuracy: 0.6957 - precision: 0.3473 - recall: 0.6231 - auc: 0.7317 - prc: 0.4315 - val_loss: 0.5542 - val_tp: 45.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 46.0000 - val_accuracy: 0.7727 - val_precision: 0.3947 - val_recall: 0.4945 - val_auc: 0.6945 - val_prc: 0.3775\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9550 - tp: 241.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 157.0000 - accuracy: 0.7223 - precision: 0.3731 - recall: 0.6055 - auc: 0.7346 - prc: 0.4476 - val_loss: 0.5842 - val_tp: 47.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 44.0000 - val_accuracy: 0.7273 - val_precision: 0.3333 - val_recall: 0.5165 - val_auc: 0.6951 - val_prc: 0.3768\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9557 - tp: 241.0000 - fp: 383.0000 - tn: 1243.0000 - fn: 157.0000 - accuracy: 0.7332 - precision: 0.3862 - recall: 0.6055 - auc: 0.7340 - prc: 0.4528 - val_loss: 0.5998 - val_tp: 51.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 40.0000 - val_accuracy: 0.7095 - val_precision: 0.3228 - val_recall: 0.5604 - val_auc: 0.6940 - val_prc: 0.3757\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9542 - tp: 241.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 157.0000 - accuracy: 0.7228 - precision: 0.3736 - recall: 0.6055 - auc: 0.7342 - prc: 0.4490 - val_loss: 0.5931 - val_tp: 50.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.7174 - val_precision: 0.3289 - val_recall: 0.5495 - val_auc: 0.6935 - val_prc: 0.3750\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9588 - tp: 241.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 157.0000 - accuracy: 0.7070 - precision: 0.3560 - recall: 0.6055 - auc: 0.7298 - prc: 0.4386 - val_loss: 0.5872 - val_tp: 48.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 43.0000 - val_accuracy: 0.7253 - val_precision: 0.3333 - val_recall: 0.5275 - val_auc: 0.6954 - val_prc: 0.3769\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9528 - tp: 234.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 164.0000 - accuracy: 0.7312 - precision: 0.3811 - recall: 0.5879 - auc: 0.7353 - prc: 0.4573 - val_loss: 0.6418 - val_tp: 54.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 37.0000 - val_accuracy: 0.6502 - val_precision: 0.2784 - val_recall: 0.5934 - val_auc: 0.6927 - val_prc: 0.3775\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9569 - tp: 242.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 156.0000 - accuracy: 0.7159 - precision: 0.3661 - recall: 0.6080 - auc: 0.7320 - prc: 0.4396 - val_loss: 0.5974 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.6926 - val_prc: 0.3716\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9541 - tp: 240.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 158.0000 - accuracy: 0.7090 - precision: 0.3577 - recall: 0.6030 - auc: 0.7353 - prc: 0.4437 - val_loss: 0.5798 - val_tp: 49.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 42.0000 - val_accuracy: 0.7411 - val_precision: 0.3551 - val_recall: 0.5385 - val_auc: 0.6945 - val_prc: 0.3767\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9564 - tp: 229.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 169.0000 - accuracy: 0.7268 - precision: 0.3736 - recall: 0.5754 - auc: 0.7319 - prc: 0.4469 - val_loss: 0.5954 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6937 - val_prc: 0.3733\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9592 - tp: 244.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 154.0000 - accuracy: 0.7228 - precision: 0.3748 - recall: 0.6131 - auc: 0.7304 - prc: 0.4378 - val_loss: 0.6210 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6940 - val_prc: 0.3716\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9558 - tp: 240.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 158.0000 - accuracy: 0.7189 - precision: 0.3687 - recall: 0.6030 - auc: 0.7330 - prc: 0.4431 - val_loss: 0.5925 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6931 - val_prc: 0.3751\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9535 - tp: 241.0000 - fp: 421.0000 - tn: 1205.0000 - fn: 157.0000 - accuracy: 0.7144 - precision: 0.3640 - recall: 0.6055 - auc: 0.7346 - prc: 0.4492 - val_loss: 0.6034 - val_tp: 50.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 41.0000 - val_accuracy: 0.7075 - val_precision: 0.3185 - val_recall: 0.5495 - val_auc: 0.6933 - val_prc: 0.3725\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9546 - tp: 239.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 159.0000 - accuracy: 0.7248 - precision: 0.3752 - recall: 0.6005 - auc: 0.7342 - prc: 0.4508 - val_loss: 0.5663 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6941 - val_prc: 0.3760\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9582 - tp: 236.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 162.0000 - accuracy: 0.7208 - precision: 0.3693 - recall: 0.5930 - auc: 0.7311 - prc: 0.4341 - val_loss: 0.6221 - val_tp: 53.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 38.0000 - val_accuracy: 0.6877 - val_precision: 0.3064 - val_recall: 0.5824 - val_auc: 0.6927 - val_prc: 0.3736\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9587 - tp: 252.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 146.0000 - accuracy: 0.7021 - precision: 0.3554 - recall: 0.6332 - auc: 0.7310 - prc: 0.4388 - val_loss: 0.6012 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6929 - val_prc: 0.3744\n",
      "Epoch 165/500\n",
      " 90/102 [=========================>....] - ETA: 0s - loss: 0.9605 - tp: 215.0000 - fp: 345.0000 - tn: 1097.0000 - fn: 143.0000 - accuracy: 0.7289 - precision: 0.3839 - recall: 0.6006 - auc: 0.7307 - prc: 0.4575Restoring model weights from the end of the best epoch: 115.\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9549 - tp: 240.0000 - fp: 391.0000 - tn: 1235.0000 - fn: 158.0000 - accuracy: 0.7288 - precision: 0.3803 - recall: 0.6030 - auc: 0.7343 - prc: 0.4462 - val_loss: 0.5820 - val_tp: 48.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 43.0000 - val_accuracy: 0.7372 - val_precision: 0.3478 - val_recall: 0.5275 - val_auc: 0.6928 - val_prc: 0.3731\n",
      "Epoch 165: early stopping\n",
      "26/26 [==============================] - 0s 597us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 1.5999 - tp: 48.0000 - fp: 90.0000 - tn: 1951.0000 - fn: 441.0000 - accuracy: 0.7901 - precision: 0.3478 - recall: 0.0982 - auc: 0.5095 - prc: 0.2276 - val_loss: 0.4738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.5526 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4994 - prc: 0.1936 - val_loss: 0.4768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.5109 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4980 - prc: 0.1952 - val_loss: 0.4809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4717 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5194 - prc: 0.2100 - val_loss: 0.4859 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4350 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5076 - prc: 0.2084 - val_loss: 0.4921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.4022 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4780 - prc: 0.1859 - val_loss: 0.4993 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5079 - prc: 0.1983 - val_loss: 0.5069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3467 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5144 - prc: 0.2036 - val_loss: 0.5151 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.3227 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4843 - prc: 0.1937 - val_loss: 0.5241 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.3014 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - prc: 0.1903 - val_loss: 0.5334 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2828 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4730 - prc: 0.1820 - val_loss: 0.5432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4951 - prc: 0.1907 - val_loss: 0.5528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2514 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4933 - prc: 0.1941 - val_loss: 0.5629 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2386 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4957 - prc: 0.1935 - val_loss: 0.5727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4939 - prc: 0.1944 - val_loss: 0.5830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5101 - prc: 0.2023 - val_loss: 0.5928 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4972 - prc: 0.1932 - val_loss: 0.6031 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.2018 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4904 - prc: 0.1925 - val_loss: 0.6123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5108 - val_prc: 0.1831\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1959 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4810 - prc: 0.1880 - val_loss: 0.6223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1906 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4897 - prc: 0.1923 - val_loss: 0.6305 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1864 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4998 - prc: 0.1941 - val_loss: 0.6386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5072 - val_prc: 0.1820\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1828 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001 - prc: 0.1965 - val_loss: 0.6470 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5084 - val_prc: 0.1824\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5036 - prc: 0.1975 - val_loss: 0.6545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5133 - val_prc: 0.1838\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1772 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4906 - prc: 0.1928 - val_loss: 0.6616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5120 - val_prc: 0.1835\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1752 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5081 - prc: 0.1999 - val_loss: 0.6673 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5241 - val_prc: 0.1872\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1735 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5335 - prc: 0.2172 - val_loss: 0.6728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5178 - val_prc: 0.1853\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1701 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5557 - prc: 0.2202 - val_loss: 0.6713 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5916 - val_prc: 0.2146\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1630 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6199 - prc: 0.2652 - val_loss: 0.6370 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6505 - val_prc: 0.2977\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1578 - tp: 70.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 328.0000 - accuracy: 0.7777 - precision: 0.3646 - recall: 0.1759 - auc: 0.6258 - prc: 0.2688 - val_loss: 0.6453 - val_tp: 46.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 45.0000 - val_accuracy: 0.7134 - val_precision: 0.3151 - val_recall: 0.5055 - val_auc: 0.6581 - val_prc: 0.2690\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1476 - tp: 214.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 184.0000 - accuracy: 0.6670 - precision: 0.3040 - recall: 0.5377 - auc: 0.6515 - prc: 0.2986 - val_loss: 0.6422 - val_tp: 54.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 37.0000 - val_accuracy: 0.6403 - val_precision: 0.2714 - val_recall: 0.5934 - val_auc: 0.6616 - val_prc: 0.2707\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1412 - tp: 212.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 186.0000 - accuracy: 0.6803 - precision: 0.3150 - recall: 0.5327 - auc: 0.6617 - prc: 0.3124 - val_loss: 0.6176 - val_tp: 40.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 51.0000 - val_accuracy: 0.7233 - val_precision: 0.3101 - val_recall: 0.4396 - val_auc: 0.6788 - val_prc: 0.3085\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1361 - tp: 235.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 163.0000 - accuracy: 0.6537 - precision: 0.3040 - recall: 0.5905 - auc: 0.6627 - prc: 0.3114 - val_loss: 0.6073 - val_tp: 43.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 48.0000 - val_accuracy: 0.7411 - val_precision: 0.3413 - val_recall: 0.4725 - val_auc: 0.6835 - val_prc: 0.3275\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1312 - tp: 216.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 182.0000 - accuracy: 0.6640 - precision: 0.3025 - recall: 0.5427 - auc: 0.6607 - prc: 0.2956 - val_loss: 0.6364 - val_tp: 58.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 33.0000 - val_accuracy: 0.6502 - val_precision: 0.2871 - val_recall: 0.6374 - val_auc: 0.6766 - val_prc: 0.2955\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1212 - tp: 226.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 172.0000 - accuracy: 0.6719 - precision: 0.3148 - recall: 0.5678 - auc: 0.6774 - prc: 0.3126 - val_loss: 0.6726 - val_tp: 69.0000 - val_fp: 230.0000 - val_tn: 185.0000 - val_fn: 22.0000 - val_accuracy: 0.5020 - val_precision: 0.2308 - val_recall: 0.7582 - val_auc: 0.6486 - val_prc: 0.2560\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1210 - tp: 243.0000 - fp: 559.0000 - tn: 1067.0000 - fn: 155.0000 - accuracy: 0.6472 - precision: 0.3030 - recall: 0.6106 - auc: 0.6693 - prc: 0.2932 - val_loss: 0.6455 - val_tp: 59.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 32.0000 - val_accuracy: 0.5988 - val_precision: 0.2565 - val_recall: 0.6484 - val_auc: 0.6698 - val_prc: 0.2866\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1155 - tp: 248.0000 - fp: 574.0000 - tn: 1052.0000 - fn: 150.0000 - accuracy: 0.6423 - precision: 0.3017 - recall: 0.6231 - auc: 0.6750 - prc: 0.3113 - val_loss: 0.6507 - val_tp: 61.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 30.0000 - val_accuracy: 0.5771 - val_precision: 0.2490 - val_recall: 0.6703 - val_auc: 0.6683 - val_prc: 0.2830\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1053 - tp: 247.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 151.0000 - accuracy: 0.6621 - precision: 0.3167 - recall: 0.6206 - auc: 0.6877 - prc: 0.3229 - val_loss: 0.6595 - val_tp: 64.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 27.0000 - val_accuracy: 0.5316 - val_precision: 0.2336 - val_recall: 0.7033 - val_auc: 0.6642 - val_prc: 0.2753\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.1060 - tp: 246.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 152.0000 - accuracy: 0.6527 - precision: 0.3087 - recall: 0.6181 - auc: 0.6826 - prc: 0.3157 - val_loss: 0.6607 - val_tp: 65.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 26.0000 - val_accuracy: 0.5336 - val_precision: 0.2364 - val_recall: 0.7143 - val_auc: 0.6656 - val_prc: 0.2765\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0957 - tp: 249.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 149.0000 - accuracy: 0.6625 - precision: 0.3180 - recall: 0.6256 - auc: 0.6923 - prc: 0.3284 - val_loss: 0.7024 - val_tp: 76.0000 - val_fp: 268.0000 - val_tn: 147.0000 - val_fn: 15.0000 - val_accuracy: 0.4407 - val_precision: 0.2209 - val_recall: 0.8352 - val_auc: 0.6280 - val_prc: 0.2368\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0980 - tp: 265.0000 - fp: 638.0000 - tn: 988.0000 - fn: 133.0000 - accuracy: 0.6191 - precision: 0.2935 - recall: 0.6658 - auc: 0.6837 - prc: 0.3175 - val_loss: 0.6088 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6817 - val_prc: 0.3192\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0952 - tp: 252.0000 - fp: 602.0000 - tn: 1024.0000 - fn: 146.0000 - accuracy: 0.6304 - precision: 0.2951 - recall: 0.6332 - auc: 0.6891 - prc: 0.3314 - val_loss: 0.5868 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.6854 - val_prc: 0.3277\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0937 - tp: 254.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 144.0000 - accuracy: 0.6630 - precision: 0.3207 - recall: 0.6382 - auc: 0.6902 - prc: 0.3339 - val_loss: 0.6158 - val_tp: 56.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 35.0000 - val_accuracy: 0.6443 - val_precision: 0.2786 - val_recall: 0.6154 - val_auc: 0.6827 - val_prc: 0.3146\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0850 - tp: 264.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 134.0000 - accuracy: 0.6472 - precision: 0.3128 - recall: 0.6633 - auc: 0.6993 - prc: 0.3455 - val_loss: 0.6001 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6835 - val_prc: 0.3248\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0843 - tp: 269.0000 - fp: 626.0000 - tn: 1000.0000 - fn: 129.0000 - accuracy: 0.6270 - precision: 0.3006 - recall: 0.6759 - auc: 0.6913 - prc: 0.3259 - val_loss: 0.5565 - val_tp: 40.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 51.0000 - val_accuracy: 0.7470 - val_precision: 0.3419 - val_recall: 0.4396 - val_auc: 0.6860 - val_prc: 0.3452\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0854 - tp: 252.0000 - fp: 562.0000 - tn: 1064.0000 - fn: 146.0000 - accuracy: 0.6502 - precision: 0.3096 - recall: 0.6332 - auc: 0.6959 - prc: 0.3459 - val_loss: 0.6541 - val_tp: 61.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 30.0000 - val_accuracy: 0.5672 - val_precision: 0.2440 - val_recall: 0.6703 - val_auc: 0.6770 - val_prc: 0.3012\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0763 - tp: 275.0000 - fp: 645.0000 - tn: 981.0000 - fn: 123.0000 - accuracy: 0.6206 - precision: 0.2989 - recall: 0.6910 - auc: 0.7039 - prc: 0.3503 - val_loss: 0.5698 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6862 - val_prc: 0.3377\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0764 - tp: 253.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 145.0000 - accuracy: 0.6665 - precision: 0.3231 - recall: 0.6357 - auc: 0.6985 - prc: 0.3359 - val_loss: 0.6624 - val_tp: 62.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 29.0000 - val_accuracy: 0.5593 - val_precision: 0.2422 - val_recall: 0.6813 - val_auc: 0.6755 - val_prc: 0.2960\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0779 - tp: 271.0000 - fp: 621.0000 - tn: 1005.0000 - fn: 127.0000 - accuracy: 0.6304 - precision: 0.3038 - recall: 0.6809 - auc: 0.7009 - prc: 0.3586 - val_loss: 0.6256 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.6827 - val_prc: 0.3208\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0752 - tp: 260.0000 - fp: 571.0000 - tn: 1055.0000 - fn: 138.0000 - accuracy: 0.6497 - precision: 0.3129 - recall: 0.6533 - auc: 0.6984 - prc: 0.3443 - val_loss: 0.6377 - val_tp: 58.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 33.0000 - val_accuracy: 0.6067 - val_precision: 0.2589 - val_recall: 0.6374 - val_auc: 0.6825 - val_prc: 0.3186\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0697 - tp: 266.0000 - fp: 592.0000 - tn: 1034.0000 - fn: 132.0000 - accuracy: 0.6423 - precision: 0.3100 - recall: 0.6683 - auc: 0.7057 - prc: 0.3572 - val_loss: 0.6230 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6848 - val_prc: 0.3234\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0712 - tp: 270.0000 - fp: 637.0000 - tn: 989.0000 - fn: 128.0000 - accuracy: 0.6220 - precision: 0.2977 - recall: 0.6784 - auc: 0.7021 - prc: 0.3532 - val_loss: 0.5906 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6883 - val_prc: 0.3403\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0693 - tp: 253.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 145.0000 - accuracy: 0.6606 - precision: 0.3182 - recall: 0.6357 - auc: 0.7064 - prc: 0.3733 - val_loss: 0.6187 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.6870 - val_prc: 0.3387\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0646 - tp: 258.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 140.0000 - accuracy: 0.6542 - precision: 0.3154 - recall: 0.6482 - auc: 0.7090 - prc: 0.3681 - val_loss: 0.6268 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6883 - val_prc: 0.3325\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0634 - tp: 258.0000 - fp: 582.0000 - tn: 1044.0000 - fn: 140.0000 - accuracy: 0.6433 - precision: 0.3071 - recall: 0.6482 - auc: 0.7084 - prc: 0.3641 - val_loss: 0.6396 - val_tp: 59.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 32.0000 - val_accuracy: 0.6206 - val_precision: 0.2694 - val_recall: 0.6484 - val_auc: 0.6879 - val_prc: 0.3290\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0627 - tp: 254.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 144.0000 - accuracy: 0.6645 - precision: 0.3219 - recall: 0.6382 - auc: 0.7096 - prc: 0.3663 - val_loss: 0.6605 - val_tp: 62.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 29.0000 - val_accuracy: 0.5711 - val_precision: 0.2480 - val_recall: 0.6813 - val_auc: 0.6870 - val_prc: 0.3197\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0607 - tp: 264.0000 - fp: 612.0000 - tn: 1014.0000 - fn: 134.0000 - accuracy: 0.6314 - precision: 0.3014 - recall: 0.6633 - auc: 0.7104 - prc: 0.3689 - val_loss: 0.6324 - val_tp: 59.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 32.0000 - val_accuracy: 0.6304 - val_precision: 0.2757 - val_recall: 0.6484 - val_auc: 0.6911 - val_prc: 0.3392\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0613 - tp: 259.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 139.0000 - accuracy: 0.6571 - precision: 0.3182 - recall: 0.6508 - auc: 0.7092 - prc: 0.3716 - val_loss: 0.6281 - val_tp: 59.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 32.0000 - val_accuracy: 0.6383 - val_precision: 0.2810 - val_recall: 0.6484 - val_auc: 0.6903 - val_prc: 0.3372\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0604 - tp: 264.0000 - fp: 610.0000 - tn: 1016.0000 - fn: 134.0000 - accuracy: 0.6324 - precision: 0.3021 - recall: 0.6633 - auc: 0.7092 - prc: 0.3729 - val_loss: 0.6621 - val_tp: 62.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 29.0000 - val_accuracy: 0.5731 - val_precision: 0.2490 - val_recall: 0.6813 - val_auc: 0.6877 - val_prc: 0.3260\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0512 - tp: 270.0000 - fp: 587.0000 - tn: 1039.0000 - fn: 128.0000 - accuracy: 0.6467 - precision: 0.3151 - recall: 0.6784 - auc: 0.7202 - prc: 0.3914 - val_loss: 0.5866 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6942 - val_prc: 0.3617\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0561 - tp: 254.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 144.0000 - accuracy: 0.6596 - precision: 0.3179 - recall: 0.6382 - auc: 0.7131 - prc: 0.3934 - val_loss: 0.6119 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6927 - val_prc: 0.3488\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0505 - tp: 262.0000 - fp: 591.0000 - tn: 1035.0000 - fn: 136.0000 - accuracy: 0.6408 - precision: 0.3072 - recall: 0.6583 - auc: 0.7159 - prc: 0.3848 - val_loss: 0.5859 - val_tp: 49.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 42.0000 - val_accuracy: 0.7134 - val_precision: 0.3224 - val_recall: 0.5385 - val_auc: 0.6956 - val_prc: 0.3601\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0517 - tp: 246.0000 - fp: 532.0000 - tn: 1094.0000 - fn: 152.0000 - accuracy: 0.6621 - precision: 0.3162 - recall: 0.6181 - auc: 0.7155 - prc: 0.3833 - val_loss: 0.6384 - val_tp: 59.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 32.0000 - val_accuracy: 0.6225 - val_precision: 0.2706 - val_recall: 0.6484 - val_auc: 0.6926 - val_prc: 0.3448\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0513 - tp: 255.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 143.0000 - accuracy: 0.6606 - precision: 0.3191 - recall: 0.6407 - auc: 0.7168 - prc: 0.3979 - val_loss: 0.6041 - val_tp: 54.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 37.0000 - val_accuracy: 0.6838 - val_precision: 0.3051 - val_recall: 0.5934 - val_auc: 0.6936 - val_prc: 0.3513\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0525 - tp: 252.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 146.0000 - accuracy: 0.6665 - precision: 0.3227 - recall: 0.6332 - auc: 0.7153 - prc: 0.4040 - val_loss: 0.6252 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.6972 - val_prc: 0.3547\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0475 - tp: 250.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 148.0000 - accuracy: 0.6823 - precision: 0.3356 - recall: 0.6281 - auc: 0.7198 - prc: 0.4036 - val_loss: 0.6559 - val_tp: 63.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 28.0000 - val_accuracy: 0.5968 - val_precision: 0.2636 - val_recall: 0.6923 - val_auc: 0.6937 - val_prc: 0.3428\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0452 - tp: 265.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 133.0000 - accuracy: 0.6477 - precision: 0.3136 - recall: 0.6658 - auc: 0.7192 - prc: 0.3950 - val_loss: 0.5945 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6959 - val_prc: 0.3628\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0445 - tp: 246.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 152.0000 - accuracy: 0.6749 - precision: 0.3271 - recall: 0.6181 - auc: 0.7208 - prc: 0.4020 - val_loss: 0.6564 - val_tp: 63.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 28.0000 - val_accuracy: 0.6008 - val_precision: 0.2658 - val_recall: 0.6923 - val_auc: 0.6953 - val_prc: 0.3506\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0425 - tp: 262.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 136.0000 - accuracy: 0.6616 - precision: 0.3231 - recall: 0.6583 - auc: 0.7216 - prc: 0.4022 - val_loss: 0.6248 - val_tp: 57.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 34.0000 - val_accuracy: 0.6522 - val_precision: 0.2864 - val_recall: 0.6264 - val_auc: 0.6956 - val_prc: 0.3528\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0414 - tp: 257.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 141.0000 - accuracy: 0.6690 - precision: 0.3270 - recall: 0.6457 - auc: 0.7226 - prc: 0.4159 - val_loss: 0.6503 - val_tp: 63.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 28.0000 - val_accuracy: 0.6126 - val_precision: 0.2727 - val_recall: 0.6923 - val_auc: 0.6946 - val_prc: 0.3488\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0424 - tp: 266.0000 - fp: 563.0000 - tn: 1063.0000 - fn: 132.0000 - accuracy: 0.6566 - precision: 0.3209 - recall: 0.6683 - auc: 0.7199 - prc: 0.3977 - val_loss: 0.6132 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6962 - val_prc: 0.3532\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0396 - tp: 250.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 148.0000 - accuracy: 0.6754 - precision: 0.3294 - recall: 0.6281 - auc: 0.7224 - prc: 0.4115 - val_loss: 0.6789 - val_tp: 65.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 26.0000 - val_accuracy: 0.5652 - val_precision: 0.2510 - val_recall: 0.7143 - val_auc: 0.6929 - val_prc: 0.3369\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0406 - tp: 262.0000 - fp: 572.0000 - tn: 1054.0000 - fn: 136.0000 - accuracy: 0.6502 - precision: 0.3141 - recall: 0.6583 - auc: 0.7213 - prc: 0.4010 - val_loss: 0.6412 - val_tp: 61.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 30.0000 - val_accuracy: 0.6166 - val_precision: 0.2711 - val_recall: 0.6703 - val_auc: 0.6972 - val_prc: 0.3545\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0383 - tp: 266.0000 - fp: 568.0000 - tn: 1058.0000 - fn: 132.0000 - accuracy: 0.6542 - precision: 0.3189 - recall: 0.6683 - auc: 0.7233 - prc: 0.3879 - val_loss: 0.6306 - val_tp: 57.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 34.0000 - val_accuracy: 0.6364 - val_precision: 0.2754 - val_recall: 0.6264 - val_auc: 0.6964 - val_prc: 0.3609\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0380 - tp: 264.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 134.0000 - accuracy: 0.6744 - precision: 0.3346 - recall: 0.6633 - auc: 0.7241 - prc: 0.4104 - val_loss: 0.6168 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6964 - val_prc: 0.3533\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0371 - tp: 260.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 138.0000 - accuracy: 0.6616 - precision: 0.3222 - recall: 0.6533 - auc: 0.7241 - prc: 0.4226 - val_loss: 0.6665 - val_tp: 64.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 27.0000 - val_accuracy: 0.5889 - val_precision: 0.2612 - val_recall: 0.7033 - val_auc: 0.6957 - val_prc: 0.3524\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0358 - tp: 267.0000 - fp: 585.0000 - tn: 1041.0000 - fn: 131.0000 - accuracy: 0.6462 - precision: 0.3134 - recall: 0.6709 - auc: 0.7238 - prc: 0.4096 - val_loss: 0.5880 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6990 - val_prc: 0.3602\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0326 - tp: 253.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 145.0000 - accuracy: 0.6719 - precision: 0.3277 - recall: 0.6357 - auc: 0.7275 - prc: 0.4229 - val_loss: 0.6616 - val_tp: 64.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 27.0000 - val_accuracy: 0.5909 - val_precision: 0.2623 - val_recall: 0.7033 - val_auc: 0.6951 - val_prc: 0.3495\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0352 - tp: 259.0000 - fp: 537.0000 - tn: 1089.0000 - fn: 139.0000 - accuracy: 0.6660 - precision: 0.3254 - recall: 0.6508 - auc: 0.7234 - prc: 0.4100 - val_loss: 0.6252 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6957 - val_prc: 0.3499\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0359 - tp: 261.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 137.0000 - accuracy: 0.6650 - precision: 0.3254 - recall: 0.6558 - auc: 0.7234 - prc: 0.4092 - val_loss: 0.6358 - val_tp: 58.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 33.0000 - val_accuracy: 0.6304 - val_precision: 0.2736 - val_recall: 0.6374 - val_auc: 0.6966 - val_prc: 0.3605\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0338 - tp: 262.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 136.0000 - accuracy: 0.6581 - precision: 0.3203 - recall: 0.6583 - auc: 0.7253 - prc: 0.4135 - val_loss: 0.6300 - val_tp: 57.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 34.0000 - val_accuracy: 0.6423 - val_precision: 0.2794 - val_recall: 0.6264 - val_auc: 0.6960 - val_prc: 0.3575\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0364 - tp: 261.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 137.0000 - accuracy: 0.6700 - precision: 0.3295 - recall: 0.6558 - auc: 0.7215 - prc: 0.4124 - val_loss: 0.6317 - val_tp: 59.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 32.0000 - val_accuracy: 0.6403 - val_precision: 0.2823 - val_recall: 0.6484 - val_auc: 0.6965 - val_prc: 0.3560\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0290 - tp: 260.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 138.0000 - accuracy: 0.6630 - precision: 0.3234 - recall: 0.6533 - auc: 0.7285 - prc: 0.4193 - val_loss: 0.6124 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6982 - val_prc: 0.3629\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0311 - tp: 257.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 141.0000 - accuracy: 0.6660 - precision: 0.3245 - recall: 0.6457 - auc: 0.7251 - prc: 0.4105 - val_loss: 0.6016 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6991 - val_prc: 0.3651\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0315 - tp: 265.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 133.0000 - accuracy: 0.6497 - precision: 0.3151 - recall: 0.6658 - auc: 0.7248 - prc: 0.4148 - val_loss: 0.6107 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6987 - val_prc: 0.3669\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0286 - tp: 255.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 143.0000 - accuracy: 0.6769 - precision: 0.3329 - recall: 0.6407 - auc: 0.7287 - prc: 0.4279 - val_loss: 0.6575 - val_tp: 61.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 30.0000 - val_accuracy: 0.6107 - val_precision: 0.2675 - val_recall: 0.6703 - val_auc: 0.6957 - val_prc: 0.3481\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0303 - tp: 258.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 140.0000 - accuracy: 0.6705 - precision: 0.3287 - recall: 0.6482 - auc: 0.7264 - prc: 0.4115 - val_loss: 0.7020 - val_tp: 68.0000 - val_fp: 204.0000 - val_tn: 211.0000 - val_fn: 23.0000 - val_accuracy: 0.5514 - val_precision: 0.2500 - val_recall: 0.7473 - val_auc: 0.6940 - val_prc: 0.3439\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0343 - tp: 262.0000 - fp: 586.0000 - tn: 1040.0000 - fn: 136.0000 - accuracy: 0.6433 - precision: 0.3090 - recall: 0.6583 - auc: 0.7219 - prc: 0.4078 - val_loss: 0.5803 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.7002 - val_prc: 0.3634\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0291 - tp: 263.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 135.0000 - accuracy: 0.6665 - precision: 0.3275 - recall: 0.6608 - auc: 0.7266 - prc: 0.3971 - val_loss: 0.6112 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.6992 - val_prc: 0.3615\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0281 - tp: 257.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 141.0000 - accuracy: 0.6695 - precision: 0.3274 - recall: 0.6457 - auc: 0.7285 - prc: 0.4303 - val_loss: 0.6784 - val_tp: 65.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 26.0000 - val_accuracy: 0.5751 - val_precision: 0.2559 - val_recall: 0.7143 - val_auc: 0.6953 - val_prc: 0.3528\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0255 - tp: 263.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 135.0000 - accuracy: 0.6670 - precision: 0.3279 - recall: 0.6608 - auc: 0.7302 - prc: 0.4230 - val_loss: 0.6762 - val_tp: 64.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 27.0000 - val_accuracy: 0.5731 - val_precision: 0.2530 - val_recall: 0.7033 - val_auc: 0.6945 - val_prc: 0.3526\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0293 - tp: 262.0000 - fp: 559.0000 - tn: 1067.0000 - fn: 136.0000 - accuracy: 0.6566 - precision: 0.3191 - recall: 0.6583 - auc: 0.7256 - prc: 0.4299 - val_loss: 0.6473 - val_tp: 60.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 31.0000 - val_accuracy: 0.6245 - val_precision: 0.2740 - val_recall: 0.6593 - val_auc: 0.6967 - val_prc: 0.3624\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0236 - tp: 255.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 143.0000 - accuracy: 0.6818 - precision: 0.3373 - recall: 0.6407 - auc: 0.7318 - prc: 0.4354 - val_loss: 0.6460 - val_tp: 61.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 30.0000 - val_accuracy: 0.6245 - val_precision: 0.2760 - val_recall: 0.6703 - val_auc: 0.6967 - val_prc: 0.3576\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0245 - tp: 270.0000 - fp: 596.0000 - tn: 1030.0000 - fn: 128.0000 - accuracy: 0.6423 - precision: 0.3118 - recall: 0.6784 - auc: 0.7308 - prc: 0.4184 - val_loss: 0.5674 - val_tp: 48.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 43.0000 - val_accuracy: 0.7490 - val_precision: 0.3636 - val_recall: 0.5275 - val_auc: 0.7006 - val_prc: 0.3704\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0285 - tp: 247.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 151.0000 - accuracy: 0.6779 - precision: 0.3302 - recall: 0.6206 - auc: 0.7258 - prc: 0.4109 - val_loss: 0.6597 - val_tp: 63.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 28.0000 - val_accuracy: 0.6166 - val_precision: 0.2751 - val_recall: 0.6923 - val_auc: 0.6960 - val_prc: 0.3591\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0249 - tp: 259.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 139.0000 - accuracy: 0.6621 - precision: 0.3221 - recall: 0.6508 - auc: 0.7286 - prc: 0.4209 - val_loss: 0.6269 - val_tp: 58.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 33.0000 - val_accuracy: 0.6443 - val_precision: 0.2829 - val_recall: 0.6374 - val_auc: 0.6977 - val_prc: 0.3696\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0230 - tp: 258.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 140.0000 - accuracy: 0.6700 - precision: 0.3282 - recall: 0.6482 - auc: 0.7310 - prc: 0.4215 - val_loss: 0.7094 - val_tp: 69.0000 - val_fp: 211.0000 - val_tn: 204.0000 - val_fn: 22.0000 - val_accuracy: 0.5395 - val_precision: 0.2464 - val_recall: 0.7582 - val_auc: 0.6948 - val_prc: 0.3515\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0257 - tp: 271.0000 - fp: 569.0000 - tn: 1057.0000 - fn: 127.0000 - accuracy: 0.6561 - precision: 0.3226 - recall: 0.6809 - auc: 0.7286 - prc: 0.4363 - val_loss: 0.6107 - val_tp: 55.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 36.0000 - val_accuracy: 0.6759 - val_precision: 0.3005 - val_recall: 0.6044 - val_auc: 0.6994 - val_prc: 0.3722\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0237 - tp: 254.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 144.0000 - accuracy: 0.6774 - precision: 0.3329 - recall: 0.6382 - auc: 0.7300 - prc: 0.4286 - val_loss: 0.6389 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6989 - val_prc: 0.3674\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0221 - tp: 257.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 141.0000 - accuracy: 0.6695 - precision: 0.3274 - recall: 0.6457 - auc: 0.7311 - prc: 0.4299 - val_loss: 0.6952 - val_tp: 67.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 24.0000 - val_accuracy: 0.5573 - val_precision: 0.2509 - val_recall: 0.7363 - val_auc: 0.6959 - val_prc: 0.3582\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0204 - tp: 261.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 137.0000 - accuracy: 0.6640 - precision: 0.3246 - recall: 0.6558 - auc: 0.7321 - prc: 0.4445 - val_loss: 0.6389 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6990 - val_prc: 0.3707\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0240 - tp: 261.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 137.0000 - accuracy: 0.6793 - precision: 0.3376 - recall: 0.6558 - auc: 0.7289 - prc: 0.4287 - val_loss: 0.6434 - val_tp: 58.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 33.0000 - val_accuracy: 0.6245 - val_precision: 0.2698 - val_recall: 0.6374 - val_auc: 0.6993 - val_prc: 0.3716\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0200 - tp: 266.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 132.0000 - accuracy: 0.6655 - precision: 0.3280 - recall: 0.6683 - auc: 0.7328 - prc: 0.4273 - val_loss: 0.5901 - val_tp: 52.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 39.0000 - val_accuracy: 0.7134 - val_precision: 0.3291 - val_recall: 0.5714 - val_auc: 0.6999 - val_prc: 0.3657\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0207 - tp: 260.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 138.0000 - accuracy: 0.6838 - precision: 0.3412 - recall: 0.6533 - auc: 0.7298 - prc: 0.4343 - val_loss: 0.6451 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6979 - val_prc: 0.3741\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0185 - tp: 259.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 139.0000 - accuracy: 0.6784 - precision: 0.3359 - recall: 0.6508 - auc: 0.7332 - prc: 0.4506 - val_loss: 0.6163 - val_tp: 57.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 34.0000 - val_accuracy: 0.6700 - val_precision: 0.3000 - val_recall: 0.6264 - val_auc: 0.7000 - val_prc: 0.3719\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0180 - tp: 269.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 129.0000 - accuracy: 0.6428 - precision: 0.3117 - recall: 0.6759 - auc: 0.7351 - prc: 0.4333 - val_loss: 0.5737 - val_tp: 49.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 42.0000 - val_accuracy: 0.7253 - val_precision: 0.3356 - val_recall: 0.5385 - val_auc: 0.7010 - val_prc: 0.3773\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0191 - tp: 256.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 142.0000 - accuracy: 0.6848 - precision: 0.3404 - recall: 0.6432 - auc: 0.7327 - prc: 0.4230 - val_loss: 0.6148 - val_tp: 56.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 35.0000 - val_accuracy: 0.6700 - val_precision: 0.2979 - val_recall: 0.6154 - val_auc: 0.6972 - val_prc: 0.3624\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0175 - tp: 260.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 138.0000 - accuracy: 0.6734 - precision: 0.3321 - recall: 0.6533 - auc: 0.7333 - prc: 0.4382 - val_loss: 0.6445 - val_tp: 60.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 31.0000 - val_accuracy: 0.6265 - val_precision: 0.2752 - val_recall: 0.6593 - val_auc: 0.6961 - val_prc: 0.3672\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0189 - tp: 257.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 141.0000 - accuracy: 0.6719 - precision: 0.3295 - recall: 0.6457 - auc: 0.7316 - prc: 0.4356 - val_loss: 0.6250 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6999 - val_prc: 0.3709\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0193 - tp: 263.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 135.0000 - accuracy: 0.6808 - precision: 0.3398 - recall: 0.6608 - auc: 0.7309 - prc: 0.4474 - val_loss: 0.6543 - val_tp: 61.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 30.0000 - val_accuracy: 0.6186 - val_precision: 0.2723 - val_recall: 0.6703 - val_auc: 0.6981 - val_prc: 0.3700\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0176 - tp: 259.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 139.0000 - accuracy: 0.6754 - precision: 0.3333 - recall: 0.6508 - auc: 0.7334 - prc: 0.4422 - val_loss: 0.6264 - val_tp: 57.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 34.0000 - val_accuracy: 0.6601 - val_precision: 0.2923 - val_recall: 0.6264 - val_auc: 0.7021 - val_prc: 0.3770\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0145 - tp: 254.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 144.0000 - accuracy: 0.6719 - precision: 0.3282 - recall: 0.6382 - auc: 0.7347 - prc: 0.4349 - val_loss: 0.6058 - val_tp: 55.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 36.0000 - val_accuracy: 0.6917 - val_precision: 0.3143 - val_recall: 0.6044 - val_auc: 0.7012 - val_prc: 0.3662\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0183 - tp: 259.0000 - fp: 537.0000 - tn: 1089.0000 - fn: 139.0000 - accuracy: 0.6660 - precision: 0.3254 - recall: 0.6508 - auc: 0.7323 - prc: 0.4286 - val_loss: 0.6613 - val_tp: 62.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 29.0000 - val_accuracy: 0.6126 - val_precision: 0.2707 - val_recall: 0.6813 - val_auc: 0.6968 - val_prc: 0.3688\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0207 - tp: 262.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 136.0000 - accuracy: 0.6714 - precision: 0.3312 - recall: 0.6583 - auc: 0.7303 - prc: 0.4271 - val_loss: 0.6638 - val_tp: 62.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 29.0000 - val_accuracy: 0.6008 - val_precision: 0.2638 - val_recall: 0.6813 - val_auc: 0.7024 - val_prc: 0.3763\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0196 - tp: 264.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 134.0000 - accuracy: 0.6719 - precision: 0.3325 - recall: 0.6633 - auc: 0.7299 - prc: 0.4332 - val_loss: 0.6467 - val_tp: 59.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 32.0000 - val_accuracy: 0.6265 - val_precision: 0.2731 - val_recall: 0.6484 - val_auc: 0.6990 - val_prc: 0.3701\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0150 - tp: 258.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 140.0000 - accuracy: 0.6798 - precision: 0.3368 - recall: 0.6482 - auc: 0.7340 - prc: 0.4324 - val_loss: 0.6428 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6989 - val_prc: 0.3709\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0189 - tp: 264.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 134.0000 - accuracy: 0.6645 - precision: 0.3263 - recall: 0.6633 - auc: 0.7321 - prc: 0.4339 - val_loss: 0.6476 - val_tp: 60.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 31.0000 - val_accuracy: 0.6344 - val_precision: 0.2804 - val_recall: 0.6593 - val_auc: 0.7004 - val_prc: 0.3699\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0150 - tp: 265.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 133.0000 - accuracy: 0.6670 - precision: 0.3288 - recall: 0.6658 - auc: 0.7343 - prc: 0.4339 - val_loss: 0.6357 - val_tp: 58.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 33.0000 - val_accuracy: 0.6443 - val_precision: 0.2829 - val_recall: 0.6374 - val_auc: 0.6994 - val_prc: 0.3698\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0156 - tp: 260.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 138.0000 - accuracy: 0.6640 - precision: 0.3242 - recall: 0.6533 - auc: 0.7337 - prc: 0.4412 - val_loss: 0.6079 - val_tp: 54.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 37.0000 - val_accuracy: 0.6818 - val_precision: 0.3034 - val_recall: 0.5934 - val_auc: 0.7003 - val_prc: 0.3663\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0142 - tp: 260.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 138.0000 - accuracy: 0.6739 - precision: 0.3325 - recall: 0.6533 - auc: 0.7341 - prc: 0.4299 - val_loss: 0.5844 - val_tp: 51.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 40.0000 - val_accuracy: 0.7292 - val_precision: 0.3446 - val_recall: 0.5604 - val_auc: 0.7010 - val_prc: 0.3722\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0107 - tp: 252.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 146.0000 - accuracy: 0.6971 - precision: 0.3505 - recall: 0.6332 - auc: 0.7388 - prc: 0.4326 - val_loss: 0.7022 - val_tp: 67.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 24.0000 - val_accuracy: 0.5534 - val_precision: 0.2491 - val_recall: 0.7363 - val_auc: 0.6956 - val_prc: 0.3640\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0141 - tp: 262.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 136.0000 - accuracy: 0.6808 - precision: 0.3394 - recall: 0.6583 - auc: 0.7354 - prc: 0.4401 - val_loss: 0.6608 - val_tp: 62.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 29.0000 - val_accuracy: 0.6067 - val_precision: 0.2672 - val_recall: 0.6813 - val_auc: 0.6964 - val_prc: 0.3698\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0137 - tp: 269.0000 - fp: 573.0000 - tn: 1053.0000 - fn: 129.0000 - accuracy: 0.6532 - precision: 0.3195 - recall: 0.6759 - auc: 0.7369 - prc: 0.4390 - val_loss: 0.5708 - val_tp: 48.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 43.0000 - val_accuracy: 0.7451 - val_precision: 0.3582 - val_recall: 0.5275 - val_auc: 0.7033 - val_prc: 0.3797\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0121 - tp: 260.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 138.0000 - accuracy: 0.6843 - precision: 0.3417 - recall: 0.6533 - auc: 0.7365 - prc: 0.4449 - val_loss: 0.6011 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6986 - val_prc: 0.3703\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0139 - tp: 259.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 139.0000 - accuracy: 0.6818 - precision: 0.3390 - recall: 0.6508 - auc: 0.7345 - prc: 0.4503 - val_loss: 0.6108 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6974 - val_prc: 0.3657\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0115 - tp: 263.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 135.0000 - accuracy: 0.6729 - precision: 0.3329 - recall: 0.6608 - auc: 0.7367 - prc: 0.4449 - val_loss: 0.5925 - val_tp: 51.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 40.0000 - val_accuracy: 0.7154 - val_precision: 0.3290 - val_recall: 0.5604 - val_auc: 0.7001 - val_prc: 0.3689\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0124 - tp: 262.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 136.0000 - accuracy: 0.6764 - precision: 0.3355 - recall: 0.6583 - auc: 0.7364 - prc: 0.4400 - val_loss: 0.6108 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6984 - val_prc: 0.3681\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0119 - tp: 255.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 143.0000 - accuracy: 0.6873 - precision: 0.3423 - recall: 0.6407 - auc: 0.7366 - prc: 0.4542 - val_loss: 0.6631 - val_tp: 63.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 28.0000 - val_accuracy: 0.6047 - val_precision: 0.2681 - val_recall: 0.6923 - val_auc: 0.6973 - val_prc: 0.3734\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0119 - tp: 273.0000 - fp: 574.0000 - tn: 1052.0000 - fn: 125.0000 - accuracy: 0.6546 - precision: 0.3223 - recall: 0.6859 - auc: 0.7363 - prc: 0.4404 - val_loss: 0.6126 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.7003 - val_prc: 0.3760\n",
      "Epoch 129/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0117 - tp: 251.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 147.0000 - accuracy: 0.6853 - precision: 0.3387 - recall: 0.6307 - auc: 0.7351 - prc: 0.4469 - val_loss: 0.6534 - val_tp: 59.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 32.0000 - val_accuracy: 0.6265 - val_precision: 0.2731 - val_recall: 0.6484 - val_auc: 0.7019 - val_prc: 0.3742\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0129 - tp: 266.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 132.0000 - accuracy: 0.6601 - precision: 0.3236 - recall: 0.6683 - auc: 0.7355 - prc: 0.4412 - val_loss: 0.6235 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6999 - val_prc: 0.3685\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0114 - tp: 263.0000 - fp: 532.0000 - tn: 1094.0000 - fn: 135.0000 - accuracy: 0.6705 - precision: 0.3308 - recall: 0.6608 - auc: 0.7358 - prc: 0.4431 - val_loss: 0.6069 - val_tp: 54.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 37.0000 - val_accuracy: 0.6897 - val_precision: 0.3103 - val_recall: 0.5934 - val_auc: 0.7004 - val_prc: 0.3702\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0093 - tp: 260.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 138.0000 - accuracy: 0.6853 - precision: 0.3426 - recall: 0.6533 - auc: 0.7374 - prc: 0.4461 - val_loss: 0.6393 - val_tp: 57.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 34.0000 - val_accuracy: 0.6403 - val_precision: 0.2780 - val_recall: 0.6264 - val_auc: 0.6999 - val_prc: 0.3747\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0116 - tp: 267.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 131.0000 - accuracy: 0.6690 - precision: 0.3313 - recall: 0.6709 - auc: 0.7357 - prc: 0.4433 - val_loss: 0.6205 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.7007 - val_prc: 0.3740\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0082 - tp: 265.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 133.0000 - accuracy: 0.6685 - precision: 0.3300 - recall: 0.6658 - auc: 0.7405 - prc: 0.4383 - val_loss: 0.6010 - val_tp: 54.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 37.0000 - val_accuracy: 0.7036 - val_precision: 0.3234 - val_recall: 0.5934 - val_auc: 0.7010 - val_prc: 0.3753\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0093 - tp: 259.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 139.0000 - accuracy: 0.6779 - precision: 0.3355 - recall: 0.6508 - auc: 0.7375 - prc: 0.4491 - val_loss: 0.6260 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.7004 - val_prc: 0.3725\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0088 - tp: 258.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 140.0000 - accuracy: 0.6833 - precision: 0.3399 - recall: 0.6482 - auc: 0.7363 - prc: 0.4571 - val_loss: 0.6577 - val_tp: 60.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 31.0000 - val_accuracy: 0.6107 - val_precision: 0.2655 - val_recall: 0.6593 - val_auc: 0.7022 - val_prc: 0.3750\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0072 - tp: 267.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 131.0000 - accuracy: 0.6675 - precision: 0.3300 - recall: 0.6709 - auc: 0.7392 - prc: 0.4435 - val_loss: 0.6575 - val_tp: 58.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 33.0000 - val_accuracy: 0.6107 - val_precision: 0.2613 - val_recall: 0.6374 - val_auc: 0.6976 - val_prc: 0.3749\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0100 - tp: 265.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 133.0000 - accuracy: 0.6596 - precision: 0.3228 - recall: 0.6658 - auc: 0.7358 - prc: 0.4389 - val_loss: 0.5868 - val_tp: 51.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 40.0000 - val_accuracy: 0.7213 - val_precision: 0.3355 - val_recall: 0.5604 - val_auc: 0.6995 - val_prc: 0.3790\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0101 - tp: 253.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 145.0000 - accuracy: 0.6700 - precision: 0.3260 - recall: 0.6357 - auc: 0.7360 - prc: 0.4306 - val_loss: 0.6073 - val_tp: 56.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 35.0000 - val_accuracy: 0.6996 - val_precision: 0.3237 - val_recall: 0.6154 - val_auc: 0.7028 - val_prc: 0.3735\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0080 - tp: 269.0000 - fp: 567.0000 - tn: 1059.0000 - fn: 129.0000 - accuracy: 0.6561 - precision: 0.3218 - recall: 0.6759 - auc: 0.7381 - prc: 0.4313 - val_loss: 0.6216 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.7000 - val_prc: 0.3801\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0074 - tp: 258.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 140.0000 - accuracy: 0.6779 - precision: 0.3351 - recall: 0.6482 - auc: 0.7374 - prc: 0.4534 - val_loss: 0.6181 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6994 - val_prc: 0.3763\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0109 - tp: 258.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 140.0000 - accuracy: 0.6848 - precision: 0.3413 - recall: 0.6482 - auc: 0.7357 - prc: 0.4496 - val_loss: 0.6859 - val_tp: 65.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 26.0000 - val_accuracy: 0.5771 - val_precision: 0.2569 - val_recall: 0.7143 - val_auc: 0.6980 - val_prc: 0.3715\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0062 - tp: 266.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 132.0000 - accuracy: 0.6655 - precision: 0.3280 - recall: 0.6683 - auc: 0.7387 - prc: 0.4518 - val_loss: 0.6393 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.7012 - val_prc: 0.3748\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0087 - tp: 263.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 135.0000 - accuracy: 0.6719 - precision: 0.3321 - recall: 0.6608 - auc: 0.7368 - prc: 0.4425 - val_loss: 0.6831 - val_tp: 64.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 27.0000 - val_accuracy: 0.5850 - val_precision: 0.2591 - val_recall: 0.7033 - val_auc: 0.6955 - val_prc: 0.3698\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0062 - tp: 266.0000 - fp: 524.0000 - tn: 1102.0000 - fn: 132.0000 - accuracy: 0.6759 - precision: 0.3367 - recall: 0.6683 - auc: 0.7395 - prc: 0.4528 - val_loss: 0.5941 - val_tp: 51.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 40.0000 - val_accuracy: 0.7055 - val_precision: 0.3187 - val_recall: 0.5604 - val_auc: 0.6984 - val_prc: 0.3720\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0092 - tp: 260.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 138.0000 - accuracy: 0.6655 - precision: 0.3254 - recall: 0.6533 - auc: 0.7350 - prc: 0.4308 - val_loss: 0.6597 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.7015 - val_prc: 0.3822\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0059 - tp: 260.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 138.0000 - accuracy: 0.6784 - precision: 0.3364 - recall: 0.6533 - auc: 0.7399 - prc: 0.4556 - val_loss: 0.6361 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6976 - val_prc: 0.3736\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0045 - tp: 262.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 136.0000 - accuracy: 0.6793 - precision: 0.3381 - recall: 0.6583 - auc: 0.7400 - prc: 0.4383 - val_loss: 0.5844 - val_tp: 52.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 39.0000 - val_accuracy: 0.7312 - val_precision: 0.3490 - val_recall: 0.5714 - val_auc: 0.7011 - val_prc: 0.3704\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0056 - tp: 262.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 136.0000 - accuracy: 0.6729 - precision: 0.3325 - recall: 0.6583 - auc: 0.7384 - prc: 0.4629 - val_loss: 0.6251 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.7017 - val_prc: 0.3823\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0045 - tp: 258.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 140.0000 - accuracy: 0.6868 - precision: 0.3431 - recall: 0.6482 - auc: 0.7400 - prc: 0.4576 - val_loss: 0.6518 - val_tp: 56.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 35.0000 - val_accuracy: 0.6186 - val_precision: 0.2617 - val_recall: 0.6154 - val_auc: 0.7007 - val_prc: 0.3796\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0063 - tp: 259.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 139.0000 - accuracy: 0.6838 - precision: 0.3408 - recall: 0.6508 - auc: 0.7391 - prc: 0.4571 - val_loss: 0.6045 - val_tp: 53.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 38.0000 - val_accuracy: 0.6976 - val_precision: 0.3155 - val_recall: 0.5824 - val_auc: 0.7028 - val_prc: 0.3778\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0043 - tp: 269.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 129.0000 - accuracy: 0.6749 - precision: 0.3371 - recall: 0.6759 - auc: 0.7402 - prc: 0.4539 - val_loss: 0.5767 - val_tp: 48.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 43.0000 - val_accuracy: 0.7332 - val_precision: 0.3429 - val_recall: 0.5275 - val_auc: 0.7024 - val_prc: 0.3862\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0066 - tp: 260.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 138.0000 - accuracy: 0.6917 - precision: 0.3485 - recall: 0.6533 - auc: 0.7388 - prc: 0.4484 - val_loss: 0.6774 - val_tp: 63.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 28.0000 - val_accuracy: 0.5949 - val_precision: 0.2625 - val_recall: 0.6923 - val_auc: 0.6989 - val_prc: 0.3775\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0058 - tp: 260.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 138.0000 - accuracy: 0.6635 - precision: 0.3238 - recall: 0.6533 - auc: 0.7378 - prc: 0.4563 - val_loss: 0.5876 - val_tp: 51.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 40.0000 - val_accuracy: 0.7292 - val_precision: 0.3446 - val_recall: 0.5604 - val_auc: 0.7038 - val_prc: 0.3840\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0062 - tp: 252.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 146.0000 - accuracy: 0.6947 - precision: 0.3481 - recall: 0.6332 - auc: 0.7389 - prc: 0.4585 - val_loss: 0.6570 - val_tp: 57.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 34.0000 - val_accuracy: 0.6166 - val_precision: 0.2627 - val_recall: 0.6264 - val_auc: 0.7001 - val_prc: 0.3790\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0057 - tp: 267.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 131.0000 - accuracy: 0.6606 - precision: 0.3244 - recall: 0.6709 - auc: 0.7387 - prc: 0.4400 - val_loss: 0.6340 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.7032 - val_prc: 0.3765\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0043 - tp: 266.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 132.0000 - accuracy: 0.6685 - precision: 0.3304 - recall: 0.6683 - auc: 0.7397 - prc: 0.4535 - val_loss: 0.6195 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.7028 - val_prc: 0.3792\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0036 - tp: 262.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 136.0000 - accuracy: 0.6789 - precision: 0.3376 - recall: 0.6583 - auc: 0.7401 - prc: 0.4525 - val_loss: 0.6289 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.7005 - val_prc: 0.3795\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0043 - tp: 264.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 134.0000 - accuracy: 0.6813 - precision: 0.3406 - recall: 0.6633 - auc: 0.7405 - prc: 0.4506 - val_loss: 0.6195 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.7019 - val_prc: 0.3843\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0045 - tp: 265.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 133.0000 - accuracy: 0.6729 - precision: 0.3338 - recall: 0.6658 - auc: 0.7392 - prc: 0.4701 - val_loss: 0.6368 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.7004 - val_prc: 0.3776\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0081 - tp: 261.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 137.0000 - accuracy: 0.6759 - precision: 0.3346 - recall: 0.6558 - auc: 0.7371 - prc: 0.4444 - val_loss: 0.6294 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.7026 - val_prc: 0.3869\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0016 - tp: 263.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 135.0000 - accuracy: 0.6887 - precision: 0.3470 - recall: 0.6608 - auc: 0.7423 - prc: 0.4573 - val_loss: 0.6218 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.7014 - val_prc: 0.3891\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0024 - tp: 263.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 135.0000 - accuracy: 0.6793 - precision: 0.3385 - recall: 0.6608 - auc: 0.7406 - prc: 0.4489 - val_loss: 0.6222 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.7015 - val_prc: 0.3816\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0047 - tp: 263.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 135.0000 - accuracy: 0.6789 - precision: 0.3380 - recall: 0.6608 - auc: 0.7384 - prc: 0.4419 - val_loss: 0.6074 - val_tp: 53.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 38.0000 - val_accuracy: 0.6937 - val_precision: 0.3118 - val_recall: 0.5824 - val_auc: 0.7017 - val_prc: 0.3778\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0034 - tp: 260.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 138.0000 - accuracy: 0.6789 - precision: 0.3368 - recall: 0.6533 - auc: 0.7403 - prc: 0.4609 - val_loss: 0.6237 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.7016 - val_prc: 0.3848\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0044 - tp: 263.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 135.0000 - accuracy: 0.6700 - precision: 0.3304 - recall: 0.6608 - auc: 0.7393 - prc: 0.4587 - val_loss: 0.6050 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.7001 - val_prc: 0.3757\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0027 - tp: 260.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 138.0000 - accuracy: 0.6863 - precision: 0.3435 - recall: 0.6533 - auc: 0.7415 - prc: 0.4545 - val_loss: 0.6521 - val_tp: 58.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 33.0000 - val_accuracy: 0.6245 - val_precision: 0.2698 - val_recall: 0.6374 - val_auc: 0.7016 - val_prc: 0.3797\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9997 - tp: 259.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 139.0000 - accuracy: 0.6818 - precision: 0.3390 - recall: 0.6508 - auc: 0.7427 - prc: 0.4522 - val_loss: 0.6564 - val_tp: 56.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 35.0000 - val_accuracy: 0.6166 - val_precision: 0.2605 - val_recall: 0.6154 - val_auc: 0.6997 - val_prc: 0.3770\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0035 - tp: 259.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 139.0000 - accuracy: 0.6828 - precision: 0.3399 - recall: 0.6508 - auc: 0.7390 - prc: 0.4504 - val_loss: 0.6618 - val_tp: 58.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 33.0000 - val_accuracy: 0.6107 - val_precision: 0.2613 - val_recall: 0.6374 - val_auc: 0.7024 - val_prc: 0.3789\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0049 - tp: 267.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 131.0000 - accuracy: 0.6774 - precision: 0.3384 - recall: 0.6709 - auc: 0.7391 - prc: 0.4566 - val_loss: 0.6600 - val_tp: 57.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 34.0000 - val_accuracy: 0.6146 - val_precision: 0.2615 - val_recall: 0.6264 - val_auc: 0.7002 - val_prc: 0.3754\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0006 - tp: 267.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 131.0000 - accuracy: 0.6754 - precision: 0.3367 - recall: 0.6709 - auc: 0.7409 - prc: 0.4561 - val_loss: 0.6476 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.7018 - val_prc: 0.3783\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9995 - tp: 261.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 137.0000 - accuracy: 0.6823 - precision: 0.3403 - recall: 0.6558 - auc: 0.7420 - prc: 0.4603 - val_loss: 0.6618 - val_tp: 57.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 34.0000 - val_accuracy: 0.6107 - val_precision: 0.2591 - val_recall: 0.6264 - val_auc: 0.6988 - val_prc: 0.3749\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0025 - tp: 266.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 132.0000 - accuracy: 0.6729 - precision: 0.3342 - recall: 0.6683 - auc: 0.7397 - prc: 0.4490 - val_loss: 0.6311 - val_tp: 56.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 35.0000 - val_accuracy: 0.6621 - val_precision: 0.2917 - val_recall: 0.6154 - val_auc: 0.7024 - val_prc: 0.3816\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9991 - tp: 263.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 135.0000 - accuracy: 0.6942 - precision: 0.3521 - recall: 0.6608 - auc: 0.7428 - prc: 0.4560 - val_loss: 0.6504 - val_tp: 56.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 35.0000 - val_accuracy: 0.6364 - val_precision: 0.2732 - val_recall: 0.6154 - val_auc: 0.7020 - val_prc: 0.3756\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0006 - tp: 265.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 133.0000 - accuracy: 0.6645 - precision: 0.3268 - recall: 0.6658 - auc: 0.7419 - prc: 0.4579 - val_loss: 0.5722 - val_tp: 48.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 43.0000 - val_accuracy: 0.7470 - val_precision: 0.3609 - val_recall: 0.5275 - val_auc: 0.7007 - val_prc: 0.3823\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0005 - tp: 265.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 133.0000 - accuracy: 0.6868 - precision: 0.3460 - recall: 0.6658 - auc: 0.7416 - prc: 0.4667 - val_loss: 0.5459 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6994 - val_prc: 0.3840\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0038 - tp: 253.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 145.0000 - accuracy: 0.6877 - precision: 0.3419 - recall: 0.6357 - auc: 0.7391 - prc: 0.4569 - val_loss: 0.6714 - val_tp: 59.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 32.0000 - val_accuracy: 0.6008 - val_precision: 0.2576 - val_recall: 0.6484 - val_auc: 0.7016 - val_prc: 0.3732\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9991 - tp: 273.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 125.0000 - accuracy: 0.6798 - precision: 0.3430 - recall: 0.6859 - auc: 0.7435 - prc: 0.4506 - val_loss: 0.5858 - val_tp: 51.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 40.0000 - val_accuracy: 0.7352 - val_precision: 0.3517 - val_recall: 0.5604 - val_auc: 0.7007 - val_prc: 0.3818\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9995 - tp: 260.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 138.0000 - accuracy: 0.6966 - precision: 0.3533 - recall: 0.6533 - auc: 0.7424 - prc: 0.4619 - val_loss: 0.6619 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.7026 - val_prc: 0.3789\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0034 - tp: 262.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 136.0000 - accuracy: 0.6789 - precision: 0.3376 - recall: 0.6583 - auc: 0.7387 - prc: 0.4498 - val_loss: 0.6663 - val_tp: 58.0000 - val_fp: 169.0000 - val_tn: 246.0000 - val_fn: 33.0000 - val_accuracy: 0.6008 - val_precision: 0.2555 - val_recall: 0.6374 - val_auc: 0.7023 - val_prc: 0.3802\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0035 - tp: 266.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 132.0000 - accuracy: 0.6645 - precision: 0.3272 - recall: 0.6683 - auc: 0.7376 - prc: 0.4492 - val_loss: 0.6174 - val_tp: 54.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 37.0000 - val_accuracy: 0.6838 - val_precision: 0.3051 - val_recall: 0.5934 - val_auc: 0.7013 - val_prc: 0.3835\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0012 - tp: 261.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 137.0000 - accuracy: 0.6749 - precision: 0.3338 - recall: 0.6558 - auc: 0.7411 - prc: 0.4605 - val_loss: 0.6339 - val_tp: 56.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 35.0000 - val_accuracy: 0.6601 - val_precision: 0.2902 - val_recall: 0.6154 - val_auc: 0.7016 - val_prc: 0.3845\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9994 - tp: 263.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 135.0000 - accuracy: 0.6848 - precision: 0.3433 - recall: 0.6608 - auc: 0.7414 - prc: 0.4531 - val_loss: 0.6481 - val_tp: 56.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 35.0000 - val_accuracy: 0.6285 - val_precision: 0.2679 - val_recall: 0.6154 - val_auc: 0.6982 - val_prc: 0.3749\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9994 - tp: 262.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 136.0000 - accuracy: 0.6877 - precision: 0.3456 - recall: 0.6583 - auc: 0.7418 - prc: 0.4606 - val_loss: 0.6291 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.7007 - val_prc: 0.3912\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9999 - tp: 265.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 133.0000 - accuracy: 0.6705 - precision: 0.3317 - recall: 0.6658 - auc: 0.7404 - prc: 0.4640 - val_loss: 0.6353 - val_tp: 56.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 35.0000 - val_accuracy: 0.6621 - val_precision: 0.2917 - val_recall: 0.6154 - val_auc: 0.7034 - val_prc: 0.3904\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9985 - tp: 268.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 130.0000 - accuracy: 0.6744 - precision: 0.3363 - recall: 0.6734 - auc: 0.7421 - prc: 0.4508 - val_loss: 0.5764 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.7036 - val_prc: 0.3814\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9997 - tp: 261.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 137.0000 - accuracy: 0.6858 - precision: 0.3434 - recall: 0.6558 - auc: 0.7426 - prc: 0.4567 - val_loss: 0.5962 - val_tp: 52.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 39.0000 - val_accuracy: 0.7174 - val_precision: 0.3333 - val_recall: 0.5714 - val_auc: 0.7012 - val_prc: 0.3800\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0005 - tp: 257.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 141.0000 - accuracy: 0.6813 - precision: 0.3377 - recall: 0.6457 - auc: 0.7427 - prc: 0.4417 - val_loss: 0.6113 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.7019 - val_prc: 0.3808\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9988 - tp: 262.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 136.0000 - accuracy: 0.6843 - precision: 0.3425 - recall: 0.6583 - auc: 0.7417 - prc: 0.4545 - val_loss: 0.6207 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.7006 - val_prc: 0.3794\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9993 - tp: 259.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 139.0000 - accuracy: 0.6823 - precision: 0.3394 - recall: 0.6508 - auc: 0.7413 - prc: 0.4590 - val_loss: 0.6451 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.7013 - val_prc: 0.3853\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9995 - tp: 260.0000 - fp: 524.0000 - tn: 1102.0000 - fn: 138.0000 - accuracy: 0.6729 - precision: 0.3316 - recall: 0.6533 - auc: 0.7417 - prc: 0.4633 - val_loss: 0.6649 - val_tp: 57.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 34.0000 - val_accuracy: 0.6166 - val_precision: 0.2627 - val_recall: 0.6264 - val_auc: 0.6957 - val_prc: 0.3688\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0033 - tp: 270.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 128.0000 - accuracy: 0.6685 - precision: 0.3321 - recall: 0.6784 - auc: 0.7391 - prc: 0.4515 - val_loss: 0.5908 - val_tp: 51.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 40.0000 - val_accuracy: 0.7194 - val_precision: 0.3333 - val_recall: 0.5604 - val_auc: 0.6993 - val_prc: 0.3724\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9964 - tp: 259.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 139.0000 - accuracy: 0.6887 - precision: 0.3453 - recall: 0.6508 - auc: 0.7437 - prc: 0.4623 - val_loss: 0.6633 - val_tp: 57.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 34.0000 - val_accuracy: 0.6126 - val_precision: 0.2603 - val_recall: 0.6264 - val_auc: 0.7015 - val_prc: 0.3811\n",
      "Epoch 194/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9995 - tp: 264.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 134.0000 - accuracy: 0.6892 - precision: 0.3478 - recall: 0.6633 - auc: 0.7415 - prc: 0.4579 - val_loss: 0.6241 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.7002 - val_prc: 0.3845\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9985 - tp: 264.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 134.0000 - accuracy: 0.6739 - precision: 0.3342 - recall: 0.6633 - auc: 0.7410 - prc: 0.4572 - val_loss: 0.6164 - val_tp: 54.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 37.0000 - val_accuracy: 0.6897 - val_precision: 0.3103 - val_recall: 0.5934 - val_auc: 0.7026 - val_prc: 0.3786\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9974 - tp: 257.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 141.0000 - accuracy: 0.6873 - precision: 0.3431 - recall: 0.6457 - auc: 0.7418 - prc: 0.4557 - val_loss: 0.6681 - val_tp: 57.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 34.0000 - val_accuracy: 0.6067 - val_precision: 0.2568 - val_recall: 0.6264 - val_auc: 0.7002 - val_prc: 0.3737\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9973 - tp: 262.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 136.0000 - accuracy: 0.6823 - precision: 0.3407 - recall: 0.6583 - auc: 0.7429 - prc: 0.4649 - val_loss: 0.6427 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6999 - val_prc: 0.3790\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9940 - tp: 255.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 143.0000 - accuracy: 0.6971 - precision: 0.3517 - recall: 0.6407 - auc: 0.7448 - prc: 0.4583 - val_loss: 0.6999 - val_tp: 64.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 27.0000 - val_accuracy: 0.5771 - val_precision: 0.2550 - val_recall: 0.7033 - val_auc: 0.6975 - val_prc: 0.3741\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9984 - tp: 266.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 132.0000 - accuracy: 0.6808 - precision: 0.3410 - recall: 0.6683 - auc: 0.7426 - prc: 0.4502 - val_loss: 0.6277 - val_tp: 55.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 36.0000 - val_accuracy: 0.6700 - val_precision: 0.2957 - val_recall: 0.6044 - val_auc: 0.7025 - val_prc: 0.3829\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9973 - tp: 265.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 133.0000 - accuracy: 0.6897 - precision: 0.3487 - recall: 0.6658 - auc: 0.7425 - prc: 0.4633 - val_loss: 0.6233 - val_tp: 55.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 36.0000 - val_accuracy: 0.6759 - val_precision: 0.3005 - val_recall: 0.6044 - val_auc: 0.7022 - val_prc: 0.3793\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0024 - tp: 257.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 141.0000 - accuracy: 0.6803 - precision: 0.3368 - recall: 0.6457 - auc: 0.7389 - prc: 0.4543 - val_loss: 0.6237 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6991 - val_prc: 0.3823\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9977 - tp: 263.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 135.0000 - accuracy: 0.6917 - precision: 0.3497 - recall: 0.6608 - auc: 0.7421 - prc: 0.4610 - val_loss: 0.6491 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6981 - val_prc: 0.3759\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9982 - tp: 265.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 133.0000 - accuracy: 0.6813 - precision: 0.3411 - recall: 0.6658 - auc: 0.7423 - prc: 0.4572 - val_loss: 0.6199 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.7026 - val_prc: 0.3809\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 1.0000 - tp: 260.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 138.0000 - accuracy: 0.6882 - precision: 0.3453 - recall: 0.6533 - auc: 0.7404 - prc: 0.4542 - val_loss: 0.6274 - val_tp: 55.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 36.0000 - val_accuracy: 0.6759 - val_precision: 0.3005 - val_recall: 0.6044 - val_auc: 0.7017 - val_prc: 0.3845\n",
      "Epoch 205/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9996 - tp: 263.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 135.0000 - accuracy: 0.6803 - precision: 0.3394 - recall: 0.6608 - auc: 0.7414 - prc: 0.4494 - val_loss: 0.5858 - val_tp: 49.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 42.0000 - val_accuracy: 0.7332 - val_precision: 0.3451 - val_recall: 0.5385 - val_auc: 0.7025 - val_prc: 0.3853\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9965 - tp: 264.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 134.0000 - accuracy: 0.6858 - precision: 0.3446 - recall: 0.6633 - auc: 0.7437 - prc: 0.4626 - val_loss: 0.6217 - val_tp: 55.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 36.0000 - val_accuracy: 0.6838 - val_precision: 0.3073 - val_recall: 0.6044 - val_auc: 0.7008 - val_prc: 0.3829\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9941 - tp: 265.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 133.0000 - accuracy: 0.6858 - precision: 0.3451 - recall: 0.6658 - auc: 0.7447 - prc: 0.4592 - val_loss: 0.5972 - val_tp: 51.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 40.0000 - val_accuracy: 0.7174 - val_precision: 0.3312 - val_recall: 0.5604 - val_auc: 0.7003 - val_prc: 0.3768\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9956 - tp: 261.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 137.0000 - accuracy: 0.6858 - precision: 0.3434 - recall: 0.6558 - auc: 0.7440 - prc: 0.4579 - val_loss: 0.5754 - val_tp: 49.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 42.0000 - val_accuracy: 0.7451 - val_precision: 0.3603 - val_recall: 0.5385 - val_auc: 0.7020 - val_prc: 0.3881\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9963 - tp: 262.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 136.0000 - accuracy: 0.6991 - precision: 0.3565 - recall: 0.6583 - auc: 0.7450 - prc: 0.4570 - val_loss: 0.6460 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6995 - val_prc: 0.3795\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9945 - tp: 264.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 134.0000 - accuracy: 0.7021 - precision: 0.3602 - recall: 0.6633 - auc: 0.7440 - prc: 0.4559 - val_loss: 0.6906 - val_tp: 62.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 29.0000 - val_accuracy: 0.5850 - val_precision: 0.2551 - val_recall: 0.6813 - val_auc: 0.7038 - val_prc: 0.3794\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9971 - tp: 270.0000 - fp: 553.0000 - tn: 1073.0000 - fn: 128.0000 - accuracy: 0.6635 - precision: 0.3281 - recall: 0.6784 - auc: 0.7442 - prc: 0.4565 - val_loss: 0.6300 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.7015 - val_prc: 0.3895\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9970 - tp: 262.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 136.0000 - accuracy: 0.6828 - precision: 0.3411 - recall: 0.6583 - auc: 0.7441 - prc: 0.4516 - val_loss: 0.6321 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6983 - val_prc: 0.3839\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9939 - tp: 267.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 131.0000 - accuracy: 0.6902 - precision: 0.3499 - recall: 0.6709 - auc: 0.7449 - prc: 0.4553 - val_loss: 0.6331 - val_tp: 53.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 38.0000 - val_accuracy: 0.6640 - val_precision: 0.2865 - val_recall: 0.5824 - val_auc: 0.6965 - val_prc: 0.3819\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9935 - tp: 266.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 132.0000 - accuracy: 0.6833 - precision: 0.3432 - recall: 0.6683 - auc: 0.7441 - prc: 0.4565 - val_loss: 0.5921 - val_tp: 51.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 40.0000 - val_accuracy: 0.7352 - val_precision: 0.3517 - val_recall: 0.5604 - val_auc: 0.6966 - val_prc: 0.3781\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9953 - tp: 259.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 139.0000 - accuracy: 0.6907 - precision: 0.3472 - recall: 0.6508 - auc: 0.7445 - prc: 0.4670 - val_loss: 0.5888 - val_tp: 51.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 40.0000 - val_accuracy: 0.7411 - val_precision: 0.3592 - val_recall: 0.5604 - val_auc: 0.7005 - val_prc: 0.3804\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9915 - tp: 262.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 136.0000 - accuracy: 0.6882 - precision: 0.3461 - recall: 0.6583 - auc: 0.7471 - prc: 0.4593 - val_loss: 0.6956 - val_tp: 63.0000 - val_fp: 182.0000 - val_tn: 233.0000 - val_fn: 28.0000 - val_accuracy: 0.5850 - val_precision: 0.2571 - val_recall: 0.6923 - val_auc: 0.7009 - val_prc: 0.3833\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9968 - tp: 259.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 139.0000 - accuracy: 0.6863 - precision: 0.3430 - recall: 0.6508 - auc: 0.7411 - prc: 0.4530 - val_loss: 0.6476 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.7052 - val_prc: 0.3896\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9966 - tp: 260.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 138.0000 - accuracy: 0.6803 - precision: 0.3381 - recall: 0.6533 - auc: 0.7427 - prc: 0.4673 - val_loss: 0.6597 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.7003 - val_prc: 0.3714\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9978 - tp: 263.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 135.0000 - accuracy: 0.6828 - precision: 0.3416 - recall: 0.6608 - auc: 0.7415 - prc: 0.4514 - val_loss: 0.6316 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.6992 - val_prc: 0.3911\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9972 - tp: 262.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 136.0000 - accuracy: 0.6897 - precision: 0.3475 - recall: 0.6583 - auc: 0.7412 - prc: 0.4592 - val_loss: 0.6626 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.7001 - val_prc: 0.3774\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9938 - tp: 258.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 140.0000 - accuracy: 0.6877 - precision: 0.3440 - recall: 0.6482 - auc: 0.7449 - prc: 0.4617 - val_loss: 0.6187 - val_tp: 54.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 37.0000 - val_accuracy: 0.6877 - val_precision: 0.3086 - val_recall: 0.5934 - val_auc: 0.7016 - val_prc: 0.3841\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9930 - tp: 266.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 132.0000 - accuracy: 0.6808 - precision: 0.3410 - recall: 0.6683 - auc: 0.7455 - prc: 0.4536 - val_loss: 0.5797 - val_tp: 49.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 42.0000 - val_accuracy: 0.7451 - val_precision: 0.3603 - val_recall: 0.5385 - val_auc: 0.6992 - val_prc: 0.3812\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9946 - tp: 263.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 135.0000 - accuracy: 0.6971 - precision: 0.3549 - recall: 0.6608 - auc: 0.7437 - prc: 0.4687 - val_loss: 0.6258 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6990 - val_prc: 0.3879\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9929 - tp: 268.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 130.0000 - accuracy: 0.6932 - precision: 0.3531 - recall: 0.6734 - auc: 0.7451 - prc: 0.4576 - val_loss: 0.5908 - val_tp: 50.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 41.0000 - val_accuracy: 0.7332 - val_precision: 0.3472 - val_recall: 0.5495 - val_auc: 0.6992 - val_prc: 0.3830\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9932 - tp: 265.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 133.0000 - accuracy: 0.6848 - precision: 0.3442 - recall: 0.6658 - auc: 0.7457 - prc: 0.4601 - val_loss: 0.6215 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.7047 - val_prc: 0.3870\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9929 - tp: 258.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 140.0000 - accuracy: 0.7110 - precision: 0.3670 - recall: 0.6482 - auc: 0.7460 - prc: 0.4577 - val_loss: 0.7344 - val_tp: 69.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 22.0000 - val_accuracy: 0.5494 - val_precision: 0.2509 - val_recall: 0.7582 - val_auc: 0.7019 - val_prc: 0.3793\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9944 - tp: 270.0000 - fp: 561.0000 - tn: 1065.0000 - fn: 128.0000 - accuracy: 0.6596 - precision: 0.3249 - recall: 0.6784 - auc: 0.7452 - prc: 0.4487 - val_loss: 0.5959 - val_tp: 50.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 41.0000 - val_accuracy: 0.7253 - val_precision: 0.3378 - val_recall: 0.5495 - val_auc: 0.7003 - val_prc: 0.3894\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9967 - tp: 261.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 137.0000 - accuracy: 0.7080 - precision: 0.3650 - recall: 0.6558 - auc: 0.7423 - prc: 0.4608 - val_loss: 0.6608 - val_tp: 56.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 35.0000 - val_accuracy: 0.6304 - val_precision: 0.2692 - val_recall: 0.6154 - val_auc: 0.6974 - val_prc: 0.3822\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9972 - tp: 259.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 139.0000 - accuracy: 0.6749 - precision: 0.3329 - recall: 0.6508 - auc: 0.7409 - prc: 0.4487 - val_loss: 0.5898 - val_tp: 50.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 41.0000 - val_accuracy: 0.7332 - val_precision: 0.3472 - val_recall: 0.5495 - val_auc: 0.7016 - val_prc: 0.3820\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9977 - tp: 255.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 143.0000 - accuracy: 0.7031 - precision: 0.3576 - recall: 0.6407 - auc: 0.7414 - prc: 0.4586 - val_loss: 0.6882 - val_tp: 61.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 30.0000 - val_accuracy: 0.5949 - val_precision: 0.2585 - val_recall: 0.6703 - val_auc: 0.6989 - val_prc: 0.3812\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9970 - tp: 262.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 136.0000 - accuracy: 0.6808 - precision: 0.3394 - recall: 0.6583 - auc: 0.7424 - prc: 0.4587 - val_loss: 0.6410 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.6984 - val_prc: 0.3845\n",
      "Epoch 232/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9932 - tp: 266.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 132.0000 - accuracy: 0.6823 - precision: 0.3423 - recall: 0.6683 - auc: 0.7446 - prc: 0.4603 - val_loss: 0.5794 - val_tp: 49.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 42.0000 - val_accuracy: 0.7431 - val_precision: 0.3577 - val_recall: 0.5385 - val_auc: 0.7020 - val_prc: 0.3879\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9922 - tp: 257.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 141.0000 - accuracy: 0.7036 - precision: 0.3589 - recall: 0.6457 - auc: 0.7460 - prc: 0.4638 - val_loss: 0.6460 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6992 - val_prc: 0.3786\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9920 - tp: 264.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 134.0000 - accuracy: 0.6927 - precision: 0.3511 - recall: 0.6633 - auc: 0.7451 - prc: 0.4651 - val_loss: 0.5796 - val_tp: 49.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 42.0000 - val_accuracy: 0.7391 - val_precision: 0.3525 - val_recall: 0.5385 - val_auc: 0.7019 - val_prc: 0.3917\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9915 - tp: 261.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 137.0000 - accuracy: 0.6858 - precision: 0.3434 - recall: 0.6558 - auc: 0.7460 - prc: 0.4631 - val_loss: 0.5429 - val_tp: 44.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 47.0000 - val_accuracy: 0.7747 - val_precision: 0.3964 - val_recall: 0.4835 - val_auc: 0.6995 - val_prc: 0.3941\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9932 - tp: 249.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 149.0000 - accuracy: 0.6976 - precision: 0.3497 - recall: 0.6256 - auc: 0.7451 - prc: 0.4600 - val_loss: 0.6341 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.7002 - val_prc: 0.3851\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9909 - tp: 256.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 142.0000 - accuracy: 0.6927 - precision: 0.3478 - recall: 0.6432 - auc: 0.7472 - prc: 0.4662 - val_loss: 0.6044 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6972 - val_prc: 0.3826\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9932 - tp: 258.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 140.0000 - accuracy: 0.6848 - precision: 0.3413 - recall: 0.6482 - auc: 0.7452 - prc: 0.4687 - val_loss: 0.6042 - val_tp: 51.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 40.0000 - val_accuracy: 0.7134 - val_precision: 0.3269 - val_recall: 0.5604 - val_auc: 0.6992 - val_prc: 0.3807\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9925 - tp: 261.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 137.0000 - accuracy: 0.7011 - precision: 0.3580 - recall: 0.6558 - auc: 0.7452 - prc: 0.4679 - val_loss: 0.6140 - val_tp: 52.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 39.0000 - val_accuracy: 0.6937 - val_precision: 0.3095 - val_recall: 0.5714 - val_auc: 0.7000 - val_prc: 0.3802\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9984 - tp: 262.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 136.0000 - accuracy: 0.6882 - precision: 0.3461 - recall: 0.6583 - auc: 0.7400 - prc: 0.4501 - val_loss: 0.6415 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6986 - val_prc: 0.3834\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9913 - tp: 260.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 138.0000 - accuracy: 0.6971 - precision: 0.3537 - recall: 0.6533 - auc: 0.7454 - prc: 0.4636 - val_loss: 0.6580 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.7027 - val_prc: 0.3876\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9917 - tp: 268.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 130.0000 - accuracy: 0.6868 - precision: 0.3472 - recall: 0.6734 - auc: 0.7472 - prc: 0.4639 - val_loss: 0.6119 - val_tp: 51.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 40.0000 - val_accuracy: 0.7055 - val_precision: 0.3187 - val_recall: 0.5604 - val_auc: 0.6967 - val_prc: 0.3734\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9893 - tp: 255.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 143.0000 - accuracy: 0.7050 - precision: 0.3597 - recall: 0.6407 - auc: 0.7469 - prc: 0.4648 - val_loss: 0.6988 - val_tp: 63.0000 - val_fp: 182.0000 - val_tn: 233.0000 - val_fn: 28.0000 - val_accuracy: 0.5850 - val_precision: 0.2571 - val_recall: 0.6923 - val_auc: 0.7002 - val_prc: 0.3804\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9931 - tp: 263.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 135.0000 - accuracy: 0.6769 - precision: 0.3363 - recall: 0.6608 - auc: 0.7460 - prc: 0.4557 - val_loss: 0.6357 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.7000 - val_prc: 0.3924\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9915 - tp: 259.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 139.0000 - accuracy: 0.6986 - precision: 0.3548 - recall: 0.6508 - auc: 0.7464 - prc: 0.4653 - val_loss: 0.6325 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6956 - val_prc: 0.3875\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9916 - tp: 262.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 136.0000 - accuracy: 0.6838 - precision: 0.3420 - recall: 0.6583 - auc: 0.7457 - prc: 0.4648 - val_loss: 0.5875 - val_tp: 49.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 42.0000 - val_accuracy: 0.7352 - val_precision: 0.3475 - val_recall: 0.5385 - val_auc: 0.7015 - val_prc: 0.3937\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9937 - tp: 259.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 139.0000 - accuracy: 0.6932 - precision: 0.3495 - recall: 0.6508 - auc: 0.7434 - prc: 0.4602 - val_loss: 0.6326 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.7022 - val_prc: 0.3867\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9937 - tp: 259.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 139.0000 - accuracy: 0.6981 - precision: 0.3543 - recall: 0.6508 - auc: 0.7444 - prc: 0.4666 - val_loss: 0.6654 - val_tp: 58.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 33.0000 - val_accuracy: 0.6285 - val_precision: 0.2723 - val_recall: 0.6374 - val_auc: 0.7011 - val_prc: 0.3800\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9992 - tp: 251.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 147.0000 - accuracy: 0.6808 - precision: 0.3347 - recall: 0.6307 - auc: 0.7407 - prc: 0.4567 - val_loss: 0.5978 - val_tp: 51.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 40.0000 - val_accuracy: 0.7233 - val_precision: 0.3377 - val_recall: 0.5604 - val_auc: 0.7020 - val_prc: 0.3931\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9868 - tp: 263.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 135.0000 - accuracy: 0.6887 - precision: 0.3470 - recall: 0.6608 - auc: 0.7479 - prc: 0.4735 - val_loss: 0.5533 - val_tp: 44.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 47.0000 - val_accuracy: 0.7589 - val_precision: 0.3697 - val_recall: 0.4835 - val_auc: 0.6996 - val_prc: 0.3895\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9915 - tp: 243.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 155.0000 - accuracy: 0.7085 - precision: 0.3584 - recall: 0.6106 - auc: 0.7463 - prc: 0.4689 - val_loss: 0.6961 - val_tp: 61.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 30.0000 - val_accuracy: 0.5889 - val_precision: 0.2552 - val_recall: 0.6703 - val_auc: 0.7018 - val_prc: 0.3773\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9895 - tp: 267.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 131.0000 - accuracy: 0.6877 - precision: 0.3477 - recall: 0.6709 - auc: 0.7470 - prc: 0.4705 - val_loss: 0.6163 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6992 - val_prc: 0.3851\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9926 - tp: 257.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 141.0000 - accuracy: 0.7090 - precision: 0.3645 - recall: 0.6457 - auc: 0.7443 - prc: 0.4697 - val_loss: 0.6515 - val_tp: 56.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 35.0000 - val_accuracy: 0.6423 - val_precision: 0.2772 - val_recall: 0.6154 - val_auc: 0.6998 - val_prc: 0.3808\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9922 - tp: 268.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 130.0000 - accuracy: 0.6912 - precision: 0.3512 - recall: 0.6734 - auc: 0.7464 - prc: 0.4650 - val_loss: 0.6105 - val_tp: 51.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 40.0000 - val_accuracy: 0.7036 - val_precision: 0.3168 - val_recall: 0.5604 - val_auc: 0.7018 - val_prc: 0.3914\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9948 - tp: 260.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 138.0000 - accuracy: 0.6734 - precision: 0.3321 - recall: 0.6533 - auc: 0.7413 - prc: 0.4646 - val_loss: 0.6557 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6999 - val_prc: 0.3846\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9887 - tp: 261.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 137.0000 - accuracy: 0.6863 - precision: 0.3439 - recall: 0.6558 - auc: 0.7474 - prc: 0.4692 - val_loss: 0.5845 - val_tp: 49.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 42.0000 - val_accuracy: 0.7332 - val_precision: 0.3451 - val_recall: 0.5385 - val_auc: 0.7010 - val_prc: 0.3954\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9896 - tp: 255.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 143.0000 - accuracy: 0.7125 - precision: 0.3674 - recall: 0.6407 - auc: 0.7481 - prc: 0.4625 - val_loss: 0.6928 - val_tp: 62.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 29.0000 - val_accuracy: 0.5929 - val_precision: 0.2594 - val_recall: 0.6813 - val_auc: 0.7019 - val_prc: 0.3754\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9941 - tp: 269.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 129.0000 - accuracy: 0.6789 - precision: 0.3405 - recall: 0.6759 - auc: 0.7430 - prc: 0.4665 - val_loss: 0.5976 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.7014 - val_prc: 0.3903\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9904 - tp: 260.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 138.0000 - accuracy: 0.6858 - precision: 0.3430 - recall: 0.6533 - auc: 0.7462 - prc: 0.4717 - val_loss: 0.6185 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6969 - val_prc: 0.3911\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9908 - tp: 258.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 140.0000 - accuracy: 0.6957 - precision: 0.3515 - recall: 0.6482 - auc: 0.7458 - prc: 0.4610 - val_loss: 0.6283 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6999 - val_prc: 0.3928\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9889 - tp: 259.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 139.0000 - accuracy: 0.7090 - precision: 0.3653 - recall: 0.6508 - auc: 0.7487 - prc: 0.4522 - val_loss: 0.6353 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6971 - val_prc: 0.3805\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9888 - tp: 267.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 131.0000 - accuracy: 0.6714 - precision: 0.3333 - recall: 0.6709 - auc: 0.7479 - prc: 0.4630 - val_loss: 0.6124 - val_tp: 51.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 40.0000 - val_accuracy: 0.7036 - val_precision: 0.3168 - val_recall: 0.5604 - val_auc: 0.6999 - val_prc: 0.3942\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9890 - tp: 260.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 138.0000 - accuracy: 0.7050 - precision: 0.3616 - recall: 0.6533 - auc: 0.7484 - prc: 0.4726 - val_loss: 0.6344 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.7007 - val_prc: 0.3922\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9916 - tp: 264.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 134.0000 - accuracy: 0.6838 - precision: 0.3429 - recall: 0.6633 - auc: 0.7440 - prc: 0.4603 - val_loss: 0.6170 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.7002 - val_prc: 0.3875\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9894 - tp: 257.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 141.0000 - accuracy: 0.6981 - precision: 0.3535 - recall: 0.6457 - auc: 0.7470 - prc: 0.4681 - val_loss: 0.6681 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6995 - val_prc: 0.3847\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9886 - tp: 259.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 139.0000 - accuracy: 0.6843 - precision: 0.3412 - recall: 0.6508 - auc: 0.7470 - prc: 0.4672 - val_loss: 0.6335 - val_tp: 55.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 36.0000 - val_accuracy: 0.6779 - val_precision: 0.3022 - val_recall: 0.6044 - val_auc: 0.7049 - val_prc: 0.3885\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9916 - tp: 253.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 145.0000 - accuracy: 0.7055 - precision: 0.3594 - recall: 0.6357 - auc: 0.7470 - prc: 0.4657 - val_loss: 0.6320 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6971 - val_prc: 0.3916\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9894 - tp: 261.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 137.0000 - accuracy: 0.6848 - precision: 0.3425 - recall: 0.6558 - auc: 0.7465 - prc: 0.4666 - val_loss: 0.6305 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6999 - val_prc: 0.3905\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9888 - tp: 260.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 138.0000 - accuracy: 0.6897 - precision: 0.3467 - recall: 0.6533 - auc: 0.7467 - prc: 0.4665 - val_loss: 0.6280 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6995 - val_prc: 0.3833\n",
      "Epoch 270/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9897 - tp: 254.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 144.0000 - accuracy: 0.7060 - precision: 0.3603 - recall: 0.6382 - auc: 0.7460 - prc: 0.4793 - val_loss: 0.6607 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6990 - val_prc: 0.3781\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9898 - tp: 263.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 135.0000 - accuracy: 0.6892 - precision: 0.3474 - recall: 0.6608 - auc: 0.7463 - prc: 0.4676 - val_loss: 0.6008 - val_tp: 51.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 40.0000 - val_accuracy: 0.7213 - val_precision: 0.3355 - val_recall: 0.5604 - val_auc: 0.7007 - val_prc: 0.3849\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9895 - tp: 255.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 143.0000 - accuracy: 0.7065 - precision: 0.3612 - recall: 0.6407 - auc: 0.7475 - prc: 0.4639 - val_loss: 0.6949 - val_tp: 60.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 31.0000 - val_accuracy: 0.5929 - val_precision: 0.2553 - val_recall: 0.6593 - val_auc: 0.6967 - val_prc: 0.3821\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9897 - tp: 262.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 136.0000 - accuracy: 0.6897 - precision: 0.3475 - recall: 0.6583 - auc: 0.7460 - prc: 0.4700 - val_loss: 0.6351 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.7028 - val_prc: 0.3888\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9893 - tp: 273.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 125.0000 - accuracy: 0.6818 - precision: 0.3447 - recall: 0.6859 - auc: 0.7464 - prc: 0.4682 - val_loss: 0.6009 - val_tp: 51.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 40.0000 - val_accuracy: 0.7194 - val_precision: 0.3333 - val_recall: 0.5604 - val_auc: 0.7020 - val_prc: 0.3811\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9888 - tp: 264.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 134.0000 - accuracy: 0.6823 - precision: 0.3415 - recall: 0.6633 - auc: 0.7477 - prc: 0.4624 - val_loss: 0.5906 - val_tp: 51.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 40.0000 - val_accuracy: 0.7372 - val_precision: 0.3542 - val_recall: 0.5604 - val_auc: 0.6960 - val_prc: 0.3789\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9952 - tp: 251.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 147.0000 - accuracy: 0.7036 - precision: 0.3565 - recall: 0.6307 - auc: 0.7426 - prc: 0.4583 - val_loss: 0.6285 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6998 - val_prc: 0.3878\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9878 - tp: 263.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 135.0000 - accuracy: 0.7041 - precision: 0.3618 - recall: 0.6608 - auc: 0.7495 - prc: 0.4679 - val_loss: 0.6618 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.7014 - val_prc: 0.3868\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9905 - tp: 256.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 142.0000 - accuracy: 0.7065 - precision: 0.3616 - recall: 0.6432 - auc: 0.7467 - prc: 0.4674 - val_loss: 0.6740 - val_tp: 59.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 32.0000 - val_accuracy: 0.6186 - val_precision: 0.2682 - val_recall: 0.6484 - val_auc: 0.7021 - val_prc: 0.3806\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9916 - tp: 266.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 132.0000 - accuracy: 0.6705 - precision: 0.3321 - recall: 0.6683 - auc: 0.7456 - prc: 0.4668 - val_loss: 0.6022 - val_tp: 51.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 40.0000 - val_accuracy: 0.7213 - val_precision: 0.3355 - val_recall: 0.5604 - val_auc: 0.6982 - val_prc: 0.3935\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9882 - tp: 258.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 140.0000 - accuracy: 0.6937 - precision: 0.3496 - recall: 0.6482 - auc: 0.7460 - prc: 0.4684 - val_loss: 0.6170 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.7006 - val_prc: 0.3846\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9867 - tp: 258.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 140.0000 - accuracy: 0.6986 - precision: 0.3544 - recall: 0.6482 - auc: 0.7492 - prc: 0.4681 - val_loss: 0.5874 - val_tp: 50.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 41.0000 - val_accuracy: 0.7372 - val_precision: 0.3521 - val_recall: 0.5495 - val_auc: 0.6994 - val_prc: 0.3826\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9895 - tp: 262.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 136.0000 - accuracy: 0.7031 - precision: 0.3604 - recall: 0.6583 - auc: 0.7476 - prc: 0.4710 - val_loss: 0.5980 - val_tp: 51.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 40.0000 - val_accuracy: 0.7253 - val_precision: 0.3400 - val_recall: 0.5604 - val_auc: 0.6992 - val_prc: 0.3945\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9868 - tp: 257.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 141.0000 - accuracy: 0.7120 - precision: 0.3677 - recall: 0.6457 - auc: 0.7502 - prc: 0.4703 - val_loss: 0.6758 - val_tp: 59.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 32.0000 - val_accuracy: 0.6166 - val_precision: 0.2670 - val_recall: 0.6484 - val_auc: 0.7014 - val_prc: 0.3801\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9902 - tp: 265.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 133.0000 - accuracy: 0.6779 - precision: 0.3380 - recall: 0.6658 - auc: 0.7477 - prc: 0.4627 - val_loss: 0.5895 - val_tp: 49.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 42.0000 - val_accuracy: 0.7332 - val_precision: 0.3451 - val_recall: 0.5385 - val_auc: 0.6985 - val_prc: 0.3946\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9953 - tp: 256.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 142.0000 - accuracy: 0.7065 - precision: 0.3616 - recall: 0.6432 - auc: 0.7440 - prc: 0.4655 - val_loss: 0.6479 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.7009 - val_prc: 0.3861\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9858 - tp: 266.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 132.0000 - accuracy: 0.6897 - precision: 0.3491 - recall: 0.6683 - auc: 0.7488 - prc: 0.4720 - val_loss: 0.5642 - val_tp: 47.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 44.0000 - val_accuracy: 0.7530 - val_precision: 0.3672 - val_recall: 0.5165 - val_auc: 0.7002 - val_prc: 0.3894\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9898 - tp: 254.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 144.0000 - accuracy: 0.6961 - precision: 0.3503 - recall: 0.6382 - auc: 0.7463 - prc: 0.4675 - val_loss: 0.6387 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.7022 - val_prc: 0.3916\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9891 - tp: 266.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 132.0000 - accuracy: 0.6828 - precision: 0.3428 - recall: 0.6683 - auc: 0.7470 - prc: 0.4619 - val_loss: 0.5577 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6995 - val_prc: 0.3890\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9874 - tp: 262.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 136.0000 - accuracy: 0.6966 - precision: 0.3541 - recall: 0.6583 - auc: 0.7479 - prc: 0.4656 - val_loss: 0.6183 - val_tp: 53.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 38.0000 - val_accuracy: 0.6957 - val_precision: 0.3136 - val_recall: 0.5824 - val_auc: 0.7021 - val_prc: 0.3874\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9901 - tp: 254.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 144.0000 - accuracy: 0.6966 - precision: 0.3508 - recall: 0.6382 - auc: 0.7464 - prc: 0.4686 - val_loss: 0.6268 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.7001 - val_prc: 0.3960\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9869 - tp: 263.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 135.0000 - accuracy: 0.7021 - precision: 0.3598 - recall: 0.6608 - auc: 0.7490 - prc: 0.4722 - val_loss: 0.6764 - val_tp: 60.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 31.0000 - val_accuracy: 0.6166 - val_precision: 0.2691 - val_recall: 0.6593 - val_auc: 0.7009 - val_prc: 0.3845\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9927 - tp: 267.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 131.0000 - accuracy: 0.6828 - precision: 0.3432 - recall: 0.6709 - auc: 0.7448 - prc: 0.4605 - val_loss: 0.5735 - val_tp: 46.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 45.0000 - val_accuracy: 0.7451 - val_precision: 0.3538 - val_recall: 0.5055 - val_auc: 0.7008 - val_prc: 0.3887\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9880 - tp: 254.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 144.0000 - accuracy: 0.6971 - precision: 0.3513 - recall: 0.6382 - auc: 0.7477 - prc: 0.4682 - val_loss: 0.6503 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.7011 - val_prc: 0.3867\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9881 - tp: 259.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 139.0000 - accuracy: 0.7011 - precision: 0.3572 - recall: 0.6508 - auc: 0.7491 - prc: 0.4694 - val_loss: 0.6242 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6972 - val_prc: 0.3826\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9910 - tp: 264.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 134.0000 - accuracy: 0.6942 - precision: 0.3525 - recall: 0.6633 - auc: 0.7462 - prc: 0.4675 - val_loss: 0.6499 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.7006 - val_prc: 0.3873\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9865 - tp: 257.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 141.0000 - accuracy: 0.6981 - precision: 0.3535 - recall: 0.6457 - auc: 0.7473 - prc: 0.4674 - val_loss: 0.6522 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6995 - val_prc: 0.3899\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9925 - tp: 262.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 136.0000 - accuracy: 0.6947 - precision: 0.3522 - recall: 0.6583 - auc: 0.7452 - prc: 0.4679 - val_loss: 0.6736 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.7009 - val_prc: 0.3903\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9873 - tp: 263.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 135.0000 - accuracy: 0.6952 - precision: 0.3530 - recall: 0.6608 - auc: 0.7482 - prc: 0.4694 - val_loss: 0.6551 - val_tp: 55.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 36.0000 - val_accuracy: 0.6423 - val_precision: 0.2750 - val_recall: 0.6044 - val_auc: 0.7026 - val_prc: 0.3855\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9859 - tp: 256.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 142.0000 - accuracy: 0.7070 - precision: 0.3621 - recall: 0.6432 - auc: 0.7499 - prc: 0.4707 - val_loss: 0.6446 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6999 - val_prc: 0.3764\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9832 - tp: 268.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 130.0000 - accuracy: 0.6882 - precision: 0.3485 - recall: 0.6734 - auc: 0.7524 - prc: 0.4667 - val_loss: 0.5839 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.7025 - val_prc: 0.3831\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9888 - tp: 262.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 136.0000 - accuracy: 0.6927 - precision: 0.3503 - recall: 0.6583 - auc: 0.7474 - prc: 0.4637 - val_loss: 0.5893 - val_tp: 50.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 41.0000 - val_accuracy: 0.7273 - val_precision: 0.3401 - val_recall: 0.5495 - val_auc: 0.7000 - val_prc: 0.3928\n",
      "Epoch 302/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9868 - tp: 255.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 143.0000 - accuracy: 0.7016 - precision: 0.3561 - recall: 0.6407 - auc: 0.7485 - prc: 0.4666 - val_loss: 0.6265 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.7009 - val_prc: 0.3923\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9840 - tp: 262.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 136.0000 - accuracy: 0.6927 - precision: 0.3503 - recall: 0.6583 - auc: 0.7503 - prc: 0.4691 - val_loss: 0.6327 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6991 - val_prc: 0.3915\n",
      "Epoch 304/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9893 - tp: 257.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 141.0000 - accuracy: 0.6927 - precision: 0.3482 - recall: 0.6457 - auc: 0.7460 - prc: 0.4676 - val_loss: 0.6089 - val_tp: 53.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 38.0000 - val_accuracy: 0.7036 - val_precision: 0.3212 - val_recall: 0.5824 - val_auc: 0.7016 - val_prc: 0.3854\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9861 - tp: 264.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 134.0000 - accuracy: 0.6907 - precision: 0.3492 - recall: 0.6633 - auc: 0.7509 - prc: 0.4682 - val_loss: 0.6358 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6976 - val_prc: 0.3886\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9872 - tp: 263.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 135.0000 - accuracy: 0.6981 - precision: 0.3559 - recall: 0.6608 - auc: 0.7477 - prc: 0.4627 - val_loss: 0.6118 - val_tp: 51.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 40.0000 - val_accuracy: 0.7036 - val_precision: 0.3168 - val_recall: 0.5604 - val_auc: 0.6990 - val_prc: 0.3900\n",
      "Epoch 307/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9908 - tp: 258.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 140.0000 - accuracy: 0.6952 - precision: 0.3510 - recall: 0.6482 - auc: 0.7468 - prc: 0.4646 - val_loss: 0.6308 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.7011 - val_prc: 0.3838\n",
      "Epoch 308/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9894 - tp: 253.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 145.0000 - accuracy: 0.6996 - precision: 0.3534 - recall: 0.6357 - auc: 0.7467 - prc: 0.4736 - val_loss: 0.7058 - val_tp: 62.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 29.0000 - val_accuracy: 0.5791 - val_precision: 0.2520 - val_recall: 0.6813 - val_auc: 0.6945 - val_prc: 0.3772\n",
      "Epoch 309/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9871 - tp: 270.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 128.0000 - accuracy: 0.6942 - precision: 0.3548 - recall: 0.6784 - auc: 0.7492 - prc: 0.4658 - val_loss: 0.6691 - val_tp: 57.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 34.0000 - val_accuracy: 0.6166 - val_precision: 0.2627 - val_recall: 0.6264 - val_auc: 0.6958 - val_prc: 0.3882\n",
      "Epoch 310/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9948 - tp: 259.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 139.0000 - accuracy: 0.6734 - precision: 0.3316 - recall: 0.6508 - auc: 0.7418 - prc: 0.4633 - val_loss: 0.5558 - val_tp: 44.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 47.0000 - val_accuracy: 0.7549 - val_precision: 0.3636 - val_recall: 0.4835 - val_auc: 0.6981 - val_prc: 0.3894\n",
      "Epoch 311/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9873 - tp: 259.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 139.0000 - accuracy: 0.7006 - precision: 0.3567 - recall: 0.6508 - auc: 0.7483 - prc: 0.4775 - val_loss: 0.6781 - val_tp: 58.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 33.0000 - val_accuracy: 0.5968 - val_precision: 0.2533 - val_recall: 0.6374 - val_auc: 0.6953 - val_prc: 0.3786\n",
      "Epoch 312/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9844 - tp: 268.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 130.0000 - accuracy: 0.6838 - precision: 0.3445 - recall: 0.6734 - auc: 0.7517 - prc: 0.4729 - val_loss: 0.5666 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6978 - val_prc: 0.3922\n",
      "Epoch 313/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9876 - tp: 256.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 142.0000 - accuracy: 0.7041 - precision: 0.3590 - recall: 0.6432 - auc: 0.7484 - prc: 0.4720 - val_loss: 0.6098 - val_tp: 52.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 39.0000 - val_accuracy: 0.7016 - val_precision: 0.3171 - val_recall: 0.5714 - val_auc: 0.7022 - val_prc: 0.3904\n",
      "Epoch 314/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9849 - tp: 267.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 131.0000 - accuracy: 0.6996 - precision: 0.3589 - recall: 0.6709 - auc: 0.7492 - prc: 0.4716 - val_loss: 0.6272 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6997 - val_prc: 0.3951\n",
      "Epoch 315/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9873 - tp: 268.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 130.0000 - accuracy: 0.6793 - precision: 0.3405 - recall: 0.6734 - auc: 0.7482 - prc: 0.4730 - val_loss: 0.5962 - val_tp: 50.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 41.0000 - val_accuracy: 0.7213 - val_precision: 0.3333 - val_recall: 0.5495 - val_auc: 0.7019 - val_prc: 0.3776\n",
      "Epoch 316/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9844 - tp: 253.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 145.0000 - accuracy: 0.7021 - precision: 0.3558 - recall: 0.6357 - auc: 0.7503 - prc: 0.4718 - val_loss: 0.6460 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6994 - val_prc: 0.3917\n",
      "Epoch 317/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9893 - tp: 262.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 136.0000 - accuracy: 0.6912 - precision: 0.3489 - recall: 0.6583 - auc: 0.7458 - prc: 0.4660 - val_loss: 0.6580 - val_tp: 55.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 36.0000 - val_accuracy: 0.6364 - val_precision: 0.2709 - val_recall: 0.6044 - val_auc: 0.6960 - val_prc: 0.3848\n",
      "Epoch 318/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9888 - tp: 264.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 134.0000 - accuracy: 0.6863 - precision: 0.3451 - recall: 0.6633 - auc: 0.7473 - prc: 0.4665 - val_loss: 0.6703 - val_tp: 58.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 33.0000 - val_accuracy: 0.6107 - val_precision: 0.2613 - val_recall: 0.6374 - val_auc: 0.6991 - val_prc: 0.3892\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9860 - tp: 259.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 139.0000 - accuracy: 0.6971 - precision: 0.3533 - recall: 0.6508 - auc: 0.7488 - prc: 0.4703 - val_loss: 0.6683 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6996 - val_prc: 0.3888\n",
      "Epoch 320/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9899 - tp: 259.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 139.0000 - accuracy: 0.6873 - precision: 0.3440 - recall: 0.6508 - auc: 0.7456 - prc: 0.4686 - val_loss: 0.6780 - val_tp: 58.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 33.0000 - val_accuracy: 0.6067 - val_precision: 0.2589 - val_recall: 0.6374 - val_auc: 0.6969 - val_prc: 0.3848\n",
      "Epoch 321/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9868 - tp: 261.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 137.0000 - accuracy: 0.6917 - precision: 0.3489 - recall: 0.6558 - auc: 0.7485 - prc: 0.4706 - val_loss: 0.6147 - val_tp: 52.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 39.0000 - val_accuracy: 0.6957 - val_precision: 0.3114 - val_recall: 0.5714 - val_auc: 0.7023 - val_prc: 0.3863\n",
      "Epoch 322/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9842 - tp: 247.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 151.0000 - accuracy: 0.7055 - precision: 0.3569 - recall: 0.6206 - auc: 0.7495 - prc: 0.4743 - val_loss: 0.6724 - val_tp: 59.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 32.0000 - val_accuracy: 0.6166 - val_precision: 0.2670 - val_recall: 0.6484 - val_auc: 0.7008 - val_prc: 0.3873\n",
      "Epoch 323/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9882 - tp: 257.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 141.0000 - accuracy: 0.6853 - precision: 0.3413 - recall: 0.6457 - auc: 0.7474 - prc: 0.4658 - val_loss: 0.6520 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6993 - val_prc: 0.3811\n",
      "Epoch 324/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9870 - tp: 262.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 136.0000 - accuracy: 0.6917 - precision: 0.3493 - recall: 0.6583 - auc: 0.7483 - prc: 0.4725 - val_loss: 0.5915 - val_tp: 49.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 42.0000 - val_accuracy: 0.7332 - val_precision: 0.3451 - val_recall: 0.5385 - val_auc: 0.7016 - val_prc: 0.3860\n",
      "Epoch 325/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9832 - tp: 254.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 144.0000 - accuracy: 0.7011 - precision: 0.3552 - recall: 0.6382 - auc: 0.7505 - prc: 0.4833 - val_loss: 0.5936 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.7007 - val_prc: 0.3855\n",
      "Epoch 326/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9869 - tp: 267.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 131.0000 - accuracy: 0.6907 - precision: 0.3504 - recall: 0.6709 - auc: 0.7486 - prc: 0.4716 - val_loss: 0.6324 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6978 - val_prc: 0.3928\n",
      "Epoch 327/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9895 - tp: 265.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 133.0000 - accuracy: 0.6887 - precision: 0.3478 - recall: 0.6658 - auc: 0.7473 - prc: 0.4667 - val_loss: 0.6005 - val_tp: 51.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 40.0000 - val_accuracy: 0.7174 - val_precision: 0.3312 - val_recall: 0.5604 - val_auc: 0.6990 - val_prc: 0.3828\n",
      "Epoch 328/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9847 - tp: 261.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 137.0000 - accuracy: 0.7075 - precision: 0.3645 - recall: 0.6558 - auc: 0.7497 - prc: 0.4729 - val_loss: 0.6412 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6960 - val_prc: 0.3777\n",
      "Epoch 329/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9857 - tp: 256.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 142.0000 - accuracy: 0.6996 - precision: 0.3546 - recall: 0.6432 - auc: 0.7482 - prc: 0.4612 - val_loss: 0.6783 - val_tp: 60.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 31.0000 - val_accuracy: 0.6186 - val_precision: 0.2703 - val_recall: 0.6593 - val_auc: 0.6998 - val_prc: 0.3892\n",
      "Epoch 330/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9827 - tp: 265.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 133.0000 - accuracy: 0.6863 - precision: 0.3455 - recall: 0.6658 - auc: 0.7517 - prc: 0.4762 - val_loss: 0.6109 - val_tp: 51.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 40.0000 - val_accuracy: 0.7055 - val_precision: 0.3187 - val_recall: 0.5604 - val_auc: 0.7000 - val_prc: 0.3881\n",
      "Epoch 331/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9819 - tp: 262.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 136.0000 - accuracy: 0.6986 - precision: 0.3560 - recall: 0.6583 - auc: 0.7528 - prc: 0.4800 - val_loss: 0.5717 - val_tp: 47.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 44.0000 - val_accuracy: 0.7470 - val_precision: 0.3588 - val_recall: 0.5165 - val_auc: 0.6959 - val_prc: 0.3870\n",
      "Epoch 332/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9866 - tp: 256.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 142.0000 - accuracy: 0.7075 - precision: 0.3626 - recall: 0.6432 - auc: 0.7482 - prc: 0.4701 - val_loss: 0.6577 - val_tp: 55.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 36.0000 - val_accuracy: 0.6265 - val_precision: 0.2644 - val_recall: 0.6044 - val_auc: 0.6987 - val_prc: 0.3829\n",
      "Epoch 333/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9861 - tp: 260.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 138.0000 - accuracy: 0.6853 - precision: 0.3426 - recall: 0.6533 - auc: 0.7478 - prc: 0.4714 - val_loss: 0.5882 - val_tp: 50.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 41.0000 - val_accuracy: 0.7332 - val_precision: 0.3472 - val_recall: 0.5495 - val_auc: 0.6972 - val_prc: 0.3779\n",
      "Epoch 334/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9834 - tp: 262.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 136.0000 - accuracy: 0.7070 - precision: 0.3644 - recall: 0.6583 - auc: 0.7499 - prc: 0.4762 - val_loss: 0.6127 - val_tp: 52.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 39.0000 - val_accuracy: 0.7055 - val_precision: 0.3210 - val_recall: 0.5714 - val_auc: 0.7026 - val_prc: 0.3817\n",
      "Epoch 335/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9829 - tp: 261.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 137.0000 - accuracy: 0.7016 - precision: 0.3585 - recall: 0.6558 - auc: 0.7515 - prc: 0.4708 - val_loss: 0.6485 - val_tp: 54.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 37.0000 - val_accuracy: 0.6502 - val_precision: 0.2784 - val_recall: 0.5934 - val_auc: 0.6979 - val_prc: 0.3817\n",
      "Epoch 336/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9878 - tp: 269.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 129.0000 - accuracy: 0.6769 - precision: 0.3388 - recall: 0.6759 - auc: 0.7483 - prc: 0.4662 - val_loss: 0.6575 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6988 - val_prc: 0.3776\n",
      "Epoch 337/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9832 - tp: 259.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 139.0000 - accuracy: 0.7105 - precision: 0.3669 - recall: 0.6508 - auc: 0.7516 - prc: 0.4755 - val_loss: 0.6213 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6973 - val_prc: 0.3912\n",
      "Epoch 338/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9819 - tp: 258.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 140.0000 - accuracy: 0.7065 - precision: 0.3624 - recall: 0.6482 - auc: 0.7514 - prc: 0.4803 - val_loss: 0.6392 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.7003 - val_prc: 0.3754\n",
      "Epoch 339/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9872 - tp: 267.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 131.0000 - accuracy: 0.6833 - precision: 0.3436 - recall: 0.6709 - auc: 0.7469 - prc: 0.4747 - val_loss: 0.6335 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.7000 - val_prc: 0.3985\n",
      "Epoch 340/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9869 - tp: 260.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 138.0000 - accuracy: 0.6813 - precision: 0.3390 - recall: 0.6533 - auc: 0.7493 - prc: 0.4692 - val_loss: 0.5768 - val_tp: 48.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 43.0000 - val_accuracy: 0.7451 - val_precision: 0.3582 - val_recall: 0.5275 - val_auc: 0.6991 - val_prc: 0.3815\n",
      "Epoch 341/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9875 - tp: 258.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 140.0000 - accuracy: 0.7164 - precision: 0.3728 - recall: 0.6482 - auc: 0.7488 - prc: 0.4728 - val_loss: 0.6423 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6972 - val_prc: 0.3885\n",
      "Epoch 342/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9845 - tp: 259.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 139.0000 - accuracy: 0.6961 - precision: 0.3524 - recall: 0.6508 - auc: 0.7497 - prc: 0.4727 - val_loss: 0.6552 - val_tp: 55.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 36.0000 - val_accuracy: 0.6383 - val_precision: 0.2723 - val_recall: 0.6044 - val_auc: 0.6984 - val_prc: 0.3743\n",
      "Epoch 343/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9849 - tp: 266.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 132.0000 - accuracy: 0.6902 - precision: 0.3495 - recall: 0.6683 - auc: 0.7529 - prc: 0.4733 - val_loss: 0.6165 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6963 - val_prc: 0.3815\n",
      "Epoch 344/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9834 - tp: 264.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 134.0000 - accuracy: 0.6991 - precision: 0.3572 - recall: 0.6633 - auc: 0.7513 - prc: 0.4782 - val_loss: 0.6156 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6969 - val_prc: 0.3903\n",
      "Epoch 345/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9839 - tp: 264.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 134.0000 - accuracy: 0.6952 - precision: 0.3534 - recall: 0.6633 - auc: 0.7508 - prc: 0.4726 - val_loss: 0.5861 - val_tp: 48.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 43.0000 - val_accuracy: 0.7332 - val_precision: 0.3429 - val_recall: 0.5275 - val_auc: 0.7005 - val_prc: 0.3850\n",
      "Epoch 346/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9896 - tp: 254.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 144.0000 - accuracy: 0.6932 - precision: 0.3475 - recall: 0.6382 - auc: 0.7472 - prc: 0.4701 - val_loss: 0.6222 - val_tp: 54.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 37.0000 - val_accuracy: 0.6957 - val_precision: 0.3158 - val_recall: 0.5934 - val_auc: 0.7011 - val_prc: 0.3757\n",
      "Epoch 347/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9836 - tp: 261.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 137.0000 - accuracy: 0.6947 - precision: 0.3518 - recall: 0.6558 - auc: 0.7513 - prc: 0.4774 - val_loss: 0.5874 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.6979 - val_prc: 0.3867\n",
      "Epoch 348/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9863 - tp: 258.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 140.0000 - accuracy: 0.6971 - precision: 0.3529 - recall: 0.6482 - auc: 0.7484 - prc: 0.4760 - val_loss: 0.6353 - val_tp: 52.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 39.0000 - val_accuracy: 0.6561 - val_precision: 0.2781 - val_recall: 0.5714 - val_auc: 0.6957 - val_prc: 0.3765\n",
      "Epoch 349/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9859 - tp: 257.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 141.0000 - accuracy: 0.6966 - precision: 0.3521 - recall: 0.6457 - auc: 0.7480 - prc: 0.4812 - val_loss: 0.6097 - val_tp: 52.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 39.0000 - val_accuracy: 0.7095 - val_precision: 0.3250 - val_recall: 0.5714 - val_auc: 0.6984 - val_prc: 0.3889\n",
      "Epoch 350/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9836 - tp: 268.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 130.0000 - accuracy: 0.6789 - precision: 0.3401 - recall: 0.6734 - auc: 0.7510 - prc: 0.4673 - val_loss: 0.5593 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6992 - val_prc: 0.3924\n",
      "Epoch 351/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9804 - tp: 257.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 141.0000 - accuracy: 0.6952 - precision: 0.3506 - recall: 0.6457 - auc: 0.7531 - prc: 0.4811 - val_loss: 0.6350 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6983 - val_prc: 0.3911\n",
      "Epoch 352/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9841 - tp: 257.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 141.0000 - accuracy: 0.6957 - precision: 0.3511 - recall: 0.6457 - auc: 0.7496 - prc: 0.4693 - val_loss: 0.6354 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6965 - val_prc: 0.3773\n",
      "Epoch 353/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9843 - tp: 266.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 132.0000 - accuracy: 0.6848 - precision: 0.3446 - recall: 0.6683 - auc: 0.7495 - prc: 0.4758 - val_loss: 0.5656 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6994 - val_prc: 0.3903\n",
      "Epoch 354/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9827 - tp: 261.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 137.0000 - accuracy: 0.7031 - precision: 0.3600 - recall: 0.6558 - auc: 0.7521 - prc: 0.4831 - val_loss: 0.6519 - val_tp: 55.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 36.0000 - val_accuracy: 0.6383 - val_precision: 0.2723 - val_recall: 0.6044 - val_auc: 0.6979 - val_prc: 0.3822\n",
      "Epoch 355/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9847 - tp: 261.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 137.0000 - accuracy: 0.6917 - precision: 0.3489 - recall: 0.6558 - auc: 0.7498 - prc: 0.4728 - val_loss: 0.7227 - val_tp: 64.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 27.0000 - val_accuracy: 0.5672 - val_precision: 0.2500 - val_recall: 0.7033 - val_auc: 0.6977 - val_prc: 0.3769\n",
      "Epoch 356/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9856 - tp: 267.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 131.0000 - accuracy: 0.6848 - precision: 0.3450 - recall: 0.6709 - auc: 0.7490 - prc: 0.4809 - val_loss: 0.6215 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6988 - val_prc: 0.3911\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9823 - tp: 265.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 133.0000 - accuracy: 0.6927 - precision: 0.3515 - recall: 0.6658 - auc: 0.7522 - prc: 0.4704 - val_loss: 0.5652 - val_tp: 45.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 46.0000 - val_accuracy: 0.7510 - val_precision: 0.3600 - val_recall: 0.4945 - val_auc: 0.6958 - val_prc: 0.3869\n",
      "Epoch 358/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9797 - tp: 260.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 138.0000 - accuracy: 0.6976 - precision: 0.3542 - recall: 0.6533 - auc: 0.7534 - prc: 0.4747 - val_loss: 0.5960 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6980 - val_prc: 0.3874\n",
      "Epoch 359/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9904 - tp: 262.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 136.0000 - accuracy: 0.6823 - precision: 0.3407 - recall: 0.6583 - auc: 0.7447 - prc: 0.4741 - val_loss: 0.6076 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.6965 - val_prc: 0.3749\n",
      "Epoch 360/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9818 - tp: 259.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 139.0000 - accuracy: 0.7085 - precision: 0.3648 - recall: 0.6508 - auc: 0.7523 - prc: 0.4765 - val_loss: 0.6914 - val_tp: 61.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 30.0000 - val_accuracy: 0.5909 - val_precision: 0.2563 - val_recall: 0.6703 - val_auc: 0.6947 - val_prc: 0.3756\n",
      "Epoch 361/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9857 - tp: 268.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 130.0000 - accuracy: 0.6749 - precision: 0.3367 - recall: 0.6734 - auc: 0.7488 - prc: 0.4698 - val_loss: 0.6100 - val_tp: 51.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 40.0000 - val_accuracy: 0.6976 - val_precision: 0.3110 - val_recall: 0.5604 - val_auc: 0.6958 - val_prc: 0.3841\n",
      "Epoch 362/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9815 - tp: 263.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 135.0000 - accuracy: 0.6848 - precision: 0.3433 - recall: 0.6608 - auc: 0.7528 - prc: 0.4764 - val_loss: 0.5938 - val_tp: 51.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 40.0000 - val_accuracy: 0.7292 - val_precision: 0.3446 - val_recall: 0.5604 - val_auc: 0.6984 - val_prc: 0.3748\n",
      "Epoch 363/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9856 - tp: 254.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 144.0000 - accuracy: 0.7105 - precision: 0.3649 - recall: 0.6382 - auc: 0.7491 - prc: 0.4794 - val_loss: 0.6031 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.6972 - val_prc: 0.3824\n",
      "Epoch 364/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9823 - tp: 263.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 135.0000 - accuracy: 0.6952 - precision: 0.3530 - recall: 0.6608 - auc: 0.7522 - prc: 0.4734 - val_loss: 0.6697 - val_tp: 58.0000 - val_fp: 169.0000 - val_tn: 246.0000 - val_fn: 33.0000 - val_accuracy: 0.6008 - val_precision: 0.2555 - val_recall: 0.6374 - val_auc: 0.6948 - val_prc: 0.3917\n",
      "Epoch 365/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9809 - tp: 262.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 136.0000 - accuracy: 0.7016 - precision: 0.3589 - recall: 0.6583 - auc: 0.7528 - prc: 0.4795 - val_loss: 0.6320 - val_tp: 53.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 38.0000 - val_accuracy: 0.6581 - val_precision: 0.2819 - val_recall: 0.5824 - val_auc: 0.6965 - val_prc: 0.3797\n",
      "Epoch 366/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9796 - tp: 260.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 138.0000 - accuracy: 0.6942 - precision: 0.3509 - recall: 0.6533 - auc: 0.7529 - prc: 0.4823 - val_loss: 0.6169 - val_tp: 52.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 39.0000 - val_accuracy: 0.6759 - val_precision: 0.2938 - val_recall: 0.5714 - val_auc: 0.6990 - val_prc: 0.3824\n",
      "Epoch 367/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9825 - tp: 271.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 127.0000 - accuracy: 0.6917 - precision: 0.3529 - recall: 0.6809 - auc: 0.7514 - prc: 0.4788 - val_loss: 0.6223 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6976 - val_prc: 0.3868\n",
      "Epoch 368/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9808 - tp: 268.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 130.0000 - accuracy: 0.6927 - precision: 0.3526 - recall: 0.6734 - auc: 0.7526 - prc: 0.4760 - val_loss: 0.5946 - val_tp: 51.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 40.0000 - val_accuracy: 0.7273 - val_precision: 0.3423 - val_recall: 0.5604 - val_auc: 0.6969 - val_prc: 0.3788\n",
      "Epoch 369/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9815 - tp: 265.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 133.0000 - accuracy: 0.6887 - precision: 0.3478 - recall: 0.6658 - auc: 0.7508 - prc: 0.4806 - val_loss: 0.6170 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6977 - val_prc: 0.3877\n",
      "Epoch 370/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9783 - tp: 260.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 138.0000 - accuracy: 0.7006 - precision: 0.3571 - recall: 0.6533 - auc: 0.7560 - prc: 0.4809 - val_loss: 0.6280 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6948 - val_prc: 0.3863\n",
      "Epoch 371/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9814 - tp: 262.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 136.0000 - accuracy: 0.6863 - precision: 0.3443 - recall: 0.6583 - auc: 0.7519 - prc: 0.4744 - val_loss: 0.6096 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6977 - val_prc: 0.3862\n",
      "Epoch 372/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9877 - tp: 261.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 137.0000 - accuracy: 0.6947 - precision: 0.3518 - recall: 0.6558 - auc: 0.7483 - prc: 0.4658 - val_loss: 0.6023 - val_tp: 51.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 40.0000 - val_accuracy: 0.7095 - val_precision: 0.3228 - val_recall: 0.5604 - val_auc: 0.6968 - val_prc: 0.3855\n",
      "Epoch 373/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9818 - tp: 259.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 139.0000 - accuracy: 0.6912 - precision: 0.3477 - recall: 0.6508 - auc: 0.7515 - prc: 0.4763 - val_loss: 0.6116 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6956 - val_prc: 0.3835\n",
      "Epoch 374/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9827 - tp: 269.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 129.0000 - accuracy: 0.6784 - precision: 0.3401 - recall: 0.6759 - auc: 0.7514 - prc: 0.4758 - val_loss: 0.5737 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6961 - val_prc: 0.3920\n",
      "Epoch 375/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9793 - tp: 255.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 143.0000 - accuracy: 0.6957 - precision: 0.3503 - recall: 0.6407 - auc: 0.7533 - prc: 0.4764 - val_loss: 0.6267 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6992 - val_prc: 0.3842\n",
      "Epoch 376/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9804 - tp: 262.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 136.0000 - accuracy: 0.7036 - precision: 0.3609 - recall: 0.6583 - auc: 0.7526 - prc: 0.4782 - val_loss: 0.6117 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6958 - val_prc: 0.3846\n",
      "Epoch 377/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9785 - tp: 265.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 133.0000 - accuracy: 0.6907 - precision: 0.3496 - recall: 0.6658 - auc: 0.7537 - prc: 0.4763 - val_loss: 0.6197 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6965 - val_prc: 0.3875\n",
      "Epoch 378/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9779 - tp: 265.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 133.0000 - accuracy: 0.6976 - precision: 0.3562 - recall: 0.6658 - auc: 0.7534 - prc: 0.4825 - val_loss: 0.6316 - val_tp: 53.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 38.0000 - val_accuracy: 0.6522 - val_precision: 0.2775 - val_recall: 0.5824 - val_auc: 0.6968 - val_prc: 0.3821\n",
      "Epoch 379/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9828 - tp: 265.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 133.0000 - accuracy: 0.6971 - precision: 0.3557 - recall: 0.6658 - auc: 0.7521 - prc: 0.4759 - val_loss: 0.6357 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6978 - val_prc: 0.3780\n",
      "Epoch 380/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9764 - tp: 265.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 133.0000 - accuracy: 0.6927 - precision: 0.3515 - recall: 0.6658 - auc: 0.7560 - prc: 0.4823 - val_loss: 0.6415 - val_tp: 54.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 37.0000 - val_accuracy: 0.6443 - val_precision: 0.2741 - val_recall: 0.5934 - val_auc: 0.6946 - val_prc: 0.3718\n",
      "Epoch 381/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9793 - tp: 268.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 130.0000 - accuracy: 0.6838 - precision: 0.3445 - recall: 0.6734 - auc: 0.7517 - prc: 0.4816 - val_loss: 0.6274 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6956 - val_prc: 0.3847\n",
      "Epoch 382/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9836 - tp: 259.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 139.0000 - accuracy: 0.6877 - precision: 0.3444 - recall: 0.6508 - auc: 0.7499 - prc: 0.4711 - val_loss: 0.6505 - val_tp: 55.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 36.0000 - val_accuracy: 0.6344 - val_precision: 0.2696 - val_recall: 0.6044 - val_auc: 0.6986 - val_prc: 0.3878\n",
      "Epoch 383/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9756 - tp: 264.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 134.0000 - accuracy: 0.7041 - precision: 0.3621 - recall: 0.6633 - auc: 0.7582 - prc: 0.4762 - val_loss: 0.6615 - val_tp: 57.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 34.0000 - val_accuracy: 0.6087 - val_precision: 0.2579 - val_recall: 0.6264 - val_auc: 0.6925 - val_prc: 0.3804\n",
      "Epoch 384/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9833 - tp: 267.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 131.0000 - accuracy: 0.6823 - precision: 0.3427 - recall: 0.6709 - auc: 0.7504 - prc: 0.4789 - val_loss: 0.6410 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6974 - val_prc: 0.3813\n",
      "Epoch 385/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9788 - tp: 266.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 132.0000 - accuracy: 0.6873 - precision: 0.3468 - recall: 0.6683 - auc: 0.7536 - prc: 0.4822 - val_loss: 0.6356 - val_tp: 54.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 37.0000 - val_accuracy: 0.6423 - val_precision: 0.2727 - val_recall: 0.5934 - val_auc: 0.6960 - val_prc: 0.3900\n",
      "Epoch 386/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9808 - tp: 263.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 135.0000 - accuracy: 0.6892 - precision: 0.3474 - recall: 0.6608 - auc: 0.7523 - prc: 0.4775 - val_loss: 0.6416 - val_tp: 54.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 37.0000 - val_accuracy: 0.6443 - val_precision: 0.2741 - val_recall: 0.5934 - val_auc: 0.6958 - val_prc: 0.3892\n",
      "Epoch 387/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9802 - tp: 268.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 130.0000 - accuracy: 0.6907 - precision: 0.3508 - recall: 0.6734 - auc: 0.7540 - prc: 0.4714 - val_loss: 0.5972 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6950 - val_prc: 0.3829\n",
      "Epoch 388/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.9820 - tp: 265.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 133.0000 - accuracy: 0.6823 - precision: 0.3419 - recall: 0.6658 - auc: 0.7532 - prc: 0.4726 - val_loss: 0.5945 - val_tp: 50.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 41.0000 - val_accuracy: 0.7253 - val_precision: 0.3378 - val_recall: 0.5495 - val_auc: 0.6969 - val_prc: 0.3895\n",
      "Epoch 389/500\n",
      " 79/102 [======================>.......] - ETA: 0s - loss: 0.9708 - tp: 212.0000 - fp: 379.0000 - tn: 888.0000 - fn: 101.0000 - accuracy: 0.6962 - precision: 0.3587 - recall: 0.6773 - auc: 0.7618 - prc: 0.4866Restoring model weights from the end of the best epoch: 339.\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9788 - tp: 265.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 133.0000 - accuracy: 0.6927 - precision: 0.3515 - recall: 0.6658 - auc: 0.7543 - prc: 0.4791 - val_loss: 0.6225 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6982 - val_prc: 0.3731\n",
      "Epoch 389: early stopping\n",
      "26/26 [==============================] - 0s 620us/step\n",
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.9147 - tp: 52.0000 - fp: 126.0000 - tn: 1915.0000 - fn: 437.0000 - accuracy: 0.7775 - precision: 0.2921 - recall: 0.1063 - auc: 0.5012 - prc: 0.2257 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8895 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5139 - prc: 0.2017 - val_loss: 0.4766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5149 - prc: 0.1982 - val_loss: 0.4808 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8448 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5166 - prc: 0.2072 - val_loss: 0.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8263 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5082 - prc: 0.1986 - val_loss: 0.4916 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8094 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5110 - prc: 0.2017 - val_loss: 0.4980 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5057 - prc: 0.2043 - val_loss: 0.5054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4831 - prc: 0.1898 - val_loss: 0.5137 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7673 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5234 - prc: 0.2073 - val_loss: 0.5218 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7565 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4949 - prc: 0.1855 - val_loss: 0.5310 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7469 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5079 - prc: 0.1992 - val_loss: 0.5395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7385 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4999 - prc: 0.1933 - val_loss: 0.5494 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4760 - prc: 0.1855 - val_loss: 0.5579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7249 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4772 - prc: 0.1875 - val_loss: 0.5676 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7195 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5024 - prc: 0.2011 - val_loss: 0.5765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5096 - val_prc: 0.1827\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7147 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5022 - prc: 0.1964 - val_loss: 0.5859 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4861 - prc: 0.1907 - val_loss: 0.5944 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7075 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4816 - prc: 0.1879 - val_loss: 0.6034 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5083 - prc: 0.1979 - val_loss: 0.6103 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5240 - val_prc: 0.1873\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7022 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5081 - prc: 0.1996 - val_loss: 0.6178 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5287 - val_prc: 0.1888\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7000 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5247 - prc: 0.2194 - val_loss: 0.6196 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5917 - val_prc: 0.2169\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6975 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5616 - prc: 0.2216 - val_loss: 0.6286 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5564 - val_prc: 0.1989\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6950 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5865 - prc: 0.2423 - val_loss: 0.6266 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6410 - val_prc: 0.2504\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6909 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6042 - prc: 0.2403 - val_loss: 0.6409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5836 - val_prc: 0.2098\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6860 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6497 - prc: 0.2977 - val_loss: 0.6150 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6650 - val_prc: 0.2756\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6819 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6431 - prc: 0.2728 - val_loss: 0.6171 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6592 - val_prc: 0.2691\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6795 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6421 - prc: 0.2682 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6825 - val_prc: 0.3146\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6757 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6509 - prc: 0.2763 - val_loss: 0.5888 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6784 - val_prc: 0.3055\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6708 - tp: 59.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 339.0000 - accuracy: 0.7866 - precision: 0.3882 - recall: 0.1482 - auc: 0.6718 - prc: 0.3097 - val_loss: 0.6408 - val_tp: 65.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 26.0000 - val_accuracy: 0.5692 - val_precision: 0.2529 - val_recall: 0.7143 - val_auc: 0.6364 - val_prc: 0.2433\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6719 - tp: 222.0000 - fp: 524.0000 - tn: 1102.0000 - fn: 176.0000 - accuracy: 0.6542 - precision: 0.2976 - recall: 0.5578 - auc: 0.6584 - prc: 0.2960 - val_loss: 0.6173 - val_tp: 50.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 41.0000 - val_accuracy: 0.6838 - val_precision: 0.2959 - val_recall: 0.5495 - val_auc: 0.6613 - val_prc: 0.2727\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6653 - tp: 191.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 207.0000 - accuracy: 0.7228 - precision: 0.3505 - recall: 0.4799 - auc: 0.6820 - prc: 0.3270 - val_loss: 0.5966 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6769 - val_prc: 0.3060\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6627 - tp: 189.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 209.0000 - accuracy: 0.7263 - precision: 0.3539 - recall: 0.4749 - auc: 0.6852 - prc: 0.3360 - val_loss: 0.6294 - val_tp: 57.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 34.0000 - val_accuracy: 0.6225 - val_precision: 0.2664 - val_recall: 0.6264 - val_auc: 0.6609 - val_prc: 0.2720\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6605 - tp: 221.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 177.0000 - accuracy: 0.6902 - precision: 0.3294 - recall: 0.5553 - auc: 0.6824 - prc: 0.3133 - val_loss: 0.6031 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6775 - val_prc: 0.3049\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6569 - tp: 225.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 173.0000 - accuracy: 0.6976 - precision: 0.3389 - recall: 0.5653 - auc: 0.6794 - prc: 0.3022 - val_loss: 0.6487 - val_tp: 64.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 27.0000 - val_accuracy: 0.5593 - val_precision: 0.2462 - val_recall: 0.7033 - val_auc: 0.6504 - val_prc: 0.2574\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6559 - tp: 222.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 176.0000 - accuracy: 0.6754 - precision: 0.3158 - recall: 0.5578 - auc: 0.6846 - prc: 0.3214 - val_loss: 0.5984 - val_tp: 48.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 43.0000 - val_accuracy: 0.6957 - val_precision: 0.3019 - val_recall: 0.5275 - val_auc: 0.6780 - val_prc: 0.3093\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6531 - tp: 213.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 185.0000 - accuracy: 0.7041 - precision: 0.3397 - recall: 0.5352 - auc: 0.6923 - prc: 0.3460 - val_loss: 0.5757 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6826 - val_prc: 0.3292\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6511 - tp: 229.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 169.0000 - accuracy: 0.6912 - precision: 0.3343 - recall: 0.5754 - auc: 0.6978 - prc: 0.3550 - val_loss: 0.5867 - val_tp: 46.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 45.0000 - val_accuracy: 0.7332 - val_precision: 0.3382 - val_recall: 0.5055 - val_auc: 0.6816 - val_prc: 0.3237\n",
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6490 - tp: 222.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 176.0000 - accuracy: 0.6991 - precision: 0.3389 - recall: 0.5578 - auc: 0.6931 - prc: 0.3314 - val_loss: 0.6075 - val_tp: 51.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 40.0000 - val_accuracy: 0.6640 - val_precision: 0.2818 - val_recall: 0.5604 - val_auc: 0.6806 - val_prc: 0.3161\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6457 - tp: 241.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 157.0000 - accuracy: 0.6670 - precision: 0.3179 - recall: 0.6055 - auc: 0.6979 - prc: 0.3317 - val_loss: 0.5410 - val_tp: 37.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 54.0000 - val_accuracy: 0.7885 - val_precision: 0.4111 - val_recall: 0.4066 - val_auc: 0.6829 - val_prc: 0.3374\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6455 - tp: 221.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 177.0000 - accuracy: 0.6952 - precision: 0.3343 - recall: 0.5553 - auc: 0.6949 - prc: 0.3337 - val_loss: 0.5680 - val_tp: 42.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 49.0000 - val_accuracy: 0.7352 - val_precision: 0.3307 - val_recall: 0.4615 - val_auc: 0.6819 - val_prc: 0.3251\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6455 - tp: 214.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 184.0000 - accuracy: 0.6887 - precision: 0.3242 - recall: 0.5377 - auc: 0.6952 - prc: 0.3432 - val_loss: 0.6120 - val_tp: 52.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 39.0000 - val_accuracy: 0.6581 - val_precision: 0.2796 - val_recall: 0.5714 - val_auc: 0.6769 - val_prc: 0.3081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6429 - tp: 244.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 154.0000 - accuracy: 0.6838 - precision: 0.3342 - recall: 0.6131 - auc: 0.6984 - prc: 0.3459 - val_loss: 0.5801 - val_tp: 49.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 42.0000 - val_accuracy: 0.7194 - val_precision: 0.3289 - val_recall: 0.5385 - val_auc: 0.6858 - val_prc: 0.3419\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6419 - tp: 220.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 178.0000 - accuracy: 0.7095 - precision: 0.3492 - recall: 0.5528 - auc: 0.7027 - prc: 0.3644 - val_loss: 0.6333 - val_tp: 58.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 33.0000 - val_accuracy: 0.6067 - val_precision: 0.2589 - val_recall: 0.6374 - val_auc: 0.6758 - val_prc: 0.3031\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6414 - tp: 248.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 150.0000 - accuracy: 0.6685 - precision: 0.3225 - recall: 0.6231 - auc: 0.6993 - prc: 0.3505 - val_loss: 0.5894 - val_tp: 50.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 41.0000 - val_accuracy: 0.7154 - val_precision: 0.3268 - val_recall: 0.5495 - val_auc: 0.6842 - val_prc: 0.3348\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6395 - tp: 225.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 173.0000 - accuracy: 0.7006 - precision: 0.3419 - recall: 0.5653 - auc: 0.7051 - prc: 0.3769 - val_loss: 0.6199 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.6817 - val_prc: 0.3262\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6375 - tp: 247.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 151.0000 - accuracy: 0.6739 - precision: 0.3267 - recall: 0.6206 - auc: 0.7033 - prc: 0.3488 - val_loss: 0.6291 - val_tp: 59.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 32.0000 - val_accuracy: 0.6245 - val_precision: 0.2719 - val_recall: 0.6484 - val_auc: 0.6801 - val_prc: 0.3147\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6381 - tp: 248.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 150.0000 - accuracy: 0.6665 - precision: 0.3208 - recall: 0.6231 - auc: 0.6990 - prc: 0.3394 - val_loss: 0.6350 - val_tp: 59.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 32.0000 - val_accuracy: 0.6087 - val_precision: 0.2622 - val_recall: 0.6484 - val_auc: 0.6784 - val_prc: 0.3084\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6350 - tp: 240.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 158.0000 - accuracy: 0.6784 - precision: 0.3274 - recall: 0.6030 - auc: 0.7043 - prc: 0.3451 - val_loss: 0.6298 - val_tp: 59.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 32.0000 - val_accuracy: 0.6285 - val_precision: 0.2744 - val_recall: 0.6484 - val_auc: 0.6797 - val_prc: 0.3174\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6371 - tp: 242.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 156.0000 - accuracy: 0.6719 - precision: 0.3227 - recall: 0.6080 - auc: 0.7002 - prc: 0.3536 - val_loss: 0.6010 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6843 - val_prc: 0.3361\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6356 - tp: 235.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 163.0000 - accuracy: 0.6897 - precision: 0.3357 - recall: 0.5905 - auc: 0.7053 - prc: 0.3752 - val_loss: 0.5949 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6843 - val_prc: 0.3375\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6335 - tp: 243.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 155.0000 - accuracy: 0.6709 - precision: 0.3223 - recall: 0.6106 - auc: 0.7029 - prc: 0.3465 - val_loss: 0.5972 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6836 - val_prc: 0.3305\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6322 - tp: 244.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 154.0000 - accuracy: 0.6739 - precision: 0.3253 - recall: 0.6131 - auc: 0.7087 - prc: 0.3734 - val_loss: 0.6016 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6881 - val_prc: 0.3404\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6328 - tp: 247.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 151.0000 - accuracy: 0.6616 - precision: 0.3163 - recall: 0.6206 - auc: 0.7021 - prc: 0.3477 - val_loss: 0.5702 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6846 - val_prc: 0.3406\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6305 - tp: 237.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 161.0000 - accuracy: 0.6838 - precision: 0.3310 - recall: 0.5955 - auc: 0.7083 - prc: 0.3676 - val_loss: 0.5670 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.6853 - val_prc: 0.3368\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6311 - tp: 233.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 165.0000 - accuracy: 0.6996 - precision: 0.3447 - recall: 0.5854 - auc: 0.7080 - prc: 0.3729 - val_loss: 0.6169 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6885 - val_prc: 0.3456\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6286 - tp: 251.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 147.0000 - accuracy: 0.6853 - precision: 0.3387 - recall: 0.6307 - auc: 0.7114 - prc: 0.3777 - val_loss: 0.6144 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6879 - val_prc: 0.3473\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6277 - tp: 247.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 151.0000 - accuracy: 0.6848 - precision: 0.3365 - recall: 0.6206 - auc: 0.7107 - prc: 0.3745 - val_loss: 0.6219 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6903 - val_prc: 0.3512\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6280 - tp: 251.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 147.0000 - accuracy: 0.6705 - precision: 0.3256 - recall: 0.6307 - auc: 0.7095 - prc: 0.3677 - val_loss: 0.5783 - val_tp: 49.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 42.0000 - val_accuracy: 0.7233 - val_precision: 0.3333 - val_recall: 0.5385 - val_auc: 0.6879 - val_prc: 0.3439\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6269 - tp: 243.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 155.0000 - accuracy: 0.6808 - precision: 0.3311 - recall: 0.6106 - auc: 0.7117 - prc: 0.3837 - val_loss: 0.6111 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.6876 - val_prc: 0.3408\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6248 - tp: 254.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 144.0000 - accuracy: 0.6808 - precision: 0.3360 - recall: 0.6382 - auc: 0.7165 - prc: 0.3905 - val_loss: 0.5934 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.6883 - val_prc: 0.3420\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6247 - tp: 238.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 160.0000 - accuracy: 0.6798 - precision: 0.3278 - recall: 0.5980 - auc: 0.7144 - prc: 0.3780 - val_loss: 0.6297 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6902 - val_prc: 0.3476\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6255 - tp: 238.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 160.0000 - accuracy: 0.6793 - precision: 0.3274 - recall: 0.5980 - auc: 0.7119 - prc: 0.3810 - val_loss: 0.6144 - val_tp: 56.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 35.0000 - val_accuracy: 0.6621 - val_precision: 0.2917 - val_recall: 0.6154 - val_auc: 0.6892 - val_prc: 0.3429\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6215 - tp: 248.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 150.0000 - accuracy: 0.6976 - precision: 0.3493 - recall: 0.6231 - auc: 0.7194 - prc: 0.3996 - val_loss: 0.6529 - val_tp: 59.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 32.0000 - val_accuracy: 0.5909 - val_precision: 0.2521 - val_recall: 0.6484 - val_auc: 0.6891 - val_prc: 0.3432\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6231 - tp: 249.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 149.0000 - accuracy: 0.6764 - precision: 0.3298 - recall: 0.6256 - auc: 0.7161 - prc: 0.3912 - val_loss: 0.6494 - val_tp: 59.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 32.0000 - val_accuracy: 0.5929 - val_precision: 0.2532 - val_recall: 0.6484 - val_auc: 0.6915 - val_prc: 0.3514\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6220 - tp: 259.0000 - fp: 550.0000 - tn: 1076.0000 - fn: 139.0000 - accuracy: 0.6596 - precision: 0.3201 - recall: 0.6508 - auc: 0.7169 - prc: 0.3805 - val_loss: 0.5782 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6910 - val_prc: 0.3516\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6228 - tp: 238.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 160.0000 - accuracy: 0.6779 - precision: 0.3260 - recall: 0.5980 - auc: 0.7148 - prc: 0.3860 - val_loss: 0.6056 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6913 - val_prc: 0.3461\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6218 - tp: 251.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 147.0000 - accuracy: 0.6744 - precision: 0.3290 - recall: 0.6307 - auc: 0.7166 - prc: 0.3843 - val_loss: 0.5821 - val_tp: 50.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 41.0000 - val_accuracy: 0.7154 - val_precision: 0.3268 - val_recall: 0.5495 - val_auc: 0.6912 - val_prc: 0.3503\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6221 - tp: 249.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 149.0000 - accuracy: 0.6877 - precision: 0.3402 - recall: 0.6256 - auc: 0.7162 - prc: 0.3871 - val_loss: 0.6000 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6915 - val_prc: 0.3489\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6202 - tp: 243.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 155.0000 - accuracy: 0.6897 - precision: 0.3394 - recall: 0.6106 - auc: 0.7164 - prc: 0.3766 - val_loss: 0.6498 - val_tp: 60.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 31.0000 - val_accuracy: 0.5988 - val_precision: 0.2586 - val_recall: 0.6593 - val_auc: 0.6900 - val_prc: 0.3379\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6202 - tp: 247.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 151.0000 - accuracy: 0.6843 - precision: 0.3361 - recall: 0.6206 - auc: 0.7181 - prc: 0.3989 - val_loss: 0.6117 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6903 - val_prc: 0.3455\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6202 - tp: 240.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 158.0000 - accuracy: 0.6971 - precision: 0.3453 - recall: 0.6030 - auc: 0.7171 - prc: 0.3957 - val_loss: 0.6757 - val_tp: 67.0000 - val_fp: 190.0000 - val_tn: 225.0000 - val_fn: 24.0000 - val_accuracy: 0.5771 - val_precision: 0.2607 - val_recall: 0.7363 - val_auc: 0.6902 - val_prc: 0.3393\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6200 - tp: 253.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 145.0000 - accuracy: 0.6670 - precision: 0.3235 - recall: 0.6357 - auc: 0.7172 - prc: 0.3963 - val_loss: 0.5869 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6937 - val_prc: 0.3628\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6190 - tp: 245.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 153.0000 - accuracy: 0.6897 - precision: 0.3403 - recall: 0.6156 - auc: 0.7183 - prc: 0.3932 - val_loss: 0.5822 - val_tp: 50.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 41.0000 - val_accuracy: 0.7194 - val_precision: 0.3311 - val_recall: 0.5495 - val_auc: 0.6946 - val_prc: 0.3664\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6183 - tp: 249.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 149.0000 - accuracy: 0.7031 - precision: 0.3552 - recall: 0.6256 - auc: 0.7195 - prc: 0.4059 - val_loss: 0.6181 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6914 - val_prc: 0.3509\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6168 - tp: 254.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 144.0000 - accuracy: 0.6868 - precision: 0.3414 - recall: 0.6382 - auc: 0.7215 - prc: 0.4030 - val_loss: 0.5661 - val_tp: 48.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 43.0000 - val_accuracy: 0.7451 - val_precision: 0.3582 - val_recall: 0.5275 - val_auc: 0.6937 - val_prc: 0.3672\n",
      "Epoch 76/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6168 - tp: 249.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 149.0000 - accuracy: 0.6882 - precision: 0.3406 - recall: 0.6256 - auc: 0.7214 - prc: 0.4093 - val_loss: 0.6100 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6913 - val_prc: 0.3557\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6161 - tp: 249.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 149.0000 - accuracy: 0.6927 - precision: 0.3449 - recall: 0.6256 - auc: 0.7230 - prc: 0.4179 - val_loss: 0.6278 - val_tp: 57.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 34.0000 - val_accuracy: 0.6383 - val_precision: 0.2767 - val_recall: 0.6264 - val_auc: 0.6925 - val_prc: 0.3526\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6173 - tp: 255.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 143.0000 - accuracy: 0.6848 - precision: 0.3400 - recall: 0.6407 - auc: 0.7211 - prc: 0.4009 - val_loss: 0.6249 - val_tp: 56.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 35.0000 - val_accuracy: 0.6462 - val_precision: 0.2800 - val_recall: 0.6154 - val_auc: 0.6907 - val_prc: 0.3483\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6144 - tp: 247.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 151.0000 - accuracy: 0.6868 - precision: 0.3384 - recall: 0.6206 - auc: 0.7250 - prc: 0.4014 - val_loss: 0.5656 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6934 - val_prc: 0.3724\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6173 - tp: 256.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 142.0000 - accuracy: 0.6724 - precision: 0.3295 - recall: 0.6432 - auc: 0.7197 - prc: 0.3957 - val_loss: 0.5928 - val_tp: 51.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 40.0000 - val_accuracy: 0.7016 - val_precision: 0.3148 - val_recall: 0.5604 - val_auc: 0.6957 - val_prc: 0.3704\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6150 - tp: 251.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 147.0000 - accuracy: 0.6892 - precision: 0.3424 - recall: 0.6307 - auc: 0.7219 - prc: 0.4054 - val_loss: 0.5855 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6943 - val_prc: 0.3681\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6127 - tp: 245.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 153.0000 - accuracy: 0.7016 - precision: 0.3520 - recall: 0.6156 - auc: 0.7254 - prc: 0.4042 - val_loss: 0.6040 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6951 - val_prc: 0.3669\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6131 - tp: 242.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 156.0000 - accuracy: 0.6981 - precision: 0.3472 - recall: 0.6080 - auc: 0.7249 - prc: 0.4078 - val_loss: 0.6433 - val_tp: 60.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 31.0000 - val_accuracy: 0.6245 - val_precision: 0.2740 - val_recall: 0.6593 - val_auc: 0.6937 - val_prc: 0.3561\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6152 - tp: 242.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 156.0000 - accuracy: 0.6892 - precision: 0.3385 - recall: 0.6080 - auc: 0.7218 - prc: 0.4061 - val_loss: 0.6559 - val_tp: 61.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 30.0000 - val_accuracy: 0.5929 - val_precision: 0.2574 - val_recall: 0.6703 - val_auc: 0.6944 - val_prc: 0.3568\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6117 - tp: 255.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 143.0000 - accuracy: 0.6803 - precision: 0.3360 - recall: 0.6407 - auc: 0.7264 - prc: 0.4106 - val_loss: 0.5643 - val_tp: 47.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 44.0000 - val_accuracy: 0.7372 - val_precision: 0.3456 - val_recall: 0.5165 - val_auc: 0.6947 - val_prc: 0.3730\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6129 - tp: 245.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 153.0000 - accuracy: 0.6882 - precision: 0.3389 - recall: 0.6156 - auc: 0.7254 - prc: 0.4033 - val_loss: 0.6011 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6963 - val_prc: 0.3665\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6136 - tp: 254.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 144.0000 - accuracy: 0.6754 - precision: 0.3312 - recall: 0.6382 - auc: 0.7236 - prc: 0.4018 - val_loss: 0.6015 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6941 - val_prc: 0.3663\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6118 - tp: 248.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 150.0000 - accuracy: 0.6996 - precision: 0.3513 - recall: 0.6231 - auc: 0.7268 - prc: 0.4131 - val_loss: 0.6371 - val_tp: 59.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 32.0000 - val_accuracy: 0.6324 - val_precision: 0.2770 - val_recall: 0.6484 - val_auc: 0.6936 - val_prc: 0.3484\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6120 - tp: 247.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 151.0000 - accuracy: 0.6942 - precision: 0.3455 - recall: 0.6206 - auc: 0.7257 - prc: 0.4188 - val_loss: 0.6205 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6958 - val_prc: 0.3577\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6129 - tp: 252.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 146.0000 - accuracy: 0.6789 - precision: 0.3333 - recall: 0.6332 - auc: 0.7236 - prc: 0.4099 - val_loss: 0.6008 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6944 - val_prc: 0.3664\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6108 - tp: 245.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 153.0000 - accuracy: 0.6932 - precision: 0.3436 - recall: 0.6156 - auc: 0.7275 - prc: 0.4213 - val_loss: 0.6182 - val_tp: 55.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 36.0000 - val_accuracy: 0.6601 - val_precision: 0.2880 - val_recall: 0.6044 - val_auc: 0.6958 - val_prc: 0.3601\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6108 - tp: 255.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 143.0000 - accuracy: 0.6853 - precision: 0.3405 - recall: 0.6407 - auc: 0.7268 - prc: 0.4210 - val_loss: 0.5775 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6933 - val_prc: 0.3605\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6094 - tp: 240.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 158.0000 - accuracy: 0.7006 - precision: 0.3488 - recall: 0.6030 - auc: 0.7281 - prc: 0.4184 - val_loss: 0.6314 - val_tp: 58.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 33.0000 - val_accuracy: 0.6502 - val_precision: 0.2871 - val_recall: 0.6374 - val_auc: 0.6961 - val_prc: 0.3602\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6096 - tp: 255.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 143.0000 - accuracy: 0.6818 - precision: 0.3373 - recall: 0.6407 - auc: 0.7274 - prc: 0.4167 - val_loss: 0.5788 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6973 - val_prc: 0.3715\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6091 - tp: 256.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 142.0000 - accuracy: 0.6947 - precision: 0.3497 - recall: 0.6432 - auc: 0.7281 - prc: 0.4194 - val_loss: 0.5863 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6961 - val_prc: 0.3661\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6091 - tp: 246.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 152.0000 - accuracy: 0.7001 - precision: 0.3509 - recall: 0.6181 - auc: 0.7293 - prc: 0.4238 - val_loss: 0.6019 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6952 - val_prc: 0.3679\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6078 - tp: 249.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 149.0000 - accuracy: 0.6952 - precision: 0.3473 - recall: 0.6256 - auc: 0.7301 - prc: 0.4241 - val_loss: 0.6176 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6964 - val_prc: 0.3647\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6078 - tp: 259.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 139.0000 - accuracy: 0.6838 - precision: 0.3408 - recall: 0.6508 - auc: 0.7294 - prc: 0.4117 - val_loss: 0.6288 - val_tp: 59.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 32.0000 - val_accuracy: 0.6502 - val_precision: 0.2892 - val_recall: 0.6484 - val_auc: 0.6940 - val_prc: 0.3583\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6086 - tp: 255.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 143.0000 - accuracy: 0.6863 - precision: 0.3414 - recall: 0.6407 - auc: 0.7284 - prc: 0.4211 - val_loss: 0.5857 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6967 - val_prc: 0.3735\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6081 - tp: 245.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 153.0000 - accuracy: 0.6991 - precision: 0.3495 - recall: 0.6156 - auc: 0.7293 - prc: 0.4264 - val_loss: 0.6342 - val_tp: 60.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 31.0000 - val_accuracy: 0.6482 - val_precision: 0.2899 - val_recall: 0.6593 - val_auc: 0.6962 - val_prc: 0.3535\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6085 - tp: 259.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 139.0000 - accuracy: 0.6690 - precision: 0.3278 - recall: 0.6508 - auc: 0.7281 - prc: 0.4093 - val_loss: 0.5513 - val_tp: 46.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 45.0000 - val_accuracy: 0.7549 - val_precision: 0.3680 - val_recall: 0.5055 - val_auc: 0.6980 - val_prc: 0.3698\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6114 - tp: 240.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 158.0000 - accuracy: 0.6947 - precision: 0.3429 - recall: 0.6030 - auc: 0.7241 - prc: 0.4101 - val_loss: 0.6302 - val_tp: 59.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 32.0000 - val_accuracy: 0.6542 - val_precision: 0.2921 - val_recall: 0.6484 - val_auc: 0.6979 - val_prc: 0.3616\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6085 - tp: 248.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 150.0000 - accuracy: 0.7065 - precision: 0.3584 - recall: 0.6231 - auc: 0.7293 - prc: 0.4178 - val_loss: 0.6232 - val_tp: 56.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 35.0000 - val_accuracy: 0.6581 - val_precision: 0.2887 - val_recall: 0.6154 - val_auc: 0.6980 - val_prc: 0.3696\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6077 - tp: 254.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 144.0000 - accuracy: 0.6858 - precision: 0.3405 - recall: 0.6382 - auc: 0.7303 - prc: 0.4212 - val_loss: 0.6061 - val_tp: 55.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 36.0000 - val_accuracy: 0.6818 - val_precision: 0.3056 - val_recall: 0.6044 - val_auc: 0.6949 - val_prc: 0.3675\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6084 - tp: 250.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 148.0000 - accuracy: 0.7001 - precision: 0.3526 - recall: 0.6281 - auc: 0.7293 - prc: 0.4163 - val_loss: 0.6336 - val_tp: 58.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 33.0000 - val_accuracy: 0.6423 - val_precision: 0.2816 - val_recall: 0.6374 - val_auc: 0.6913 - val_prc: 0.3543\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6075 - tp: 253.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 145.0000 - accuracy: 0.6848 - precision: 0.3391 - recall: 0.6357 - auc: 0.7305 - prc: 0.4188 - val_loss: 0.5607 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.6967 - val_prc: 0.3682\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6068 - tp: 242.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 156.0000 - accuracy: 0.7026 - precision: 0.3517 - recall: 0.6080 - auc: 0.7300 - prc: 0.4350 - val_loss: 0.6045 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6945 - val_prc: 0.3694\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6085 - tp: 250.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 148.0000 - accuracy: 0.6922 - precision: 0.3448 - recall: 0.6281 - auc: 0.7276 - prc: 0.4200 - val_loss: 0.6008 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6977 - val_prc: 0.3750\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6069 - tp: 256.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 142.0000 - accuracy: 0.6853 - precision: 0.3409 - recall: 0.6432 - auc: 0.7285 - prc: 0.4216 - val_loss: 0.5900 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6985 - val_prc: 0.3753\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6079 - tp: 254.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 144.0000 - accuracy: 0.6932 - precision: 0.3475 - recall: 0.6382 - auc: 0.7287 - prc: 0.4182 - val_loss: 0.6560 - val_tp: 61.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 30.0000 - val_accuracy: 0.6146 - val_precision: 0.2699 - val_recall: 0.6703 - val_auc: 0.6964 - val_prc: 0.3675\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6065 - tp: 253.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 145.0000 - accuracy: 0.6902 - precision: 0.3442 - recall: 0.6357 - auc: 0.7294 - prc: 0.4219 - val_loss: 0.6134 - val_tp: 53.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 38.0000 - val_accuracy: 0.6621 - val_precision: 0.2849 - val_recall: 0.5824 - val_auc: 0.6967 - val_prc: 0.3780\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6059 - tp: 253.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 145.0000 - accuracy: 0.6833 - precision: 0.3378 - recall: 0.6357 - auc: 0.7305 - prc: 0.4222 - val_loss: 0.6442 - val_tp: 59.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 32.0000 - val_accuracy: 0.6304 - val_precision: 0.2757 - val_recall: 0.6484 - val_auc: 0.6938 - val_prc: 0.3571\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6051 - tp: 254.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 144.0000 - accuracy: 0.6828 - precision: 0.3378 - recall: 0.6382 - auc: 0.7326 - prc: 0.4271 - val_loss: 0.6159 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6950 - val_prc: 0.3702\n",
      "Epoch 114/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6066 - tp: 245.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 153.0000 - accuracy: 0.6932 - precision: 0.3436 - recall: 0.6156 - auc: 0.7296 - prc: 0.4126 - val_loss: 0.6106 - val_tp: 56.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 35.0000 - val_accuracy: 0.6680 - val_precision: 0.2963 - val_recall: 0.6154 - val_auc: 0.6971 - val_prc: 0.3750\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6079 - tp: 258.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 140.0000 - accuracy: 0.6789 - precision: 0.3359 - recall: 0.6482 - auc: 0.7288 - prc: 0.4169 - val_loss: 0.5875 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6985 - val_prc: 0.3697\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6032 - tp: 256.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 142.0000 - accuracy: 0.6843 - precision: 0.3400 - recall: 0.6432 - auc: 0.7349 - prc: 0.4288 - val_loss: 0.5643 - val_tp: 48.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 43.0000 - val_accuracy: 0.7451 - val_precision: 0.3582 - val_recall: 0.5275 - val_auc: 0.6986 - val_prc: 0.3679\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6054 - tp: 244.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 154.0000 - accuracy: 0.6976 - precision: 0.3476 - recall: 0.6131 - auc: 0.7307 - prc: 0.4236 - val_loss: 0.6012 - val_tp: 52.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 39.0000 - val_accuracy: 0.6759 - val_precision: 0.2938 - val_recall: 0.5714 - val_auc: 0.6968 - val_prc: 0.3734\n",
      "Epoch 118/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6046 - tp: 250.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 148.0000 - accuracy: 0.6932 - precision: 0.3458 - recall: 0.6281 - auc: 0.7315 - prc: 0.4285 - val_loss: 0.6027 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6963 - val_prc: 0.3761\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6051 - tp: 249.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 149.0000 - accuracy: 0.6966 - precision: 0.3487 - recall: 0.6256 - auc: 0.7322 - prc: 0.4311 - val_loss: 0.6810 - val_tp: 62.0000 - val_fp: 182.0000 - val_tn: 233.0000 - val_fn: 29.0000 - val_accuracy: 0.5830 - val_precision: 0.2541 - val_recall: 0.6813 - val_auc: 0.6930 - val_prc: 0.3630\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6050 - tp: 257.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 141.0000 - accuracy: 0.6858 - precision: 0.3418 - recall: 0.6457 - auc: 0.7309 - prc: 0.4231 - val_loss: 0.6483 - val_tp: 60.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 31.0000 - val_accuracy: 0.6285 - val_precision: 0.2765 - val_recall: 0.6593 - val_auc: 0.6953 - val_prc: 0.3670\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6079 - tp: 250.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 148.0000 - accuracy: 0.6764 - precision: 0.3303 - recall: 0.6281 - auc: 0.7264 - prc: 0.4208 - val_loss: 0.5811 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6961 - val_prc: 0.3676\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6042 - tp: 250.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 148.0000 - accuracy: 0.6897 - precision: 0.3425 - recall: 0.6281 - auc: 0.7324 - prc: 0.4267 - val_loss: 0.5837 - val_tp: 49.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 42.0000 - val_accuracy: 0.7075 - val_precision: 0.3161 - val_recall: 0.5385 - val_auc: 0.6987 - val_prc: 0.3697\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6041 - tp: 255.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 143.0000 - accuracy: 0.6917 - precision: 0.3465 - recall: 0.6407 - auc: 0.7327 - prc: 0.4261 - val_loss: 0.5928 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6967 - val_prc: 0.3785\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6044 - tp: 252.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 146.0000 - accuracy: 0.7050 - precision: 0.3585 - recall: 0.6332 - auc: 0.7318 - prc: 0.4377 - val_loss: 0.5998 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6985 - val_prc: 0.3789\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6048 - tp: 247.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 151.0000 - accuracy: 0.6907 - precision: 0.3421 - recall: 0.6206 - auc: 0.7307 - prc: 0.4133 - val_loss: 0.6099 - val_tp: 53.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 38.0000 - val_accuracy: 0.6700 - val_precision: 0.2912 - val_recall: 0.5824 - val_auc: 0.6963 - val_prc: 0.3776\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6024 - tp: 265.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 133.0000 - accuracy: 0.6784 - precision: 0.3384 - recall: 0.6658 - auc: 0.7361 - prc: 0.4254 - val_loss: 0.5549 - val_tp: 48.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 43.0000 - val_accuracy: 0.7470 - val_precision: 0.3609 - val_recall: 0.5275 - val_auc: 0.6974 - val_prc: 0.3636\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6049 - tp: 249.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 149.0000 - accuracy: 0.6892 - precision: 0.3416 - recall: 0.6256 - auc: 0.7313 - prc: 0.4229 - val_loss: 0.6084 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6955 - val_prc: 0.3688\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6031 - tp: 254.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 144.0000 - accuracy: 0.6882 - precision: 0.3428 - recall: 0.6382 - auc: 0.7338 - prc: 0.4300 - val_loss: 0.6443 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.6949 - val_prc: 0.3700\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6031 - tp: 252.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 146.0000 - accuracy: 0.7085 - precision: 0.3621 - recall: 0.6332 - auc: 0.7339 - prc: 0.4373 - val_loss: 0.6164 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.6973 - val_prc: 0.3768\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6020 - tp: 253.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 145.0000 - accuracy: 0.6971 - precision: 0.3509 - recall: 0.6357 - auc: 0.7339 - prc: 0.4291 - val_loss: 0.6147 - val_tp: 55.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 36.0000 - val_accuracy: 0.6660 - val_precision: 0.2926 - val_recall: 0.6044 - val_auc: 0.6964 - val_prc: 0.3777\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6017 - tp: 254.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 144.0000 - accuracy: 0.6887 - precision: 0.3432 - recall: 0.6382 - auc: 0.7350 - prc: 0.4369 - val_loss: 0.5586 - val_tp: 48.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 43.0000 - val_accuracy: 0.7530 - val_precision: 0.3692 - val_recall: 0.5275 - val_auc: 0.6989 - val_prc: 0.3752\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6036 - tp: 251.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 147.0000 - accuracy: 0.7006 - precision: 0.3535 - recall: 0.6307 - auc: 0.7346 - prc: 0.4295 - val_loss: 0.6050 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6979 - val_prc: 0.3782\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6042 - tp: 255.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 143.0000 - accuracy: 0.6793 - precision: 0.3351 - recall: 0.6407 - auc: 0.7322 - prc: 0.4223 - val_loss: 0.6080 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6962 - val_prc: 0.3766\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6028 - tp: 253.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 145.0000 - accuracy: 0.6952 - precision: 0.3490 - recall: 0.6357 - auc: 0.7337 - prc: 0.4337 - val_loss: 0.6104 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6962 - val_prc: 0.3759\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6021 - tp: 250.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 148.0000 - accuracy: 0.7036 - precision: 0.3561 - recall: 0.6281 - auc: 0.7353 - prc: 0.4342 - val_loss: 0.5918 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6969 - val_prc: 0.3721\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6027 - tp: 257.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 141.0000 - accuracy: 0.7075 - precision: 0.3630 - recall: 0.6457 - auc: 0.7355 - prc: 0.4393 - val_loss: 0.6295 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6957 - val_prc: 0.3753\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6034 - tp: 262.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 136.0000 - accuracy: 0.6942 - precision: 0.3517 - recall: 0.6583 - auc: 0.7320 - prc: 0.4352 - val_loss: 0.6367 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6967 - val_prc: 0.3694\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6007 - tp: 254.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 144.0000 - accuracy: 0.6912 - precision: 0.3456 - recall: 0.6382 - auc: 0.7364 - prc: 0.4298 - val_loss: 0.5870 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6979 - val_prc: 0.3652\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6009 - tp: 249.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 149.0000 - accuracy: 0.6986 - precision: 0.3507 - recall: 0.6256 - auc: 0.7357 - prc: 0.4420 - val_loss: 0.6186 - val_tp: 57.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 34.0000 - val_accuracy: 0.6640 - val_precision: 0.2953 - val_recall: 0.6264 - val_auc: 0.6995 - val_prc: 0.3772\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6013 - tp: 250.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 148.0000 - accuracy: 0.6966 - precision: 0.3492 - recall: 0.6281 - auc: 0.7355 - prc: 0.4391 - val_loss: 0.5991 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6956 - val_prc: 0.3661\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6016 - tp: 253.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 145.0000 - accuracy: 0.7060 - precision: 0.3599 - recall: 0.6357 - auc: 0.7346 - prc: 0.4434 - val_loss: 0.5871 - val_tp: 51.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 40.0000 - val_accuracy: 0.7253 - val_precision: 0.3400 - val_recall: 0.5604 - val_auc: 0.6982 - val_prc: 0.3731\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5999 - tp: 252.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 146.0000 - accuracy: 0.6932 - precision: 0.3466 - recall: 0.6332 - auc: 0.7375 - prc: 0.4427 - val_loss: 0.6068 - val_tp: 54.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 37.0000 - val_accuracy: 0.6937 - val_precision: 0.3140 - val_recall: 0.5934 - val_auc: 0.6969 - val_prc: 0.3604\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6005 - tp: 243.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 155.0000 - accuracy: 0.7090 - precision: 0.3589 - recall: 0.6106 - auc: 0.7367 - prc: 0.4451 - val_loss: 0.5926 - val_tp: 51.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 40.0000 - val_accuracy: 0.7055 - val_precision: 0.3187 - val_recall: 0.5604 - val_auc: 0.6997 - val_prc: 0.3627\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6034 - tp: 261.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 137.0000 - accuracy: 0.6966 - precision: 0.3537 - recall: 0.6558 - auc: 0.7329 - prc: 0.4323 - val_loss: 0.6187 - val_tp: 57.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 34.0000 - val_accuracy: 0.6700 - val_precision: 0.3000 - val_recall: 0.6264 - val_auc: 0.6989 - val_prc: 0.3728\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6022 - tp: 250.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 148.0000 - accuracy: 0.7055 - precision: 0.3582 - recall: 0.6281 - auc: 0.7341 - prc: 0.4488 - val_loss: 0.5575 - val_tp: 48.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 43.0000 - val_accuracy: 0.7549 - val_precision: 0.3721 - val_recall: 0.5275 - val_auc: 0.6997 - val_prc: 0.3712\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6005 - tp: 254.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 144.0000 - accuracy: 0.6932 - precision: 0.3475 - recall: 0.6382 - auc: 0.7372 - prc: 0.4402 - val_loss: 0.5895 - val_tp: 51.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 40.0000 - val_accuracy: 0.7213 - val_precision: 0.3355 - val_recall: 0.5604 - val_auc: 0.6987 - val_prc: 0.3697\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5995 - tp: 259.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 139.0000 - accuracy: 0.6922 - precision: 0.3486 - recall: 0.6508 - auc: 0.7377 - prc: 0.4478 - val_loss: 0.6090 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6951 - val_prc: 0.3693\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5994 - tp: 247.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 151.0000 - accuracy: 0.7184 - precision: 0.3709 - recall: 0.6206 - auc: 0.7363 - prc: 0.4536 - val_loss: 0.6395 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6994 - val_prc: 0.3770\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6007 - tp: 254.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 144.0000 - accuracy: 0.6833 - precision: 0.3382 - recall: 0.6382 - auc: 0.7347 - prc: 0.4402 - val_loss: 0.6076 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6941 - val_prc: 0.3695\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5981 - tp: 257.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 141.0000 - accuracy: 0.6863 - precision: 0.3422 - recall: 0.6457 - auc: 0.7390 - prc: 0.4444 - val_loss: 0.5379 - val_tp: 45.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 46.0000 - val_accuracy: 0.7648 - val_precision: 0.3814 - val_recall: 0.4945 - val_auc: 0.6999 - val_prc: 0.3653\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6057 - tp: 240.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 158.0000 - accuracy: 0.7134 - precision: 0.3625 - recall: 0.6030 - auc: 0.7306 - prc: 0.4292 - val_loss: 0.6356 - val_tp: 57.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 34.0000 - val_accuracy: 0.6403 - val_precision: 0.2780 - val_recall: 0.6264 - val_auc: 0.6964 - val_prc: 0.3713\n",
      "Epoch 152/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6004 - tp: 258.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 140.0000 - accuracy: 0.7021 - precision: 0.3578 - recall: 0.6482 - auc: 0.7359 - prc: 0.4505 - val_loss: 0.6364 - val_tp: 58.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 33.0000 - val_accuracy: 0.6423 - val_precision: 0.2816 - val_recall: 0.6374 - val_auc: 0.6987 - val_prc: 0.3796\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6010 - tp: 246.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 152.0000 - accuracy: 0.7036 - precision: 0.3545 - recall: 0.6181 - auc: 0.7343 - prc: 0.4351 - val_loss: 0.5917 - val_tp: 53.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 38.0000 - val_accuracy: 0.7134 - val_precision: 0.3313 - val_recall: 0.5824 - val_auc: 0.7026 - val_prc: 0.3790\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5990 - tp: 245.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 153.0000 - accuracy: 0.7026 - precision: 0.3530 - recall: 0.6156 - auc: 0.7377 - prc: 0.4509 - val_loss: 0.5587 - val_tp: 47.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 44.0000 - val_accuracy: 0.7490 - val_precision: 0.3615 - val_recall: 0.5165 - val_auc: 0.7018 - val_prc: 0.3731\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6004 - tp: 252.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 146.0000 - accuracy: 0.7065 - precision: 0.3600 - recall: 0.6332 - auc: 0.7353 - prc: 0.4475 - val_loss: 0.6147 - val_tp: 56.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 35.0000 - val_accuracy: 0.6798 - val_precision: 0.3060 - val_recall: 0.6154 - val_auc: 0.7002 - val_prc: 0.3734\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6003 - tp: 255.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 143.0000 - accuracy: 0.6863 - precision: 0.3414 - recall: 0.6407 - auc: 0.7352 - prc: 0.4445 - val_loss: 0.5451 - val_tp: 46.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 45.0000 - val_accuracy: 0.7628 - val_precision: 0.3802 - val_recall: 0.5055 - val_auc: 0.7014 - val_prc: 0.3723\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6004 - tp: 245.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 153.0000 - accuracy: 0.7139 - precision: 0.3651 - recall: 0.6156 - auc: 0.7360 - prc: 0.4450 - val_loss: 0.5974 - val_tp: 52.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 39.0000 - val_accuracy: 0.6996 - val_precision: 0.3152 - val_recall: 0.5714 - val_auc: 0.6991 - val_prc: 0.3733\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5983 - tp: 243.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 155.0000 - accuracy: 0.7055 - precision: 0.3553 - recall: 0.6106 - auc: 0.7387 - prc: 0.4444 - val_loss: 0.6585 - val_tp: 58.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 33.0000 - val_accuracy: 0.6047 - val_precision: 0.2578 - val_recall: 0.6374 - val_auc: 0.6994 - val_prc: 0.3782\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5994 - tp: 258.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 140.0000 - accuracy: 0.6961 - precision: 0.3520 - recall: 0.6482 - auc: 0.7375 - prc: 0.4390 - val_loss: 0.5639 - val_tp: 47.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 44.0000 - val_accuracy: 0.7451 - val_precision: 0.3561 - val_recall: 0.5165 - val_auc: 0.7012 - val_prc: 0.3691\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5984 - tp: 248.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 150.0000 - accuracy: 0.7070 - precision: 0.3589 - recall: 0.6231 - auc: 0.7383 - prc: 0.4435 - val_loss: 0.5900 - val_tp: 53.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 38.0000 - val_accuracy: 0.7115 - val_precision: 0.3292 - val_recall: 0.5824 - val_auc: 0.7019 - val_prc: 0.3751\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5962 - tp: 254.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 144.0000 - accuracy: 0.7011 - precision: 0.3552 - recall: 0.6382 - auc: 0.7408 - prc: 0.4527 - val_loss: 0.5742 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.6996 - val_prc: 0.3711\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6000 - tp: 257.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 141.0000 - accuracy: 0.6848 - precision: 0.3408 - recall: 0.6457 - auc: 0.7359 - prc: 0.4389 - val_loss: 0.5798 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.7015 - val_prc: 0.3763\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5985 - tp: 248.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 150.0000 - accuracy: 0.6981 - precision: 0.3498 - recall: 0.6231 - auc: 0.7383 - prc: 0.4468 - val_loss: 0.5838 - val_tp: 50.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.7174 - val_precision: 0.3289 - val_recall: 0.5495 - val_auc: 0.7001 - val_prc: 0.3716\n",
      "Epoch 164/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5983 - tp: 251.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 147.0000 - accuracy: 0.7070 - precision: 0.3601 - recall: 0.6307 - auc: 0.7382 - prc: 0.4497 - val_loss: 0.6183 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.7006 - val_prc: 0.3738\n",
      "Epoch 165/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5991 - tp: 243.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 155.0000 - accuracy: 0.7169 - precision: 0.3676 - recall: 0.6106 - auc: 0.7374 - prc: 0.4585 - val_loss: 0.6276 - val_tp: 57.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 34.0000 - val_accuracy: 0.6601 - val_precision: 0.2923 - val_recall: 0.6264 - val_auc: 0.7011 - val_prc: 0.3744\n",
      "Epoch 166/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5962 - tp: 258.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 140.0000 - accuracy: 0.6961 - precision: 0.3520 - recall: 0.6482 - auc: 0.7417 - prc: 0.4438 - val_loss: 0.6522 - val_tp: 59.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 32.0000 - val_accuracy: 0.6324 - val_precision: 0.2770 - val_recall: 0.6484 - val_auc: 0.6995 - val_prc: 0.3783\n",
      "Epoch 167/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5953 - tp: 252.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 146.0000 - accuracy: 0.7001 - precision: 0.3534 - recall: 0.6332 - auc: 0.7426 - prc: 0.4582 - val_loss: 0.5975 - val_tp: 53.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 38.0000 - val_accuracy: 0.6957 - val_precision: 0.3136 - val_recall: 0.5824 - val_auc: 0.7026 - val_prc: 0.3777\n",
      "Epoch 168/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5984 - tp: 250.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 148.0000 - accuracy: 0.6996 - precision: 0.3521 - recall: 0.6281 - auc: 0.7365 - prc: 0.4595 - val_loss: 0.5705 - val_tp: 49.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 42.0000 - val_accuracy: 0.7451 - val_precision: 0.3603 - val_recall: 0.5385 - val_auc: 0.7033 - val_prc: 0.3788\n",
      "Epoch 169/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5960 - tp: 250.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 148.0000 - accuracy: 0.7129 - precision: 0.3660 - recall: 0.6281 - auc: 0.7408 - prc: 0.4526 - val_loss: 0.5972 - val_tp: 53.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 38.0000 - val_accuracy: 0.6976 - val_precision: 0.3155 - val_recall: 0.5824 - val_auc: 0.7021 - val_prc: 0.3779\n",
      "Epoch 170/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5966 - tp: 254.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 144.0000 - accuracy: 0.7090 - precision: 0.3634 - recall: 0.6382 - auc: 0.7398 - prc: 0.4570 - val_loss: 0.5942 - val_tp: 53.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 38.0000 - val_accuracy: 0.7055 - val_precision: 0.3232 - val_recall: 0.5824 - val_auc: 0.7027 - val_prc: 0.3780\n",
      "Epoch 171/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5966 - tp: 244.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 154.0000 - accuracy: 0.7060 - precision: 0.3562 - recall: 0.6131 - auc: 0.7384 - prc: 0.4456 - val_loss: 0.6178 - val_tp: 55.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 36.0000 - val_accuracy: 0.6759 - val_precision: 0.3005 - val_recall: 0.6044 - val_auc: 0.7002 - val_prc: 0.3765\n",
      "Epoch 172/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5973 - tp: 251.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 147.0000 - accuracy: 0.7085 - precision: 0.3617 - recall: 0.6307 - auc: 0.7393 - prc: 0.4556 - val_loss: 0.6129 - val_tp: 56.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 35.0000 - val_accuracy: 0.6759 - val_precision: 0.3027 - val_recall: 0.6154 - val_auc: 0.7009 - val_prc: 0.3757\n",
      "Epoch 173/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5986 - tp: 246.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 152.0000 - accuracy: 0.7070 - precision: 0.3581 - recall: 0.6181 - auc: 0.7359 - prc: 0.4552 - val_loss: 0.6386 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6997 - val_prc: 0.3733\n",
      "Epoch 174/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5969 - tp: 255.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 143.0000 - accuracy: 0.7006 - precision: 0.3552 - recall: 0.6407 - auc: 0.7401 - prc: 0.4534 - val_loss: 0.5958 - val_tp: 52.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 39.0000 - val_accuracy: 0.7016 - val_precision: 0.3171 - val_recall: 0.5714 - val_auc: 0.7018 - val_prc: 0.3766\n",
      "Epoch 175/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5968 - tp: 260.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 138.0000 - accuracy: 0.7031 - precision: 0.3596 - recall: 0.6533 - auc: 0.7397 - prc: 0.4546 - val_loss: 0.5963 - val_tp: 55.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 36.0000 - val_accuracy: 0.7154 - val_precision: 0.3374 - val_recall: 0.6044 - val_auc: 0.7024 - val_prc: 0.3776\n",
      "Epoch 176/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5970 - tp: 251.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 147.0000 - accuracy: 0.7031 - precision: 0.3560 - recall: 0.6307 - auc: 0.7407 - prc: 0.4438 - val_loss: 0.5669 - val_tp: 49.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 42.0000 - val_accuracy: 0.7411 - val_precision: 0.3551 - val_recall: 0.5385 - val_auc: 0.7011 - val_prc: 0.3729\n",
      "Epoch 177/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5948 - tp: 248.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 150.0000 - accuracy: 0.6976 - precision: 0.3493 - recall: 0.6231 - auc: 0.7419 - prc: 0.4552 - val_loss: 0.6400 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6983 - val_prc: 0.3751\n",
      "Epoch 178/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5979 - tp: 251.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 147.0000 - accuracy: 0.7001 - precision: 0.3530 - recall: 0.6307 - auc: 0.7384 - prc: 0.4594 - val_loss: 0.6195 - val_tp: 57.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 34.0000 - val_accuracy: 0.6719 - val_precision: 0.3016 - val_recall: 0.6264 - val_auc: 0.7015 - val_prc: 0.3765\n",
      "Epoch 179/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5976 - tp: 253.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 145.0000 - accuracy: 0.6996 - precision: 0.3534 - recall: 0.6357 - auc: 0.7387 - prc: 0.4508 - val_loss: 0.6120 - val_tp: 55.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 36.0000 - val_accuracy: 0.6858 - val_precision: 0.3090 - val_recall: 0.6044 - val_auc: 0.7014 - val_prc: 0.3734\n",
      "Epoch 180/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5950 - tp: 257.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 141.0000 - accuracy: 0.6922 - precision: 0.3478 - recall: 0.6457 - auc: 0.7400 - prc: 0.4532 - val_loss: 0.6247 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.7023 - val_prc: 0.3735\n",
      "Epoch 181/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5940 - tp: 261.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 137.0000 - accuracy: 0.6952 - precision: 0.3522 - recall: 0.6558 - auc: 0.7431 - prc: 0.4587 - val_loss: 0.5490 - val_tp: 45.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 46.0000 - val_accuracy: 0.7628 - val_precision: 0.3782 - val_recall: 0.4945 - val_auc: 0.7022 - val_prc: 0.3673\n",
      "Epoch 182/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5969 - tp: 244.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 154.0000 - accuracy: 0.7125 - precision: 0.3631 - recall: 0.6131 - auc: 0.7398 - prc: 0.4380 - val_loss: 0.6464 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6998 - val_prc: 0.3737\n",
      "Epoch 183/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5993 - tp: 254.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 144.0000 - accuracy: 0.6976 - precision: 0.3518 - recall: 0.6382 - auc: 0.7366 - prc: 0.4394 - val_loss: 0.6206 - val_tp: 57.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 34.0000 - val_accuracy: 0.6719 - val_precision: 0.3016 - val_recall: 0.6264 - val_auc: 0.7023 - val_prc: 0.3799\n",
      "Epoch 184/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5956 - tp: 252.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 146.0000 - accuracy: 0.6957 - precision: 0.3490 - recall: 0.6332 - auc: 0.7398 - prc: 0.4540 - val_loss: 0.5603 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.7032 - val_prc: 0.3787\n",
      "Epoch 185/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5956 - tp: 250.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 148.0000 - accuracy: 0.7129 - precision: 0.3660 - recall: 0.6281 - auc: 0.7406 - prc: 0.4552 - val_loss: 0.6149 - val_tp: 55.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 36.0000 - val_accuracy: 0.6779 - val_precision: 0.3022 - val_recall: 0.6044 - val_auc: 0.7012 - val_prc: 0.3774\n",
      "Epoch 186/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5953 - tp: 255.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 143.0000 - accuracy: 0.6971 - precision: 0.3517 - recall: 0.6407 - auc: 0.7386 - prc: 0.4604 - val_loss: 0.6456 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.6998 - val_prc: 0.3743\n",
      "Epoch 187/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5967 - tp: 250.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 148.0000 - accuracy: 0.7129 - precision: 0.3660 - recall: 0.6281 - auc: 0.7388 - prc: 0.4545 - val_loss: 0.6180 - val_tp: 56.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 35.0000 - val_accuracy: 0.6798 - val_precision: 0.3060 - val_recall: 0.6154 - val_auc: 0.7017 - val_prc: 0.3731\n",
      "Epoch 188/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5967 - tp: 245.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 153.0000 - accuracy: 0.7026 - precision: 0.3530 - recall: 0.6156 - auc: 0.7387 - prc: 0.4543 - val_loss: 0.6079 - val_tp: 55.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 36.0000 - val_accuracy: 0.6858 - val_precision: 0.3090 - val_recall: 0.6044 - val_auc: 0.7032 - val_prc: 0.3815\n",
      "Epoch 189/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5942 - tp: 246.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 152.0000 - accuracy: 0.7055 - precision: 0.3565 - recall: 0.6181 - auc: 0.7400 - prc: 0.4564 - val_loss: 0.6204 - val_tp: 56.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 35.0000 - val_accuracy: 0.6759 - val_precision: 0.3027 - val_recall: 0.6154 - val_auc: 0.7016 - val_prc: 0.3784\n",
      "Epoch 190/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5956 - tp: 251.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 147.0000 - accuracy: 0.7075 - precision: 0.3606 - recall: 0.6307 - auc: 0.7393 - prc: 0.4531 - val_loss: 0.5999 - val_tp: 53.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 38.0000 - val_accuracy: 0.6976 - val_precision: 0.3155 - val_recall: 0.5824 - val_auc: 0.7028 - val_prc: 0.3767\n",
      "Epoch 191/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5937 - tp: 250.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 148.0000 - accuracy: 0.7036 - precision: 0.3561 - recall: 0.6281 - auc: 0.7434 - prc: 0.4555 - val_loss: 0.5983 - val_tp: 52.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 39.0000 - val_accuracy: 0.6937 - val_precision: 0.3095 - val_recall: 0.5714 - val_auc: 0.7021 - val_prc: 0.3729\n",
      "Epoch 192/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5957 - tp: 247.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 151.0000 - accuracy: 0.6957 - precision: 0.3469 - recall: 0.6206 - auc: 0.7409 - prc: 0.4541 - val_loss: 0.6026 - val_tp: 54.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 37.0000 - val_accuracy: 0.6976 - val_precision: 0.3176 - val_recall: 0.5934 - val_auc: 0.7037 - val_prc: 0.3782\n",
      "Epoch 193/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5942 - tp: 252.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 146.0000 - accuracy: 0.7149 - precision: 0.3690 - recall: 0.6332 - auc: 0.7424 - prc: 0.4598 - val_loss: 0.5794 - val_tp: 51.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 40.0000 - val_accuracy: 0.7312 - val_precision: 0.3469 - val_recall: 0.5604 - val_auc: 0.7035 - val_prc: 0.3819\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5963 - tp: 252.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 146.0000 - accuracy: 0.7100 - precision: 0.3636 - recall: 0.6332 - auc: 0.7397 - prc: 0.4483 - val_loss: 0.6228 - val_tp: 56.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 35.0000 - val_accuracy: 0.6700 - val_precision: 0.2979 - val_recall: 0.6154 - val_auc: 0.7027 - val_prc: 0.3769\n",
      "Epoch 195/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5929 - tp: 253.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 145.0000 - accuracy: 0.7075 - precision: 0.3614 - recall: 0.6357 - auc: 0.7431 - prc: 0.4586 - val_loss: 0.6635 - val_tp: 61.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 30.0000 - val_accuracy: 0.6047 - val_precision: 0.2641 - val_recall: 0.6703 - val_auc: 0.7003 - val_prc: 0.3870\n",
      "Epoch 196/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5948 - tp: 257.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 141.0000 - accuracy: 0.6932 - precision: 0.3487 - recall: 0.6457 - auc: 0.7417 - prc: 0.4551 - val_loss: 0.5830 - val_tp: 51.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 40.0000 - val_accuracy: 0.7273 - val_precision: 0.3423 - val_recall: 0.5604 - val_auc: 0.7040 - val_prc: 0.3829\n",
      "Epoch 197/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5946 - tp: 245.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 153.0000 - accuracy: 0.7021 - precision: 0.3525 - recall: 0.6156 - auc: 0.7402 - prc: 0.4495 - val_loss: 0.6106 - val_tp: 54.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 37.0000 - val_accuracy: 0.6858 - val_precision: 0.3068 - val_recall: 0.5934 - val_auc: 0.7034 - val_prc: 0.3771\n",
      "Epoch 198/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5948 - tp: 255.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 143.0000 - accuracy: 0.7100 - precision: 0.3648 - recall: 0.6407 - auc: 0.7413 - prc: 0.4495 - val_loss: 0.6143 - val_tp: 55.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 36.0000 - val_accuracy: 0.6798 - val_precision: 0.3039 - val_recall: 0.6044 - val_auc: 0.7035 - val_prc: 0.3702\n",
      "Epoch 199/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5978 - tp: 252.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 146.0000 - accuracy: 0.6942 - precision: 0.3476 - recall: 0.6332 - auc: 0.7361 - prc: 0.4481 - val_loss: 0.5973 - val_tp: 54.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 37.0000 - val_accuracy: 0.7036 - val_precision: 0.3234 - val_recall: 0.5934 - val_auc: 0.7044 - val_prc: 0.3818\n",
      "Epoch 200/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5972 - tp: 249.0000 - fp: 429.0000 - tn: 1197.0000 - fn: 149.0000 - accuracy: 0.7144 - precision: 0.3673 - recall: 0.6256 - auc: 0.7380 - prc: 0.4507 - val_loss: 0.5684 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.7053 - val_prc: 0.3786\n",
      "Epoch 201/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5942 - tp: 248.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 150.0000 - accuracy: 0.7050 - precision: 0.3568 - recall: 0.6231 - auc: 0.7412 - prc: 0.4619 - val_loss: 0.6073 - val_tp: 54.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 37.0000 - val_accuracy: 0.6917 - val_precision: 0.3121 - val_recall: 0.5934 - val_auc: 0.7037 - val_prc: 0.3770\n",
      "Epoch 202/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5943 - tp: 244.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 154.0000 - accuracy: 0.7110 - precision: 0.3615 - recall: 0.6131 - auc: 0.7402 - prc: 0.4599 - val_loss: 0.6134 - val_tp: 56.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 35.0000 - val_accuracy: 0.6877 - val_precision: 0.3128 - val_recall: 0.6154 - val_auc: 0.7039 - val_prc: 0.3787\n",
      "Epoch 203/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5949 - tp: 254.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 144.0000 - accuracy: 0.7006 - precision: 0.3547 - recall: 0.6382 - auc: 0.7405 - prc: 0.4572 - val_loss: 0.5603 - val_tp: 47.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 44.0000 - val_accuracy: 0.7490 - val_precision: 0.3615 - val_recall: 0.5165 - val_auc: 0.7060 - val_prc: 0.3754\n",
      "Epoch 204/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5931 - tp: 261.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 137.0000 - accuracy: 0.7031 - precision: 0.3600 - recall: 0.6558 - auc: 0.7432 - prc: 0.4503 - val_loss: 0.5740 - val_tp: 48.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 43.0000 - val_accuracy: 0.7352 - val_precision: 0.3453 - val_recall: 0.5275 - val_auc: 0.7039 - val_prc: 0.3834\n",
      "Epoch 205/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5951 - tp: 253.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 145.0000 - accuracy: 0.6976 - precision: 0.3514 - recall: 0.6357 - auc: 0.7407 - prc: 0.4446 - val_loss: 0.5356 - val_tp: 45.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 46.0000 - val_accuracy: 0.7747 - val_precision: 0.3982 - val_recall: 0.4945 - val_auc: 0.7065 - val_prc: 0.3882\n",
      "Epoch 206/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5944 - tp: 254.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 144.0000 - accuracy: 0.7026 - precision: 0.3567 - recall: 0.6382 - auc: 0.7414 - prc: 0.4552 - val_loss: 0.5623 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.7051 - val_prc: 0.3768\n",
      "Epoch 207/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5960 - tp: 254.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 144.0000 - accuracy: 0.7031 - precision: 0.3572 - recall: 0.6382 - auc: 0.7389 - prc: 0.4468 - val_loss: 0.5741 - val_tp: 50.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 41.0000 - val_accuracy: 0.7372 - val_precision: 0.3521 - val_recall: 0.5495 - val_auc: 0.7045 - val_prc: 0.3792\n",
      "Epoch 208/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5936 - tp: 255.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 143.0000 - accuracy: 0.7085 - precision: 0.3632 - recall: 0.6407 - auc: 0.7419 - prc: 0.4537 - val_loss: 0.5877 - val_tp: 53.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 38.0000 - val_accuracy: 0.7174 - val_precision: 0.3354 - val_recall: 0.5824 - val_auc: 0.7052 - val_prc: 0.3842\n",
      "Epoch 209/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5956 - tp: 247.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 151.0000 - accuracy: 0.7085 - precision: 0.3601 - recall: 0.6206 - auc: 0.7384 - prc: 0.4572 - val_loss: 0.6789 - val_tp: 62.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 29.0000 - val_accuracy: 0.5870 - val_precision: 0.2562 - val_recall: 0.6813 - val_auc: 0.7005 - val_prc: 0.3866\n",
      "Epoch 210/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5947 - tp: 253.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 145.0000 - accuracy: 0.6986 - precision: 0.3524 - recall: 0.6357 - auc: 0.7412 - prc: 0.4537 - val_loss: 0.5585 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.7050 - val_prc: 0.3793\n",
      "Epoch 211/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5930 - tp: 247.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 151.0000 - accuracy: 0.7169 - precision: 0.3692 - recall: 0.6206 - auc: 0.7411 - prc: 0.4633 - val_loss: 0.6012 - val_tp: 55.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 36.0000 - val_accuracy: 0.7075 - val_precision: 0.3293 - val_recall: 0.6044 - val_auc: 0.7023 - val_prc: 0.3789\n",
      "Epoch 212/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5947 - tp: 256.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 142.0000 - accuracy: 0.7031 - precision: 0.3580 - recall: 0.6432 - auc: 0.7416 - prc: 0.4546 - val_loss: 0.5920 - val_tp: 51.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 40.0000 - val_accuracy: 0.7115 - val_precision: 0.3248 - val_recall: 0.5604 - val_auc: 0.7019 - val_prc: 0.3803\n",
      "Epoch 213/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5964 - tp: 250.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 148.0000 - accuracy: 0.7055 - precision: 0.3582 - recall: 0.6281 - auc: 0.7387 - prc: 0.4404 - val_loss: 0.6205 - val_tp: 56.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 35.0000 - val_accuracy: 0.6779 - val_precision: 0.3043 - val_recall: 0.6154 - val_auc: 0.7035 - val_prc: 0.3812\n",
      "Epoch 214/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5932 - tp: 258.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 140.0000 - accuracy: 0.6932 - precision: 0.3491 - recall: 0.6482 - auc: 0.7425 - prc: 0.4598 - val_loss: 0.5573 - val_tp: 46.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 45.0000 - val_accuracy: 0.7530 - val_precision: 0.3651 - val_recall: 0.5055 - val_auc: 0.7052 - val_prc: 0.3840\n",
      "Epoch 215/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5948 - tp: 243.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 155.0000 - accuracy: 0.7194 - precision: 0.3704 - recall: 0.6106 - auc: 0.7400 - prc: 0.4611 - val_loss: 0.5994 - val_tp: 53.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 38.0000 - val_accuracy: 0.6996 - val_precision: 0.3174 - val_recall: 0.5824 - val_auc: 0.7046 - val_prc: 0.3857\n",
      "Epoch 216/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5930 - tp: 253.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 145.0000 - accuracy: 0.7060 - precision: 0.3599 - recall: 0.6357 - auc: 0.7419 - prc: 0.4570 - val_loss: 0.6416 - val_tp: 58.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 33.0000 - val_accuracy: 0.6364 - val_precision: 0.2775 - val_recall: 0.6374 - val_auc: 0.7028 - val_prc: 0.3825\n",
      "Epoch 217/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5938 - tp: 256.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 142.0000 - accuracy: 0.6927 - precision: 0.3478 - recall: 0.6432 - auc: 0.7430 - prc: 0.4577 - val_loss: 0.5722 - val_tp: 49.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 42.0000 - val_accuracy: 0.7332 - val_precision: 0.3451 - val_recall: 0.5385 - val_auc: 0.7067 - val_prc: 0.3805\n",
      "Epoch 218/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5932 - tp: 253.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 145.0000 - accuracy: 0.7095 - precision: 0.3635 - recall: 0.6357 - auc: 0.7424 - prc: 0.4551 - val_loss: 0.5764 - val_tp: 51.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 40.0000 - val_accuracy: 0.7292 - val_precision: 0.3446 - val_recall: 0.5604 - val_auc: 0.7062 - val_prc: 0.3815\n",
      "Epoch 219/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5938 - tp: 251.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 147.0000 - accuracy: 0.7100 - precision: 0.3632 - recall: 0.6307 - auc: 0.7424 - prc: 0.4575 - val_loss: 0.6632 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.6996 - val_prc: 0.3730\n",
      "Epoch 220/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5977 - tp: 253.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 145.0000 - accuracy: 0.6966 - precision: 0.3504 - recall: 0.6357 - auc: 0.7367 - prc: 0.4490 - val_loss: 0.5734 - val_tp: 49.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 42.0000 - val_accuracy: 0.7352 - val_precision: 0.3475 - val_recall: 0.5385 - val_auc: 0.7050 - val_prc: 0.3809\n",
      "Epoch 221/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5955 - tp: 248.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 150.0000 - accuracy: 0.6957 - precision: 0.3473 - recall: 0.6231 - auc: 0.7383 - prc: 0.4513 - val_loss: 0.5904 - val_tp: 53.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 38.0000 - val_accuracy: 0.7174 - val_precision: 0.3354 - val_recall: 0.5824 - val_auc: 0.7061 - val_prc: 0.3896\n",
      "Epoch 222/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5923 - tp: 250.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 148.0000 - accuracy: 0.7085 - precision: 0.3613 - recall: 0.6281 - auc: 0.7438 - prc: 0.4588 - val_loss: 0.6576 - val_tp: 59.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 32.0000 - val_accuracy: 0.6225 - val_precision: 0.2706 - val_recall: 0.6484 - val_auc: 0.7014 - val_prc: 0.3808\n",
      "Epoch 223/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5918 - tp: 255.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 143.0000 - accuracy: 0.7031 - precision: 0.3576 - recall: 0.6407 - auc: 0.7444 - prc: 0.4657 - val_loss: 0.6045 - val_tp: 54.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 37.0000 - val_accuracy: 0.6996 - val_precision: 0.3195 - val_recall: 0.5934 - val_auc: 0.7051 - val_prc: 0.3815\n",
      "Epoch 224/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5932 - tp: 256.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 142.0000 - accuracy: 0.6961 - precision: 0.3512 - recall: 0.6432 - auc: 0.7425 - prc: 0.4528 - val_loss: 0.6067 - val_tp: 54.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 37.0000 - val_accuracy: 0.6917 - val_precision: 0.3121 - val_recall: 0.5934 - val_auc: 0.7033 - val_prc: 0.3789\n",
      "Epoch 225/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5937 - tp: 261.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 137.0000 - accuracy: 0.6927 - precision: 0.3499 - recall: 0.6558 - auc: 0.7418 - prc: 0.4540 - val_loss: 0.5668 - val_tp: 49.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 42.0000 - val_accuracy: 0.7470 - val_precision: 0.3630 - val_recall: 0.5385 - val_auc: 0.7052 - val_prc: 0.3779\n",
      "Epoch 226/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5941 - tp: 242.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 156.0000 - accuracy: 0.7164 - precision: 0.3667 - recall: 0.6080 - auc: 0.7395 - prc: 0.4522 - val_loss: 0.6176 - val_tp: 55.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 36.0000 - val_accuracy: 0.6818 - val_precision: 0.3056 - val_recall: 0.6044 - val_auc: 0.7047 - val_prc: 0.3848\n",
      "Epoch 227/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5909 - tp: 259.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 139.0000 - accuracy: 0.7085 - precision: 0.3648 - recall: 0.6508 - auc: 0.7457 - prc: 0.4634 - val_loss: 0.5809 - val_tp: 51.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 40.0000 - val_accuracy: 0.7273 - val_precision: 0.3423 - val_recall: 0.5604 - val_auc: 0.7068 - val_prc: 0.3884\n",
      "Epoch 228/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5928 - tp: 254.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 144.0000 - accuracy: 0.7075 - precision: 0.3618 - recall: 0.6382 - auc: 0.7422 - prc: 0.4593 - val_loss: 0.6389 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.7038 - val_prc: 0.3874\n",
      "Epoch 229/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5938 - tp: 254.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 144.0000 - accuracy: 0.6952 - precision: 0.3494 - recall: 0.6382 - auc: 0.7417 - prc: 0.4529 - val_loss: 0.6343 - val_tp: 58.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 33.0000 - val_accuracy: 0.6561 - val_precision: 0.2915 - val_recall: 0.6374 - val_auc: 0.7029 - val_prc: 0.3866\n",
      "Epoch 230/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5900 - tp: 268.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 130.0000 - accuracy: 0.6813 - precision: 0.3423 - recall: 0.6734 - auc: 0.7475 - prc: 0.4609 - val_loss: 0.5073 - val_tp: 42.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 49.0000 - val_accuracy: 0.8024 - val_precision: 0.4516 - val_recall: 0.4615 - val_auc: 0.7054 - val_prc: 0.3942\n",
      "Epoch 231/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5962 - tp: 241.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 157.0000 - accuracy: 0.7036 - precision: 0.3523 - recall: 0.6055 - auc: 0.7367 - prc: 0.4583 - val_loss: 0.5599 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.7067 - val_prc: 0.3848\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5947 - tp: 252.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 146.0000 - accuracy: 0.7134 - precision: 0.3673 - recall: 0.6332 - auc: 0.7409 - prc: 0.4529 - val_loss: 0.6248 - val_tp: 57.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 34.0000 - val_accuracy: 0.6759 - val_precision: 0.3048 - val_recall: 0.6264 - val_auc: 0.7041 - val_prc: 0.3886\n",
      "Epoch 233/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5923 - tp: 256.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 142.0000 - accuracy: 0.6986 - precision: 0.3536 - recall: 0.6432 - auc: 0.7464 - prc: 0.4548 - val_loss: 0.5815 - val_tp: 50.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 41.0000 - val_accuracy: 0.7213 - val_precision: 0.3333 - val_recall: 0.5495 - val_auc: 0.7064 - val_prc: 0.3802\n",
      "Epoch 234/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5930 - tp: 253.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 145.0000 - accuracy: 0.7050 - precision: 0.3589 - recall: 0.6357 - auc: 0.7430 - prc: 0.4579 - val_loss: 0.6062 - val_tp: 55.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 36.0000 - val_accuracy: 0.6957 - val_precision: 0.3179 - val_recall: 0.6044 - val_auc: 0.7055 - val_prc: 0.3840\n",
      "Epoch 235/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5919 - tp: 248.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 150.0000 - accuracy: 0.7041 - precision: 0.3558 - recall: 0.6231 - auc: 0.7441 - prc: 0.4584 - val_loss: 0.5448 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.7053 - val_prc: 0.3801\n",
      "Epoch 236/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5951 - tp: 252.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 146.0000 - accuracy: 0.7011 - precision: 0.3544 - recall: 0.6332 - auc: 0.7394 - prc: 0.4471 - val_loss: 0.6263 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.7043 - val_prc: 0.3880\n",
      "Epoch 237/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5914 - tp: 247.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 151.0000 - accuracy: 0.7149 - precision: 0.3670 - recall: 0.6206 - auc: 0.7437 - prc: 0.4664 - val_loss: 0.5651 - val_tp: 49.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 42.0000 - val_accuracy: 0.7431 - val_precision: 0.3577 - val_recall: 0.5385 - val_auc: 0.7050 - val_prc: 0.3814\n",
      "Epoch 238/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5934 - tp: 255.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 143.0000 - accuracy: 0.7105 - precision: 0.3653 - recall: 0.6407 - auc: 0.7429 - prc: 0.4571 - val_loss: 0.6047 - val_tp: 55.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 36.0000 - val_accuracy: 0.7036 - val_precision: 0.3254 - val_recall: 0.6044 - val_auc: 0.7048 - val_prc: 0.3832\n",
      "Epoch 239/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5912 - tp: 256.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 142.0000 - accuracy: 0.7105 - precision: 0.3657 - recall: 0.6432 - auc: 0.7442 - prc: 0.4605 - val_loss: 0.6036 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.7047 - val_prc: 0.3845\n",
      "Epoch 240/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5948 - tp: 254.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 144.0000 - accuracy: 0.7060 - precision: 0.3603 - recall: 0.6382 - auc: 0.7397 - prc: 0.4455 - val_loss: 0.5778 - val_tp: 49.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 42.0000 - val_accuracy: 0.7312 - val_precision: 0.3427 - val_recall: 0.5385 - val_auc: 0.7046 - val_prc: 0.3856\n",
      "Epoch 241/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5928 - tp: 252.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 146.0000 - accuracy: 0.6961 - precision: 0.3495 - recall: 0.6332 - auc: 0.7409 - prc: 0.4431 - val_loss: 0.5621 - val_tp: 48.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 43.0000 - val_accuracy: 0.7490 - val_precision: 0.3636 - val_recall: 0.5275 - val_auc: 0.7069 - val_prc: 0.3770\n",
      "Epoch 242/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5928 - tp: 251.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 147.0000 - accuracy: 0.7036 - precision: 0.3565 - recall: 0.6307 - auc: 0.7416 - prc: 0.4537 - val_loss: 0.5978 - val_tp: 51.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 40.0000 - val_accuracy: 0.7075 - val_precision: 0.3208 - val_recall: 0.5604 - val_auc: 0.7029 - val_prc: 0.3816\n",
      "Epoch 243/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5901 - tp: 246.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 152.0000 - accuracy: 0.7070 - precision: 0.3581 - recall: 0.6181 - auc: 0.7464 - prc: 0.4584 - val_loss: 0.6669 - val_tp: 60.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 31.0000 - val_accuracy: 0.6225 - val_precision: 0.2727 - val_recall: 0.6593 - val_auc: 0.7010 - val_prc: 0.3798\n",
      "Epoch 244/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5921 - tp: 255.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 143.0000 - accuracy: 0.6877 - precision: 0.3427 - recall: 0.6407 - auc: 0.7452 - prc: 0.4565 - val_loss: 0.5693 - val_tp: 49.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 42.0000 - val_accuracy: 0.7411 - val_precision: 0.3551 - val_recall: 0.5385 - val_auc: 0.7039 - val_prc: 0.3820\n",
      "Epoch 245/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5895 - tp: 258.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 140.0000 - accuracy: 0.7011 - precision: 0.3568 - recall: 0.6482 - auc: 0.7463 - prc: 0.4635 - val_loss: 0.5436 - val_tp: 45.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 46.0000 - val_accuracy: 0.7609 - val_precision: 0.3750 - val_recall: 0.4945 - val_auc: 0.7048 - val_prc: 0.3767\n",
      "Epoch 246/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5924 - tp: 255.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 143.0000 - accuracy: 0.7139 - precision: 0.3690 - recall: 0.6407 - auc: 0.7450 - prc: 0.4461 - val_loss: 0.5715 - val_tp: 50.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 41.0000 - val_accuracy: 0.7352 - val_precision: 0.3497 - val_recall: 0.5495 - val_auc: 0.7072 - val_prc: 0.3888\n",
      "Epoch 247/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5912 - tp: 243.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 155.0000 - accuracy: 0.7208 - precision: 0.3721 - recall: 0.6106 - auc: 0.7441 - prc: 0.4550 - val_loss: 0.7019 - val_tp: 65.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 26.0000 - val_accuracy: 0.5751 - val_precision: 0.2559 - val_recall: 0.7143 - val_auc: 0.7003 - val_prc: 0.3841\n",
      "Epoch 248/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5971 - tp: 243.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 155.0000 - accuracy: 0.6971 - precision: 0.3466 - recall: 0.6106 - auc: 0.7345 - prc: 0.4523 - val_loss: 0.6247 - val_tp: 56.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 35.0000 - val_accuracy: 0.6798 - val_precision: 0.3060 - val_recall: 0.6154 - val_auc: 0.7034 - val_prc: 0.3862\n",
      "Epoch 249/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5915 - tp: 253.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 145.0000 - accuracy: 0.7026 - precision: 0.3563 - recall: 0.6357 - auc: 0.7431 - prc: 0.4600 - val_loss: 0.5776 - val_tp: 50.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 41.0000 - val_accuracy: 0.7332 - val_precision: 0.3472 - val_recall: 0.5495 - val_auc: 0.7063 - val_prc: 0.3845\n",
      "Epoch 250/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5916 - tp: 243.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 155.0000 - accuracy: 0.7085 - precision: 0.3584 - recall: 0.6106 - auc: 0.7441 - prc: 0.4519 - val_loss: 0.6277 - val_tp: 57.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 34.0000 - val_accuracy: 0.6680 - val_precision: 0.2984 - val_recall: 0.6264 - val_auc: 0.7068 - val_prc: 0.3868\n",
      "Epoch 251/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5914 - tp: 248.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 150.0000 - accuracy: 0.7050 - precision: 0.3568 - recall: 0.6231 - auc: 0.7449 - prc: 0.4558 - val_loss: 0.6204 - val_tp: 57.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 34.0000 - val_accuracy: 0.6838 - val_precision: 0.3115 - val_recall: 0.6264 - val_auc: 0.7073 - val_prc: 0.3901\n",
      "Epoch 252/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5913 - tp: 249.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 149.0000 - accuracy: 0.7100 - precision: 0.3624 - recall: 0.6256 - auc: 0.7441 - prc: 0.4617 - val_loss: 0.6013 - val_tp: 54.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 37.0000 - val_accuracy: 0.7154 - val_precision: 0.3354 - val_recall: 0.5934 - val_auc: 0.7049 - val_prc: 0.3853\n",
      "Epoch 253/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5914 - tp: 256.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 142.0000 - accuracy: 0.7041 - precision: 0.3590 - recall: 0.6432 - auc: 0.7427 - prc: 0.4599 - val_loss: 0.5736 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.7061 - val_prc: 0.3845\n",
      "Epoch 254/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5901 - tp: 251.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 147.0000 - accuracy: 0.6937 - precision: 0.3467 - recall: 0.6307 - auc: 0.7472 - prc: 0.4547 - val_loss: 0.6073 - val_tp: 53.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 38.0000 - val_accuracy: 0.6996 - val_precision: 0.3174 - val_recall: 0.5824 - val_auc: 0.7054 - val_prc: 0.3826\n",
      "Epoch 255/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5907 - tp: 257.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 141.0000 - accuracy: 0.7085 - precision: 0.3640 - recall: 0.6457 - auc: 0.7447 - prc: 0.4557 - val_loss: 0.5798 - val_tp: 50.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 41.0000 - val_accuracy: 0.7292 - val_precision: 0.3425 - val_recall: 0.5495 - val_auc: 0.7061 - val_prc: 0.3827\n",
      "Epoch 256/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5916 - tp: 255.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 143.0000 - accuracy: 0.7001 - precision: 0.3547 - recall: 0.6407 - auc: 0.7438 - prc: 0.4524 - val_loss: 0.5483 - val_tp: 46.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 45.0000 - val_accuracy: 0.7648 - val_precision: 0.3833 - val_recall: 0.5055 - val_auc: 0.7078 - val_prc: 0.3949\n",
      "Epoch 257/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5915 - tp: 248.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 150.0000 - accuracy: 0.7095 - precision: 0.3615 - recall: 0.6231 - auc: 0.7437 - prc: 0.4581 - val_loss: 0.6085 - val_tp: 55.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 36.0000 - val_accuracy: 0.7016 - val_precision: 0.3235 - val_recall: 0.6044 - val_auc: 0.7055 - val_prc: 0.3882\n",
      "Epoch 258/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5920 - tp: 248.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 150.0000 - accuracy: 0.6981 - precision: 0.3498 - recall: 0.6231 - auc: 0.7438 - prc: 0.4514 - val_loss: 0.6004 - val_tp: 53.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 38.0000 - val_accuracy: 0.7075 - val_precision: 0.3252 - val_recall: 0.5824 - val_auc: 0.7052 - val_prc: 0.3859\n",
      "Epoch 259/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5915 - tp: 253.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 145.0000 - accuracy: 0.6981 - precision: 0.3519 - recall: 0.6357 - auc: 0.7434 - prc: 0.4518 - val_loss: 0.5993 - val_tp: 52.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 39.0000 - val_accuracy: 0.7055 - val_precision: 0.3210 - val_recall: 0.5714 - val_auc: 0.7031 - val_prc: 0.3861\n",
      "Epoch 260/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5887 - tp: 249.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 149.0000 - accuracy: 0.7218 - precision: 0.3756 - recall: 0.6256 - auc: 0.7473 - prc: 0.4713 - val_loss: 0.6372 - val_tp: 58.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 33.0000 - val_accuracy: 0.6581 - val_precision: 0.2929 - val_recall: 0.6374 - val_auc: 0.7040 - val_prc: 0.3929\n",
      "Epoch 261/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5919 - tp: 254.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 144.0000 - accuracy: 0.6887 - precision: 0.3432 - recall: 0.6382 - auc: 0.7444 - prc: 0.4427 - val_loss: 0.5334 - val_tp: 45.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 46.0000 - val_accuracy: 0.7668 - val_precision: 0.3846 - val_recall: 0.4945 - val_auc: 0.7064 - val_prc: 0.3984\n",
      "Epoch 262/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5920 - tp: 249.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 149.0000 - accuracy: 0.7095 - precision: 0.3619 - recall: 0.6256 - auc: 0.7427 - prc: 0.4597 - val_loss: 0.5706 - val_tp: 49.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 42.0000 - val_accuracy: 0.7352 - val_precision: 0.3475 - val_recall: 0.5385 - val_auc: 0.7062 - val_prc: 0.3973\n",
      "Epoch 263/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5902 - tp: 249.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 149.0000 - accuracy: 0.7090 - precision: 0.3614 - recall: 0.6256 - auc: 0.7443 - prc: 0.4655 - val_loss: 0.5756 - val_tp: 50.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 41.0000 - val_accuracy: 0.7332 - val_precision: 0.3472 - val_recall: 0.5495 - val_auc: 0.7075 - val_prc: 0.3872\n",
      "Epoch 264/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5919 - tp: 252.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 146.0000 - accuracy: 0.7055 - precision: 0.3590 - recall: 0.6332 - auc: 0.7433 - prc: 0.4596 - val_loss: 0.5679 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.7055 - val_prc: 0.3909\n",
      "Epoch 265/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5902 - tp: 252.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 146.0000 - accuracy: 0.7110 - precision: 0.3647 - recall: 0.6332 - auc: 0.7460 - prc: 0.4615 - val_loss: 0.6329 - val_tp: 60.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 31.0000 - val_accuracy: 0.6719 - val_precision: 0.3077 - val_recall: 0.6593 - val_auc: 0.7050 - val_prc: 0.3904\n",
      "Epoch 266/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5909 - tp: 254.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 144.0000 - accuracy: 0.7045 - precision: 0.3588 - recall: 0.6382 - auc: 0.7444 - prc: 0.4638 - val_loss: 0.6172 - val_tp: 54.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 37.0000 - val_accuracy: 0.6897 - val_precision: 0.3103 - val_recall: 0.5934 - val_auc: 0.7035 - val_prc: 0.3846\n",
      "Epoch 267/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5907 - tp: 249.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 149.0000 - accuracy: 0.7090 - precision: 0.3614 - recall: 0.6256 - auc: 0.7433 - prc: 0.4630 - val_loss: 0.6437 - val_tp: 58.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 33.0000 - val_accuracy: 0.6522 - val_precision: 0.2886 - val_recall: 0.6374 - val_auc: 0.7057 - val_prc: 0.3926\n",
      "Epoch 268/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5896 - tp: 250.0000 - fp: 406.0000 - tn: 1220.0000 - fn: 148.0000 - accuracy: 0.7263 - precision: 0.3811 - recall: 0.6281 - auc: 0.7457 - prc: 0.4662 - val_loss: 0.6457 - val_tp: 59.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 32.0000 - val_accuracy: 0.6482 - val_precision: 0.2878 - val_recall: 0.6484 - val_auc: 0.7057 - val_prc: 0.3914\n",
      "Epoch 269/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5912 - tp: 257.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 141.0000 - accuracy: 0.6957 - precision: 0.3511 - recall: 0.6457 - auc: 0.7452 - prc: 0.4523 - val_loss: 0.5774 - val_tp: 49.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 42.0000 - val_accuracy: 0.7292 - val_precision: 0.3403 - val_recall: 0.5385 - val_auc: 0.7029 - val_prc: 0.3832\n",
      "Epoch 270/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5905 - tp: 251.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 147.0000 - accuracy: 0.6991 - precision: 0.3520 - recall: 0.6307 - auc: 0.7444 - prc: 0.4624 - val_loss: 0.5608 - val_tp: 48.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 43.0000 - val_accuracy: 0.7451 - val_precision: 0.3582 - val_recall: 0.5275 - val_auc: 0.7044 - val_prc: 0.3793\n",
      "Epoch 271/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5919 - tp: 249.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 149.0000 - accuracy: 0.7045 - precision: 0.3567 - recall: 0.6256 - auc: 0.7423 - prc: 0.4571 - val_loss: 0.6015 - val_tp: 53.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 38.0000 - val_accuracy: 0.7075 - val_precision: 0.3252 - val_recall: 0.5824 - val_auc: 0.7036 - val_prc: 0.3874\n",
      "Epoch 272/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5911 - tp: 261.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 137.0000 - accuracy: 0.7011 - precision: 0.3580 - recall: 0.6558 - auc: 0.7435 - prc: 0.4609 - val_loss: 0.5859 - val_tp: 50.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 41.0000 - val_accuracy: 0.7233 - val_precision: 0.3356 - val_recall: 0.5495 - val_auc: 0.7077 - val_prc: 0.3890\n",
      "Epoch 273/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5909 - tp: 242.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 156.0000 - accuracy: 0.7115 - precision: 0.3612 - recall: 0.6080 - auc: 0.7431 - prc: 0.4543 - val_loss: 0.6331 - val_tp: 58.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 33.0000 - val_accuracy: 0.6601 - val_precision: 0.2944 - val_recall: 0.6374 - val_auc: 0.7057 - val_prc: 0.3897\n",
      "Epoch 274/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5915 - tp: 246.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 152.0000 - accuracy: 0.7149 - precision: 0.3666 - recall: 0.6181 - auc: 0.7415 - prc: 0.4595 - val_loss: 0.5580 - val_tp: 47.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 44.0000 - val_accuracy: 0.7490 - val_precision: 0.3615 - val_recall: 0.5165 - val_auc: 0.7075 - val_prc: 0.3931\n",
      "Epoch 275/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5929 - tp: 252.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 146.0000 - accuracy: 0.7065 - precision: 0.3600 - recall: 0.6332 - auc: 0.7410 - prc: 0.4644 - val_loss: 0.6858 - val_tp: 63.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 28.0000 - val_accuracy: 0.5949 - val_precision: 0.2625 - val_recall: 0.6923 - val_auc: 0.7021 - val_prc: 0.3854\n",
      "Epoch 276/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5943 - tp: 241.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 157.0000 - accuracy: 0.6986 - precision: 0.3473 - recall: 0.6055 - auc: 0.7375 - prc: 0.4588 - val_loss: 0.6263 - val_tp: 57.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 34.0000 - val_accuracy: 0.6798 - val_precision: 0.3081 - val_recall: 0.6264 - val_auc: 0.7051 - val_prc: 0.3880\n",
      "Epoch 277/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5889 - tp: 253.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 145.0000 - accuracy: 0.7090 - precision: 0.3630 - recall: 0.6357 - auc: 0.7451 - prc: 0.4642 - val_loss: 0.5952 - val_tp: 52.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 39.0000 - val_accuracy: 0.7253 - val_precision: 0.3421 - val_recall: 0.5714 - val_auc: 0.7063 - val_prc: 0.3906\n",
      "Epoch 278/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5912 - tp: 254.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 144.0000 - accuracy: 0.6912 - precision: 0.3456 - recall: 0.6382 - auc: 0.7426 - prc: 0.4588 - val_loss: 0.5779 - val_tp: 50.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 41.0000 - val_accuracy: 0.7292 - val_precision: 0.3425 - val_recall: 0.5495 - val_auc: 0.7069 - val_prc: 0.3911\n",
      "Epoch 279/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5892 - tp: 253.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 145.0000 - accuracy: 0.7075 - precision: 0.3614 - recall: 0.6357 - auc: 0.7461 - prc: 0.4575 - val_loss: 0.6035 - val_tp: 52.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 39.0000 - val_accuracy: 0.7036 - val_precision: 0.3190 - val_recall: 0.5714 - val_auc: 0.7034 - val_prc: 0.3798\n",
      "Epoch 280/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5912 - tp: 250.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 148.0000 - accuracy: 0.7100 - precision: 0.3628 - recall: 0.6281 - auc: 0.7451 - prc: 0.4533 - val_loss: 0.6438 - val_tp: 60.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 31.0000 - val_accuracy: 0.6502 - val_precision: 0.2913 - val_recall: 0.6593 - val_auc: 0.7049 - val_prc: 0.3900\n",
      "Epoch 281/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5902 - tp: 257.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 141.0000 - accuracy: 0.6942 - precision: 0.3497 - recall: 0.6457 - auc: 0.7450 - prc: 0.4597 - val_loss: 0.5961 - val_tp: 52.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 39.0000 - val_accuracy: 0.7194 - val_precision: 0.3355 - val_recall: 0.5714 - val_auc: 0.7022 - val_prc: 0.3791\n",
      "Epoch 282/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5893 - tp: 251.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 147.0000 - accuracy: 0.6957 - precision: 0.3486 - recall: 0.6307 - auc: 0.7456 - prc: 0.4613 - val_loss: 0.5783 - val_tp: 50.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 41.0000 - val_accuracy: 0.7312 - val_precision: 0.3448 - val_recall: 0.5495 - val_auc: 0.7068 - val_prc: 0.3838\n",
      "Epoch 283/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5896 - tp: 253.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 145.0000 - accuracy: 0.7055 - precision: 0.3594 - recall: 0.6357 - auc: 0.7453 - prc: 0.4642 - val_loss: 0.6107 - val_tp: 55.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 36.0000 - val_accuracy: 0.6957 - val_precision: 0.3179 - val_recall: 0.6044 - val_auc: 0.7051 - val_prc: 0.3846\n",
      "Epoch 284/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5900 - tp: 255.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 143.0000 - accuracy: 0.7026 - precision: 0.3571 - recall: 0.6407 - auc: 0.7454 - prc: 0.4585 - val_loss: 0.5845 - val_tp: 51.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 40.0000 - val_accuracy: 0.7253 - val_precision: 0.3400 - val_recall: 0.5604 - val_auc: 0.7055 - val_prc: 0.3915\n",
      "Epoch 285/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5907 - tp: 253.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 145.0000 - accuracy: 0.7075 - precision: 0.3614 - recall: 0.6357 - auc: 0.7443 - prc: 0.4620 - val_loss: 0.5973 - val_tp: 53.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 38.0000 - val_accuracy: 0.7194 - val_precision: 0.3376 - val_recall: 0.5824 - val_auc: 0.7036 - val_prc: 0.3887\n",
      "Epoch 286/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 255.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 143.0000 - accuracy: 0.7041 - precision: 0.3586 - recall: 0.6407 - auc: 0.7462 - prc: 0.4610 - val_loss: 0.6242 - val_tp: 57.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 34.0000 - val_accuracy: 0.6779 - val_precision: 0.3065 - val_recall: 0.6264 - val_auc: 0.7030 - val_prc: 0.3872\n",
      "Epoch 287/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5932 - tp: 250.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 148.0000 - accuracy: 0.7065 - precision: 0.3592 - recall: 0.6281 - auc: 0.7400 - prc: 0.4531 - val_loss: 0.5631 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.7064 - val_prc: 0.3879\n",
      "Epoch 288/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5908 - tp: 250.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 148.0000 - accuracy: 0.7041 - precision: 0.3566 - recall: 0.6281 - auc: 0.7443 - prc: 0.4524 - val_loss: 0.6006 - val_tp: 54.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 37.0000 - val_accuracy: 0.7115 - val_precision: 0.3313 - val_recall: 0.5934 - val_auc: 0.7066 - val_prc: 0.3822\n",
      "Epoch 289/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5912 - tp: 251.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 147.0000 - accuracy: 0.6976 - precision: 0.3506 - recall: 0.6307 - auc: 0.7418 - prc: 0.4619 - val_loss: 0.5822 - val_tp: 51.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 40.0000 - val_accuracy: 0.7253 - val_precision: 0.3400 - val_recall: 0.5604 - val_auc: 0.7077 - val_prc: 0.3882\n",
      "Epoch 290/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5896 - tp: 253.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 145.0000 - accuracy: 0.7041 - precision: 0.3579 - recall: 0.6357 - auc: 0.7463 - prc: 0.4627 - val_loss: 0.6236 - val_tp: 57.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 34.0000 - val_accuracy: 0.6818 - val_precision: 0.3098 - val_recall: 0.6264 - val_auc: 0.7060 - val_prc: 0.3850\n",
      "Epoch 291/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5914 - tp: 244.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 154.0000 - accuracy: 0.7080 - precision: 0.3583 - recall: 0.6131 - auc: 0.7435 - prc: 0.4654 - val_loss: 0.6108 - val_tp: 54.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 37.0000 - val_accuracy: 0.7036 - val_precision: 0.3234 - val_recall: 0.5934 - val_auc: 0.7017 - val_prc: 0.3817\n",
      "Epoch 292/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5921 - tp: 258.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 140.0000 - accuracy: 0.6966 - precision: 0.3525 - recall: 0.6482 - auc: 0.7412 - prc: 0.4507 - val_loss: 0.5883 - val_tp: 50.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 41.0000 - val_accuracy: 0.7233 - val_precision: 0.3356 - val_recall: 0.5495 - val_auc: 0.7055 - val_prc: 0.3857\n",
      "Epoch 293/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5905 - tp: 246.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 152.0000 - accuracy: 0.7110 - precision: 0.3623 - recall: 0.6181 - auc: 0.7442 - prc: 0.4586 - val_loss: 0.6378 - val_tp: 58.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 33.0000 - val_accuracy: 0.6581 - val_precision: 0.2929 - val_recall: 0.6374 - val_auc: 0.7021 - val_prc: 0.3765\n",
      "Epoch 294/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5878 - tp: 248.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 150.0000 - accuracy: 0.6952 - precision: 0.3469 - recall: 0.6231 - auc: 0.7467 - prc: 0.4579 - val_loss: 0.6100 - val_tp: 55.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 36.0000 - val_accuracy: 0.7095 - val_precision: 0.3313 - val_recall: 0.6044 - val_auc: 0.7033 - val_prc: 0.3768\n",
      "Epoch 295/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5895 - tp: 254.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 144.0000 - accuracy: 0.7060 - precision: 0.3603 - recall: 0.6382 - auc: 0.7452 - prc: 0.4607 - val_loss: 0.5800 - val_tp: 50.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 41.0000 - val_accuracy: 0.7253 - val_precision: 0.3378 - val_recall: 0.5495 - val_auc: 0.7050 - val_prc: 0.3850\n",
      "Epoch 296/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5895 - tp: 245.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 153.0000 - accuracy: 0.7154 - precision: 0.3668 - recall: 0.6156 - auc: 0.7467 - prc: 0.4649 - val_loss: 0.6582 - val_tp: 60.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 31.0000 - val_accuracy: 0.6324 - val_precision: 0.2791 - val_recall: 0.6593 - val_auc: 0.7035 - val_prc: 0.3851\n",
      "Epoch 297/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5876 - tp: 253.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 145.0000 - accuracy: 0.6981 - precision: 0.3519 - recall: 0.6357 - auc: 0.7473 - prc: 0.4603 - val_loss: 0.5991 - val_tp: 53.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 38.0000 - val_accuracy: 0.7154 - val_precision: 0.3333 - val_recall: 0.5824 - val_auc: 0.7008 - val_prc: 0.3825\n",
      "Epoch 298/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 251.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 147.0000 - accuracy: 0.7134 - precision: 0.3670 - recall: 0.6307 - auc: 0.7463 - prc: 0.4627 - val_loss: 0.6073 - val_tp: 54.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 37.0000 - val_accuracy: 0.6957 - val_precision: 0.3158 - val_recall: 0.5934 - val_auc: 0.7051 - val_prc: 0.3764\n",
      "Epoch 299/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5885 - tp: 256.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 142.0000 - accuracy: 0.6922 - precision: 0.3474 - recall: 0.6432 - auc: 0.7470 - prc: 0.4584 - val_loss: 0.5599 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.7074 - val_prc: 0.3998\n",
      "Epoch 300/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5869 - tp: 242.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 156.0000 - accuracy: 0.7179 - precision: 0.3683 - recall: 0.6080 - auc: 0.7479 - prc: 0.4597 - val_loss: 0.6704 - val_tp: 61.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 30.0000 - val_accuracy: 0.6206 - val_precision: 0.2735 - val_recall: 0.6703 - val_auc: 0.7047 - val_prc: 0.3756\n",
      "Epoch 301/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5907 - tp: 258.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 140.0000 - accuracy: 0.6912 - precision: 0.3472 - recall: 0.6482 - auc: 0.7422 - prc: 0.4661 - val_loss: 0.5754 - val_tp: 50.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 41.0000 - val_accuracy: 0.7292 - val_precision: 0.3425 - val_recall: 0.5495 - val_auc: 0.7054 - val_prc: 0.3907\n",
      "Epoch 302/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5886 - tp: 252.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 146.0000 - accuracy: 0.7110 - precision: 0.3647 - recall: 0.6332 - auc: 0.7470 - prc: 0.4567 - val_loss: 0.6139 - val_tp: 56.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 35.0000 - val_accuracy: 0.6877 - val_precision: 0.3128 - val_recall: 0.6154 - val_auc: 0.7044 - val_prc: 0.3867\n",
      "Epoch 303/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5900 - tp: 260.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 138.0000 - accuracy: 0.6868 - precision: 0.3439 - recall: 0.6533 - auc: 0.7452 - prc: 0.4508 - val_loss: 0.5806 - val_tp: 51.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 40.0000 - val_accuracy: 0.7292 - val_precision: 0.3446 - val_recall: 0.5604 - val_auc: 0.7048 - val_prc: 0.3890\n",
      "Epoch 304/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5887 - tp: 249.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 149.0000 - accuracy: 0.7075 - precision: 0.3598 - recall: 0.6256 - auc: 0.7457 - prc: 0.4714 - val_loss: 0.5899 - val_tp: 52.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 39.0000 - val_accuracy: 0.7312 - val_precision: 0.3490 - val_recall: 0.5714 - val_auc: 0.7031 - val_prc: 0.3852\n",
      "Epoch 305/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5875 - tp: 251.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 147.0000 - accuracy: 0.7095 - precision: 0.3627 - recall: 0.6307 - auc: 0.7485 - prc: 0.4675 - val_loss: 0.6206 - val_tp: 56.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 35.0000 - val_accuracy: 0.6838 - val_precision: 0.3094 - val_recall: 0.6154 - val_auc: 0.7051 - val_prc: 0.3866\n",
      "Epoch 306/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 252.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 146.0000 - accuracy: 0.7045 - precision: 0.3580 - recall: 0.6332 - auc: 0.7456 - prc: 0.4704 - val_loss: 0.5676 - val_tp: 48.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 43.0000 - val_accuracy: 0.7312 - val_precision: 0.3404 - val_recall: 0.5275 - val_auc: 0.7022 - val_prc: 0.3899\n",
      "Epoch 307/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5890 - tp: 253.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 145.0000 - accuracy: 0.7090 - precision: 0.3630 - recall: 0.6357 - auc: 0.7447 - prc: 0.4624 - val_loss: 0.5978 - val_tp: 53.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 38.0000 - val_accuracy: 0.7194 - val_precision: 0.3376 - val_recall: 0.5824 - val_auc: 0.7061 - val_prc: 0.3878\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5860 - tp: 245.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 153.0000 - accuracy: 0.7154 - precision: 0.3668 - recall: 0.6156 - auc: 0.7506 - prc: 0.4660 - val_loss: 0.6896 - val_tp: 62.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 29.0000 - val_accuracy: 0.5889 - val_precision: 0.2573 - val_recall: 0.6813 - val_auc: 0.7037 - val_prc: 0.3786\n",
      "Epoch 309/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5865 - tp: 258.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 140.0000 - accuracy: 0.7006 - precision: 0.3564 - recall: 0.6482 - auc: 0.7488 - prc: 0.4623 - val_loss: 0.6174 - val_tp: 57.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 34.0000 - val_accuracy: 0.6957 - val_precision: 0.3220 - val_recall: 0.6264 - val_auc: 0.7032 - val_prc: 0.3839\n",
      "Epoch 310/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5871 - tp: 244.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 154.0000 - accuracy: 0.7144 - precision: 0.3653 - recall: 0.6131 - auc: 0.7476 - prc: 0.4683 - val_loss: 0.5936 - val_tp: 54.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 37.0000 - val_accuracy: 0.7233 - val_precision: 0.3439 - val_recall: 0.5934 - val_auc: 0.7064 - val_prc: 0.3920\n",
      "Epoch 311/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5869 - tp: 249.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 149.0000 - accuracy: 0.7139 - precision: 0.3667 - recall: 0.6256 - auc: 0.7478 - prc: 0.4691 - val_loss: 0.6737 - val_tp: 62.0000 - val_fp: 169.0000 - val_tn: 246.0000 - val_fn: 29.0000 - val_accuracy: 0.6087 - val_precision: 0.2684 - val_recall: 0.6813 - val_auc: 0.7035 - val_prc: 0.3704\n",
      "Epoch 312/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5881 - tp: 256.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 142.0000 - accuracy: 0.7036 - precision: 0.3585 - recall: 0.6432 - auc: 0.7463 - prc: 0.4654 - val_loss: 0.5826 - val_tp: 50.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 41.0000 - val_accuracy: 0.7213 - val_precision: 0.3333 - val_recall: 0.5495 - val_auc: 0.7065 - val_prc: 0.3832\n",
      "Epoch 313/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5871 - tp: 246.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 152.0000 - accuracy: 0.7080 - precision: 0.3591 - recall: 0.6181 - auc: 0.7468 - prc: 0.4614 - val_loss: 0.6026 - val_tp: 52.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 39.0000 - val_accuracy: 0.7095 - val_precision: 0.3250 - val_recall: 0.5714 - val_auc: 0.7007 - val_prc: 0.3873\n",
      "Epoch 314/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 252.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 146.0000 - accuracy: 0.7021 - precision: 0.3554 - recall: 0.6332 - auc: 0.7457 - prc: 0.4593 - val_loss: 0.5987 - val_tp: 54.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 37.0000 - val_accuracy: 0.7194 - val_precision: 0.3396 - val_recall: 0.5934 - val_auc: 0.7056 - val_prc: 0.3903\n",
      "Epoch 315/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5860 - tp: 253.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 145.0000 - accuracy: 0.7001 - precision: 0.3538 - recall: 0.6357 - auc: 0.7491 - prc: 0.4625 - val_loss: 0.5945 - val_tp: 53.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 38.0000 - val_accuracy: 0.7233 - val_precision: 0.3419 - val_recall: 0.5824 - val_auc: 0.7046 - val_prc: 0.3876\n",
      "Epoch 316/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5877 - tp: 250.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 148.0000 - accuracy: 0.7070 - precision: 0.3597 - recall: 0.6281 - auc: 0.7462 - prc: 0.4684 - val_loss: 0.5703 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.7052 - val_prc: 0.3814\n",
      "Epoch 317/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 253.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 145.0000 - accuracy: 0.7095 - precision: 0.3635 - recall: 0.6357 - auc: 0.7459 - prc: 0.4643 - val_loss: 0.6018 - val_tp: 53.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 38.0000 - val_accuracy: 0.7154 - val_precision: 0.3333 - val_recall: 0.5824 - val_auc: 0.7034 - val_prc: 0.3857\n",
      "Epoch 318/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5856 - tp: 256.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 142.0000 - accuracy: 0.7065 - precision: 0.3616 - recall: 0.6432 - auc: 0.7495 - prc: 0.4684 - val_loss: 0.5774 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.7040 - val_prc: 0.3854\n",
      "Epoch 319/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5882 - tp: 243.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 155.0000 - accuracy: 0.7149 - precision: 0.3654 - recall: 0.6106 - auc: 0.7465 - prc: 0.4715 - val_loss: 0.6308 - val_tp: 57.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 34.0000 - val_accuracy: 0.6621 - val_precision: 0.2938 - val_recall: 0.6264 - val_auc: 0.7057 - val_prc: 0.3894\n",
      "Epoch 320/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5888 - tp: 264.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 134.0000 - accuracy: 0.6877 - precision: 0.3465 - recall: 0.6633 - auc: 0.7461 - prc: 0.4652 - val_loss: 0.5560 - val_tp: 48.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 43.0000 - val_accuracy: 0.7470 - val_precision: 0.3609 - val_recall: 0.5275 - val_auc: 0.7064 - val_prc: 0.3916\n",
      "Epoch 321/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5890 - tp: 255.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 143.0000 - accuracy: 0.7060 - precision: 0.3607 - recall: 0.6407 - auc: 0.7451 - prc: 0.4627 - val_loss: 0.5634 - val_tp: 49.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 42.0000 - val_accuracy: 0.7431 - val_precision: 0.3577 - val_recall: 0.5385 - val_auc: 0.7070 - val_prc: 0.3974\n",
      "Epoch 322/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5895 - tp: 248.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 150.0000 - accuracy: 0.7026 - precision: 0.3543 - recall: 0.6231 - auc: 0.7435 - prc: 0.4633 - val_loss: 0.5728 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.7052 - val_prc: 0.3863\n",
      "Epoch 323/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5868 - tp: 249.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 149.0000 - accuracy: 0.7139 - precision: 0.3667 - recall: 0.6256 - auc: 0.7479 - prc: 0.4692 - val_loss: 0.5485 - val_tp: 46.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 45.0000 - val_accuracy: 0.7510 - val_precision: 0.3622 - val_recall: 0.5055 - val_auc: 0.7025 - val_prc: 0.3877\n",
      "Epoch 324/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5888 - tp: 242.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 156.0000 - accuracy: 0.7129 - precision: 0.3628 - recall: 0.6080 - auc: 0.7446 - prc: 0.4707 - val_loss: 0.6223 - val_tp: 56.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 35.0000 - val_accuracy: 0.6818 - val_precision: 0.3077 - val_recall: 0.6154 - val_auc: 0.7032 - val_prc: 0.3812\n",
      "Epoch 325/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5880 - tp: 258.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 140.0000 - accuracy: 0.7001 - precision: 0.3559 - recall: 0.6482 - auc: 0.7461 - prc: 0.4646 - val_loss: 0.5752 - val_tp: 49.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 42.0000 - val_accuracy: 0.7312 - val_precision: 0.3427 - val_recall: 0.5385 - val_auc: 0.7072 - val_prc: 0.3889\n",
      "Epoch 326/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5898 - tp: 253.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 145.0000 - accuracy: 0.7050 - precision: 0.3589 - recall: 0.6357 - auc: 0.7449 - prc: 0.4612 - val_loss: 0.5957 - val_tp: 54.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 37.0000 - val_accuracy: 0.7194 - val_precision: 0.3396 - val_recall: 0.5934 - val_auc: 0.7064 - val_prc: 0.3917\n",
      "Epoch 327/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5866 - tp: 253.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 145.0000 - accuracy: 0.7021 - precision: 0.3558 - recall: 0.6357 - auc: 0.7481 - prc: 0.4674 - val_loss: 0.5981 - val_tp: 53.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 38.0000 - val_accuracy: 0.7253 - val_precision: 0.3442 - val_recall: 0.5824 - val_auc: 0.7062 - val_prc: 0.3858\n",
      "Epoch 328/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5875 - tp: 249.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 149.0000 - accuracy: 0.7095 - precision: 0.3619 - recall: 0.6256 - auc: 0.7450 - prc: 0.4679 - val_loss: 0.6037 - val_tp: 54.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 37.0000 - val_accuracy: 0.7095 - val_precision: 0.3293 - val_recall: 0.5934 - val_auc: 0.7058 - val_prc: 0.3873\n",
      "Epoch 329/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5880 - tp: 251.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 147.0000 - accuracy: 0.7041 - precision: 0.3570 - recall: 0.6307 - auc: 0.7467 - prc: 0.4677 - val_loss: 0.5959 - val_tp: 53.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 38.0000 - val_accuracy: 0.7194 - val_precision: 0.3376 - val_recall: 0.5824 - val_auc: 0.7055 - val_prc: 0.3865\n",
      "Epoch 330/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5884 - tp: 239.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 159.0000 - accuracy: 0.7144 - precision: 0.3632 - recall: 0.6005 - auc: 0.7469 - prc: 0.4680 - val_loss: 0.6387 - val_tp: 58.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 33.0000 - val_accuracy: 0.6561 - val_precision: 0.2915 - val_recall: 0.6374 - val_auc: 0.7048 - val_prc: 0.3794\n",
      "Epoch 331/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5905 - tp: 251.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 147.0000 - accuracy: 0.6981 - precision: 0.3510 - recall: 0.6307 - auc: 0.7440 - prc: 0.4644 - val_loss: 0.6028 - val_tp: 55.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 36.0000 - val_accuracy: 0.7055 - val_precision: 0.3274 - val_recall: 0.6044 - val_auc: 0.7056 - val_prc: 0.3838\n",
      "Epoch 332/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5875 - tp: 251.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 147.0000 - accuracy: 0.7065 - precision: 0.3596 - recall: 0.6307 - auc: 0.7479 - prc: 0.4688 - val_loss: 0.6203 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.7039 - val_prc: 0.3913\n",
      "Epoch 333/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5872 - tp: 250.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 148.0000 - accuracy: 0.7021 - precision: 0.3546 - recall: 0.6281 - auc: 0.7461 - prc: 0.4593 - val_loss: 0.5595 - val_tp: 48.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 43.0000 - val_accuracy: 0.7411 - val_precision: 0.3529 - val_recall: 0.5275 - val_auc: 0.7058 - val_prc: 0.3984\n",
      "Epoch 334/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5869 - tp: 249.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 149.0000 - accuracy: 0.7045 - precision: 0.3567 - recall: 0.6256 - auc: 0.7477 - prc: 0.4669 - val_loss: 0.6299 - val_tp: 56.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 35.0000 - val_accuracy: 0.6680 - val_precision: 0.2963 - val_recall: 0.6154 - val_auc: 0.7027 - val_prc: 0.3829\n",
      "Epoch 335/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5874 - tp: 244.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 154.0000 - accuracy: 0.7036 - precision: 0.3536 - recall: 0.6131 - auc: 0.7470 - prc: 0.4658 - val_loss: 0.6577 - val_tp: 59.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 32.0000 - val_accuracy: 0.6285 - val_precision: 0.2744 - val_recall: 0.6484 - val_auc: 0.7029 - val_prc: 0.3818\n",
      "Epoch 336/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5883 - tp: 252.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 146.0000 - accuracy: 0.6961 - precision: 0.3495 - recall: 0.6332 - auc: 0.7469 - prc: 0.4669 - val_loss: 0.5886 - val_tp: 52.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 39.0000 - val_accuracy: 0.7213 - val_precision: 0.3377 - val_recall: 0.5714 - val_auc: 0.7072 - val_prc: 0.3881\n",
      "Epoch 337/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5873 - tp: 244.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 154.0000 - accuracy: 0.7144 - precision: 0.3653 - recall: 0.6131 - auc: 0.7469 - prc: 0.4665 - val_loss: 0.5881 - val_tp: 52.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 39.0000 - val_accuracy: 0.7253 - val_precision: 0.3421 - val_recall: 0.5714 - val_auc: 0.7057 - val_prc: 0.3889\n",
      "Epoch 338/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5864 - tp: 259.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 139.0000 - accuracy: 0.7036 - precision: 0.3597 - recall: 0.6508 - auc: 0.7501 - prc: 0.4638 - val_loss: 0.6016 - val_tp: 54.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 37.0000 - val_accuracy: 0.7213 - val_precision: 0.3418 - val_recall: 0.5934 - val_auc: 0.7032 - val_prc: 0.3811\n",
      "Epoch 339/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5861 - tp: 254.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 144.0000 - accuracy: 0.6981 - precision: 0.3523 - recall: 0.6382 - auc: 0.7498 - prc: 0.4573 - val_loss: 0.5503 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.7059 - val_prc: 0.4075\n",
      "Epoch 340/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5868 - tp: 246.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 152.0000 - accuracy: 0.7184 - precision: 0.3705 - recall: 0.6181 - auc: 0.7479 - prc: 0.4665 - val_loss: 0.5929 - val_tp: 53.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 38.0000 - val_accuracy: 0.7194 - val_precision: 0.3376 - val_recall: 0.5824 - val_auc: 0.7043 - val_prc: 0.3919\n",
      "Epoch 341/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5885 - tp: 254.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 144.0000 - accuracy: 0.7134 - precision: 0.3681 - recall: 0.6382 - auc: 0.7451 - prc: 0.4618 - val_loss: 0.5878 - val_tp: 53.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 38.0000 - val_accuracy: 0.7253 - val_precision: 0.3442 - val_recall: 0.5824 - val_auc: 0.7064 - val_prc: 0.3915\n",
      "Epoch 342/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5873 - tp: 251.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 147.0000 - accuracy: 0.7085 - precision: 0.3617 - recall: 0.6307 - auc: 0.7478 - prc: 0.4659 - val_loss: 0.5860 - val_tp: 51.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 40.0000 - val_accuracy: 0.7233 - val_precision: 0.3377 - val_recall: 0.5604 - val_auc: 0.7027 - val_prc: 0.3854\n",
      "Epoch 343/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5879 - tp: 251.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 147.0000 - accuracy: 0.7075 - precision: 0.3606 - recall: 0.6307 - auc: 0.7474 - prc: 0.4689 - val_loss: 0.6247 - val_tp: 57.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 34.0000 - val_accuracy: 0.6719 - val_precision: 0.3016 - val_recall: 0.6264 - val_auc: 0.7065 - val_prc: 0.3888\n",
      "Epoch 344/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5876 - tp: 248.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 150.0000 - accuracy: 0.7070 - precision: 0.3589 - recall: 0.6231 - auc: 0.7452 - prc: 0.4726 - val_loss: 0.5888 - val_tp: 52.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 39.0000 - val_accuracy: 0.7194 - val_precision: 0.3355 - val_recall: 0.5714 - val_auc: 0.7062 - val_prc: 0.3826\n",
      "Epoch 345/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5889 - tp: 247.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 151.0000 - accuracy: 0.7050 - precision: 0.3564 - recall: 0.6206 - auc: 0.7453 - prc: 0.4542 - val_loss: 0.5931 - val_tp: 54.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 37.0000 - val_accuracy: 0.7194 - val_precision: 0.3396 - val_recall: 0.5934 - val_auc: 0.7053 - val_prc: 0.3977\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5874 - tp: 253.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 145.0000 - accuracy: 0.7031 - precision: 0.3568 - recall: 0.6357 - auc: 0.7468 - prc: 0.4656 - val_loss: 0.6299 - val_tp: 57.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 34.0000 - val_accuracy: 0.6700 - val_precision: 0.3000 - val_recall: 0.6264 - val_auc: 0.7054 - val_prc: 0.3855\n",
      "Epoch 347/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5864 - tp: 263.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 135.0000 - accuracy: 0.6927 - precision: 0.3507 - recall: 0.6608 - auc: 0.7494 - prc: 0.4658 - val_loss: 0.5506 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.7053 - val_prc: 0.3962\n",
      "Epoch 348/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5865 - tp: 252.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 146.0000 - accuracy: 0.7115 - precision: 0.3652 - recall: 0.6332 - auc: 0.7483 - prc: 0.4726 - val_loss: 0.5303 - val_tp: 45.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 46.0000 - val_accuracy: 0.7727 - val_precision: 0.3947 - val_recall: 0.4945 - val_auc: 0.7031 - val_prc: 0.4039\n",
      "Epoch 349/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5875 - tp: 247.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 151.0000 - accuracy: 0.7268 - precision: 0.3806 - recall: 0.6206 - auc: 0.7465 - prc: 0.4597 - val_loss: 0.5941 - val_tp: 52.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 39.0000 - val_accuracy: 0.7095 - val_precision: 0.3250 - val_recall: 0.5714 - val_auc: 0.7048 - val_prc: 0.3875\n",
      "Epoch 350/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5844 - tp: 250.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 148.0000 - accuracy: 0.7041 - precision: 0.3566 - recall: 0.6281 - auc: 0.7505 - prc: 0.4649 - val_loss: 0.5579 - val_tp: 48.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 43.0000 - val_accuracy: 0.7431 - val_precision: 0.3556 - val_recall: 0.5275 - val_auc: 0.6994 - val_prc: 0.3823\n",
      "Epoch 351/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5848 - tp: 251.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 147.0000 - accuracy: 0.6971 - precision: 0.3501 - recall: 0.6307 - auc: 0.7509 - prc: 0.4611 - val_loss: 0.5485 - val_tp: 47.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 44.0000 - val_accuracy: 0.7530 - val_precision: 0.3672 - val_recall: 0.5165 - val_auc: 0.7070 - val_prc: 0.3977\n",
      "Epoch 352/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5860 - tp: 250.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 148.0000 - accuracy: 0.7090 - precision: 0.3618 - recall: 0.6281 - auc: 0.7484 - prc: 0.4724 - val_loss: 0.5896 - val_tp: 52.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 39.0000 - val_accuracy: 0.7253 - val_precision: 0.3421 - val_recall: 0.5714 - val_auc: 0.7021 - val_prc: 0.3927\n",
      "Epoch 353/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5857 - tp: 248.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 150.0000 - accuracy: 0.7194 - precision: 0.3724 - recall: 0.6231 - auc: 0.7496 - prc: 0.4701 - val_loss: 0.6593 - val_tp: 60.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 31.0000 - val_accuracy: 0.6285 - val_precision: 0.2765 - val_recall: 0.6593 - val_auc: 0.7037 - val_prc: 0.3974\n",
      "Epoch 354/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5872 - tp: 255.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 143.0000 - accuracy: 0.7134 - precision: 0.3685 - recall: 0.6407 - auc: 0.7490 - prc: 0.4702 - val_loss: 0.6444 - val_tp: 57.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 34.0000 - val_accuracy: 0.6423 - val_precision: 0.2794 - val_recall: 0.6264 - val_auc: 0.7022 - val_prc: 0.3952\n",
      "Epoch 355/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5852 - tp: 261.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 137.0000 - accuracy: 0.6917 - precision: 0.3489 - recall: 0.6558 - auc: 0.7500 - prc: 0.4697 - val_loss: 0.5659 - val_tp: 49.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 42.0000 - val_accuracy: 0.7352 - val_precision: 0.3475 - val_recall: 0.5385 - val_auc: 0.7033 - val_prc: 0.3950\n",
      "Epoch 356/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5934 - tp: 256.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 142.0000 - accuracy: 0.7070 - precision: 0.3621 - recall: 0.6432 - auc: 0.7393 - prc: 0.4567 - val_loss: 0.6549 - val_tp: 59.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 32.0000 - val_accuracy: 0.6423 - val_precision: 0.2837 - val_recall: 0.6484 - val_auc: 0.7046 - val_prc: 0.3936\n",
      "Epoch 357/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5846 - tp: 244.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 154.0000 - accuracy: 0.7238 - precision: 0.3760 - recall: 0.6131 - auc: 0.7510 - prc: 0.4675 - val_loss: 0.6233 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.7024 - val_prc: 0.3888\n",
      "Epoch 358/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5859 - tp: 257.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 141.0000 - accuracy: 0.7011 - precision: 0.3564 - recall: 0.6457 - auc: 0.7482 - prc: 0.4697 - val_loss: 0.6155 - val_tp: 56.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 35.0000 - val_accuracy: 0.6937 - val_precision: 0.3182 - val_recall: 0.6154 - val_auc: 0.7046 - val_prc: 0.3907\n",
      "Epoch 359/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5886 - tp: 249.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 149.0000 - accuracy: 0.7134 - precision: 0.3662 - recall: 0.6256 - auc: 0.7449 - prc: 0.4639 - val_loss: 0.6231 - val_tp: 54.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 37.0000 - val_accuracy: 0.6739 - val_precision: 0.2967 - val_recall: 0.5934 - val_auc: 0.7031 - val_prc: 0.3910\n",
      "Epoch 360/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5852 - tp: 253.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 145.0000 - accuracy: 0.7125 - precision: 0.3667 - recall: 0.6357 - auc: 0.7494 - prc: 0.4745 - val_loss: 0.6260 - val_tp: 55.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 36.0000 - val_accuracy: 0.6818 - val_precision: 0.3056 - val_recall: 0.6044 - val_auc: 0.7001 - val_prc: 0.3861\n",
      "Epoch 361/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5841 - tp: 256.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 142.0000 - accuracy: 0.7174 - precision: 0.3732 - recall: 0.6432 - auc: 0.7505 - prc: 0.4711 - val_loss: 0.6068 - val_tp: 52.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 39.0000 - val_accuracy: 0.6957 - val_precision: 0.3114 - val_recall: 0.5714 - val_auc: 0.6987 - val_prc: 0.3865\n",
      "Epoch 362/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5877 - tp: 255.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 143.0000 - accuracy: 0.6991 - precision: 0.3537 - recall: 0.6407 - auc: 0.7458 - prc: 0.4690 - val_loss: 0.5890 - val_tp: 52.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 39.0000 - val_accuracy: 0.7154 - val_precision: 0.3312 - val_recall: 0.5714 - val_auc: 0.7053 - val_prc: 0.3870\n",
      "Epoch 363/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5847 - tp: 252.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 146.0000 - accuracy: 0.7149 - precision: 0.3690 - recall: 0.6332 - auc: 0.7500 - prc: 0.4702 - val_loss: 0.6355 - val_tp: 57.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 34.0000 - val_accuracy: 0.6581 - val_precision: 0.2908 - val_recall: 0.6264 - val_auc: 0.7033 - val_prc: 0.3895\n",
      "Epoch 364/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5854 - tp: 250.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 148.0000 - accuracy: 0.7105 - precision: 0.3634 - recall: 0.6281 - auc: 0.7488 - prc: 0.4716 - val_loss: 0.6190 - val_tp: 55.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 36.0000 - val_accuracy: 0.6858 - val_precision: 0.3090 - val_recall: 0.6044 - val_auc: 0.7032 - val_prc: 0.3847\n",
      "Epoch 365/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5836 - tp: 247.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 151.0000 - accuracy: 0.7129 - precision: 0.3648 - recall: 0.6206 - auc: 0.7514 - prc: 0.4751 - val_loss: 0.6359 - val_tp: 57.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 34.0000 - val_accuracy: 0.6502 - val_precision: 0.2850 - val_recall: 0.6264 - val_auc: 0.7035 - val_prc: 0.3913\n",
      "Epoch 366/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5880 - tp: 264.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 134.0000 - accuracy: 0.6932 - precision: 0.3515 - recall: 0.6633 - auc: 0.7462 - prc: 0.4678 - val_loss: 0.5278 - val_tp: 45.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 46.0000 - val_accuracy: 0.7727 - val_precision: 0.3947 - val_recall: 0.4945 - val_auc: 0.7069 - val_prc: 0.4126\n",
      "Epoch 367/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5870 - tp: 244.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 154.0000 - accuracy: 0.7179 - precision: 0.3691 - recall: 0.6131 - auc: 0.7443 - prc: 0.4729 - val_loss: 0.5920 - val_tp: 53.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 38.0000 - val_accuracy: 0.7194 - val_precision: 0.3376 - val_recall: 0.5824 - val_auc: 0.7053 - val_prc: 0.3952\n",
      "Epoch 368/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5868 - tp: 258.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 140.0000 - accuracy: 0.7075 - precision: 0.3634 - recall: 0.6482 - auc: 0.7470 - prc: 0.4721 - val_loss: 0.6124 - val_tp: 56.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 35.0000 - val_accuracy: 0.6976 - val_precision: 0.3218 - val_recall: 0.6154 - val_auc: 0.7056 - val_prc: 0.3833\n",
      "Epoch 369/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5856 - tp: 254.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 144.0000 - accuracy: 0.7174 - precision: 0.3724 - recall: 0.6382 - auc: 0.7501 - prc: 0.4705 - val_loss: 0.5670 - val_tp: 49.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 42.0000 - val_accuracy: 0.7391 - val_precision: 0.3525 - val_recall: 0.5385 - val_auc: 0.7082 - val_prc: 0.4012\n",
      "Epoch 370/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5879 - tp: 253.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 145.0000 - accuracy: 0.7065 - precision: 0.3604 - recall: 0.6357 - auc: 0.7484 - prc: 0.4651 - val_loss: 0.5475 - val_tp: 48.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 43.0000 - val_accuracy: 0.7628 - val_precision: 0.3840 - val_recall: 0.5275 - val_auc: 0.7059 - val_prc: 0.3992\n",
      "Epoch 371/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5848 - tp: 244.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 154.0000 - accuracy: 0.7184 - precision: 0.3697 - recall: 0.6131 - auc: 0.7496 - prc: 0.4706 - val_loss: 0.6563 - val_tp: 59.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 32.0000 - val_accuracy: 0.6462 - val_precision: 0.2864 - val_recall: 0.6484 - val_auc: 0.7014 - val_prc: 0.3788\n",
      "Epoch 372/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5863 - tp: 256.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 142.0000 - accuracy: 0.6961 - precision: 0.3512 - recall: 0.6432 - auc: 0.7479 - prc: 0.4708 - val_loss: 0.5453 - val_tp: 47.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 44.0000 - val_accuracy: 0.7589 - val_precision: 0.3760 - val_recall: 0.5165 - val_auc: 0.7072 - val_prc: 0.4074\n",
      "Epoch 373/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5890 - tp: 249.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 149.0000 - accuracy: 0.7036 - precision: 0.3557 - recall: 0.6256 - auc: 0.7448 - prc: 0.4684 - val_loss: 0.5600 - val_tp: 49.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 42.0000 - val_accuracy: 0.7490 - val_precision: 0.3657 - val_recall: 0.5385 - val_auc: 0.7091 - val_prc: 0.3979\n",
      "Epoch 374/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5866 - tp: 248.0000 - fp: 435.0000 - tn: 1191.0000 - fn: 150.0000 - accuracy: 0.7110 - precision: 0.3631 - recall: 0.6231 - auc: 0.7473 - prc: 0.4644 - val_loss: 0.5892 - val_tp: 52.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 39.0000 - val_accuracy: 0.7134 - val_precision: 0.3291 - val_recall: 0.5714 - val_auc: 0.7064 - val_prc: 0.3940\n",
      "Epoch 375/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5847 - tp: 247.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 151.0000 - accuracy: 0.7263 - precision: 0.3800 - recall: 0.6206 - auc: 0.7506 - prc: 0.4811 - val_loss: 0.6572 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.7030 - val_prc: 0.3831\n",
      "Epoch 376/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5862 - tp: 251.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 147.0000 - accuracy: 0.7026 - precision: 0.3555 - recall: 0.6307 - auc: 0.7483 - prc: 0.4675 - val_loss: 0.6249 - val_tp: 56.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 35.0000 - val_accuracy: 0.6818 - val_precision: 0.3077 - val_recall: 0.6154 - val_auc: 0.7033 - val_prc: 0.3823\n",
      "Epoch 377/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5866 - tp: 251.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 147.0000 - accuracy: 0.7050 - precision: 0.3581 - recall: 0.6307 - auc: 0.7477 - prc: 0.4576 - val_loss: 0.5775 - val_tp: 51.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 40.0000 - val_accuracy: 0.7233 - val_precision: 0.3377 - val_recall: 0.5604 - val_auc: 0.7041 - val_prc: 0.3899\n",
      "Epoch 378/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5841 - tp: 255.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 143.0000 - accuracy: 0.7041 - precision: 0.3586 - recall: 0.6407 - auc: 0.7509 - prc: 0.4671 - val_loss: 0.6000 - val_tp: 53.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 38.0000 - val_accuracy: 0.7075 - val_precision: 0.3252 - val_recall: 0.5824 - val_auc: 0.7036 - val_prc: 0.3928\n",
      "Epoch 379/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5825 - tp: 255.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 143.0000 - accuracy: 0.7026 - precision: 0.3571 - recall: 0.6407 - auc: 0.7522 - prc: 0.4762 - val_loss: 0.5409 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.7005 - val_prc: 0.3898\n",
      "Epoch 380/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5868 - tp: 243.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 155.0000 - accuracy: 0.7258 - precision: 0.3779 - recall: 0.6106 - auc: 0.7467 - prc: 0.4669 - val_loss: 0.6101 - val_tp: 53.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 38.0000 - val_accuracy: 0.6937 - val_precision: 0.3118 - val_recall: 0.5824 - val_auc: 0.7019 - val_prc: 0.3859\n",
      "Epoch 381/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5844 - tp: 256.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 142.0000 - accuracy: 0.7110 - precision: 0.3662 - recall: 0.6432 - auc: 0.7501 - prc: 0.4763 - val_loss: 0.5900 - val_tp: 52.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 39.0000 - val_accuracy: 0.7174 - val_precision: 0.3333 - val_recall: 0.5714 - val_auc: 0.7048 - val_prc: 0.3931\n",
      "Epoch 382/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5851 - tp: 251.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 147.0000 - accuracy: 0.7199 - precision: 0.3741 - recall: 0.6307 - auc: 0.7498 - prc: 0.4710 - val_loss: 0.6822 - val_tp: 61.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 30.0000 - val_accuracy: 0.5889 - val_precision: 0.2552 - val_recall: 0.6703 - val_auc: 0.6996 - val_prc: 0.3817\n",
      "Epoch 383/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5846 - tp: 261.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 137.0000 - accuracy: 0.7055 - precision: 0.3625 - recall: 0.6558 - auc: 0.7497 - prc: 0.4695 - val_loss: 0.5757 - val_tp: 49.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 42.0000 - val_accuracy: 0.7312 - val_precision: 0.3427 - val_recall: 0.5385 - val_auc: 0.7074 - val_prc: 0.3874\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5847 - tp: 249.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 149.0000 - accuracy: 0.7110 - precision: 0.3635 - recall: 0.6256 - auc: 0.7487 - prc: 0.4693 - val_loss: 0.6119 - val_tp: 54.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 37.0000 - val_accuracy: 0.6917 - val_precision: 0.3121 - val_recall: 0.5934 - val_auc: 0.7060 - val_prc: 0.3831\n",
      "Epoch 385/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5857 - tp: 256.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 142.0000 - accuracy: 0.7085 - precision: 0.3636 - recall: 0.6432 - auc: 0.7488 - prc: 0.4687 - val_loss: 0.6025 - val_tp: 54.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 37.0000 - val_accuracy: 0.7134 - val_precision: 0.3333 - val_recall: 0.5934 - val_auc: 0.7056 - val_prc: 0.3847\n",
      "Epoch 386/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5837 - tp: 251.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 147.0000 - accuracy: 0.7179 - precision: 0.3719 - recall: 0.6307 - auc: 0.7510 - prc: 0.4750 - val_loss: 0.6449 - val_tp: 57.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 34.0000 - val_accuracy: 0.6522 - val_precision: 0.2864 - val_recall: 0.6264 - val_auc: 0.7041 - val_prc: 0.3832\n",
      "Epoch 387/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5865 - tp: 258.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 140.0000 - accuracy: 0.7075 - precision: 0.3634 - recall: 0.6482 - auc: 0.7474 - prc: 0.4704 - val_loss: 0.6045 - val_tp: 54.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 37.0000 - val_accuracy: 0.7036 - val_precision: 0.3234 - val_recall: 0.5934 - val_auc: 0.7044 - val_prc: 0.3897\n",
      "Epoch 388/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5863 - tp: 248.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 150.0000 - accuracy: 0.7011 - precision: 0.3528 - recall: 0.6231 - auc: 0.7476 - prc: 0.4671 - val_loss: 0.5856 - val_tp: 51.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 40.0000 - val_accuracy: 0.7213 - val_precision: 0.3355 - val_recall: 0.5604 - val_auc: 0.7031 - val_prc: 0.3838\n",
      "Epoch 389/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5861 - tp: 252.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 146.0000 - accuracy: 0.7065 - precision: 0.3600 - recall: 0.6332 - auc: 0.7473 - prc: 0.4649 - val_loss: 0.6390 - val_tp: 57.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 34.0000 - val_accuracy: 0.6542 - val_precision: 0.2879 - val_recall: 0.6264 - val_auc: 0.7014 - val_prc: 0.3834\n",
      "Epoch 390/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5864 - tp: 253.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 145.0000 - accuracy: 0.7105 - precision: 0.3646 - recall: 0.6357 - auc: 0.7469 - prc: 0.4660 - val_loss: 0.6273 - val_tp: 56.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 35.0000 - val_accuracy: 0.6719 - val_precision: 0.2995 - val_recall: 0.6154 - val_auc: 0.7028 - val_prc: 0.3865\n",
      "Epoch 391/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5850 - tp: 246.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 152.0000 - accuracy: 0.7085 - precision: 0.3596 - recall: 0.6181 - auc: 0.7483 - prc: 0.4715 - val_loss: 0.5877 - val_tp: 52.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 39.0000 - val_accuracy: 0.7174 - val_precision: 0.3333 - val_recall: 0.5714 - val_auc: 0.7031 - val_prc: 0.3897\n",
      "Epoch 392/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5853 - tp: 256.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 142.0000 - accuracy: 0.7184 - precision: 0.3743 - recall: 0.6432 - auc: 0.7481 - prc: 0.4751 - val_loss: 0.5921 - val_tp: 52.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 39.0000 - val_accuracy: 0.7292 - val_precision: 0.3467 - val_recall: 0.5714 - val_auc: 0.7014 - val_prc: 0.3828\n",
      "Epoch 393/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5828 - tp: 257.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 141.0000 - accuracy: 0.7169 - precision: 0.3730 - recall: 0.6457 - auc: 0.7516 - prc: 0.4715 - val_loss: 0.6593 - val_tp: 58.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 33.0000 - val_accuracy: 0.6285 - val_precision: 0.2723 - val_recall: 0.6374 - val_auc: 0.7004 - val_prc: 0.3848\n",
      "Epoch 394/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5847 - tp: 256.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 142.0000 - accuracy: 0.7060 - precision: 0.3611 - recall: 0.6432 - auc: 0.7488 - prc: 0.4722 - val_loss: 0.6108 - val_tp: 53.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 38.0000 - val_accuracy: 0.6937 - val_precision: 0.3118 - val_recall: 0.5824 - val_auc: 0.7013 - val_prc: 0.3895\n",
      "Epoch 395/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5843 - tp: 255.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 143.0000 - accuracy: 0.7100 - precision: 0.3648 - recall: 0.6407 - auc: 0.7488 - prc: 0.4747 - val_loss: 0.5685 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.7070 - val_prc: 0.3943\n",
      "Epoch 396/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5832 - tp: 248.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 150.0000 - accuracy: 0.7233 - precision: 0.3769 - recall: 0.6231 - auc: 0.7530 - prc: 0.4756 - val_loss: 0.6327 - val_tp: 56.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 35.0000 - val_accuracy: 0.6680 - val_precision: 0.2963 - val_recall: 0.6154 - val_auc: 0.7037 - val_prc: 0.3778\n",
      "Epoch 397/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5859 - tp: 260.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 138.0000 - accuracy: 0.6986 - precision: 0.3552 - recall: 0.6533 - auc: 0.7503 - prc: 0.4594 - val_loss: 0.6673 - val_tp: 59.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 32.0000 - val_accuracy: 0.6107 - val_precision: 0.2634 - val_recall: 0.6484 - val_auc: 0.6967 - val_prc: 0.3843\n",
      "Epoch 398/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5838 - tp: 257.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 141.0000 - accuracy: 0.7011 - precision: 0.3564 - recall: 0.6457 - auc: 0.7497 - prc: 0.4713 - val_loss: 0.5588 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.7070 - val_prc: 0.4015\n",
      "Epoch 399/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5845 - tp: 249.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 149.0000 - accuracy: 0.7238 - precision: 0.3778 - recall: 0.6256 - auc: 0.7487 - prc: 0.4791 - val_loss: 0.5500 - val_tp: 47.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 44.0000 - val_accuracy: 0.7589 - val_precision: 0.3760 - val_recall: 0.5165 - val_auc: 0.7046 - val_prc: 0.3999\n",
      "Epoch 400/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5880 - tp: 249.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 149.0000 - accuracy: 0.7070 - precision: 0.3593 - recall: 0.6256 - auc: 0.7444 - prc: 0.4640 - val_loss: 0.5798 - val_tp: 49.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 42.0000 - val_accuracy: 0.7154 - val_precision: 0.3245 - val_recall: 0.5385 - val_auc: 0.7067 - val_prc: 0.3934\n",
      "Epoch 401/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5857 - tp: 250.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 148.0000 - accuracy: 0.7129 - precision: 0.3660 - recall: 0.6281 - auc: 0.7479 - prc: 0.4768 - val_loss: 0.5895 - val_tp: 52.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 39.0000 - val_accuracy: 0.7213 - val_precision: 0.3377 - val_recall: 0.5714 - val_auc: 0.7025 - val_prc: 0.3930\n",
      "Epoch 402/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5844 - tp: 251.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 147.0000 - accuracy: 0.7134 - precision: 0.3670 - recall: 0.6307 - auc: 0.7498 - prc: 0.4728 - val_loss: 0.6405 - val_tp: 57.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 34.0000 - val_accuracy: 0.6561 - val_precision: 0.2893 - val_recall: 0.6264 - val_auc: 0.7013 - val_prc: 0.3921\n",
      "Epoch 403/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5815 - tp: 256.0000 - fp: 439.0000 - tn: 1187.0000 - fn: 142.0000 - accuracy: 0.7129 - precision: 0.3683 - recall: 0.6432 - auc: 0.7533 - prc: 0.4773 - val_loss: 0.5840 - val_tp: 49.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 42.0000 - val_accuracy: 0.7154 - val_precision: 0.3245 - val_recall: 0.5385 - val_auc: 0.7052 - val_prc: 0.3965\n",
      "Epoch 404/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5861 - tp: 246.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 152.0000 - accuracy: 0.7144 - precision: 0.3661 - recall: 0.6181 - auc: 0.7464 - prc: 0.4818 - val_loss: 0.5965 - val_tp: 54.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 37.0000 - val_accuracy: 0.7174 - val_precision: 0.3375 - val_recall: 0.5934 - val_auc: 0.7044 - val_prc: 0.3891\n",
      "Epoch 405/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5842 - tp: 260.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 138.0000 - accuracy: 0.6976 - precision: 0.3542 - recall: 0.6533 - auc: 0.7507 - prc: 0.4707 - val_loss: 0.6274 - val_tp: 56.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 35.0000 - val_accuracy: 0.6858 - val_precision: 0.3111 - val_recall: 0.6154 - val_auc: 0.7038 - val_prc: 0.3822\n",
      "Epoch 406/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5841 - tp: 246.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 152.0000 - accuracy: 0.7095 - precision: 0.3607 - recall: 0.6181 - auc: 0.7486 - prc: 0.4743 - val_loss: 0.5486 - val_tp: 47.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 44.0000 - val_accuracy: 0.7589 - val_precision: 0.3760 - val_recall: 0.5165 - val_auc: 0.7028 - val_prc: 0.3989\n",
      "Epoch 407/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5822 - tp: 244.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 154.0000 - accuracy: 0.7218 - precision: 0.3737 - recall: 0.6131 - auc: 0.7513 - prc: 0.4687 - val_loss: 0.6039 - val_tp: 53.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 38.0000 - val_accuracy: 0.7016 - val_precision: 0.3193 - val_recall: 0.5824 - val_auc: 0.7024 - val_prc: 0.3944\n",
      "Epoch 408/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5827 - tp: 259.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 139.0000 - accuracy: 0.7105 - precision: 0.3669 - recall: 0.6508 - auc: 0.7517 - prc: 0.4766 - val_loss: 0.6081 - val_tp: 53.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 38.0000 - val_accuracy: 0.6917 - val_precision: 0.3099 - val_recall: 0.5824 - val_auc: 0.7016 - val_prc: 0.3946\n",
      "Epoch 409/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5842 - tp: 249.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 149.0000 - accuracy: 0.7026 - precision: 0.3547 - recall: 0.6256 - auc: 0.7482 - prc: 0.4702 - val_loss: 0.6335 - val_tp: 56.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 35.0000 - val_accuracy: 0.6700 - val_precision: 0.2979 - val_recall: 0.6154 - val_auc: 0.7041 - val_prc: 0.3876\n",
      "Epoch 410/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5855 - tp: 254.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 144.0000 - accuracy: 0.7021 - precision: 0.3562 - recall: 0.6382 - auc: 0.7484 - prc: 0.4738 - val_loss: 0.5862 - val_tp: 51.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 40.0000 - val_accuracy: 0.7194 - val_precision: 0.3333 - val_recall: 0.5604 - val_auc: 0.7041 - val_prc: 0.3831\n",
      "Epoch 411/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5840 - tp: 252.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 146.0000 - accuracy: 0.7208 - precision: 0.3756 - recall: 0.6332 - auc: 0.7504 - prc: 0.4810 - val_loss: 0.6370 - val_tp: 57.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 34.0000 - val_accuracy: 0.6621 - val_precision: 0.2938 - val_recall: 0.6264 - val_auc: 0.7074 - val_prc: 0.3852\n",
      "Epoch 412/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5859 - tp: 251.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 147.0000 - accuracy: 0.7055 - precision: 0.3586 - recall: 0.6307 - auc: 0.7477 - prc: 0.4655 - val_loss: 0.5797 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.7048 - val_prc: 0.3940\n",
      "Epoch 413/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5826 - tp: 257.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 141.0000 - accuracy: 0.7041 - precision: 0.3594 - recall: 0.6457 - auc: 0.7517 - prc: 0.4787 - val_loss: 0.5736 - val_tp: 49.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 42.0000 - val_accuracy: 0.7194 - val_precision: 0.3289 - val_recall: 0.5385 - val_auc: 0.7066 - val_prc: 0.3899\n",
      "Epoch 414/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5822 - tp: 252.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 146.0000 - accuracy: 0.7055 - precision: 0.3590 - recall: 0.6332 - auc: 0.7518 - prc: 0.4815 - val_loss: 0.5403 - val_tp: 46.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 45.0000 - val_accuracy: 0.7668 - val_precision: 0.3866 - val_recall: 0.5055 - val_auc: 0.7055 - val_prc: 0.4097\n",
      "Epoch 415/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5822 - tp: 239.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 159.0000 - accuracy: 0.7149 - precision: 0.3638 - recall: 0.6005 - auc: 0.7526 - prc: 0.4753 - val_loss: 0.6245 - val_tp: 55.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 36.0000 - val_accuracy: 0.6818 - val_precision: 0.3056 - val_recall: 0.6044 - val_auc: 0.7031 - val_prc: 0.3799\n",
      "Epoch 416/500\n",
      " 85/102 [========================>.....] - ETA: 0s - loss: 0.5820 - tp: 209.0000 - fp: 359.0000 - tn: 1009.0000 - fn: 123.0000 - accuracy: 0.7165 - precision: 0.3680 - recall: 0.6295 - auc: 0.7491 - prc: 0.4760Restoring model weights from the end of the best epoch: 366.\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5835 - tp: 253.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 145.0000 - accuracy: 0.7154 - precision: 0.3699 - recall: 0.6357 - auc: 0.7497 - prc: 0.4775 - val_loss: 0.6079 - val_tp: 54.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 37.0000 - val_accuracy: 0.7016 - val_precision: 0.3214 - val_recall: 0.5934 - val_auc: 0.7058 - val_prc: 0.3827\n",
      "Epoch 416: early stopping\n",
      "26/26 [==============================] - 0s 538us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "# Create a dictionary mapping the class indices to their respective weights\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_values = [{0: 1, 1: 1+i/2} for i in range(1, 8)]  # list of class_weights dictionary\n",
    "class_weights_values.append(class_weights_dict)\n",
    "\n",
    "# Hyperparameter tuning for class weight\n",
    "coordinates = [[0,0]]\n",
    "for i in range(len(class_weights_values)):\n",
    "    class_weight = class_weights_values[i]\n",
    "    model = make_model()\n",
    "    model.load_weights(initial_weights)\n",
    "    baseline_history = model.fit(X_train,\n",
    "                                y_train,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                class_weight=class_weight)\n",
    "    y_pred = (model.predict(X_val, batch_size=BATCH_SIZE) > 0.5).astype(int)\n",
    "    c_mat = confusion_matrix(y_val, y_pred)\n",
    "    # save the values of sensitivity and 1-specificity for ROC curve\n",
    "    sensitivity = c_mat[1,1]/np.sum(c_mat[1,:])\n",
    "    specificity = c_mat[0,0]/np.sum(c_mat[0,:])\n",
    "    coordinates.append([1-specificity,sensitivity])\n",
    "coordinates.append([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87f5b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot roc curve\n",
    "coordinates_np = np.array(sorted(coordinates, key=lambda x: x[0]))  # first column: FP, second column: TP\n",
    "plt.plot(coordinates_np[:,0], coordinates_np[:,1], linewidth=2, marker='o')\n",
    "diag = np.linspace(0,1,20)\n",
    "plt.plot(diag, diag)\n",
    "plt.xlabel('False positives')\n",
    "plt.ylabel('True positives')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.grid(True)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3336bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6223862238622386, 1: 2.542713567839196}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use youden index to find the best class weight\n",
    "youden_np = (coordinates_np[:,1]-coordinates_np[:,0])\n",
    "optimal = coordinates_np[youden_np.argmax(), :]\n",
    "best_class_weight_idx = coordinates.index([optimal[0], optimal[1]])\n",
    "\n",
    "# -1 is needed because coordinates list began with [0,0]\n",
    "best_class_weight = class_weights_values[best_class_weight_idx-1]\n",
    "best_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d0fe4187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "102/102 [==============================] - 1s 4ms/step - loss: 0.9159 - tp: 54.0000 - fp: 114.0000 - tn: 1927.0000 - fn: 435.0000 - accuracy: 0.7830 - precision: 0.3214 - recall: 0.1104 - auc: 0.4935 - prc: 0.2244 - val_loss: 0.4736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 2/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4722 - prc: 0.1839 - val_loss: 0.4763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 3/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4875 - prc: 0.1881 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8487 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4857 - prc: 0.1953 - val_loss: 0.4847 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8296 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.2005 - val_loss: 0.4904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 6/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.8122 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4803 - prc: 0.1869 - val_loss: 0.4971 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 7/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4970 - prc: 0.1958 - val_loss: 0.5041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7821 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5101 - prc: 0.2033 - val_loss: 0.5121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1949 - val_loss: 0.5206 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 10/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7578 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4870 - prc: 0.1890 - val_loss: 0.5299 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 11/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7479 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4945 - prc: 0.1940 - val_loss: 0.5388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4850 - prc: 0.1915 - val_loss: 0.5482 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 13/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7318 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5160 - prc: 0.2026 - val_loss: 0.5574 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 14/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7253 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4915 - prc: 0.1918 - val_loss: 0.5670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 15/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5147 - prc: 0.2016 - val_loss: 0.5767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 16/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7148 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5130 - prc: 0.2024 - val_loss: 0.5854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 17/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5143 - prc: 0.2029 - val_loss: 0.5948 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 18/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7074 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4884 - prc: 0.1915 - val_loss: 0.6037 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 19/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5077 - prc: 0.2066 - val_loss: 0.6109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5072 - val_prc: 0.1820\n",
      "Epoch 20/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5077 - prc: 0.2004 - val_loss: 0.6192 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5048 - val_prc: 0.1813\n",
      "Epoch 21/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.7003 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5255 - prc: 0.2163 - val_loss: 0.6261 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5120 - val_prc: 0.1835\n",
      "Epoch 22/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4775 - prc: 0.1878 - val_loss: 0.6332 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5108 - val_prc: 0.1831\n",
      "Epoch 23/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5068 - prc: 0.1997 - val_loss: 0.6398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5060 - val_prc: 0.1816\n",
      "Epoch 24/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6965 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - prc: 0.1910 - val_loss: 0.6389 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5548 - val_prc: 0.1994\n",
      "Epoch 25/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6945 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5496 - prc: 0.2153 - val_loss: 0.6436 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5668 - val_prc: 0.2034\n",
      "Epoch 26/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5884 - prc: 0.2371 - val_loss: 0.6463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5680 - val_prc: 0.2036\n",
      "Epoch 27/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6884 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5988 - prc: 0.2400 - val_loss: 0.6526 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5751 - val_prc: 0.2068\n",
      "Epoch 28/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6844 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6233 - prc: 0.2627 - val_loss: 0.6240 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6337 - val_prc: 0.2440\n",
      "Epoch 29/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6327 - prc: 0.2708 - val_loss: 0.6021 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6597 - val_prc: 0.2843\n",
      "Epoch 30/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6784 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6411 - prc: 0.2741 - val_loss: 0.5765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6663 - val_prc: 0.3128\n",
      "Epoch 31/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6742 - tp: 152.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 246.0000 - accuracy: 0.7278 - precision: 0.3326 - recall: 0.3819 - auc: 0.6512 - prc: 0.2870 - val_loss: 0.5925 - val_tp: 31.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 60.0000 - val_accuracy: 0.7806 - val_precision: 0.3780 - val_recall: 0.3407 - val_auc: 0.6687 - val_prc: 0.3000\n",
      "Epoch 32/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6702 - tp: 166.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 232.0000 - accuracy: 0.7495 - precision: 0.3764 - recall: 0.4171 - auc: 0.6708 - prc: 0.3138 - val_loss: 0.6290 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6568 - val_prc: 0.2661\n",
      "Epoch 33/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6682 - tp: 199.0000 - fp: 405.0000 - tn: 1221.0000 - fn: 199.0000 - accuracy: 0.7016 - precision: 0.3295 - recall: 0.5000 - auc: 0.6659 - prc: 0.3066 - val_loss: 0.6265 - val_tp: 56.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 35.0000 - val_accuracy: 0.6621 - val_precision: 0.2917 - val_recall: 0.6154 - val_auc: 0.6608 - val_prc: 0.2699\n",
      "Epoch 34/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6676 - tp: 211.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 187.0000 - accuracy: 0.6774 - precision: 0.3117 - recall: 0.5302 - auc: 0.6556 - prc: 0.2855 - val_loss: 0.6271 - val_tp: 56.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 35.0000 - val_accuracy: 0.6502 - val_precision: 0.2828 - val_recall: 0.6154 - val_auc: 0.6624 - val_prc: 0.2731\n",
      "Epoch 35/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6639 - tp: 213.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 185.0000 - accuracy: 0.6858 - precision: 0.3208 - recall: 0.5352 - auc: 0.6677 - prc: 0.3021 - val_loss: 0.6189 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6659 - val_prc: 0.2788\n",
      "Epoch 36/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6598 - tp: 217.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 181.0000 - accuracy: 0.7090 - precision: 0.3472 - recall: 0.5452 - auc: 0.6819 - prc: 0.3297 - val_loss: 0.5937 - val_tp: 45.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 46.0000 - val_accuracy: 0.7194 - val_precision: 0.3191 - val_recall: 0.4945 - val_auc: 0.6774 - val_prc: 0.3109\n",
      "Epoch 37/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6586 - tp: 206.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 192.0000 - accuracy: 0.7090 - precision: 0.3416 - recall: 0.5176 - auc: 0.6846 - prc: 0.3495 - val_loss: 0.5924 - val_tp: 45.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 46.0000 - val_accuracy: 0.7134 - val_precision: 0.3125 - val_recall: 0.4945 - val_auc: 0.6802 - val_prc: 0.3196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6541 - tp: 202.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 196.0000 - accuracy: 0.7327 - precision: 0.3693 - recall: 0.5075 - auc: 0.6952 - prc: 0.3589 - val_loss: 0.6494 - val_tp: 63.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 28.0000 - val_accuracy: 0.5711 - val_precision: 0.2500 - val_recall: 0.6923 - val_auc: 0.6634 - val_prc: 0.2732\n",
      "Epoch 39/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6556 - tp: 236.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 162.0000 - accuracy: 0.6759 - precision: 0.3233 - recall: 0.5930 - auc: 0.6760 - prc: 0.3059 - val_loss: 0.5666 - val_tp: 38.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 53.0000 - val_accuracy: 0.7628 - val_precision: 0.3619 - val_recall: 0.4176 - val_auc: 0.6835 - val_prc: 0.3249\n",
      "Epoch 40/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6531 - tp: 232.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 166.0000 - accuracy: 0.6848 - precision: 0.3295 - recall: 0.5829 - auc: 0.6851 - prc: 0.3373 - val_loss: 0.6110 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6801 - val_prc: 0.3110\n",
      "Epoch 41/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6516 - tp: 216.0000 - fp: 421.0000 - tn: 1205.0000 - fn: 182.0000 - accuracy: 0.7021 - precision: 0.3391 - recall: 0.5427 - auc: 0.6840 - prc: 0.3308 - val_loss: 0.6304 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6793 - val_prc: 0.3071\n",
      "Epoch 42/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6496 - tp: 235.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 163.0000 - accuracy: 0.6744 - precision: 0.3215 - recall: 0.5905 - auc: 0.6912 - prc: 0.3504 - val_loss: 0.6023 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6839 - val_prc: 0.3181\n",
      "Epoch 43/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6427 - tp: 255.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 143.0000 - accuracy: 0.6734 - precision: 0.3299 - recall: 0.6407 - auc: 0.7015 - prc: 0.3447 - val_loss: 0.5311 - val_tp: 32.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 59.0000 - val_accuracy: 0.7905 - val_precision: 0.4051 - val_recall: 0.3516 - val_auc: 0.6894 - val_prc: 0.3540\n",
      "Epoch 44/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6469 - tp: 223.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 175.0000 - accuracy: 0.6813 - precision: 0.3218 - recall: 0.5603 - auc: 0.6895 - prc: 0.3339 - val_loss: 0.5607 - val_tp: 43.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 48.0000 - val_accuracy: 0.7688 - val_precision: 0.3839 - val_recall: 0.4725 - val_auc: 0.6865 - val_prc: 0.3283\n",
      "Epoch 45/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6430 - tp: 225.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 173.0000 - accuracy: 0.7085 - precision: 0.3505 - recall: 0.5653 - auc: 0.7008 - prc: 0.3722 - val_loss: 0.6026 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6842 - val_prc: 0.3223\n",
      "Epoch 46/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6418 - tp: 230.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 168.0000 - accuracy: 0.6922 - precision: 0.3358 - recall: 0.5779 - auc: 0.7002 - prc: 0.3699 - val_loss: 0.6097 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6845 - val_prc: 0.3195\n",
      "Epoch 47/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6410 - tp: 231.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 167.0000 - accuracy: 0.6922 - precision: 0.3362 - recall: 0.5804 - auc: 0.7002 - prc: 0.3661 - val_loss: 0.6128 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6846 - val_prc: 0.3179\n",
      "Epoch 48/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6378 - tp: 231.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 167.0000 - accuracy: 0.6996 - precision: 0.3438 - recall: 0.5804 - auc: 0.7070 - prc: 0.3810 - val_loss: 0.5750 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6880 - val_prc: 0.3277\n",
      "Epoch 49/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6368 - tp: 225.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 173.0000 - accuracy: 0.7159 - precision: 0.3589 - recall: 0.5653 - auc: 0.7063 - prc: 0.3766 - val_loss: 0.6142 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6875 - val_prc: 0.3221\n",
      "Epoch 50/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6356 - tp: 238.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 160.0000 - accuracy: 0.7031 - precision: 0.3505 - recall: 0.5980 - auc: 0.7064 - prc: 0.3736 - val_loss: 0.6007 - val_tp: 54.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 37.0000 - val_accuracy: 0.6818 - val_precision: 0.3034 - val_recall: 0.5934 - val_auc: 0.6894 - val_prc: 0.3361\n",
      "Epoch 51/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6351 - tp: 227.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 171.0000 - accuracy: 0.7105 - precision: 0.3536 - recall: 0.5704 - auc: 0.7062 - prc: 0.3769 - val_loss: 0.6384 - val_tp: 57.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 34.0000 - val_accuracy: 0.6146 - val_precision: 0.2615 - val_recall: 0.6264 - val_auc: 0.6885 - val_prc: 0.3250\n",
      "Epoch 52/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6322 - tp: 236.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 162.0000 - accuracy: 0.6897 - precision: 0.3362 - recall: 0.5930 - auc: 0.7115 - prc: 0.3879 - val_loss: 0.5892 - val_tp: 49.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 42.0000 - val_accuracy: 0.7115 - val_precision: 0.3203 - val_recall: 0.5385 - val_auc: 0.6882 - val_prc: 0.3399\n",
      "Epoch 53/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6309 - tp: 243.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 155.0000 - accuracy: 0.6952 - precision: 0.3447 - recall: 0.6106 - auc: 0.7122 - prc: 0.3782 - val_loss: 0.5595 - val_tp: 45.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 46.0000 - val_accuracy: 0.7688 - val_precision: 0.3879 - val_recall: 0.4945 - val_auc: 0.6904 - val_prc: 0.3548\n",
      "Epoch 54/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6328 - tp: 235.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 163.0000 - accuracy: 0.6917 - precision: 0.3376 - recall: 0.5905 - auc: 0.7061 - prc: 0.3662 - val_loss: 0.6000 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6880 - val_prc: 0.3362\n",
      "Epoch 55/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6304 - tp: 228.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 170.0000 - accuracy: 0.7065 - precision: 0.3497 - recall: 0.5729 - auc: 0.7133 - prc: 0.4063 - val_loss: 0.6294 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6862 - val_prc: 0.3248\n",
      "Epoch 56/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6287 - tp: 252.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 146.0000 - accuracy: 0.6640 - precision: 0.3206 - recall: 0.6332 - auc: 0.7096 - prc: 0.3563 - val_loss: 0.6000 - val_tp: 54.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 37.0000 - val_accuracy: 0.6818 - val_precision: 0.3034 - val_recall: 0.5934 - val_auc: 0.6876 - val_prc: 0.3411\n",
      "Epoch 57/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6278 - tp: 227.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 171.0000 - accuracy: 0.7144 - precision: 0.3580 - recall: 0.5704 - auc: 0.7148 - prc: 0.3901 - val_loss: 0.6246 - val_tp: 57.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 34.0000 - val_accuracy: 0.6482 - val_precision: 0.2836 - val_recall: 0.6264 - val_auc: 0.6872 - val_prc: 0.3290\n",
      "Epoch 58/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6262 - tp: 245.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 153.0000 - accuracy: 0.6803 - precision: 0.3315 - recall: 0.6156 - auc: 0.7168 - prc: 0.3854 - val_loss: 0.5935 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6900 - val_prc: 0.3492\n",
      "Epoch 59/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6245 - tp: 245.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 153.0000 - accuracy: 0.6966 - precision: 0.3470 - recall: 0.6156 - auc: 0.7160 - prc: 0.3834 - val_loss: 0.5814 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6905 - val_prc: 0.3498\n",
      "Epoch 60/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6234 - tp: 240.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 158.0000 - accuracy: 0.6892 - precision: 0.3376 - recall: 0.6030 - auc: 0.7161 - prc: 0.3834 - val_loss: 0.6173 - val_tp: 57.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 34.0000 - val_accuracy: 0.6561 - val_precision: 0.2893 - val_recall: 0.6264 - val_auc: 0.6874 - val_prc: 0.3317\n",
      "Epoch 61/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6231 - tp: 240.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 158.0000 - accuracy: 0.6957 - precision: 0.3438 - recall: 0.6030 - auc: 0.7184 - prc: 0.4071 - val_loss: 0.6225 - val_tp: 58.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 33.0000 - val_accuracy: 0.6581 - val_precision: 0.2929 - val_recall: 0.6374 - val_auc: 0.6890 - val_prc: 0.3336\n",
      "Epoch 62/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6229 - tp: 234.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 164.0000 - accuracy: 0.7100 - precision: 0.3562 - recall: 0.5879 - auc: 0.7203 - prc: 0.4084 - val_loss: 0.6412 - val_tp: 60.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 31.0000 - val_accuracy: 0.6265 - val_precision: 0.2752 - val_recall: 0.6593 - val_auc: 0.6892 - val_prc: 0.3324\n",
      "Epoch 63/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6216 - tp: 244.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 154.0000 - accuracy: 0.6813 - precision: 0.3320 - recall: 0.6131 - auc: 0.7184 - prc: 0.3984 - val_loss: 0.5958 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6937 - val_prc: 0.3551\n",
      "Epoch 64/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6231 - tp: 233.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 165.0000 - accuracy: 0.6942 - precision: 0.3392 - recall: 0.5854 - auc: 0.7162 - prc: 0.3930 - val_loss: 0.6397 - val_tp: 59.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 32.0000 - val_accuracy: 0.6285 - val_precision: 0.2744 - val_recall: 0.6484 - val_auc: 0.6899 - val_prc: 0.3366\n",
      "Epoch 65/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6215 - tp: 243.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 155.0000 - accuracy: 0.6873 - precision: 0.3370 - recall: 0.6106 - auc: 0.7167 - prc: 0.3778 - val_loss: 0.6265 - val_tp: 58.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 33.0000 - val_accuracy: 0.6482 - val_precision: 0.2857 - val_recall: 0.6374 - val_auc: 0.6904 - val_prc: 0.3374\n",
      "Epoch 66/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6195 - tp: 240.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 158.0000 - accuracy: 0.6912 - precision: 0.3395 - recall: 0.6030 - auc: 0.7213 - prc: 0.4037 - val_loss: 0.6451 - val_tp: 59.0000 - val_fp: 163.0000 - val_tn: 252.0000 - val_fn: 32.0000 - val_accuracy: 0.6146 - val_precision: 0.2658 - val_recall: 0.6484 - val_auc: 0.6884 - val_prc: 0.3336\n",
      "Epoch 67/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6214 - tp: 232.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 166.0000 - accuracy: 0.6976 - precision: 0.3422 - recall: 0.5829 - auc: 0.7171 - prc: 0.3962 - val_loss: 0.6378 - val_tp: 58.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 33.0000 - val_accuracy: 0.6304 - val_precision: 0.2736 - val_recall: 0.6374 - val_auc: 0.6897 - val_prc: 0.3375\n",
      "Epoch 68/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6182 - tp: 248.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 150.0000 - accuracy: 0.6793 - precision: 0.3320 - recall: 0.6231 - auc: 0.7214 - prc: 0.3949 - val_loss: 0.5763 - val_tp: 48.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 43.0000 - val_accuracy: 0.7233 - val_precision: 0.3310 - val_recall: 0.5275 - val_auc: 0.6949 - val_prc: 0.3630\n",
      "Epoch 69/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6177 - tp: 231.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 167.0000 - accuracy: 0.6991 - precision: 0.3432 - recall: 0.5804 - auc: 0.7237 - prc: 0.4010 - val_loss: 0.6157 - val_tp: 57.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 34.0000 - val_accuracy: 0.6621 - val_precision: 0.2938 - val_recall: 0.6264 - val_auc: 0.6916 - val_prc: 0.3491\n",
      "Epoch 70/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6163 - tp: 240.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 158.0000 - accuracy: 0.6873 - precision: 0.3357 - recall: 0.6030 - auc: 0.7240 - prc: 0.3989 - val_loss: 0.6095 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6943 - val_prc: 0.3567\n",
      "Epoch 71/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6174 - tp: 240.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 158.0000 - accuracy: 0.6981 - precision: 0.3463 - recall: 0.6030 - auc: 0.7226 - prc: 0.4048 - val_loss: 0.5962 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6935 - val_prc: 0.3585\n",
      "Epoch 72/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6149 - tp: 249.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 149.0000 - accuracy: 0.7021 - precision: 0.3542 - recall: 0.6256 - auc: 0.7252 - prc: 0.4150 - val_loss: 0.5816 - val_tp: 49.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 42.0000 - val_accuracy: 0.7273 - val_precision: 0.3379 - val_recall: 0.5385 - val_auc: 0.6958 - val_prc: 0.3613\n",
      "Epoch 73/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6156 - tp: 238.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 160.0000 - accuracy: 0.7021 - precision: 0.3495 - recall: 0.5980 - auc: 0.7251 - prc: 0.4086 - val_loss: 0.6022 - val_tp: 52.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 39.0000 - val_accuracy: 0.6680 - val_precision: 0.2873 - val_recall: 0.5714 - val_auc: 0.6955 - val_prc: 0.3649\n",
      "Epoch 74/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6145 - tp: 245.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 153.0000 - accuracy: 0.6907 - precision: 0.3412 - recall: 0.6156 - auc: 0.7266 - prc: 0.4056 - val_loss: 0.5709 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6973 - val_prc: 0.3741\n",
      "Epoch 75/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6153 - tp: 244.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 154.0000 - accuracy: 0.6927 - precision: 0.3427 - recall: 0.6131 - auc: 0.7237 - prc: 0.4050 - val_loss: 0.6434 - val_tp: 59.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 32.0000 - val_accuracy: 0.6225 - val_precision: 0.2706 - val_recall: 0.6484 - val_auc: 0.6942 - val_prc: 0.3459\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6133 - tp: 241.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 157.0000 - accuracy: 0.7036 - precision: 0.3523 - recall: 0.6055 - auc: 0.7269 - prc: 0.4083 - val_loss: 0.6504 - val_tp: 61.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 30.0000 - val_accuracy: 0.6008 - val_precision: 0.2618 - val_recall: 0.6703 - val_auc: 0.6908 - val_prc: 0.3407\n",
      "Epoch 77/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6124 - tp: 248.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 150.0000 - accuracy: 0.6833 - precision: 0.3356 - recall: 0.6231 - auc: 0.7282 - prc: 0.4111 - val_loss: 0.5523 - val_tp: 47.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 44.0000 - val_accuracy: 0.7628 - val_precision: 0.3821 - val_recall: 0.5165 - val_auc: 0.6988 - val_prc: 0.3833\n",
      "Epoch 78/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6131 - tp: 241.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 157.0000 - accuracy: 0.7090 - precision: 0.3581 - recall: 0.6055 - auc: 0.7258 - prc: 0.4168 - val_loss: 0.6189 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6938 - val_prc: 0.3583\n",
      "Epoch 79/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6139 - tp: 236.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 162.0000 - accuracy: 0.7006 - precision: 0.3471 - recall: 0.5930 - auc: 0.7262 - prc: 0.4042 - val_loss: 0.7307 - val_tp: 67.0000 - val_fp: 225.0000 - val_tn: 190.0000 - val_fn: 24.0000 - val_accuracy: 0.5079 - val_precision: 0.2295 - val_recall: 0.7363 - val_auc: 0.6865 - val_prc: 0.3324\n",
      "Epoch 80/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6136 - tp: 256.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 142.0000 - accuracy: 0.6838 - precision: 0.3395 - recall: 0.6432 - auc: 0.7250 - prc: 0.4143 - val_loss: 0.6414 - val_tp: 59.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 32.0000 - val_accuracy: 0.6245 - val_precision: 0.2719 - val_recall: 0.6484 - val_auc: 0.6953 - val_prc: 0.3620\n",
      "Epoch 81/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6101 - tp: 234.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 164.0000 - accuracy: 0.6932 - precision: 0.3386 - recall: 0.5879 - auc: 0.7297 - prc: 0.4143 - val_loss: 0.6464 - val_tp: 59.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 32.0000 - val_accuracy: 0.6166 - val_precision: 0.2670 - val_recall: 0.6484 - val_auc: 0.6966 - val_prc: 0.3556\n",
      "Epoch 82/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6100 - tp: 252.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 146.0000 - accuracy: 0.6833 - precision: 0.3373 - recall: 0.6332 - auc: 0.7307 - prc: 0.4153 - val_loss: 0.5614 - val_tp: 47.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 44.0000 - val_accuracy: 0.7470 - val_precision: 0.3588 - val_recall: 0.5165 - val_auc: 0.6982 - val_prc: 0.3801\n",
      "Epoch 83/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6128 - tp: 246.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 152.0000 - accuracy: 0.6952 - precision: 0.3460 - recall: 0.6181 - auc: 0.7255 - prc: 0.4160 - val_loss: 0.6178 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6967 - val_prc: 0.3677\n",
      "Epoch 84/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6116 - tp: 247.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 151.0000 - accuracy: 0.6823 - precision: 0.3342 - recall: 0.6206 - auc: 0.7271 - prc: 0.4144 - val_loss: 0.5711 - val_tp: 48.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 43.0000 - val_accuracy: 0.7352 - val_precision: 0.3453 - val_recall: 0.5275 - val_auc: 0.6983 - val_prc: 0.3742\n",
      "Epoch 85/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6093 - tp: 245.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 153.0000 - accuracy: 0.7149 - precision: 0.3662 - recall: 0.6156 - auc: 0.7312 - prc: 0.4263 - val_loss: 0.6371 - val_tp: 59.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 32.0000 - val_accuracy: 0.6304 - val_precision: 0.2757 - val_recall: 0.6484 - val_auc: 0.6941 - val_prc: 0.3625\n",
      "Epoch 86/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6095 - tp: 257.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 141.0000 - accuracy: 0.6902 - precision: 0.3459 - recall: 0.6457 - auc: 0.7300 - prc: 0.4055 - val_loss: 0.6777 - val_tp: 64.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 27.0000 - val_accuracy: 0.5731 - val_precision: 0.2530 - val_recall: 0.7033 - val_auc: 0.6932 - val_prc: 0.3510\n",
      "Epoch 87/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6103 - tp: 253.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 145.0000 - accuracy: 0.6793 - precision: 0.3342 - recall: 0.6357 - auc: 0.7267 - prc: 0.4177 - val_loss: 0.5533 - val_tp: 47.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 44.0000 - val_accuracy: 0.7510 - val_precision: 0.3643 - val_recall: 0.5165 - val_auc: 0.6994 - val_prc: 0.3905\n",
      "Epoch 88/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6100 - tp: 249.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 149.0000 - accuracy: 0.6917 - precision: 0.3439 - recall: 0.6256 - auc: 0.7284 - prc: 0.4305 - val_loss: 0.5854 - val_tp: 48.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 43.0000 - val_accuracy: 0.7154 - val_precision: 0.3221 - val_recall: 0.5275 - val_auc: 0.6993 - val_prc: 0.3712\n",
      "Epoch 89/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6077 - tp: 248.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 150.0000 - accuracy: 0.7001 - precision: 0.3518 - recall: 0.6231 - auc: 0.7324 - prc: 0.4212 - val_loss: 0.6384 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.6926 - val_prc: 0.3616\n",
      "Epoch 90/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6093 - tp: 251.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 147.0000 - accuracy: 0.6887 - precision: 0.3420 - recall: 0.6307 - auc: 0.7289 - prc: 0.4127 - val_loss: 0.6173 - val_tp: 54.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 37.0000 - val_accuracy: 0.6482 - val_precision: 0.2769 - val_recall: 0.5934 - val_auc: 0.6959 - val_prc: 0.3783\n",
      "Epoch 91/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6104 - tp: 249.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 149.0000 - accuracy: 0.6853 - precision: 0.3379 - recall: 0.6256 - auc: 0.7278 - prc: 0.4155 - val_loss: 0.5994 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6986 - val_prc: 0.3790\n",
      "Epoch 92/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6091 - tp: 242.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 156.0000 - accuracy: 0.6961 - precision: 0.3452 - recall: 0.6080 - auc: 0.7295 - prc: 0.4252 - val_loss: 0.5758 - val_tp: 48.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 43.0000 - val_accuracy: 0.7292 - val_precision: 0.3380 - val_recall: 0.5275 - val_auc: 0.6955 - val_prc: 0.3629\n",
      "Epoch 93/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6082 - tp: 246.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 152.0000 - accuracy: 0.6858 - precision: 0.3370 - recall: 0.6181 - auc: 0.7312 - prc: 0.4226 - val_loss: 0.5918 - val_tp: 50.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 41.0000 - val_accuracy: 0.7075 - val_precision: 0.3185 - val_recall: 0.5495 - val_auc: 0.6964 - val_prc: 0.3752\n",
      "Epoch 94/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6076 - tp: 250.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 148.0000 - accuracy: 0.6947 - precision: 0.3472 - recall: 0.6281 - auc: 0.7311 - prc: 0.4256 - val_loss: 0.5984 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6957 - val_prc: 0.3794\n",
      "Epoch 95/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6068 - tp: 245.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 153.0000 - accuracy: 0.7060 - precision: 0.3566 - recall: 0.6156 - auc: 0.7320 - prc: 0.4280 - val_loss: 0.5947 - val_tp: 50.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 41.0000 - val_accuracy: 0.6818 - val_precision: 0.2941 - val_recall: 0.5495 - val_auc: 0.6978 - val_prc: 0.3732\n",
      "Epoch 96/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6052 - tp: 249.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 149.0000 - accuracy: 0.6902 - precision: 0.3425 - recall: 0.6256 - auc: 0.7348 - prc: 0.4247 - val_loss: 0.6375 - val_tp: 57.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 34.0000 - val_accuracy: 0.6186 - val_precision: 0.2639 - val_recall: 0.6264 - val_auc: 0.6919 - val_prc: 0.3653\n",
      "Epoch 97/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6065 - tp: 257.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 141.0000 - accuracy: 0.6922 - precision: 0.3478 - recall: 0.6457 - auc: 0.7322 - prc: 0.4223 - val_loss: 0.5868 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6960 - val_prc: 0.3725\n",
      "Epoch 98/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6062 - tp: 254.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 144.0000 - accuracy: 0.6971 - precision: 0.3513 - recall: 0.6382 - auc: 0.7326 - prc: 0.4208 - val_loss: 0.6070 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6968 - val_prc: 0.3846\n",
      "Epoch 99/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6064 - tp: 255.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 143.0000 - accuracy: 0.6912 - precision: 0.3460 - recall: 0.6407 - auc: 0.7318 - prc: 0.4182 - val_loss: 0.5751 - val_tp: 49.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 42.0000 - val_accuracy: 0.7312 - val_precision: 0.3427 - val_recall: 0.5385 - val_auc: 0.6974 - val_prc: 0.3681\n",
      "Epoch 100/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6072 - tp: 248.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 150.0000 - accuracy: 0.7036 - precision: 0.3553 - recall: 0.6231 - auc: 0.7314 - prc: 0.4283 - val_loss: 0.5753 - val_tp: 49.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 42.0000 - val_accuracy: 0.7233 - val_precision: 0.3333 - val_recall: 0.5385 - val_auc: 0.6957 - val_prc: 0.3674\n",
      "Epoch 101/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6047 - tp: 244.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 154.0000 - accuracy: 0.6917 - precision: 0.3417 - recall: 0.6131 - auc: 0.7347 - prc: 0.4287 - val_loss: 0.5815 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6956 - val_prc: 0.3724\n",
      "Epoch 102/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6083 - tp: 250.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 148.0000 - accuracy: 0.7045 - precision: 0.3571 - recall: 0.6281 - auc: 0.7279 - prc: 0.4226 - val_loss: 0.6174 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6947 - val_prc: 0.3817\n",
      "Epoch 103/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6060 - tp: 251.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 147.0000 - accuracy: 0.7036 - precision: 0.3565 - recall: 0.6307 - auc: 0.7331 - prc: 0.4365 - val_loss: 0.5762 - val_tp: 49.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 42.0000 - val_accuracy: 0.7312 - val_precision: 0.3427 - val_recall: 0.5385 - val_auc: 0.6977 - val_prc: 0.3773\n",
      "Epoch 104/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6065 - tp: 248.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 150.0000 - accuracy: 0.7060 - precision: 0.3579 - recall: 0.6231 - auc: 0.7317 - prc: 0.4241 - val_loss: 0.6285 - val_tp: 54.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 37.0000 - val_accuracy: 0.6324 - val_precision: 0.2660 - val_recall: 0.5934 - val_auc: 0.6965 - val_prc: 0.3823\n",
      "Epoch 105/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6053 - tp: 253.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 145.0000 - accuracy: 0.6947 - precision: 0.3485 - recall: 0.6357 - auc: 0.7318 - prc: 0.4138 - val_loss: 0.6419 - val_tp: 59.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 32.0000 - val_accuracy: 0.6245 - val_precision: 0.2719 - val_recall: 0.6484 - val_auc: 0.6954 - val_prc: 0.3806\n",
      "Epoch 106/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6070 - tp: 243.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 155.0000 - accuracy: 0.7026 - precision: 0.3522 - recall: 0.6106 - auc: 0.7311 - prc: 0.4344 - val_loss: 0.5808 - val_tp: 51.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 40.0000 - val_accuracy: 0.7194 - val_precision: 0.3333 - val_recall: 0.5604 - val_auc: 0.6966 - val_prc: 0.3825\n",
      "Epoch 107/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6063 - tp: 251.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 147.0000 - accuracy: 0.6769 - precision: 0.3311 - recall: 0.6307 - auc: 0.7311 - prc: 0.4240 - val_loss: 0.5963 - val_tp: 53.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 38.0000 - val_accuracy: 0.6957 - val_precision: 0.3136 - val_recall: 0.5824 - val_auc: 0.6960 - val_prc: 0.3764\n",
      "Epoch 108/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6041 - tp: 250.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 148.0000 - accuracy: 0.7070 - precision: 0.3597 - recall: 0.6281 - auc: 0.7340 - prc: 0.4320 - val_loss: 0.6298 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6959 - val_prc: 0.3880\n",
      "Epoch 109/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6040 - tp: 255.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 143.0000 - accuracy: 0.6828 - precision: 0.3382 - recall: 0.6407 - auc: 0.7339 - prc: 0.4283 - val_loss: 0.6217 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6969 - val_prc: 0.3834\n",
      "Epoch 110/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6039 - tp: 243.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 155.0000 - accuracy: 0.7105 - precision: 0.3605 - recall: 0.6106 - auc: 0.7341 - prc: 0.4361 - val_loss: 0.6567 - val_tp: 61.0000 - val_fp: 166.0000 - val_tn: 249.0000 - val_fn: 30.0000 - val_accuracy: 0.6126 - val_precision: 0.2687 - val_recall: 0.6703 - val_auc: 0.6963 - val_prc: 0.3667\n",
      "Epoch 111/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6038 - tp: 258.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 140.0000 - accuracy: 0.6902 - precision: 0.3463 - recall: 0.6482 - auc: 0.7333 - prc: 0.4211 - val_loss: 0.6133 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6935 - val_prc: 0.3730\n",
      "Epoch 112/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6032 - tp: 246.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 152.0000 - accuracy: 0.7041 - precision: 0.3550 - recall: 0.6181 - auc: 0.7344 - prc: 0.4335 - val_loss: 0.5978 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6950 - val_prc: 0.3730\n",
      "Epoch 113/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6036 - tp: 250.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 148.0000 - accuracy: 0.6981 - precision: 0.3506 - recall: 0.6281 - auc: 0.7336 - prc: 0.4205 - val_loss: 0.6366 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6951 - val_prc: 0.3810\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6038 - tp: 253.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 145.0000 - accuracy: 0.6922 - precision: 0.3461 - recall: 0.6357 - auc: 0.7318 - prc: 0.4293 - val_loss: 0.5580 - val_tp: 48.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 43.0000 - val_accuracy: 0.7490 - val_precision: 0.3636 - val_recall: 0.5275 - val_auc: 0.6984 - val_prc: 0.3928\n",
      "Epoch 115/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6045 - tp: 245.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 153.0000 - accuracy: 0.6996 - precision: 0.3500 - recall: 0.6156 - auc: 0.7320 - prc: 0.4365 - val_loss: 0.6352 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6995 - val_prc: 0.3796\n",
      "Epoch 116/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6043 - tp: 256.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 142.0000 - accuracy: 0.6966 - precision: 0.3516 - recall: 0.6432 - auc: 0.7317 - prc: 0.4310 - val_loss: 0.5832 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6977 - val_prc: 0.3781\n",
      "Epoch 117/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6032 - tp: 236.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 162.0000 - accuracy: 0.6927 - precision: 0.3391 - recall: 0.5930 - auc: 0.7345 - prc: 0.4424 - val_loss: 0.7047 - val_tp: 65.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 26.0000 - val_accuracy: 0.5534 - val_precision: 0.2453 - val_recall: 0.7143 - val_auc: 0.6890 - val_prc: 0.3561\n",
      "Epoch 118/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6057 - tp: 256.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 142.0000 - accuracy: 0.6729 - precision: 0.3299 - recall: 0.6432 - auc: 0.7305 - prc: 0.4271 - val_loss: 0.5921 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6963 - val_prc: 0.3787\n",
      "Epoch 119/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6056 - tp: 242.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 156.0000 - accuracy: 0.7001 - precision: 0.3492 - recall: 0.6080 - auc: 0.7303 - prc: 0.4302 - val_loss: 0.6365 - val_tp: 56.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 35.0000 - val_accuracy: 0.6245 - val_precision: 0.2654 - val_recall: 0.6154 - val_auc: 0.6943 - val_prc: 0.3804\n",
      "Epoch 120/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6036 - tp: 253.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 145.0000 - accuracy: 0.6873 - precision: 0.3414 - recall: 0.6357 - auc: 0.7327 - prc: 0.4238 - val_loss: 0.6187 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6922 - val_prc: 0.3674\n",
      "Epoch 121/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6024 - tp: 259.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 139.0000 - accuracy: 0.6868 - precision: 0.3435 - recall: 0.6508 - auc: 0.7361 - prc: 0.4349 - val_loss: 0.5749 - val_tp: 49.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 42.0000 - val_accuracy: 0.7332 - val_precision: 0.3451 - val_recall: 0.5385 - val_auc: 0.6980 - val_prc: 0.3787\n",
      "Epoch 122/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6023 - tp: 249.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 149.0000 - accuracy: 0.7026 - precision: 0.3547 - recall: 0.6256 - auc: 0.7345 - prc: 0.4412 - val_loss: 0.6235 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6967 - val_prc: 0.3736\n",
      "Epoch 123/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6065 - tp: 239.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 159.0000 - accuracy: 0.7060 - precision: 0.3541 - recall: 0.6005 - auc: 0.7284 - prc: 0.4347 - val_loss: 0.6003 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6965 - val_prc: 0.3804\n",
      "Epoch 124/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6031 - tp: 250.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 148.0000 - accuracy: 0.7011 - precision: 0.3536 - recall: 0.6281 - auc: 0.7337 - prc: 0.4410 - val_loss: 0.6882 - val_tp: 63.0000 - val_fp: 190.0000 - val_tn: 225.0000 - val_fn: 28.0000 - val_accuracy: 0.5692 - val_precision: 0.2490 - val_recall: 0.6923 - val_auc: 0.6908 - val_prc: 0.3635\n",
      "Epoch 125/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6009 - tp: 256.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 142.0000 - accuracy: 0.6902 - precision: 0.3455 - recall: 0.6432 - auc: 0.7362 - prc: 0.4371 - val_loss: 0.6376 - val_tp: 55.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 36.0000 - val_accuracy: 0.6265 - val_precision: 0.2644 - val_recall: 0.6044 - val_auc: 0.6928 - val_prc: 0.3787\n",
      "Epoch 126/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6046 - tp: 250.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 148.0000 - accuracy: 0.6873 - precision: 0.3401 - recall: 0.6281 - auc: 0.7313 - prc: 0.4335 - val_loss: 0.5589 - val_tp: 48.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 43.0000 - val_accuracy: 0.7490 - val_precision: 0.3636 - val_recall: 0.5275 - val_auc: 0.6942 - val_prc: 0.3861\n",
      "Epoch 127/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5994 - tp: 252.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 146.0000 - accuracy: 0.7050 - precision: 0.3585 - recall: 0.6332 - auc: 0.7390 - prc: 0.4474 - val_loss: 0.5323 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6971 - val_prc: 0.3799\n",
      "Epoch 128/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6016 - tp: 245.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 153.0000 - accuracy: 0.6902 - precision: 0.3408 - recall: 0.6156 - auc: 0.7348 - prc: 0.4315 - val_loss: 0.5781 - val_tp: 50.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 41.0000 - val_accuracy: 0.7213 - val_precision: 0.3333 - val_recall: 0.5495 - val_auc: 0.6927 - val_prc: 0.3757\n",
      "Epoch 129/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6010 - tp: 245.0000 - fp: 468.0000 - tn: 1158.0000 - fn: 153.0000 - accuracy: 0.6932 - precision: 0.3436 - recall: 0.6156 - auc: 0.7355 - prc: 0.4499 - val_loss: 0.5738 - val_tp: 49.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 42.0000 - val_accuracy: 0.7372 - val_precision: 0.3500 - val_recall: 0.5385 - val_auc: 0.6998 - val_prc: 0.3857\n",
      "Epoch 130/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6017 - tp: 245.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 153.0000 - accuracy: 0.7120 - precision: 0.3630 - recall: 0.6156 - auc: 0.7342 - prc: 0.4436 - val_loss: 0.6299 - val_tp: 57.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 34.0000 - val_accuracy: 0.6482 - val_precision: 0.2836 - val_recall: 0.6264 - val_auc: 0.6961 - val_prc: 0.3772\n",
      "Epoch 131/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6023 - tp: 254.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 144.0000 - accuracy: 0.6863 - precision: 0.3409 - recall: 0.6382 - auc: 0.7348 - prc: 0.4326 - val_loss: 0.6294 - val_tp: 54.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 37.0000 - val_accuracy: 0.6462 - val_precision: 0.2755 - val_recall: 0.5934 - val_auc: 0.6929 - val_prc: 0.3723\n",
      "Epoch 132/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6031 - tp: 248.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 150.0000 - accuracy: 0.7011 - precision: 0.3528 - recall: 0.6231 - auc: 0.7323 - prc: 0.4335 - val_loss: 0.5893 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6951 - val_prc: 0.3788\n",
      "Epoch 133/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6000 - tp: 249.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 149.0000 - accuracy: 0.7001 - precision: 0.3522 - recall: 0.6256 - auc: 0.7372 - prc: 0.4516 - val_loss: 0.6234 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6948 - val_prc: 0.3816\n",
      "Epoch 134/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6006 - tp: 245.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 153.0000 - accuracy: 0.7228 - precision: 0.3752 - recall: 0.6156 - auc: 0.7369 - prc: 0.4494 - val_loss: 0.6366 - val_tp: 55.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 36.0000 - val_accuracy: 0.6245 - val_precision: 0.2632 - val_recall: 0.6044 - val_auc: 0.6928 - val_prc: 0.3721\n",
      "Epoch 135/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6027 - tp: 260.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 138.0000 - accuracy: 0.6828 - precision: 0.3403 - recall: 0.6533 - auc: 0.7332 - prc: 0.4301 - val_loss: 0.5708 - val_tp: 49.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 42.0000 - val_accuracy: 0.7411 - val_precision: 0.3551 - val_recall: 0.5385 - val_auc: 0.6952 - val_prc: 0.3778\n",
      "Epoch 136/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6015 - tp: 249.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 149.0000 - accuracy: 0.7045 - precision: 0.3567 - recall: 0.6256 - auc: 0.7348 - prc: 0.4397 - val_loss: 0.5857 - val_tp: 49.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 42.0000 - val_accuracy: 0.7194 - val_precision: 0.3289 - val_recall: 0.5385 - val_auc: 0.6993 - val_prc: 0.3891\n",
      "Epoch 137/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6017 - tp: 252.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 146.0000 - accuracy: 0.6897 - precision: 0.3433 - recall: 0.6332 - auc: 0.7336 - prc: 0.4422 - val_loss: 0.6450 - val_tp: 57.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 34.0000 - val_accuracy: 0.6206 - val_precision: 0.2651 - val_recall: 0.6264 - val_auc: 0.6925 - val_prc: 0.3702\n",
      "Epoch 138/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6012 - tp: 248.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 150.0000 - accuracy: 0.7125 - precision: 0.3647 - recall: 0.6231 - auc: 0.7353 - prc: 0.4522 - val_loss: 0.6226 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6954 - val_prc: 0.3784\n",
      "Epoch 139/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6003 - tp: 251.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 147.0000 - accuracy: 0.7065 - precision: 0.3596 - recall: 0.6307 - auc: 0.7357 - prc: 0.4500 - val_loss: 0.5946 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6945 - val_prc: 0.3797\n",
      "Epoch 140/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6008 - tp: 249.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 149.0000 - accuracy: 0.7031 - precision: 0.3552 - recall: 0.6256 - auc: 0.7349 - prc: 0.4505 - val_loss: 0.6240 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6953 - val_prc: 0.3827\n",
      "Epoch 141/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6011 - tp: 247.0000 - fp: 429.0000 - tn: 1197.0000 - fn: 151.0000 - accuracy: 0.7134 - precision: 0.3654 - recall: 0.6206 - auc: 0.7350 - prc: 0.4435 - val_loss: 0.6457 - val_tp: 57.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 34.0000 - val_accuracy: 0.6206 - val_precision: 0.2651 - val_recall: 0.6264 - val_auc: 0.6939 - val_prc: 0.3765\n",
      "Epoch 142/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5992 - tp: 254.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 144.0000 - accuracy: 0.7016 - precision: 0.3557 - recall: 0.6382 - auc: 0.7377 - prc: 0.4472 - val_loss: 0.5484 - val_tp: 46.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 45.0000 - val_accuracy: 0.7708 - val_precision: 0.3932 - val_recall: 0.5055 - val_auc: 0.6978 - val_prc: 0.3830\n",
      "Epoch 143/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5985 - tp: 243.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 155.0000 - accuracy: 0.7189 - precision: 0.3699 - recall: 0.6106 - auc: 0.7379 - prc: 0.4505 - val_loss: 0.6224 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6938 - val_prc: 0.3744\n",
      "Epoch 144/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6019 - tp: 247.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 151.0000 - accuracy: 0.7090 - precision: 0.3606 - recall: 0.6206 - auc: 0.7334 - prc: 0.4507 - val_loss: 0.6458 - val_tp: 56.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 35.0000 - val_accuracy: 0.6186 - val_precision: 0.2617 - val_recall: 0.6154 - val_auc: 0.6903 - val_prc: 0.3684\n",
      "Epoch 145/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6014 - tp: 243.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 155.0000 - accuracy: 0.7026 - precision: 0.3522 - recall: 0.6106 - auc: 0.7348 - prc: 0.4446 - val_loss: 0.6444 - val_tp: 57.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 34.0000 - val_accuracy: 0.6245 - val_precision: 0.2676 - val_recall: 0.6264 - val_auc: 0.6936 - val_prc: 0.3827\n",
      "Epoch 146/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6014 - tp: 252.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 146.0000 - accuracy: 0.7031 - precision: 0.3564 - recall: 0.6332 - auc: 0.7340 - prc: 0.4428 - val_loss: 0.6137 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6961 - val_prc: 0.3792\n",
      "Epoch 147/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6002 - tp: 246.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 152.0000 - accuracy: 0.7070 - precision: 0.3581 - recall: 0.6181 - auc: 0.7343 - prc: 0.4531 - val_loss: 0.5913 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6969 - val_prc: 0.3843\n",
      "Epoch 148/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6007 - tp: 249.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 149.0000 - accuracy: 0.6922 - precision: 0.3444 - recall: 0.6256 - auc: 0.7345 - prc: 0.4516 - val_loss: 0.6129 - val_tp: 51.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 40.0000 - val_accuracy: 0.6700 - val_precision: 0.2865 - val_recall: 0.5604 - val_auc: 0.6952 - val_prc: 0.3851\n",
      "Epoch 149/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6027 - tp: 251.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 147.0000 - accuracy: 0.7001 - precision: 0.3530 - recall: 0.6307 - auc: 0.7320 - prc: 0.4430 - val_loss: 0.6781 - val_tp: 61.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 30.0000 - val_accuracy: 0.5870 - val_precision: 0.2542 - val_recall: 0.6703 - val_auc: 0.6912 - val_prc: 0.3729\n",
      "Epoch 150/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5997 - tp: 242.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 156.0000 - accuracy: 0.7115 - precision: 0.3612 - recall: 0.6080 - auc: 0.7353 - prc: 0.4510 - val_loss: 0.7010 - val_tp: 64.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 27.0000 - val_accuracy: 0.5593 - val_precision: 0.2462 - val_recall: 0.7033 - val_auc: 0.6903 - val_prc: 0.3748\n",
      "Epoch 151/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6000 - tp: 270.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 128.0000 - accuracy: 0.6729 - precision: 0.3358 - recall: 0.6784 - auc: 0.7387 - prc: 0.4346 - val_loss: 0.5837 - val_tp: 49.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 42.0000 - val_accuracy: 0.7174 - val_precision: 0.3267 - val_recall: 0.5385 - val_auc: 0.6982 - val_prc: 0.3816\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5999 - tp: 250.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 148.0000 - accuracy: 0.7194 - precision: 0.3731 - recall: 0.6281 - auc: 0.7358 - prc: 0.4475 - val_loss: 0.6005 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6922 - val_prc: 0.3778\n",
      "Epoch 153/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6004 - tp: 248.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 150.0000 - accuracy: 0.6981 - precision: 0.3498 - recall: 0.6231 - auc: 0.7344 - prc: 0.4451 - val_loss: 0.6138 - val_tp: 52.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 39.0000 - val_accuracy: 0.6818 - val_precision: 0.2989 - val_recall: 0.5714 - val_auc: 0.6934 - val_prc: 0.3772\n",
      "Epoch 154/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5997 - tp: 256.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 142.0000 - accuracy: 0.6932 - precision: 0.3483 - recall: 0.6432 - auc: 0.7358 - prc: 0.4496 - val_loss: 0.6161 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6917 - val_prc: 0.3712\n",
      "Epoch 155/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5974 - tp: 250.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 148.0000 - accuracy: 0.7070 - precision: 0.3597 - recall: 0.6281 - auc: 0.7372 - prc: 0.4611 - val_loss: 0.6210 - val_tp: 55.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 36.0000 - val_accuracy: 0.6719 - val_precision: 0.2973 - val_recall: 0.6044 - val_auc: 0.6961 - val_prc: 0.3827\n",
      "Epoch 156/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5971 - tp: 253.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 145.0000 - accuracy: 0.6897 - precision: 0.3438 - recall: 0.6357 - auc: 0.7395 - prc: 0.4431 - val_loss: 0.5325 - val_tp: 43.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 48.0000 - val_accuracy: 0.7727 - val_precision: 0.3909 - val_recall: 0.4725 - val_auc: 0.6955 - val_prc: 0.3784\n",
      "Epoch 157/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6002 - tp: 251.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 147.0000 - accuracy: 0.6887 - precision: 0.3420 - recall: 0.6307 - auc: 0.7355 - prc: 0.4382 - val_loss: 0.5976 - val_tp: 49.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 42.0000 - val_accuracy: 0.6937 - val_precision: 0.3025 - val_recall: 0.5385 - val_auc: 0.6966 - val_prc: 0.3777\n",
      "Epoch 158/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5985 - tp: 244.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 154.0000 - accuracy: 0.7080 - precision: 0.3583 - recall: 0.6131 - auc: 0.7372 - prc: 0.4553 - val_loss: 0.6170 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6948 - val_prc: 0.3777\n",
      "Epoch 159/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.6002 - tp: 253.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 145.0000 - accuracy: 0.6922 - precision: 0.3461 - recall: 0.6357 - auc: 0.7353 - prc: 0.4398 - val_loss: 0.5626 - val_tp: 50.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 41.0000 - val_accuracy: 0.7549 - val_precision: 0.3759 - val_recall: 0.5495 - val_auc: 0.6985 - val_prc: 0.3723\n",
      "Epoch 160/500\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5989 - tp: 248.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 150.0000 - accuracy: 0.7129 - precision: 0.3652 - recall: 0.6231 - auc: 0.7354 - prc: 0.4534 - val_loss: 0.6273 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6931 - val_prc: 0.3701\n",
      "Epoch 161/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6004 - tp: 254.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 144.0000 - accuracy: 0.6922 - precision: 0.3465 - recall: 0.6382 - auc: 0.7341 - prc: 0.4376 - val_loss: 0.6193 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6971 - val_prc: 0.3855\n",
      "Epoch 162/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5977 - tp: 252.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 146.0000 - accuracy: 0.7050 - precision: 0.3585 - recall: 0.6332 - auc: 0.7370 - prc: 0.4590 - val_loss: 0.6029 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6937 - val_prc: 0.3783\n",
      "Epoch 163/500\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5995 - tp: 241.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 157.0000 - accuracy: 0.7139 - precision: 0.3635 - recall: 0.6055 - auc: 0.7354 - prc: 0.4554 - val_loss: 0.6299 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6930 - val_prc: 0.3724\n",
      "Epoch 164/500\n",
      " 92/102 [==========================>...] - ETA: 0s - loss: 0.5942 - tp: 228.0000 - fp: 423.0000 - tn: 1056.0000 - fn: 133.0000 - accuracy: 0.6978 - precision: 0.3502 - recall: 0.6316 - auc: 0.7398 - prc: 0.4661Restoring model weights from the end of the best epoch: 114.\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6011 - tp: 249.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 149.0000 - accuracy: 0.6976 - precision: 0.3497 - recall: 0.6256 - auc: 0.7325 - prc: 0.4549 - val_loss: 0.5881 - val_tp: 50.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 41.0000 - val_accuracy: 0.7154 - val_precision: 0.3268 - val_recall: 0.5495 - val_auc: 0.6955 - val_prc: 0.3818\n",
      "Epoch 164: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train a NN model based on the best class weight found\n",
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=best_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6296186c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61bfc491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 564us/step\n",
      "32/32 [==============================] - 0s 731us/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad1ba2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5776869058609009\n",
      "tp :  73.0\n",
      "fp :  112.0\n",
      "tn :  394.0\n",
      "fn :  54.0\n",
      "accuracy :  0.7377567291259766\n",
      "precision :  0.39459457993507385\n",
      "recall :  0.5748031735420227\n",
      "auc :  0.7194531559944153\n",
      "prc :  0.4240136444568634\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  394\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  112\n",
      "Fraudulent Transactions Missed (False Negatives):  54\n",
      "Fraudulent Transactions Detected (True Positives):  73\n",
      "Total Fraudulent Transactions:  127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performance report\n",
    "weighted_results = weighted_model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b0fc57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7495059288537549\n",
      "Testing Accuracy: 0.7377567140600316\n",
      "AUC: 0.7193364663409169\n",
      "Present F1 score: 0.4679487179487179\n",
      "Absent F1 score: 0.8259958071278826\n",
      "Sensitivity: 0.5748031496062992\n",
      "Speicificity: 0.7786561264822134\n"
     ]
    }
   ],
   "source": [
    "# detailed report of model performance\n",
    "train_pred = (train_predictions_weighted > 0.5).astype('int')\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, train_pred)}\")\n",
    "test_pred = (test_predictions_weighted > 0.5).astype('int')\n",
    "print(f\"Testing Accuracy: {accuracy_score(y_test, test_pred)}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, test_predictions_weighted)}\")\n",
    "print(f\"Present F1 score: {f1_score(y_test, test_pred)}\")\n",
    "print(f\"Absent F1 score: {f1_score(y_test, test_pred,pos_label=0)}\")\n",
    "print(f\"Sensitivity: {recall_score(y_test, test_pred)}\")\n",
    "print(f\"Speicificity: {recall_score(y_test, test_pred,pos_label=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0853efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
