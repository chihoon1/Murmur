{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f804ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import sklearn.discriminant_analysis as DA\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "#import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make directory for visualization\n",
    "import os\n",
    "if not os.path.exists('visualization'):\n",
    "    os.makedirs('visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69668bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c86ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cases from case features folder\n",
    "Ent_Case = pd.read_csv('case_features/Window_Entropy_Case.csv', header=None)\n",
    "Slope_Case = pd.read_csv('case_features/Window_Slope_Case.csv', header=None)\n",
    "Mf_Case = pd.read_csv('case_features/Window_Mf_Case.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991d1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load controls from control features folder\n",
    "Ent_Control = pd.read_csv('control_features/Window_Entropy_Control.csv', header=None)\n",
    "Slope_Control = pd.read_csv('control_features/Window_Slope_Control.csv', header=None)\n",
    "Mf_Control = pd.read_csv('control_features/Window_Mf_Control.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f51e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Entropy \", \"Slope \", \"ID\", \"Hurst Exponent \",\n",
    "    \"Left Slope \", \"Right Slope \",\"Left Tangent \",\n",
    "    \"Right Tangent\", \"Broadness\", \"Left Tangent Point\", \"Right Tangent Point\"]\n",
    "# combine Ent_Case and Slope_Case and Mfcc_Case\n",
    "Case = pd.concat([ Ent_Case.T, Slope_Case.T, Mf_Case ], axis=1)\n",
    "Case.columns = col_names\n",
    "Control = pd.concat([ Ent_Control.T, Slope_Control.T, Mf_Control ], axis=1)\n",
    "Control.columns = col_names\n",
    "Case['Case'] = 1\n",
    "Control['Case'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f887cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entropy                156\n",
       "Slope                  156\n",
       "ID                       0\n",
       "Hurst Exponent           0\n",
       "Left Slope               0\n",
       "Right Slope              0\n",
       "Left Tangent             0\n",
       "Right Tangent            0\n",
       "Broadness                0\n",
       "Left Tangent Point       0\n",
       "Right Tangent Point      0\n",
       "Case                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine Case and Control data\n",
    "data = pd.concat([Case, Control], axis=0)\n",
    "\n",
    "# check if any missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e4d5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffle data\n",
    "data = data.sample(frac=1, random_state= 42).reset_index(drop=True);\n",
    "# replace NaN values with mean of the column\n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "X = data.iloc[:, [0,1,9]]\n",
    "\n",
    "# replace NaN values with mean of the column\n",
    "y = data.iloc[:, 11]\n",
    "\n",
    "# split data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773db390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (2024,)\n",
      "Validation labels shape: (506,)\n",
      "Test labels shape: (633,)\n",
      "Training features shape: (2024, 3)\n",
      "Validation features shape: (506, 3)\n",
      "Test features shape: (633, 3)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Validation labels shape:', y_val.shape)\n",
    "print('Test labels shape:', y_test.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2c81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 3163\n",
      "    Positive: 616 (19.48% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(data['Case'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875f3e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:56:42.989530: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 14:56:45.087186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d02847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, metrics=METRICS, output_bias=None):\n",
    "  # build a NN model and return it\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(10, activation='relu',input_shape=(input_shape,)),\n",
    "      keras.layers.Dense(8, activation='relu'),\n",
    "      keras.layers.Dense(4, activation='relu'),\n",
    "      keras.layers.Dense(2, activation='relu'),\n",
    "      #keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid',bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c381134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model training set up\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=50,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5ea0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41942451])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "babe32e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model using three features: entorpy, slope, and left tangent point\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [data.columns[0], data.columns[1], data.columns[9]]  # predictor features name\n",
    "num_repeat=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac59fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "726bda78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "\n",
    "model = make_model(input_shape=train_features.shape[-1], output_bias=initial_bias)\n",
    "model.predict(train_features[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5024447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measures_dict = {\n",
    "        'training_accuracy': np.zeros(num_repeat),\n",
    "        'testing_accuracy': np.zeros(num_repeat),\n",
    "        'sensitivity': np.zeros(num_repeat),\n",
    "        'specificity': np.zeros(num_repeat),\n",
    "        'case_precision': np.zeros(num_repeat),\n",
    "        'control_precision': np.zeros(num_repeat),\n",
    "        'case_F1_score': np.zeros(num_repeat),\n",
    "        'control_F1_score': np.zeros(num_repeat),\n",
    "        'AUC_score': np.zeros(num_repeat)\n",
    "    }\n",
    "max_test_acc, max_cm = 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd81158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 525us/step\n",
      "31/31 [==============================] - 0s 540us/step\n",
      "8/8 [==============================] - 0s 654us/step\n",
      "8/8 [==============================] - 0s 691us/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 526us/step\n",
      "31/31 [==============================] - 0s 544us/step\n",
      "8/8 [==============================] - 0s 698us/step\n",
      "8/8 [==============================] - 0s 671us/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 514us/step\n",
      "31/31 [==============================] - 0s 576us/step\n",
      "8/8 [==============================] - 0s 704us/step\n",
      "8/8 [==============================] - 0s 682us/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 531us/step\n",
      "31/31 [==============================] - 0s 549us/step\n",
      "8/8 [==============================] - 0s 665us/step\n",
      "8/8 [==============================] - 0s 696us/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 525us/step\n",
      "31/31 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 646us/step\n",
      "8/8 [==============================] - 0s 649us/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 509us/step\n",
      "31/31 [==============================] - 0s 555us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 612us/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_29 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 543us/step\n",
      "31/31 [==============================] - 0s 565us/step\n",
      "8/8 [==============================] - 0s 625us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 535us/step\n",
      "31/31 [==============================] - 0s 540us/step\n",
      "8/8 [==============================] - 0s 564us/step\n",
      "8/8 [==============================] - 0s 620us/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_37 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 567us/step\n",
      "31/31 [==============================] - 0s 575us/step\n",
      "8/8 [==============================] - 0s 717us/step\n",
      "8/8 [==============================] - 0s 674us/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_41 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 552us/step\n",
      "31/31 [==============================] - 0s 548us/step\n",
      "8/8 [==============================] - 0s 622us/step\n",
      "8/8 [==============================] - 0s 715us/step\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 655us/step\n",
      "31/31 [==============================] - 0s 986us/step\n",
      "8/8 [==============================] - 0s 749us/step\n",
      "8/8 [==============================] - 0s 674us/step\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_49 (Dense)            (None, 5)                 20        \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 550us/step\n",
      "31/31 [==============================] - 0s 544us/step\n",
      "8/8 [==============================] - 0s 663us/step\n",
      "8/8 [==============================] - 0s 676us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# repeat training and testing models where downsampling is used to mitigate the data imbalance\n",
    "for i in range(num_repeat):\n",
    "    # select a  from Conrols of size a without replacement\n",
    "    Control_new = Control.sample(n=Case.shape[0], replace=False, random_state=42)\n",
    "\n",
    "    # combine Case and Control data\n",
    "    data = pd.concat([Case, Control_new], axis=0)\n",
    "\n",
    "    # # create feature matrix and target vector\n",
    "    X = data.loc[:, features]\n",
    "\n",
    "    # replace NaN values with mean of the column\n",
    "    X = X.fillna(X.mean())\n",
    "    y = data.loc[:, target]\n",
    "\n",
    "    # split data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train); X_test = scaler.transform(X_test)\n",
    "    input_shape = X.shape[1]\n",
    "    # Add a fully connected layer with 64 units and a sigmoid activation function\n",
    "    model = Sequential();\n",
    "    model.add(Dense(5, input_shape=(X.shape[1],),activation='relu')) # Add an input shape! (features,)\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    # Define the learning rate\n",
    "    ep = 500; bs = 50;\n",
    "    \n",
    "    \n",
    "    # Define the optimizer\n",
    "    from keras.optimizers import Adam,SGD\n",
    "    optimizer = Adam(learning_rate=.001, decay= 1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor= tf.keras.metrics.AUC(),\n",
    "                                       mode='max',\n",
    "                                       patience=200,\n",
    "                                       restore_best_weights=True)\n",
    "    # now we just update our model fit call\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        #callbacks=[es],\n",
    "                        epochs=ep, # you can set this to a big number!\n",
    "                        batch_size= bs,\n",
    "                        validation_split=0.2,\n",
    "                        shuffle= True,\n",
    "                        verbose= 0)\n",
    "\n",
    "    ## Training performance\n",
    "    model.predict(X_train) # prob of successes (survival)\n",
    "    # 1 and 0 (survival or not) so need to round to a whole number (0 or 1)\n",
    "    train_pred = np.round(model.predict(X_train),0)\n",
    "    test_pred = np.round(model.predict(X_test),0)\n",
    "    \n",
    "    # store performance metrics for each iteration\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    performance_measures_dict['training_accuracy'][i] = accuracy_score(y_train, train_pred)\n",
    "    performance_measures_dict['testing_accuracy'][i] = test_acc\n",
    "    performance_measures_dict['sensitivity'][i] = recall_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['specificity'][i] = recall_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_precision'][i] = precision_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_precision'][i] = precision_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_F1_score'][i] = f1_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_F1_score'][i] = f1_score(y_test, test_pred, pos_label=0)\n",
    "    y_prob = model.predict(X_test)\n",
    "    performance_measures_dict['AUC_score'][i] = roc_auc_score(y_test, y_prob)\n",
    "    if test_acc > max_test_acc:\n",
    "        max_test_acc = test_acc\n",
    "        max_cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "max_cm = pd.DataFrame({\"Predicted Negative(Absent)\": max_cm[:, 0], \"Predicted Positive(Present)\": max_cm[:, 1]})\n",
    "max_cm.index = [\"Actual Negative(Absent)\", \"Actual positive(Present)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "708de138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Training Accuracy: 0.6805414551607445\n",
      "Mean of Testing Accuracy: 0.6275303643724696\n",
      "Standard deviation of Testing Accuracy: 0.012478570856212514\n",
      "Mean of Sensitivity: 0.5704134366925064\n",
      "Standard deviation of Sensitivity: 0.028032007692179752\n",
      "Mean of Speicificity: 0.6899717514124294\n",
      "Standard deviation of Speicificity: 0.02799141409972658\n",
      "Mean of Case Precision: 0.6683510585402491\n",
      "Standard deviation of Case Precision: 0.015615362856346252\n",
      "Mean of Control Precision: 0.5952410488654154\n",
      "Standard deviation of Control Precision: 0.012174945742331428\n",
      "Mean of Case F1: 0.6150251791931346\n",
      "Standard deviation of Case F1: 0.017588397707827046\n",
      "Mean of Control F1: 0.6387956691405956\n",
      "Standard deviation of Control F1: 0.01429214863714532\n",
      "Mean of AUC: 0.7078351508781151\n",
      "Standard deviation of AUC: 0.007678230379498488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative(Absent)</th>\n",
       "      <th>Predicted Positive(Present)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative(Absent)</th>\n",
       "      <td>83</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual positive(Present)</th>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Negative(Absent)  \\\n",
       "Actual Negative(Absent)                           83   \n",
       "Actual positive(Present)                          51   \n",
       "\n",
       "                          Predicted Positive(Present)  \n",
       "Actual Negative(Absent)                            35  \n",
       "Actual positive(Present)                           78  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Mean of Training Accuracy: {performance_measures_dict['training_accuracy'].mean()}\")\n",
    "print(f\"Mean of Testing Accuracy: {performance_measures_dict['testing_accuracy'].mean()}\")\n",
    "print(f\"Standard deviation of Testing Accuracy: {performance_measures_dict['testing_accuracy'].std()}\")\n",
    "print(f\"Mean of Sensitivity: {performance_measures_dict['sensitivity'].mean()}\")\n",
    "print(f\"Standard deviation of Sensitivity: {performance_measures_dict['sensitivity'].std()}\")\n",
    "print(f\"Mean of Speicificity: {performance_measures_dict['specificity'].mean()}\")\n",
    "print(f\"Standard deviation of Speicificity: {performance_measures_dict['specificity'].std()}\")\n",
    "print(f\"Mean of Case Precision: {performance_measures_dict['case_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Case Precision: {performance_measures_dict['case_precision'].std()}\")\n",
    "print(f\"Mean of Control Precision: {performance_measures_dict['control_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Control Precision: {performance_measures_dict['control_precision'].std()}\")\n",
    "print(f\"Mean of Case F1: {performance_measures_dict['case_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Case F1: {performance_measures_dict['case_F1_score'].std()}\")\n",
    "print(f\"Mean of Control F1: {performance_measures_dict['control_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Control F1: {performance_measures_dict['control_F1_score'].std()}\")\n",
    "print(f\"Mean of AUC: {performance_measures_dict['AUC_score'].mean()}\")\n",
    "print(f\"Standard deviation of AUC: {performance_measures_dict['AUC_score'].std()}\")\n",
    "max_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdce6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Slope ',\n",
       " 'Hurst Exponent ',\n",
       " 'Left Slope ',\n",
       " 'Right Slope ',\n",
       " 'Left Tangent ',\n",
       " 'Left Tangent Point',\n",
       " 'Right Tangent Point']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using all features in the data\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [col_name for col_name in data.columns[1:11]]  # predictor features name\n",
    "features.pop(features.index('ID'))  # remove patient ID from feature names list\n",
    "features.pop(features.index('Broadness'))\n",
    "features.pop(features.index('Right Tangent'))\n",
    "num_repeat = 100\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b5006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb4d86dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "\n",
    "model = make_model(input_shape=train_features.shape[-1], output_bias=initial_bias)\n",
    "model.predict(train_features[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7afa8a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measures_dict = {\n",
    "        'training_accuracy': np.zeros(num_repeat),\n",
    "        'testing_accuracy': np.zeros(num_repeat),\n",
    "        'sensitivity': np.zeros(num_repeat),\n",
    "        'specificity': np.zeros(num_repeat),\n",
    "        'case_precision': np.zeros(num_repeat),\n",
    "        'control_precision': np.zeros(num_repeat),\n",
    "        'case_F1_score': np.zeros(num_repeat),\n",
    "        'control_F1_score': np.zeros(num_repeat),\n",
    "        'AUC_score': np.zeros(num_repeat)\n",
    "    }\n",
    "max_test_acc, max_cm = 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df6d9d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 494us/step\n",
      "8/8 [==============================] - 0s 552us/step\n",
      "8/8 [==============================] - 0s 627us/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 539us/step\n",
      "31/31 [==============================] - 0s 551us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "8/8 [==============================] - 0s 636us/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "8/8 [==============================] - 0s 618us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_70 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 482us/step\n",
      "31/31 [==============================] - 0s 480us/step\n",
      "8/8 [==============================] - 0s 592us/step\n",
      "8/8 [==============================] - 0s 626us/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "8/8 [==============================] - 0s 648us/step\n",
      "8/8 [==============================] - 0s 664us/step\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 502us/step\n",
      "31/31 [==============================] - 0s 524us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "8/8 [==============================] - 0s 569us/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_82 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 513us/step\n",
      "31/31 [==============================] - 0s 500us/step\n",
      "8/8 [==============================] - 0s 660us/step\n",
      "8/8 [==============================] - 0s 646us/step\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_86 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 483us/step\n",
      "31/31 [==============================] - 0s 466us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 495us/step\n",
      "31/31 [==============================] - 0s 501us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "8/8 [==============================] - 0s 544us/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_94 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 490us/step\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "8/8 [==============================] - 0s 564us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_98 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 544us/step\n",
      "31/31 [==============================] - 0s 546us/step\n",
      "8/8 [==============================] - 0s 777us/step\n",
      "8/8 [==============================] - 0s 594us/step\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_102 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "31/31 [==============================] - 0s 514us/step\n",
      "8/8 [==============================] - 0s 579us/step\n",
      "8/8 [==============================] - 0s 700us/step\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_106 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "8/8 [==============================] - 0s 588us/step\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_110 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 462us/step\n",
      "8/8 [==============================] - 0s 544us/step\n",
      "8/8 [==============================] - 0s 619us/step\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_114 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 619us/step\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 584us/step\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_122 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 515us/step\n",
      "31/31 [==============================] - 0s 517us/step\n",
      "8/8 [==============================] - 0s 611us/step\n",
      "8/8 [==============================] - 0s 576us/step\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_126 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "8/8 [==============================] - 0s 582us/step\n",
      "8/8 [==============================] - 0s 622us/step\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_130 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 499us/step\n",
      "31/31 [==============================] - 0s 496us/step\n",
      "8/8 [==============================] - 0s 613us/step\n",
      "8/8 [==============================] - 0s 629us/step\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_134 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "31/31 [==============================] - 0s 492us/step\n",
      "8/8 [==============================] - 0s 578us/step\n",
      "8/8 [==============================] - 0s 585us/step\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_138 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 533us/step\n",
      "31/31 [==============================] - 0s 454us/step\n",
      "8/8 [==============================] - 0s 546us/step\n",
      "8/8 [==============================] - 0s 618us/step\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_142 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_143 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 509us/step\n",
      "31/31 [==============================] - 0s 538us/step\n",
      "8/8 [==============================] - 0s 688us/step\n",
      "8/8 [==============================] - 0s 671us/step\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_146 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "8/8 [==============================] - 0s 549us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_150 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "31/31 [==============================] - 0s 460us/step\n",
      "8/8 [==============================] - 0s 668us/step\n",
      "8/8 [==============================] - 0s 581us/step\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_154 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 497us/step\n",
      "31/31 [==============================] - 0s 458us/step\n",
      "8/8 [==============================] - 0s 588us/step\n",
      "8/8 [==============================] - 0s 551us/step\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_158 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 513us/step\n",
      "31/31 [==============================] - 0s 537us/step\n",
      "8/8 [==============================] - 0s 593us/step\n",
      "8/8 [==============================] - 0s 685us/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_162 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 510us/step\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "8/8 [==============================] - 0s 718us/step\n",
      "8/8 [==============================] - 0s 597us/step\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_166 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 468us/step\n",
      "31/31 [==============================] - 0s 510us/step\n",
      "8/8 [==============================] - 0s 637us/step\n",
      "8/8 [==============================] - 0s 594us/step\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_170 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_172 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 482us/step\n",
      "31/31 [==============================] - 0s 486us/step\n",
      "8/8 [==============================] - 0s 555us/step\n",
      "8/8 [==============================] - 0s 573us/step\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_174 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 499us/step\n",
      "31/31 [==============================] - 0s 455us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "8/8 [==============================] - 0s 552us/step\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_178 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "31/31 [==============================] - 0s 454us/step\n",
      "8/8 [==============================] - 0s 543us/step\n",
      "8/8 [==============================] - 0s 596us/step\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_182 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "31/31 [==============================] - 0s 444us/step\n",
      "8/8 [==============================] - 0s 560us/step\n",
      "8/8 [==============================] - 0s 551us/step\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_186 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 498us/step\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "8/8 [==============================] - 0s 757us/step\n",
      "8/8 [==============================] - 0s 582us/step\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_190 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 541us/step\n",
      "31/31 [==============================] - 0s 632us/step\n",
      "8/8 [==============================] - 0s 560us/step\n",
      "8/8 [==============================] - 0s 611us/step\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_194 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 540us/step\n",
      "31/31 [==============================] - 0s 492us/step\n",
      "8/8 [==============================] - 0s 707us/step\n",
      "8/8 [==============================] - 0s 712us/step\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_198 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_201 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 458us/step\n",
      "31/31 [==============================] - 0s 460us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "8/8 [==============================] - 0s 553us/step\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_202 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 555us/step\n",
      "31/31 [==============================] - 0s 535us/step\n",
      "8/8 [==============================] - 0s 640us/step\n",
      "8/8 [==============================] - 0s 627us/step\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_206 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "31/31 [==============================] - 0s 472us/step\n",
      "8/8 [==============================] - 0s 556us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_210 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 521us/step\n",
      "31/31 [==============================] - 0s 449us/step\n",
      "8/8 [==============================] - 0s 560us/step\n",
      "8/8 [==============================] - 0s 576us/step\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_214 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 460us/step\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_218 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 485us/step\n",
      "31/31 [==============================] - 0s 505us/step\n",
      "8/8 [==============================] - 0s 547us/step\n",
      "8/8 [==============================] - 0s 642us/step\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_222 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 500us/step\n",
      "8/8 [==============================] - 0s 588us/step\n",
      "8/8 [==============================] - 0s 663us/step\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_226 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 453us/step\n",
      "8/8 [==============================] - 0s 548us/step\n",
      "8/8 [==============================] - 0s 533us/step\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_230 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 572us/step\n",
      "31/31 [==============================] - 0s 512us/step\n",
      "8/8 [==============================] - 0s 655us/step\n",
      "8/8 [==============================] - 0s 598us/step\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_234 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 476us/step\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "8/8 [==============================] - 0s 537us/step\n",
      "8/8 [==============================] - 0s 576us/step\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_238 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "31/31 [==============================] - 0s 510us/step\n",
      "8/8 [==============================] - 0s 645us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_242 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_243 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 465us/step\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "8/8 [==============================] - 0s 564us/step\n",
      "8/8 [==============================] - 0s 582us/step\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_246 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 475us/step\n",
      "31/31 [==============================] - 0s 488us/step\n",
      "8/8 [==============================] - 0s 549us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_250 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 518us/step\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "8/8 [==============================] - 0s 598us/step\n",
      "8/8 [==============================] - 0s 608us/step\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_254 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "31/31 [==============================] - 0s 506us/step\n",
      "8/8 [==============================] - 0s 554us/step\n",
      "8/8 [==============================] - 0s 545us/step\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_258 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 523us/step\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "8/8 [==============================] - 0s 528us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_262 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 485us/step\n",
      "31/31 [==============================] - 0s 448us/step\n",
      "8/8 [==============================] - 0s 556us/step\n",
      "8/8 [==============================] - 0s 545us/step\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_266 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 475us/step\n",
      "31/31 [==============================] - 0s 463us/step\n",
      "8/8 [==============================] - 0s 580us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_270 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 456us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_274 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 490us/step\n",
      "31/31 [==============================] - 0s 523us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "8/8 [==============================] - 0s 583us/step\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_278 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_282 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 471us/step\n",
      "31/31 [==============================] - 0s 455us/step\n",
      "8/8 [==============================] - 0s 581us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_286 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "31/31 [==============================] - 0s 483us/step\n",
      "8/8 [==============================] - 0s 613us/step\n",
      "8/8 [==============================] - 0s 632us/step\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_290 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_292 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_293 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 519us/step\n",
      "31/31 [==============================] - 0s 488us/step\n",
      "8/8 [==============================] - 0s 617us/step\n",
      "8/8 [==============================] - 0s 552us/step\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_294 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_295 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_296 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_297 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 478us/step\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "8/8 [==============================] - 0s 556us/step\n",
      "8/8 [==============================] - 0s 563us/step\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_298 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_301 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 495us/step\n",
      "31/31 [==============================] - 0s 520us/step\n",
      "8/8 [==============================] - 0s 645us/step\n",
      "8/8 [==============================] - 0s 646us/step\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_302 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_303 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_304 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_305 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 465us/step\n",
      "8/8 [==============================] - 0s 556us/step\n",
      "8/8 [==============================] - 0s 645us/step\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_306 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_307 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_308 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_309 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "31/31 [==============================] - 0s 515us/step\n",
      "8/8 [==============================] - 0s 605us/step\n",
      "8/8 [==============================] - 0s 624us/step\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_310 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_311 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_312 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_313 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 488us/step\n",
      "31/31 [==============================] - 0s 506us/step\n",
      "8/8 [==============================] - 0s 667us/step\n",
      "8/8 [==============================] - 0s 604us/step\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_314 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_315 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_316 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 483us/step\n",
      "31/31 [==============================] - 0s 516us/step\n",
      "8/8 [==============================] - 0s 532us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_318 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "31/31 [==============================] - 0s 470us/step\n",
      "8/8 [==============================] - 0s 547us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_322 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "31/31 [==============================] - 0s 467us/step\n",
      "8/8 [==============================] - 0s 553us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_326 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 485us/step\n",
      "31/31 [==============================] - 0s 467us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 595us/step\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_330 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 488us/step\n",
      "31/31 [==============================] - 0s 490us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_334 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "31/31 [==============================] - 0s 475us/step\n",
      "8/8 [==============================] - 0s 579us/step\n",
      "8/8 [==============================] - 0s 578us/step\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_338 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 537us/step\n",
      "31/31 [==============================] - 0s 510us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 549us/step\n",
      "8/8 [==============================] - 0s 610us/step\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_342 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 508us/step\n",
      "31/31 [==============================] - 0s 511us/step\n",
      "8/8 [==============================] - 0s 557us/step\n",
      "8/8 [==============================] - 0s 571us/step\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_346 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "31/31 [==============================] - 0s 472us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "8/8 [==============================] - 0s 555us/step\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_350 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 488us/step\n",
      "31/31 [==============================] - 0s 459us/step\n",
      "8/8 [==============================] - 0s 557us/step\n",
      "8/8 [==============================] - 0s 570us/step\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_354 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 474us/step\n",
      "31/31 [==============================] - 0s 659us/step\n",
      "8/8 [==============================] - 0s 668us/step\n",
      "8/8 [==============================] - 0s 594us/step\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_358 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "31/31 [==============================] - 0s 521us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 640us/step\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_362 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 510us/step\n",
      "31/31 [==============================] - 0s 480us/step\n",
      "8/8 [==============================] - 0s 600us/step\n",
      "8/8 [==============================] - 0s 606us/step\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_366 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "31/31 [==============================] - 0s 513us/step\n",
      "8/8 [==============================] - 0s 594us/step\n",
      "8/8 [==============================] - 0s 560us/step\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_370 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_371 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_372 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_373 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 498us/step\n",
      "31/31 [==============================] - 0s 489us/step\n",
      "8/8 [==============================] - 0s 631us/step\n",
      "8/8 [==============================] - 0s 649us/step\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_374 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_375 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_376 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_377 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 444us/step\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "8/8 [==============================] - 0s 572us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_378 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_379 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_380 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_381 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 484us/step\n",
      "31/31 [==============================] - 0s 457us/step\n",
      "8/8 [==============================] - 0s 547us/step\n",
      "8/8 [==============================] - 0s 603us/step\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_382 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_383 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_384 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_385 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 458us/step\n",
      "31/31 [==============================] - 0s 474us/step\n",
      "8/8 [==============================] - 0s 543us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_386 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_387 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_388 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_389 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 452us/step\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_390 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_391 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_392 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_393 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 471us/step\n",
      "31/31 [==============================] - 0s 477us/step\n",
      "8/8 [==============================] - 0s 554us/step\n",
      "8/8 [==============================] - 0s 552us/step\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_394 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_395 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_396 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_397 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 572us/step\n",
      "31/31 [==============================] - 0s 523us/step\n",
      "8/8 [==============================] - 0s 678us/step\n",
      "8/8 [==============================] - 0s 605us/step\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_398 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_399 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_400 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_401 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 491us/step\n",
      "31/31 [==============================] - 0s 474us/step\n",
      "8/8 [==============================] - 0s 562us/step\n",
      "8/8 [==============================] - 0s 564us/step\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_402 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_403 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_404 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_405 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "31/31 [==============================] - 0s 461us/step\n",
      "8/8 [==============================] - 0s 531us/step\n",
      "8/8 [==============================] - 0s 585us/step\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_406 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_407 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_408 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_409 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 506us/step\n",
      "31/31 [==============================] - 0s 537us/step\n",
      "8/8 [==============================] - 0s 720us/step\n",
      "8/8 [==============================] - 0s 611us/step\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_410 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_411 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_412 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_413 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 488us/step\n",
      "31/31 [==============================] - 0s 501us/step\n",
      "8/8 [==============================] - 0s 617us/step\n",
      "8/8 [==============================] - 0s 579us/step\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_414 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_415 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_416 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_417 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 490us/step\n",
      "31/31 [==============================] - 0s 490us/step\n",
      "8/8 [==============================] - 0s 559us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_418 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_419 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_420 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_421 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 473us/step\n",
      "31/31 [==============================] - 0s 500us/step\n",
      "8/8 [==============================] - 0s 579us/step\n",
      "8/8 [==============================] - 0s 575us/step\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_422 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_423 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_424 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_425 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 479us/step\n",
      "31/31 [==============================] - 0s 521us/step\n",
      "8/8 [==============================] - 0s 557us/step\n",
      "8/8 [==============================] - 0s 616us/step\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_426 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_427 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "31/31 [==============================] - 0s 468us/step\n",
      "8/8 [==============================] - 0s 561us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_430 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_431 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 499us/step\n",
      "31/31 [==============================] - 0s 503us/step\n",
      "8/8 [==============================] - 0s 567us/step\n",
      "8/8 [==============================] - 0s 569us/step\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_434 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_435 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_436 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_437 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 502us/step\n",
      "31/31 [==============================] - 0s 465us/step\n",
      "8/8 [==============================] - 0s 568us/step\n",
      "8/8 [==============================] - 0s 577us/step\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_438 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_439 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_440 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_441 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 493us/step\n",
      "31/31 [==============================] - 0s 487us/step\n",
      "8/8 [==============================] - 0s 580us/step\n",
      "8/8 [==============================] - 0s 566us/step\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_442 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_443 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_444 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_445 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 534us/step\n",
      "31/31 [==============================] - 0s 545us/step\n",
      "8/8 [==============================] - 0s 597us/step\n",
      "8/8 [==============================] - 0s 605us/step\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_446 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_447 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_448 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_449 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 469us/step\n",
      "31/31 [==============================] - 0s 497us/step\n",
      "8/8 [==============================] - 0s 619us/step\n",
      "8/8 [==============================] - 0s 642us/step\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_450 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_451 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_452 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_453 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 515us/step\n",
      "31/31 [==============================] - 0s 534us/step\n",
      "8/8 [==============================] - 0s 598us/step\n",
      "8/8 [==============================] - 0s 558us/step\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_454 (Dense)           (None, 5)                 40        \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_455 (Dense)           (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_456 (Dense)           (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_457 (Dense)           (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77\n",
      "Trainable params: 77\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "31/31 [==============================] - 0s 481us/step\n",
      "8/8 [==============================] - 0s 565us/step\n",
      "8/8 [==============================] - 0s 567us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# repeat training and testing models where downsampling is used to mitigate the data imbalance\n",
    "for i in range(num_repeat):\n",
    "    # select a  from Conrols of size a without replacement\n",
    "    Control_new = Control.sample(n=Case.shape[0], replace=False, random_state=42)\n",
    "\n",
    "    # combine Case and Control data\n",
    "    data = pd.concat([Case, Control_new], axis=0)\n",
    "\n",
    "    # # create feature matrix and target vector\n",
    "    X = data.loc[:, features]\n",
    "\n",
    "    # replace NaN values with mean of the column\n",
    "    X = X.fillna(X.mean())\n",
    "    y = data.loc[:, target]\n",
    "\n",
    "    # split data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train); X_test = scaler.transform(X_test)\n",
    "    input_shape = X.shape[1]\n",
    "    # Add a fully connected layer with 64 units and a sigmoid activation function\n",
    "    model = Sequential();\n",
    "    model.add(Dense(5, input_shape=(X.shape[1],),activation='relu')) # Add an input shape! (features,)\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    # Define the learning rate\n",
    "    ep = 500; bs = 50;\n",
    "    \n",
    "    \n",
    "    # Define the optimizer\n",
    "    from keras.optimizers import Adam,SGD\n",
    "    optimizer = Adam(learning_rate=.001, decay= 1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=['accuracy',tf.keras.metrics.AUC()])\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor= tf.keras.metrics.AUC(),\n",
    "                                       mode='max',\n",
    "                                       patience=200,\n",
    "                                       restore_best_weights=True)\n",
    "    # now we just update our model fit call\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=ep, # you can set this to a big number!\n",
    "                        batch_size= bs,\n",
    "                        validation_split=0.2,\n",
    "                        shuffle= True,\n",
    "                        verbose= 0)\n",
    "\n",
    "    ## Training performance\n",
    "    model.predict(X_train) # prob of successes (survival)\n",
    "    # 1 and 0 (survival or not) so need to round to a whole number (0 or 1)\n",
    "    train_pred = np.round(model.predict(X_train),0)\n",
    "    test_pred = np.round(model.predict(X_test),0)\n",
    "    \n",
    "    # store performance metrics for each iteration\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    performance_measures_dict['training_accuracy'][i] = accuracy_score(y_train, train_pred)\n",
    "    performance_measures_dict['testing_accuracy'][i] = test_acc\n",
    "    performance_measures_dict['sensitivity'][i] = recall_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['specificity'][i] = recall_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_precision'][i] = precision_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_precision'][i] = precision_score(y_test, test_pred, pos_label=0)\n",
    "    performance_measures_dict['case_F1_score'][i] = f1_score(y_test, test_pred, pos_label=1)\n",
    "    performance_measures_dict['control_F1_score'][i] = f1_score(y_test, test_pred, pos_label=0)\n",
    "    y_prob = model.predict(X_test)\n",
    "    performance_measures_dict['AUC_score'][i] = roc_auc_score(y_test, y_prob)\n",
    "    if test_acc > max_test_acc:\n",
    "        max_test_acc = test_acc\n",
    "        max_cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "max_cm = pd.DataFrame({\"Predicted Negative(Absent)\": max_cm[:, 0], \"Predicted Positive(Present)\": max_cm[:, 1]})\n",
    "max_cm.index = [\"Actual Negative(Absent)\", \"Actual positive(Present)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "956a880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Training Accuracy: 0.6703756345177665\n",
      "Mean of Testing Accuracy: 0.6488663967611334\n",
      "Standard deviation of Testing Accuracy: 0.03572334833256017\n",
      "Mean of Sensitivity: 0.608139534883721\n",
      "Standard deviation of Sensitivity: 0.10573583736674912\n",
      "Mean of Speicificity: 0.6933898305084747\n",
      "Standard deviation of Speicificity: 0.13428596532259035\n",
      "Mean of Case Precision: 0.6914034974203251\n",
      "Standard deviation of Case Precision: 0.04283700550695416\n",
      "Mean of Control Precision: 0.6054734503524282\n",
      "Standard deviation of Control Precision: 0.09980177937229735\n",
      "Mean of Case F1: 0.6399117120411189\n",
      "Standard deviation of Case F1: 0.05933111469814556\n",
      "Mean of Control F1: 0.643126216524007\n",
      "Standard deviation of Control F1: 0.11255370413851627\n",
      "Mean of AUC: 0.7045559059256338\n",
      "Standard deviation of AUC: 0.04747047132096598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative(Absent)</th>\n",
       "      <th>Predicted Positive(Present)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative(Absent)</th>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual positive(Present)</th>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Predicted Negative(Absent)  \\\n",
       "Actual Negative(Absent)                           91   \n",
       "Actual positive(Present)                          46   \n",
       "\n",
       "                          Predicted Positive(Present)  \n",
       "Actual Negative(Absent)                            27  \n",
       "Actual positive(Present)                           83  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Mean of Training Accuracy: {performance_measures_dict['training_accuracy'].mean()}\")\n",
    "print(f\"Mean of Testing Accuracy: {performance_measures_dict['testing_accuracy'].mean()}\")\n",
    "print(f\"Standard deviation of Testing Accuracy: {performance_measures_dict['testing_accuracy'].std()}\")\n",
    "print(f\"Mean of Sensitivity: {performance_measures_dict['sensitivity'].mean()}\")\n",
    "print(f\"Standard deviation of Sensitivity: {performance_measures_dict['sensitivity'].std()}\")\n",
    "print(f\"Mean of Speicificity: {performance_measures_dict['specificity'].mean()}\")\n",
    "print(f\"Standard deviation of Speicificity: {performance_measures_dict['specificity'].std()}\")\n",
    "print(f\"Mean of Case Precision: {performance_measures_dict['case_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Case Precision: {performance_measures_dict['case_precision'].std()}\")\n",
    "print(f\"Mean of Control Precision: {performance_measures_dict['control_precision'].mean()}\")\n",
    "print(f\"Standard deviation of Control Precision: {performance_measures_dict['control_precision'].std()}\")\n",
    "print(f\"Mean of Case F1: {performance_measures_dict['case_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Case F1: {performance_measures_dict['case_F1_score'].std()}\")\n",
    "print(f\"Mean of Control F1: {performance_measures_dict['control_F1_score'].mean()}\")\n",
    "print(f\"Standard deviation of Control F1: {performance_measures_dict['control_F1_score'].std()}\")\n",
    "print(f\"Mean of AUC: {performance_measures_dict['AUC_score'].mean()}\")\n",
    "print(f\"Standard deviation of AUC: {performance_measures_dict['AUC_score'].std()}\")\n",
    "max_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6817df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale on y-axis to show the wide range of values.\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color='r', label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color='b', label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d6ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    # plot each individual performance metric\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color='b', label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color='g', linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fabaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "# report confusion matrix\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba82ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ae238e5",
   "metadata": {},
   "source": [
    "Applying class weights without balancing the dataset to mitigate data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94712aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model using three features: entorpy, slope, and left tangent point\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [data.columns[0], data.columns[1], data.columns[9]]  # predictor features name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f26fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e45bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "'''\n",
    "model = make_model(input_shape=X_train.shape[-1], output_bias=initial_bias)\n",
    "model.predict(X_train[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d183aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 31ms/step - loss: 0.6645 - tp: 68.0000 - fp: 89.0000 - tn: 2043.0000 - fn: 457.0000 - accuracy: 0.7945 - precision: 0.4331 - recall: 0.1295 - auc: 0.4706 - prc: 0.2571 - val_loss: 0.4719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4081 - val_prc: 0.1507\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6602 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4440 - prc: 0.1729 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4751 - val_prc: 0.1694\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6568 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4804 - prc: 0.1868 - val_loss: 0.4724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4944 - val_prc: 0.1782\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6542 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4987 - prc: 0.1962 - val_loss: 0.4726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6532 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4913 - prc: 0.1937 - val_loss: 0.4728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6526 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6518 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4732 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6513 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5129 - prc: 0.2024 - val_loss: 0.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6506 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6501 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6496 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6491 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6486 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6481 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6475 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5139 - prc: 0.2043 - val_loss: 0.4753 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6467 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6462 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4762 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6459 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5214 - prc: 0.2087 - val_loss: 0.4765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6455 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4771 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6448 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4973 - prc: 0.1931 - val_loss: 0.4776 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4981 - val_prc: 0.1793\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6443 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1971 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6440 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4782 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6438 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6435 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6433 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6431 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5117 - prc: 0.2006 - val_loss: 0.4793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6429 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6427 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6425 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6423 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6421 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5047 - prc: 0.1987 - val_loss: 0.4807 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6419 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6417 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4814 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6415 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6414 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4820 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6412 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4951 - prc: 0.1940 - val_loss: 0.4823 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6411 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.4826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6410 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4829 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6408 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6407 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6406 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4836 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6405 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - prc: 0.1973 - val_loss: 0.4839 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4981 - val_prc: 0.1793\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6404 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1971 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6403 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4845 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6401 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4851 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6400 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4853 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6400 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4948 - prc: 0.1939 - val_loss: 0.4859 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6398 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6397 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4865 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6397 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4869 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4872 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6395 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4873 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6395 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6395 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4876 - prc: 0.1917 - val_loss: 0.4879 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4880 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4884 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4886 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4890 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4996 - prc: 0.1965 - val_loss: 0.4896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4998 - prc: 0.1962 - val_loss: 0.4898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4963 - val_prc: 0.1787\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6392 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4960 - prc: 0.1953 - val_loss: 0.4898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5190 - val_prc: 0.1860\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6391 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5236 - prc: 0.2049 - val_loss: 0.4900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5023 - val_prc: 0.1805\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6391 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - prc: 0.1971 - val_loss: 0.4903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5018 - val_prc: 0.1804\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6391 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - prc: 0.1971 - val_loss: 0.4905 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5011 - val_prc: 0.1802\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6390 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5059 - prc: 0.1985 - val_loss: 0.4907 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5057 - val_prc: 0.1816\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6389 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5132 - prc: 0.2010 - val_loss: 0.4900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5253 - val_prc: 0.1880\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6379 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5506 - prc: 0.2178 - val_loss: 0.4837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5564 - val_prc: 0.2034\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6339 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6100 - prc: 0.2580 - val_loss: 0.4785 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5845 - val_prc: 0.2289\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6328 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6276 - prc: 0.2989 - val_loss: 0.4799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5926 - val_prc: 0.2297\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6325 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6256 - prc: 0.2744 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5963 - val_prc: 0.2354\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6299 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6437 - prc: 0.3003 - val_loss: 0.4753 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6033 - val_prc: 0.2402\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6289 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6524 - prc: 0.3143 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6084 - val_prc: 0.2494\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6280 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6533 - prc: 0.3132 - val_loss: 0.4738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6091 - val_prc: 0.2447\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6545 - prc: 0.3121 - val_loss: 0.4692 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6190 - val_prc: 0.2673\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6264 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6588 - prc: 0.3210 - val_loss: 0.4716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6132 - val_prc: 0.2485\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6255 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6637 - prc: 0.3301 - val_loss: 0.4730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6182 - val_prc: 0.2500\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6472 - prc: 0.2865 - val_loss: 0.4742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6183 - val_prc: 0.2517\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6240 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6679 - prc: 0.3304 - val_loss: 0.4670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6303 - val_prc: 0.2767\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6227 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6747 - prc: 0.3413 - val_loss: 0.4709 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6234 - val_prc: 0.2558\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6222 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6713 - prc: 0.3285 - val_loss: 0.4668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6363 - val_prc: 0.2819\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6219 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6771 - prc: 0.3370 - val_loss: 0.4708 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6319 - val_prc: 0.2624\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6238 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6574 - prc: 0.2939 - val_loss: 0.4739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6342 - val_prc: 0.2632\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6223 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6685 - prc: 0.3346 - val_loss: 0.4638 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6434 - val_prc: 0.2946\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6202 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6733 - prc: 0.3280 - val_loss: 0.4711 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6348 - val_prc: 0.2668\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6181 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6858 - prc: 0.3507 - val_loss: 0.4630 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6491 - val_prc: 0.3000\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6195 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6784 - prc: 0.3456 - val_loss: 0.4680 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6428 - val_prc: 0.2803\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6171 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6865 - prc: 0.3535 - val_loss: 0.4635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6480 - val_prc: 0.2964\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6162 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6868 - prc: 0.3588 - val_loss: 0.4661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6451 - val_prc: 0.2818\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6154 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6888 - prc: 0.3593 - val_loss: 0.4661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6513 - val_prc: 0.2929\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6149 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6887 - prc: 0.3545 - val_loss: 0.4653 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6521 - val_prc: 0.2934\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6151 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6850 - prc: 0.3454 - val_loss: 0.4654 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6536 - val_prc: 0.2992\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6138 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6915 - prc: 0.3658 - val_loss: 0.4612 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6558 - val_prc: 0.3064\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6953 - prc: 0.3655 - val_loss: 0.4639 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6525 - val_prc: 0.2932\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6119 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6936 - prc: 0.3611 - val_loss: 0.4641 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6544 - val_prc: 0.2907\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6947 - prc: 0.3627 - val_loss: 0.4645 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6599 - val_prc: 0.2976\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6975 - prc: 0.3543 - val_loss: 0.4596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6662 - val_prc: 0.3207\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6993 - prc: 0.3709 - val_loss: 0.4620 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6631 - val_prc: 0.3012\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6994 - prc: 0.3597 - val_loss: 0.4618 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6663 - val_prc: 0.3072\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6090 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6949 - prc: 0.3465 - val_loss: 0.4617 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6636 - val_prc: 0.3031\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6085 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7002 - prc: 0.3710 - val_loss: 0.4622 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6650 - val_prc: 0.2998\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6072 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6981 - prc: 0.3581 - val_loss: 0.4589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6669 - val_prc: 0.3062\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6064 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7033 - prc: 0.3729 - val_loss: 0.4656 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6643 - val_prc: 0.2934\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6073 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6970 - prc: 0.3473 - val_loss: 0.4571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6679 - val_prc: 0.3161\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6076 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7032 - prc: 0.3788 - val_loss: 0.4625 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6670 - val_prc: 0.3018\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6059 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6967 - prc: 0.3463 - val_loss: 0.4572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6701 - val_prc: 0.3180\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6044 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7071 - prc: 0.3782 - val_loss: 0.4551 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6715 - val_prc: 0.3233\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7038 - prc: 0.3679 - val_loss: 0.4604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6725 - val_prc: 0.3076\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7060 - prc: 0.3639 - val_loss: 0.4567 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6740 - val_prc: 0.3199\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7060 - prc: 0.3734 - val_loss: 0.4558 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6732 - val_prc: 0.3188\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7033 - prc: 0.3703 - val_loss: 0.4559 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6734 - val_prc: 0.3197\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6011 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7079 - prc: 0.3735 - val_loss: 0.4537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6739 - val_prc: 0.3271\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7071 - prc: 0.3853 - val_loss: 0.4604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6750 - val_prc: 0.3100\n",
      "Epoch 127/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6001 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7081 - prc: 0.3731 - val_loss: 0.4534 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6760 - val_prc: 0.3257\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5995 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7131 - prc: 0.3827 - val_loss: 0.4655 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6731 - val_prc: 0.3049\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6807 - prc: 0.3131 - val_loss: 0.4669 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6702 - val_prc: 0.2976\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6002 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7030 - prc: 0.3667 - val_loss: 0.4537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6724 - val_prc: 0.3245\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7070 - prc: 0.3715 - val_loss: 0.4600 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6712 - val_prc: 0.3098\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7083 - prc: 0.3690 - val_loss: 0.4555 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6722 - val_prc: 0.3136\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7043 - prc: 0.3663 - val_loss: 0.4553 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6785 - val_prc: 0.3276\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5970 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7099 - prc: 0.3749 - val_loss: 0.4575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6777 - val_prc: 0.3185\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7106 - prc: 0.3669 - val_loss: 0.4575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6755 - val_prc: 0.3161\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5952 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7128 - prc: 0.3808 - val_loss: 0.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6742 - val_prc: 0.3261\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5957 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7100 - prc: 0.3780 - val_loss: 0.4578 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6759 - val_prc: 0.3159\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5952 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7099 - prc: 0.3714 - val_loss: 0.4553 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6805 - val_prc: 0.3295\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5940 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7139 - prc: 0.3781 - val_loss: 0.4589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6793 - val_prc: 0.3235\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5941 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7126 - prc: 0.3780 - val_loss: 0.4530 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6829 - val_prc: 0.3352\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7124 - prc: 0.3784 - val_loss: 0.4620 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6760 - val_prc: 0.3117\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7019 - prc: 0.3431 - val_loss: 0.4627 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6750 - val_prc: 0.3101\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5943 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7105 - prc: 0.3769 - val_loss: 0.4499 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6792 - val_prc: 0.3363\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5932 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7086 - prc: 0.3687 - val_loss: 0.4596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6775 - val_prc: 0.3170\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5920 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7114 - prc: 0.3712 - val_loss: 0.4575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6751 - val_prc: 0.3159\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5929 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7092 - prc: 0.3583 - val_loss: 0.4606 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6764 - val_prc: 0.3169\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5918 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7123 - prc: 0.3754 - val_loss: 0.4499 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6770 - val_prc: 0.3298\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5909 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7133 - prc: 0.3794 - val_loss: 0.4604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6769 - val_prc: 0.3156\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7118 - prc: 0.3704 - val_loss: 0.4562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6762 - val_prc: 0.3183\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5901 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7139 - prc: 0.3785 - val_loss: 0.4608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6780 - val_prc: 0.3171\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5921 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7103 - prc: 0.3587 - val_loss: 0.4596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6772 - val_prc: 0.3176\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7121 - prc: 0.3791 - val_loss: 0.4550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6775 - val_prc: 0.3232\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5890 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7144 - prc: 0.3768 - val_loss: 0.4615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6771 - val_prc: 0.3154\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7128 - prc: 0.3695 - val_loss: 0.4564 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6772 - val_prc: 0.3196\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5887 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7124 - prc: 0.3682 - val_loss: 0.4576 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6766 - val_prc: 0.3212\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5886 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7135 - prc: 0.3764 - val_loss: 0.4562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6783 - val_prc: 0.3233\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5908 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7086 - prc: 0.3677 - val_loss: 0.4531 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6792 - val_prc: 0.3294\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7148 - prc: 0.3810 - val_loss: 0.4579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6809 - val_prc: 0.3285\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5877 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7143 - prc: 0.3741 - val_loss: 0.4546 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6792 - val_prc: 0.3290\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5876 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7133 - prc: 0.3762 - val_loss: 0.4571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6764 - val_prc: 0.3195\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5873 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7143 - prc: 0.3772 - val_loss: 0.4540 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6768 - val_prc: 0.3217\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5867 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7146 - prc: 0.3742 - val_loss: 0.4600 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6783 - val_prc: 0.3206\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5871 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7139 - prc: 0.3731 - val_loss: 0.4501 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6824 - val_prc: 0.3390\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5871 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7137 - prc: 0.3787 - val_loss: 0.4565 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6796 - val_prc: 0.3258\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5865 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7138 - prc: 0.3775 - val_loss: 0.4554 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6754 - val_prc: 0.3188\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5865 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7139 - prc: 0.3808 - val_loss: 0.4576 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6779 - val_prc: 0.3249\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5859 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7145 - prc: 0.3779 - val_loss: 0.4562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6799 - val_prc: 0.3317\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5854 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7153 - prc: 0.3778 - val_loss: 0.4577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6796 - val_prc: 0.3257\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5859 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7141 - prc: 0.3714 - val_loss: 0.4571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6795 - val_prc: 0.3250\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5854 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7151 - prc: 0.3817 - val_loss: 0.4523 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6799 - val_prc: 0.3330\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5850 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7150 - prc: 0.3806 - val_loss: 0.4562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6782 - val_prc: 0.3232\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5852 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7158 - prc: 0.3820 - val_loss: 0.4571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6808 - val_prc: 0.3325\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5884 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7104 - prc: 0.3588 - val_loss: 0.4564 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6811 - val_prc: 0.3342\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5905 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7137 - prc: 0.3881 - val_loss: 0.4503 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6794 - val_prc: 0.3320\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5851 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7119 - prc: 0.3660 - val_loss: 0.4642 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6768 - val_prc: 0.3187\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5840 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7140 - prc: 0.3755 - val_loss: 0.4518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6803 - val_prc: 0.3322\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5842 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7157 - prc: 0.3791 - val_loss: 0.4568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6822 - val_prc: 0.3330\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5844 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7140 - prc: 0.3724 - val_loss: 0.4535 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6805 - val_prc: 0.3318\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5846 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7177 - prc: 0.4015 - val_loss: 0.4525 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6810 - val_prc: 0.3321\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5833 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7155 - prc: 0.3780 - val_loss: 0.4600 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6796 - val_prc: 0.3255\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5829 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7157 - prc: 0.3806 - val_loss: 0.4514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6810 - val_prc: 0.3324\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5848 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7113 - prc: 0.3754 - val_loss: 0.4549 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6827 - val_prc: 0.3373\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5838 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7163 - prc: 0.3895 - val_loss: 0.4569 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6826 - val_prc: 0.3372\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5826 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7167 - prc: 0.3795 - val_loss: 0.4577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6827 - val_prc: 0.3333\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5819 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7172 - prc: 0.3827 - val_loss: 0.4542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6839 - val_prc: 0.3395\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5837 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7140 - prc: 0.3809 - val_loss: 0.4599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6802 - val_prc: 0.3247\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7131 - prc: 0.3758 - val_loss: 0.4603 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6812 - val_prc: 0.3303\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5866 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7084 - prc: 0.3606 - val_loss: 0.4554 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6797 - val_prc: 0.3266\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7161 - prc: 0.3825 - val_loss: 0.4518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6799 - val_prc: 0.3299\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5814 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7165 - prc: 0.3832 - val_loss: 0.4586 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6815 - val_prc: 0.3308\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7150 - prc: 0.3768 - val_loss: 0.4544 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6786 - val_prc: 0.3274\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5817 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7128 - prc: 0.3705 - val_loss: 0.4634 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6766 - val_prc: 0.3197\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5815 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7145 - prc: 0.3742 - val_loss: 0.4550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6798 - val_prc: 0.3290\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7161 - prc: 0.3783 - val_loss: 0.4518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6799 - val_prc: 0.3282\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5814 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7132 - prc: 0.3738 - val_loss: 0.4559 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6798 - val_prc: 0.3327\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5800 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7171 - prc: 0.3784 - val_loss: 0.4507 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6820 - val_prc: 0.3381\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5800 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7179 - prc: 0.3835 - val_loss: 0.4656 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6816 - val_prc: 0.3239\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5847 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7110 - prc: 0.3617 - val_loss: 0.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3404\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5808 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7162 - prc: 0.3837 - val_loss: 0.4584 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6826 - val_prc: 0.3310\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5800 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7167 - prc: 0.3806 - val_loss: 0.4547 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6837 - val_prc: 0.3393\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7167 - prc: 0.3779 - val_loss: 0.4548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6836 - val_prc: 0.3356\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5802 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7152 - prc: 0.3754 - val_loss: 0.4561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6841 - val_prc: 0.3365\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7179 - prc: 0.3827 - val_loss: 0.4562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6836 - val_prc: 0.3369\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5799 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7162 - prc: 0.3802 - val_loss: 0.4523 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6841 - val_prc: 0.3403\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5803 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7171 - prc: 0.3840 - val_loss: 0.4550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6830 - val_prc: 0.3370\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7170 - prc: 0.3859 - val_loss: 0.4552 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6806 - val_prc: 0.3264\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7155 - prc: 0.3781 - val_loss: 0.4582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6827 - val_prc: 0.3326\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5788 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7165 - prc: 0.3774 - val_loss: 0.4600 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6828 - val_prc: 0.3327\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5799 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7171 - prc: 0.3778 - val_loss: 0.4492 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6838 - val_prc: 0.3343\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5829 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7197 - prc: 0.3973 - val_loss: 0.4561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6850 - val_prc: 0.3350\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7089 - prc: 0.3566 - val_loss: 0.4661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6830 - val_prc: 0.3288\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5786 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7185 - prc: 0.3860 - val_loss: 0.4475 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6845 - val_prc: 0.3353\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5791 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7161 - prc: 0.3827 - val_loss: 0.4602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6836 - val_prc: 0.3309\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5791 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7159 - prc: 0.3825 - val_loss: 0.4592 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6864 - val_prc: 0.3402\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5791 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7158 - prc: 0.3816 - val_loss: 0.4640 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6824 - val_prc: 0.3273\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5902 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7074 - prc: 0.3523 - val_loss: 0.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6771 - val_prc: 0.3159\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5784 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7161 - prc: 0.3812 - val_loss: 0.4463 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6794 - val_prc: 0.3291\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7148 - prc: 0.3760 - val_loss: 0.4599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6842 - val_prc: 0.3343\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5775 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7183 - prc: 0.3763 - val_loss: 0.4497 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6845 - val_prc: 0.3351\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5779 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7181 - prc: 0.3856 - val_loss: 0.4596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.3392\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7176 - prc: 0.3804 - val_loss: 0.4537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6829 - val_prc: 0.3324\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5778 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7180 - prc: 0.3777 - val_loss: 0.4506 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6819 - val_prc: 0.3351\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5791 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7143 - prc: 0.3807 - val_loss: 0.4586 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6813 - val_prc: 0.3272\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7161 - prc: 0.3854 - val_loss: 0.4513 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6821 - val_prc: 0.3344\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5772 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7171 - prc: 0.3797 - val_loss: 0.4582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6816 - val_prc: 0.3288\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5781 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7160 - prc: 0.3781 - val_loss: 0.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3385\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7181 - prc: 0.3937 - val_loss: 0.4476 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6833 - val_prc: 0.3334\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7118 - prc: 0.3717 - val_loss: 0.4637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6829 - val_prc: 0.3335\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5761 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7190 - prc: 0.3828 - val_loss: 0.4487 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6839 - val_prc: 0.3353\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5783 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7194 - prc: 0.3918 - val_loss: 0.4518 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6849 - val_prc: 0.3389\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5774 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7171 - prc: 0.3824 - val_loss: 0.4604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6862 - val_prc: 0.3418\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5774 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7172 - prc: 0.3811 - val_loss: 0.4601 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6869 - val_prc: 0.3443\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5764 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7187 - prc: 0.3872 - val_loss: 0.4502 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3361\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5768 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7184 - prc: 0.3917 - val_loss: 0.4549 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6847 - val_prc: 0.3343\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5771 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7179 - prc: 0.3883 - val_loss: 0.4561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6863 - val_prc: 0.3383\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5771 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7172 - prc: 0.3813 - val_loss: 0.4535 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6856 - val_prc: 0.3349\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5786 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7173 - prc: 0.3907 - val_loss: 0.4529 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6858 - val_prc: 0.3326\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5759 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7188 - prc: 0.3844 - val_loss: 0.4575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6859 - val_prc: 0.3361\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5762 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7177 - prc: 0.3815 - val_loss: 0.4501 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6882 - val_prc: 0.3474\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5763 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7180 - prc: 0.3852 - val_loss: 0.4582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6857 - val_prc: 0.3354\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5763 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7172 - prc: 0.3825 - val_loss: 0.4536 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6865 - val_prc: 0.3400\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5767 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7188 - prc: 0.3902 - val_loss: 0.4575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6856 - val_prc: 0.3359\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5765 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7172 - prc: 0.3846 - val_loss: 0.4534 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6855 - val_prc: 0.3371\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5761 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7183 - prc: 0.3863 - val_loss: 0.4554 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.3379\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5759 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7173 - prc: 0.3810 - val_loss: 0.4557 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6838 - val_prc: 0.3349\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5767 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7183 - prc: 0.3879 - val_loss: 0.4582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6851 - val_prc: 0.3360\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5763 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7179 - prc: 0.3814 - val_loss: 0.4567 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6853 - val_prc: 0.3377\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5759 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7197 - prc: 0.3919 - val_loss: 0.4528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6854 - val_prc: 0.3363\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5757 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7181 - prc: 0.3828 - val_loss: 0.4637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6869 - val_prc: 0.3426\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5757 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7186 - prc: 0.3847 - val_loss: 0.4551 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6865 - val_prc: 0.3361\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5752 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7187 - prc: 0.3794 - val_loss: 0.4592 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6868 - val_prc: 0.3413\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5747 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7207 - prc: 0.3938 - val_loss: 0.4534 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3332\n",
      "Epoch 253/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7179 - prc: 0.3848 - val_loss: 0.4586 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6837 - val_prc: 0.3353\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5759 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7170 - prc: 0.3782 - val_loss: 0.4594 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6838 - val_prc: 0.3331\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5752 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7180 - prc: 0.3817 - val_loss: 0.4589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6848 - val_prc: 0.3357\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5751 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7178 - prc: 0.3820 - val_loss: 0.4528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6854 - val_prc: 0.3387\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5759 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7167 - prc: 0.3846 - val_loss: 0.4565 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6855 - val_prc: 0.3378\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5752 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7175 - prc: 0.3720 - val_loss: 0.4556 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6848 - val_prc: 0.3385\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7180 - prc: 0.3805 - val_loss: 0.4562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6855 - val_prc: 0.3386\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7189 - prc: 0.3858 - val_loss: 0.4550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6849 - val_prc: 0.3386\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5751 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7174 - prc: 0.3832 - val_loss: 0.4560 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6850 - val_prc: 0.3352\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5747 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7183 - prc: 0.3818 - val_loss: 0.4577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6864 - val_prc: 0.3383\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7189 - prc: 0.3892 - val_loss: 0.4533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6860 - val_prc: 0.3369\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5746 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7177 - prc: 0.3830 - val_loss: 0.4639 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6864 - val_prc: 0.3436\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7185 - prc: 0.3872 - val_loss: 0.4508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6876 - val_prc: 0.3472\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5766 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7143 - prc: 0.3830 - val_loss: 0.4589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6864 - val_prc: 0.3384\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5772 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7156 - prc: 0.3910 - val_loss: 0.4515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6876 - val_prc: 0.3504\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7199 - prc: 0.3874 - val_loss: 0.4610 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6885 - val_prc: 0.3489\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5742 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7192 - prc: 0.3842 - val_loss: 0.4581 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6849 - val_prc: 0.3375\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5777 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7145 - prc: 0.3736 - val_loss: 0.4619 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6813 - val_prc: 0.3308\n",
      "Epoch 271/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5762 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7155 - prc: 0.3768 - val_loss: 0.4568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6825 - val_prc: 0.3368\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5744 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7173 - prc: 0.3827 - val_loss: 0.4590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6846 - val_prc: 0.3371\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5738 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7180 - prc: 0.3846 - val_loss: 0.4602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6849 - val_prc: 0.3352\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5750 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7176 - prc: 0.3846 - val_loss: 0.4529 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6855 - val_prc: 0.3378\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7192 - prc: 0.3937 - val_loss: 0.4506 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6859 - val_prc: 0.3438\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5763 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7140 - prc: 0.3809 - val_loss: 0.4540 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6869 - val_prc: 0.3414\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5746 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7193 - prc: 0.3878 - val_loss: 0.4568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6865 - val_prc: 0.3373\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7182 - prc: 0.3822 - val_loss: 0.4619 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6845 - val_prc: 0.3352\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5736 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7188 - prc: 0.3870 - val_loss: 0.4548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6833 - val_prc: 0.3353\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5738 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7187 - prc: 0.3856 - val_loss: 0.4536 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6843 - val_prc: 0.3374\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5740 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7180 - prc: 0.3872 - val_loss: 0.4579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.3346\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5736 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7192 - prc: 0.3904 - val_loss: 0.4484 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6871 - val_prc: 0.3518\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5740 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7205 - prc: 0.3984 - val_loss: 0.4566 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6861 - val_prc: 0.3369\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5763 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7157 - prc: 0.3792 - val_loss: 0.4576 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.3367\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5761 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7145 - prc: 0.3820 - val_loss: 0.4568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6855 - val_prc: 0.3378\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7189 - prc: 0.3879 - val_loss: 0.4614 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6855 - val_prc: 0.3352\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5746 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7176 - prc: 0.3887 - val_loss: 0.4581 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6872 - val_prc: 0.3410\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5744 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7184 - prc: 0.3840 - val_loss: 0.4568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6877 - val_prc: 0.3456\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7196 - prc: 0.3938 - val_loss: 0.4528 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6870 - val_prc: 0.3464\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5737 - tp: 29.0000 - fp: 26.0000 - tn: 1600.0000 - fn: 369.0000 - accuracy: 0.8048 - precision: 0.5273 - recall: 0.0729 - auc: 0.7187 - prc: 0.3888 - val_loss: 0.4605 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6863 - val_prc: 0.3405\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5744 - tp: 91.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 307.0000 - accuracy: 0.8093 - precision: 0.5353 - recall: 0.2286 - auc: 0.7169 - prc: 0.3902 - val_loss: 0.4561 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6850 - val_prc: 0.3375\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5732 - tp: 93.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 305.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2337 - auc: 0.7189 - prc: 0.3870 - val_loss: 0.4570 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6845 - val_prc: 0.3355\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5732 - tp: 91.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 307.0000 - accuracy: 0.8048 - precision: 0.5084 - recall: 0.2286 - auc: 0.7189 - prc: 0.3888 - val_loss: 0.4569 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6840 - val_prc: 0.3313\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - tp: 99.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 299.0000 - accuracy: 0.8063 - precision: 0.5156 - recall: 0.2487 - auc: 0.7193 - prc: 0.3922 - val_loss: 0.4615 - val_tp: 26.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 65.0000 - val_accuracy: 0.8083 - val_precision: 0.4483 - val_recall: 0.2857 - val_auc: 0.6847 - val_prc: 0.3364\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5731 - tp: 94.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 304.0000 - accuracy: 0.8039 - precision: 0.5027 - recall: 0.2362 - auc: 0.7187 - prc: 0.3880 - val_loss: 0.4553 - val_tp: 22.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 69.0000 - val_accuracy: 0.8063 - val_precision: 0.4314 - val_recall: 0.2418 - val_auc: 0.6860 - val_prc: 0.3392\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5734 - tp: 104.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 294.0000 - accuracy: 0.8058 - precision: 0.5123 - recall: 0.2613 - auc: 0.7185 - prc: 0.3878 - val_loss: 0.4584 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6861 - val_prc: 0.3384\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5726 - tp: 94.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 304.0000 - accuracy: 0.8098 - precision: 0.5371 - recall: 0.2362 - auc: 0.7200 - prc: 0.3936 - val_loss: 0.4458 - val_tp: 16.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 75.0000 - val_accuracy: 0.8261 - val_precision: 0.5517 - val_recall: 0.1758 - val_auc: 0.6888 - val_prc: 0.3648\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5754 - tp: 75.0000 - fp: 50.0000 - tn: 1576.0000 - fn: 323.0000 - accuracy: 0.8157 - precision: 0.6000 - recall: 0.1884 - auc: 0.7212 - prc: 0.4072 - val_loss: 0.4532 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6888 - val_prc: 0.3597\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5732 - tp: 100.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 298.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2513 - auc: 0.7191 - prc: 0.3862 - val_loss: 0.4674 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6876 - val_prc: 0.3461\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5720 - tp: 101.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 297.0000 - accuracy: 0.8058 - precision: 0.5127 - recall: 0.2538 - auc: 0.7210 - prc: 0.3907 - val_loss: 0.4477 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6864 - val_prc: 0.3557\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5760 - tp: 83.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 315.0000 - accuracy: 0.8113 - precision: 0.5533 - recall: 0.2085 - auc: 0.7163 - prc: 0.3938 - val_loss: 0.4573 - val_tp: 23.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 68.0000 - val_accuracy: 0.8063 - val_precision: 0.4340 - val_recall: 0.2527 - val_auc: 0.6857 - val_prc: 0.3382\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - tp: 93.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 305.0000 - accuracy: 0.8068 - precision: 0.5196 - recall: 0.2337 - auc: 0.7191 - prc: 0.3920 - val_loss: 0.4558 - val_tp: 22.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 69.0000 - val_accuracy: 0.8043 - val_precision: 0.4231 - val_recall: 0.2418 - val_auc: 0.6866 - val_prc: 0.3463\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5736 - tp: 98.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 300.0000 - accuracy: 0.8048 - precision: 0.5078 - recall: 0.2462 - auc: 0.7172 - prc: 0.3863 - val_loss: 0.4603 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6852 - val_prc: 0.3375\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5740 - tp: 91.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 307.0000 - accuracy: 0.8093 - precision: 0.5353 - recall: 0.2286 - auc: 0.7178 - prc: 0.3939 - val_loss: 0.4558 - val_tp: 22.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 69.0000 - val_accuracy: 0.8063 - val_precision: 0.4314 - val_recall: 0.2418 - val_auc: 0.6863 - val_prc: 0.3433\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5726 - tp: 94.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 304.0000 - accuracy: 0.8078 - precision: 0.5251 - recall: 0.2362 - auc: 0.7199 - prc: 0.3952 - val_loss: 0.4583 - val_tp: 23.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 68.0000 - val_accuracy: 0.8043 - val_precision: 0.4259 - val_recall: 0.2527 - val_auc: 0.6865 - val_prc: 0.3398\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5735 - tp: 92.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 306.0000 - accuracy: 0.8063 - precision: 0.5169 - recall: 0.2312 - auc: 0.7175 - prc: 0.3937 - val_loss: 0.4570 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6855 - val_prc: 0.3365\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5729 - tp: 99.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 299.0000 - accuracy: 0.8073 - precision: 0.5211 - recall: 0.2487 - auc: 0.7182 - prc: 0.3884 - val_loss: 0.4596 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6853 - val_prc: 0.3370\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5730 - tp: 107.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 291.0000 - accuracy: 0.8039 - precision: 0.5023 - recall: 0.2688 - auc: 0.7185 - prc: 0.3862 - val_loss: 0.4567 - val_tp: 23.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 68.0000 - val_accuracy: 0.8063 - val_precision: 0.4340 - val_recall: 0.2527 - val_auc: 0.6864 - val_prc: 0.3436\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5726 - tp: 91.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 307.0000 - accuracy: 0.8078 - precision: 0.5260 - recall: 0.2286 - auc: 0.7205 - prc: 0.3983 - val_loss: 0.4530 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6866 - val_prc: 0.3429\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5727 - tp: 95.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 303.0000 - accuracy: 0.8053 - precision: 0.5108 - recall: 0.2387 - auc: 0.7194 - prc: 0.3926 - val_loss: 0.4603 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6881 - val_prc: 0.3442\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - tp: 93.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 305.0000 - accuracy: 0.8113 - precision: 0.5471 - recall: 0.2337 - auc: 0.7199 - prc: 0.3982 - val_loss: 0.4551 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6890 - val_prc: 0.3595\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5732 - tp: 105.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 293.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2638 - auc: 0.7194 - prc: 0.3905 - val_loss: 0.4580 - val_tp: 26.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 65.0000 - val_accuracy: 0.8142 - val_precision: 0.4727 - val_recall: 0.2857 - val_auc: 0.6890 - val_prc: 0.3490\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5721 - tp: 90.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 308.0000 - accuracy: 0.8123 - precision: 0.5556 - recall: 0.2261 - auc: 0.7211 - prc: 0.4030 - val_loss: 0.4493 - val_tp: 20.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 71.0000 - val_accuracy: 0.8281 - val_precision: 0.5556 - val_recall: 0.2198 - val_auc: 0.6895 - val_prc: 0.3654\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5725 - tp: 91.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 307.0000 - accuracy: 0.8083 - precision: 0.5291 - recall: 0.2286 - auc: 0.7202 - prc: 0.3979 - val_loss: 0.4596 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6883 - val_prc: 0.3457\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5723 - tp: 104.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 294.0000 - accuracy: 0.8058 - precision: 0.5123 - recall: 0.2613 - auc: 0.7203 - prc: 0.3919 - val_loss: 0.4583 - val_tp: 25.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 66.0000 - val_accuracy: 0.8103 - val_precision: 0.4545 - val_recall: 0.2747 - val_auc: 0.6868 - val_prc: 0.3445\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5740 - tp: 87.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 311.0000 - accuracy: 0.8098 - precision: 0.5404 - recall: 0.2186 - auc: 0.7182 - prc: 0.4004 - val_loss: 0.4596 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6855 - val_prc: 0.3366\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5777 - tp: 128.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 270.0000 - accuracy: 0.7955 - precision: 0.4706 - recall: 0.3216 - auc: 0.7142 - prc: 0.3736 - val_loss: 0.4606 - val_tp: 26.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 65.0000 - val_accuracy: 0.8083 - val_precision: 0.4483 - val_recall: 0.2857 - val_auc: 0.6855 - val_prc: 0.3353\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5727 - tp: 87.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 311.0000 - accuracy: 0.8088 - precision: 0.5337 - recall: 0.2186 - auc: 0.7212 - prc: 0.4084 - val_loss: 0.4478 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6873 - val_prc: 0.3603\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5730 - tp: 86.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 312.0000 - accuracy: 0.8123 - precision: 0.5584 - recall: 0.2161 - auc: 0.7202 - prc: 0.4070 - val_loss: 0.4564 - val_tp: 25.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 66.0000 - val_accuracy: 0.8182 - val_precision: 0.4902 - val_recall: 0.2747 - val_auc: 0.6908 - val_prc: 0.3600\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5722 - tp: 104.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 294.0000 - accuracy: 0.8073 - precision: 0.5200 - recall: 0.2613 - auc: 0.7202 - prc: 0.3973 - val_loss: 0.4549 - val_tp: 22.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 69.0000 - val_accuracy: 0.8162 - val_precision: 0.4783 - val_recall: 0.2418 - val_auc: 0.6892 - val_prc: 0.3585\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5735 - tp: 84.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 314.0000 - accuracy: 0.8137 - precision: 0.5714 - recall: 0.2111 - auc: 0.7204 - prc: 0.4057 - val_loss: 0.4534 - val_tp: 21.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 70.0000 - val_accuracy: 0.8162 - val_precision: 0.4773 - val_recall: 0.2308 - val_auc: 0.6880 - val_prc: 0.3573\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5722 - tp: 102.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 296.0000 - accuracy: 0.8078 - precision: 0.5231 - recall: 0.2563 - auc: 0.7197 - prc: 0.3963 - val_loss: 0.4649 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6872 - val_prc: 0.3407\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5749 - tp: 118.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 280.0000 - accuracy: 0.7999 - precision: 0.4856 - recall: 0.2965 - auc: 0.7170 - prc: 0.3863 - val_loss: 0.4604 - val_tp: 24.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 67.0000 - val_accuracy: 0.8043 - val_precision: 0.4286 - val_recall: 0.2637 - val_auc: 0.6845 - val_prc: 0.3371\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5747 - tp: 116.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 282.0000 - accuracy: 0.7969 - precision: 0.4735 - recall: 0.2915 - auc: 0.7171 - prc: 0.3824 - val_loss: 0.4596 - val_tp: 24.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 67.0000 - val_accuracy: 0.8063 - val_precision: 0.4364 - val_recall: 0.2637 - val_auc: 0.6836 - val_prc: 0.3360\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5741 - tp: 86.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 312.0000 - accuracy: 0.8132 - precision: 0.5658 - recall: 0.2161 - auc: 0.7186 - prc: 0.4147 - val_loss: 0.4483 - val_tp: 17.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 74.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1868 - val_auc: 0.6866 - val_prc: 0.3587\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5729 - tp: 82.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 316.0000 - accuracy: 0.8113 - precision: 0.5541 - recall: 0.2060 - auc: 0.7200 - prc: 0.4068 - val_loss: 0.4617 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6864 - val_prc: 0.3455\n",
      "Epoch 327/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5741 - tp: 117.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 281.0000 - accuracy: 0.7989 - precision: 0.4815 - recall: 0.2940 - auc: 0.7185 - prc: 0.3808 - val_loss: 0.4609 - val_tp: 26.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 65.0000 - val_accuracy: 0.8063 - val_precision: 0.4407 - val_recall: 0.2857 - val_auc: 0.6866 - val_prc: 0.3453\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5724 - tp: 88.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 310.0000 - accuracy: 0.8098 - precision: 0.5399 - recall: 0.2211 - auc: 0.7210 - prc: 0.4056 - val_loss: 0.4494 - val_tp: 17.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 74.0000 - val_accuracy: 0.8142 - val_precision: 0.4595 - val_recall: 0.1868 - val_auc: 0.6859 - val_prc: 0.3586\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5761 - tp: 81.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 317.0000 - accuracy: 0.8132 - precision: 0.5704 - recall: 0.2035 - auc: 0.7185 - prc: 0.4073 - val_loss: 0.4578 - val_tp: 23.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 68.0000 - val_accuracy: 0.8043 - val_precision: 0.4259 - val_recall: 0.2527 - val_auc: 0.6838 - val_prc: 0.3420\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5723 - tp: 105.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 293.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2638 - auc: 0.7191 - prc: 0.3908 - val_loss: 0.4612 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6868 - val_prc: 0.3426\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5717 - tp: 91.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 307.0000 - accuracy: 0.8068 - precision: 0.5200 - recall: 0.2286 - auc: 0.7214 - prc: 0.4035 - val_loss: 0.4515 - val_tp: 18.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 73.0000 - val_accuracy: 0.8142 - val_precision: 0.4615 - val_recall: 0.1978 - val_auc: 0.6882 - val_prc: 0.3613\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5725 - tp: 85.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 313.0000 - accuracy: 0.8113 - precision: 0.5519 - recall: 0.2136 - auc: 0.7202 - prc: 0.4091 - val_loss: 0.4549 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6872 - val_prc: 0.3566\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5713 - tp: 97.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 301.0000 - accuracy: 0.8073 - precision: 0.5215 - recall: 0.2437 - auc: 0.7211 - prc: 0.3991 - val_loss: 0.4628 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6886 - val_prc: 0.3548\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5731 - tp: 103.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 295.0000 - accuracy: 0.8029 - precision: 0.4976 - recall: 0.2588 - auc: 0.7194 - prc: 0.3952 - val_loss: 0.4536 - val_tp: 19.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 72.0000 - val_accuracy: 0.8142 - val_precision: 0.4634 - val_recall: 0.2088 - val_auc: 0.6875 - val_prc: 0.3583\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5727 - tp: 88.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 310.0000 - accuracy: 0.8118 - precision: 0.5535 - recall: 0.2211 - auc: 0.7190 - prc: 0.4046 - val_loss: 0.4606 - val_tp: 24.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 67.0000 - val_accuracy: 0.8063 - val_precision: 0.4364 - val_recall: 0.2637 - val_auc: 0.6871 - val_prc: 0.3506\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5718 - tp: 105.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 293.0000 - accuracy: 0.8058 - precision: 0.5122 - recall: 0.2638 - auc: 0.7205 - prc: 0.3977 - val_loss: 0.4554 - val_tp: 22.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 69.0000 - val_accuracy: 0.8142 - val_precision: 0.4681 - val_recall: 0.2418 - val_auc: 0.6871 - val_prc: 0.3563\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5743 - tp: 78.0000 - fp: 52.0000 - tn: 1574.0000 - fn: 320.0000 - accuracy: 0.8162 - precision: 0.6000 - recall: 0.1960 - auc: 0.7197 - prc: 0.4110 - val_loss: 0.4491 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6884 - val_prc: 0.3706\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5706 - tp: 91.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 307.0000 - accuracy: 0.8108 - precision: 0.5449 - recall: 0.2286 - auc: 0.7223 - prc: 0.4045 - val_loss: 0.4602 - val_tp: 26.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 65.0000 - val_accuracy: 0.8142 - val_precision: 0.4727 - val_recall: 0.2857 - val_auc: 0.6891 - val_prc: 0.3547\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5713 - tp: 98.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 300.0000 - accuracy: 0.8098 - precision: 0.5355 - recall: 0.2462 - auc: 0.7212 - prc: 0.4047 - val_loss: 0.4559 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6894 - val_prc: 0.3572\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5722 - tp: 99.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 299.0000 - accuracy: 0.8048 - precision: 0.5077 - recall: 0.2487 - auc: 0.7202 - prc: 0.3998 - val_loss: 0.4542 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6898 - val_prc: 0.3681\n",
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5711 - tp: 85.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 313.0000 - accuracy: 0.8132 - precision: 0.5667 - recall: 0.2136 - auc: 0.7220 - prc: 0.4131 - val_loss: 0.4537 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6907 - val_prc: 0.3711\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5761 - tp: 109.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 289.0000 - accuracy: 0.7974 - precision: 0.4739 - recall: 0.2739 - auc: 0.7166 - prc: 0.3921 - val_loss: 0.4605 - val_tp: 25.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 66.0000 - val_accuracy: 0.8182 - val_precision: 0.4902 - val_recall: 0.2747 - val_auc: 0.6901 - val_prc: 0.3643\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - tp: 97.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 301.0000 - accuracy: 0.8152 - precision: 0.5706 - recall: 0.2437 - auc: 0.7216 - prc: 0.4064 - val_loss: 0.4492 - val_tp: 16.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 75.0000 - val_accuracy: 0.8261 - val_precision: 0.5517 - val_recall: 0.1758 - val_auc: 0.6895 - val_prc: 0.3754\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5720 - tp: 89.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 309.0000 - accuracy: 0.8147 - precision: 0.5742 - recall: 0.2236 - auc: 0.7199 - prc: 0.4037 - val_loss: 0.4576 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6904 - val_prc: 0.3726\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5714 - tp: 94.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 304.0000 - accuracy: 0.8093 - precision: 0.5341 - recall: 0.2362 - auc: 0.7205 - prc: 0.4088 - val_loss: 0.4553 - val_tp: 19.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 72.0000 - val_accuracy: 0.8123 - val_precision: 0.4524 - val_recall: 0.2088 - val_auc: 0.6885 - val_prc: 0.3652\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5714 - tp: 99.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 299.0000 - accuracy: 0.8063 - precision: 0.5156 - recall: 0.2487 - auc: 0.7209 - prc: 0.4013 - val_loss: 0.4588 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6880 - val_prc: 0.3573\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - tp: 90.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 308.0000 - accuracy: 0.8152 - precision: 0.5769 - recall: 0.2261 - auc: 0.7206 - prc: 0.4103 - val_loss: 0.4526 - val_tp: 18.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 73.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1978 - val_auc: 0.6888 - val_prc: 0.3668\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5714 - tp: 98.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 300.0000 - accuracy: 0.8058 - precision: 0.5131 - recall: 0.2462 - auc: 0.7208 - prc: 0.4001 - val_loss: 0.4634 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6886 - val_prc: 0.3578\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - tp: 107.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 291.0000 - accuracy: 0.8043 - precision: 0.5047 - recall: 0.2688 - auc: 0.7197 - prc: 0.3996 - val_loss: 0.4540 - val_tp: 18.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 73.0000 - val_accuracy: 0.8123 - val_precision: 0.4500 - val_recall: 0.1978 - val_auc: 0.6887 - val_prc: 0.3666\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5718 - tp: 82.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 316.0000 - accuracy: 0.8123 - precision: 0.5616 - recall: 0.2060 - auc: 0.7209 - prc: 0.4091 - val_loss: 0.4596 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6888 - val_prc: 0.3583\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5737 - tp: 117.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 281.0000 - accuracy: 0.8024 - precision: 0.4958 - recall: 0.2940 - auc: 0.7201 - prc: 0.3959 - val_loss: 0.4604 - val_tp: 26.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 65.0000 - val_accuracy: 0.8123 - val_precision: 0.4643 - val_recall: 0.2857 - val_auc: 0.6889 - val_prc: 0.3606\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5732 - tp: 85.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 313.0000 - accuracy: 0.8162 - precision: 0.5903 - recall: 0.2136 - auc: 0.7184 - prc: 0.4060 - val_loss: 0.4489 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6884 - val_prc: 0.3694\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5715 - tp: 97.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 301.0000 - accuracy: 0.8103 - precision: 0.5389 - recall: 0.2437 - auc: 0.7207 - prc: 0.4057 - val_loss: 0.4580 - val_tp: 22.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 69.0000 - val_accuracy: 0.8123 - val_precision: 0.4583 - val_recall: 0.2418 - val_auc: 0.6887 - val_prc: 0.3589\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5715 - tp: 81.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 317.0000 - accuracy: 0.8132 - precision: 0.5704 - recall: 0.2035 - auc: 0.7211 - prc: 0.4084 - val_loss: 0.4520 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 73.0000 - val_accuracy: 0.8221 - val_precision: 0.5143 - val_recall: 0.1978 - val_auc: 0.6894 - val_prc: 0.3735\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5709 - tp: 96.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 302.0000 - accuracy: 0.8088 - precision: 0.5304 - recall: 0.2412 - auc: 0.7208 - prc: 0.4063 - val_loss: 0.4618 - val_tp: 24.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 67.0000 - val_accuracy: 0.8063 - val_precision: 0.4364 - val_recall: 0.2637 - val_auc: 0.6879 - val_prc: 0.3545\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5708 - tp: 98.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 300.0000 - accuracy: 0.8088 - precision: 0.5297 - recall: 0.2462 - auc: 0.7213 - prc: 0.4067 - val_loss: 0.4580 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6878 - val_prc: 0.3566\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5706 - tp: 96.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 302.0000 - accuracy: 0.8108 - precision: 0.5424 - recall: 0.2412 - auc: 0.7214 - prc: 0.4067 - val_loss: 0.4571 - val_tp: 21.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 70.0000 - val_accuracy: 0.8123 - val_precision: 0.4565 - val_recall: 0.2308 - val_auc: 0.6894 - val_prc: 0.3669\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5705 - tp: 94.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 304.0000 - accuracy: 0.8137 - precision: 0.5629 - recall: 0.2362 - auc: 0.7212 - prc: 0.4083 - val_loss: 0.4561 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 70.0000 - val_accuracy: 0.8182 - val_precision: 0.4884 - val_recall: 0.2308 - val_auc: 0.6914 - val_prc: 0.3788\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - tp: 96.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 302.0000 - accuracy: 0.8103 - precision: 0.5393 - recall: 0.2412 - auc: 0.7210 - prc: 0.4081 - val_loss: 0.4538 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6915 - val_prc: 0.3787\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5721 - tp: 77.0000 - fp: 53.0000 - tn: 1573.0000 - fn: 321.0000 - accuracy: 0.8152 - precision: 0.5923 - recall: 0.1935 - auc: 0.7205 - prc: 0.4054 - val_loss: 0.4524 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 72.0000 - val_accuracy: 0.8241 - val_precision: 0.5278 - val_recall: 0.2088 - val_auc: 0.6908 - val_prc: 0.3793\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5784 - tp: 122.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 276.0000 - accuracy: 0.8029 - precision: 0.4980 - recall: 0.3065 - auc: 0.7148 - prc: 0.3933 - val_loss: 0.4606 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6908 - val_prc: 0.3721\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - tp: 73.0000 - fp: 55.0000 - tn: 1571.0000 - fn: 325.0000 - accuracy: 0.8123 - precision: 0.5703 - recall: 0.1834 - auc: 0.7238 - prc: 0.4108 - val_loss: 0.4441 - val_tp: 13.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 78.0000 - val_accuracy: 0.8261 - val_precision: 0.5652 - val_recall: 0.1429 - val_auc: 0.6892 - val_prc: 0.3799\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5716 - tp: 94.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 304.0000 - accuracy: 0.8103 - precision: 0.5402 - recall: 0.2362 - auc: 0.7194 - prc: 0.4117 - val_loss: 0.4637 - val_tp: 25.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 66.0000 - val_accuracy: 0.8083 - val_precision: 0.4464 - val_recall: 0.2747 - val_auc: 0.6867 - val_prc: 0.3525\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - tp: 86.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 312.0000 - accuracy: 0.8137 - precision: 0.5695 - recall: 0.2161 - auc: 0.7169 - prc: 0.4067 - val_loss: 0.4513 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 73.0000 - val_accuracy: 0.8221 - val_precision: 0.5143 - val_recall: 0.1978 - val_auc: 0.6870 - val_prc: 0.3706\n",
      "Epoch 365/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 97.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 301.0000 - accuracy: 0.8078 - precision: 0.5243 - recall: 0.2437 - auc: 0.7215 - prc: 0.4100 - val_loss: 0.4646 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6876 - val_prc: 0.3537\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - tp: 99.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 299.0000 - accuracy: 0.8029 - precision: 0.4975 - recall: 0.2487 - auc: 0.7197 - prc: 0.4039 - val_loss: 0.4542 - val_tp: 19.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 72.0000 - val_accuracy: 0.8123 - val_precision: 0.4524 - val_recall: 0.2088 - val_auc: 0.6892 - val_prc: 0.3732\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5707 - tp: 102.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 296.0000 - accuracy: 0.8068 - precision: 0.5178 - recall: 0.2563 - auc: 0.7215 - prc: 0.4047 - val_loss: 0.4591 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6889 - val_prc: 0.3660\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5713 - tp: 86.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 312.0000 - accuracy: 0.8103 - precision: 0.5443 - recall: 0.2161 - auc: 0.7193 - prc: 0.4096 - val_loss: 0.4466 - val_tp: 14.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 77.0000 - val_accuracy: 0.8241 - val_precision: 0.5385 - val_recall: 0.1538 - val_auc: 0.6883 - val_prc: 0.3699\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5705 - tp: 86.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 312.0000 - accuracy: 0.8113 - precision: 0.5513 - recall: 0.2161 - auc: 0.7212 - prc: 0.4092 - val_loss: 0.4615 - val_tp: 26.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 65.0000 - val_accuracy: 0.8123 - val_precision: 0.4643 - val_recall: 0.2857 - val_auc: 0.6900 - val_prc: 0.3713\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - tp: 96.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 302.0000 - accuracy: 0.8073 - precision: 0.5217 - recall: 0.2412 - auc: 0.7206 - prc: 0.4092 - val_loss: 0.4523 - val_tp: 18.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 73.0000 - val_accuracy: 0.8123 - val_precision: 0.4500 - val_recall: 0.1978 - val_auc: 0.6882 - val_prc: 0.3687\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5707 - tp: 87.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 311.0000 - accuracy: 0.8137 - precision: 0.5686 - recall: 0.2186 - auc: 0.7218 - prc: 0.4122 - val_loss: 0.4556 - val_tp: 21.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 70.0000 - val_accuracy: 0.8162 - val_precision: 0.4773 - val_recall: 0.2308 - val_auc: 0.6884 - val_prc: 0.3717\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 92.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 306.0000 - accuracy: 0.8098 - precision: 0.5380 - recall: 0.2312 - auc: 0.7216 - prc: 0.4115 - val_loss: 0.4610 - val_tp: 23.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 68.0000 - val_accuracy: 0.8043 - val_precision: 0.4259 - val_recall: 0.2527 - val_auc: 0.6867 - val_prc: 0.3563\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5703 - tp: 99.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 299.0000 - accuracy: 0.8108 - precision: 0.5410 - recall: 0.2487 - auc: 0.7213 - prc: 0.4056 - val_loss: 0.4547 - val_tp: 18.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 73.0000 - val_accuracy: 0.8103 - val_precision: 0.4390 - val_recall: 0.1978 - val_auc: 0.6880 - val_prc: 0.3715\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5709 - tp: 86.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 312.0000 - accuracy: 0.8103 - precision: 0.5443 - recall: 0.2161 - auc: 0.7204 - prc: 0.4110 - val_loss: 0.4572 - val_tp: 22.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 69.0000 - val_accuracy: 0.8123 - val_precision: 0.4583 - val_recall: 0.2418 - val_auc: 0.6875 - val_prc: 0.3689\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5706 - tp: 88.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 310.0000 - accuracy: 0.8118 - precision: 0.5535 - recall: 0.2211 - auc: 0.7206 - prc: 0.4127 - val_loss: 0.4609 - val_tp: 23.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 68.0000 - val_accuracy: 0.8063 - val_precision: 0.4340 - val_recall: 0.2527 - val_auc: 0.6892 - val_prc: 0.3661\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5737 - tp: 119.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 279.0000 - accuracy: 0.8024 - precision: 0.4958 - recall: 0.2990 - auc: 0.7202 - prc: 0.4037 - val_loss: 0.4599 - val_tp: 24.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 67.0000 - val_accuracy: 0.8142 - val_precision: 0.4706 - val_recall: 0.2637 - val_auc: 0.6906 - val_prc: 0.3790\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5729 - tp: 76.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 322.0000 - accuracy: 0.8123 - precision: 0.5672 - recall: 0.1910 - auc: 0.7184 - prc: 0.4048 - val_loss: 0.4500 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6887 - val_prc: 0.3715\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5700 - tp: 93.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 305.0000 - accuracy: 0.8118 - precision: 0.5503 - recall: 0.2337 - auc: 0.7226 - prc: 0.4208 - val_loss: 0.4583 - val_tp: 22.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 69.0000 - val_accuracy: 0.8142 - val_precision: 0.4681 - val_recall: 0.2418 - val_auc: 0.6903 - val_prc: 0.3755\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - tp: 97.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 301.0000 - accuracy: 0.8118 - precision: 0.5480 - recall: 0.2437 - auc: 0.7225 - prc: 0.4134 - val_loss: 0.4514 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6901 - val_prc: 0.3733\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5708 - tp: 84.0000 - fp: 55.0000 - tn: 1571.0000 - fn: 314.0000 - accuracy: 0.8177 - precision: 0.6043 - recall: 0.2111 - auc: 0.7213 - prc: 0.4112 - val_loss: 0.4531 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6890 - val_prc: 0.3706\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - tp: 89.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 309.0000 - accuracy: 0.8113 - precision: 0.5494 - recall: 0.2236 - auc: 0.7223 - prc: 0.4119 - val_loss: 0.4574 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6887 - val_prc: 0.3748\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5706 - tp: 94.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 304.0000 - accuracy: 0.8113 - precision: 0.5465 - recall: 0.2362 - auc: 0.7206 - prc: 0.4113 - val_loss: 0.4611 - val_tp: 23.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 68.0000 - val_accuracy: 0.8043 - val_precision: 0.4259 - val_recall: 0.2527 - val_auc: 0.6876 - val_prc: 0.3640\n",
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5720 - tp: 113.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 285.0000 - accuracy: 0.8048 - precision: 0.5067 - recall: 0.2839 - auc: 0.7202 - prc: 0.4025 - val_loss: 0.4575 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6879 - val_prc: 0.3710\n",
      "Epoch 384/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5703 - tp: 86.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 312.0000 - accuracy: 0.8132 - precision: 0.5658 - recall: 0.2161 - auc: 0.7214 - prc: 0.4103 - val_loss: 0.4519 - val_tp: 18.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 73.0000 - val_accuracy: 0.8182 - val_precision: 0.4865 - val_recall: 0.1978 - val_auc: 0.6878 - val_prc: 0.3693\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5702 - tp: 94.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 304.0000 - accuracy: 0.8098 - precision: 0.5371 - recall: 0.2362 - auc: 0.7208 - prc: 0.4126 - val_loss: 0.4571 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6878 - val_prc: 0.3712\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - tp: 92.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 306.0000 - accuracy: 0.8103 - precision: 0.5412 - recall: 0.2312 - auc: 0.7216 - prc: 0.4136 - val_loss: 0.4558 - val_tp: 20.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 71.0000 - val_accuracy: 0.8103 - val_precision: 0.4444 - val_recall: 0.2198 - val_auc: 0.6871 - val_prc: 0.3711\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5700 - tp: 94.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 304.0000 - accuracy: 0.8088 - precision: 0.5311 - recall: 0.2362 - auc: 0.7208 - prc: 0.4042 - val_loss: 0.4529 - val_tp: 18.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 73.0000 - val_accuracy: 0.8123 - val_precision: 0.4500 - val_recall: 0.1978 - val_auc: 0.6875 - val_prc: 0.3685\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5705 - tp: 95.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 303.0000 - accuracy: 0.8098 - precision: 0.5367 - recall: 0.2387 - auc: 0.7202 - prc: 0.4130 - val_loss: 0.4571 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6892 - val_prc: 0.3728\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5731 - tp: 83.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 315.0000 - accuracy: 0.8118 - precision: 0.5570 - recall: 0.2085 - auc: 0.7185 - prc: 0.4072 - val_loss: 0.4594 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6896 - val_prc: 0.3738\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5713 - tp: 106.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 292.0000 - accuracy: 0.8053 - precision: 0.5096 - recall: 0.2663 - auc: 0.7209 - prc: 0.4086 - val_loss: 0.4619 - val_tp: 25.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 66.0000 - val_accuracy: 0.8103 - val_precision: 0.4545 - val_recall: 0.2747 - val_auc: 0.6896 - val_prc: 0.3745\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5715 - tp: 107.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 291.0000 - accuracy: 0.8048 - precision: 0.5071 - recall: 0.2688 - auc: 0.7203 - prc: 0.4057 - val_loss: 0.4516 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6892 - val_prc: 0.3751\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5745 - tp: 73.0000 - fp: 51.0000 - tn: 1575.0000 - fn: 325.0000 - accuracy: 0.8142 - precision: 0.5887 - recall: 0.1834 - auc: 0.7194 - prc: 0.4134 - val_loss: 0.4485 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 75.0000 - val_accuracy: 0.8221 - val_precision: 0.5161 - val_recall: 0.1758 - val_auc: 0.6887 - val_prc: 0.3795\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5700 - tp: 84.0000 - fp: 60.0000 - tn: 1566.0000 - fn: 314.0000 - accuracy: 0.8152 - precision: 0.5833 - recall: 0.2111 - auc: 0.7226 - prc: 0.4119 - val_loss: 0.4609 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6905 - val_prc: 0.3749\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5700 - tp: 97.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 301.0000 - accuracy: 0.8073 - precision: 0.5215 - recall: 0.2437 - auc: 0.7218 - prc: 0.4164 - val_loss: 0.4584 - val_tp: 21.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 70.0000 - val_accuracy: 0.8123 - val_precision: 0.4565 - val_recall: 0.2308 - val_auc: 0.6903 - val_prc: 0.3738\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - tp: 96.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 302.0000 - accuracy: 0.8093 - precision: 0.5333 - recall: 0.2412 - auc: 0.7223 - prc: 0.4137 - val_loss: 0.4544 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6906 - val_prc: 0.3750\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - tp: 86.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 312.0000 - accuracy: 0.8147 - precision: 0.5772 - recall: 0.2161 - auc: 0.7216 - prc: 0.4112 - val_loss: 0.4544 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6916 - val_prc: 0.3800\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5702 - tp: 102.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 296.0000 - accuracy: 0.8108 - precision: 0.5397 - recall: 0.2563 - auc: 0.7216 - prc: 0.4102 - val_loss: 0.4549 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 70.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2308 - val_auc: 0.6902 - val_prc: 0.3741\n",
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5703 - tp: 79.0000 - fp: 55.0000 - tn: 1571.0000 - fn: 319.0000 - accuracy: 0.8152 - precision: 0.5896 - recall: 0.1985 - auc: 0.7219 - prc: 0.4177 - val_loss: 0.4460 - val_tp: 14.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 77.0000 - val_accuracy: 0.8221 - val_precision: 0.5185 - val_recall: 0.1538 - val_auc: 0.6896 - val_prc: 0.3815\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5702 - tp: 85.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 313.0000 - accuracy: 0.8152 - precision: 0.5822 - recall: 0.2136 - auc: 0.7215 - prc: 0.4071 - val_loss: 0.4630 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 65.0000 - val_accuracy: 0.8103 - val_precision: 0.4561 - val_recall: 0.2857 - val_auc: 0.6901 - val_prc: 0.3744\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5711 - tp: 95.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 303.0000 - accuracy: 0.8048 - precision: 0.5080 - recall: 0.2387 - auc: 0.7198 - prc: 0.4073 - val_loss: 0.4509 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6910 - val_prc: 0.3768\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - tp: 86.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 312.0000 - accuracy: 0.8157 - precision: 0.5850 - recall: 0.2161 - auc: 0.7221 - prc: 0.4116 - val_loss: 0.4566 - val_tp: 21.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 70.0000 - val_accuracy: 0.8103 - val_precision: 0.4468 - val_recall: 0.2308 - val_auc: 0.6902 - val_prc: 0.3719\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - tp: 95.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 303.0000 - accuracy: 0.8098 - precision: 0.5367 - recall: 0.2387 - auc: 0.7220 - prc: 0.4119 - val_loss: 0.4541 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6920 - val_prc: 0.3814\n",
      "Epoch 403/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - tp: 78.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 320.0000 - accuracy: 0.8137 - precision: 0.5778 - recall: 0.1960 - auc: 0.7206 - prc: 0.4126 - val_loss: 0.4547 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 70.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2308 - val_auc: 0.6914 - val_prc: 0.3737\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5695 - tp: 99.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 299.0000 - accuracy: 0.8088 - precision: 0.5294 - recall: 0.2487 - auc: 0.7222 - prc: 0.4129 - val_loss: 0.4568 - val_tp: 22.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 69.0000 - val_accuracy: 0.8162 - val_precision: 0.4783 - val_recall: 0.2418 - val_auc: 0.6916 - val_prc: 0.3758\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5693 - tp: 91.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 307.0000 - accuracy: 0.8152 - precision: 0.5759 - recall: 0.2286 - auc: 0.7220 - prc: 0.4113 - val_loss: 0.4511 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6910 - val_prc: 0.3776\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - tp: 93.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 305.0000 - accuracy: 0.8123 - precision: 0.5536 - recall: 0.2337 - auc: 0.7214 - prc: 0.4134 - val_loss: 0.4547 - val_tp: 20.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 71.0000 - val_accuracy: 0.8103 - val_precision: 0.4444 - val_recall: 0.2198 - val_auc: 0.6898 - val_prc: 0.3716\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - tp: 92.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 306.0000 - accuracy: 0.8103 - precision: 0.5412 - recall: 0.2312 - auc: 0.7221 - prc: 0.4144 - val_loss: 0.4532 - val_tp: 19.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 72.0000 - val_accuracy: 0.8123 - val_precision: 0.4524 - val_recall: 0.2088 - val_auc: 0.6893 - val_prc: 0.3717\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 86.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 312.0000 - accuracy: 0.8132 - precision: 0.5658 - recall: 0.2161 - auc: 0.7216 - prc: 0.4137 - val_loss: 0.4560 - val_tp: 21.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 70.0000 - val_accuracy: 0.8103 - val_precision: 0.4468 - val_recall: 0.2308 - val_auc: 0.6900 - val_prc: 0.3714\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 100.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 298.0000 - accuracy: 0.8058 - precision: 0.5128 - recall: 0.2513 - auc: 0.7233 - prc: 0.4148 - val_loss: 0.4625 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6898 - val_prc: 0.3763\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - tp: 100.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 298.0000 - accuracy: 0.8093 - precision: 0.5319 - recall: 0.2513 - auc: 0.7218 - prc: 0.4152 - val_loss: 0.4481 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 75.0000 - val_accuracy: 0.8221 - val_precision: 0.5161 - val_recall: 0.1758 - val_auc: 0.6906 - val_prc: 0.3767\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5709 - tp: 84.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 314.0000 - accuracy: 0.8172 - precision: 0.6000 - recall: 0.2111 - auc: 0.7216 - prc: 0.4134 - val_loss: 0.4581 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6895 - val_prc: 0.3712\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5697 - tp: 96.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 302.0000 - accuracy: 0.8068 - precision: 0.5189 - recall: 0.2412 - auc: 0.7207 - prc: 0.4142 - val_loss: 0.4564 - val_tp: 22.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 69.0000 - val_accuracy: 0.8083 - val_precision: 0.4400 - val_recall: 0.2418 - val_auc: 0.6903 - val_prc: 0.3730\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 96.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 302.0000 - accuracy: 0.8103 - precision: 0.5393 - recall: 0.2412 - auc: 0.7221 - prc: 0.4136 - val_loss: 0.4584 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6901 - val_prc: 0.3724\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - tp: 102.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 296.0000 - accuracy: 0.8063 - precision: 0.5152 - recall: 0.2563 - auc: 0.7217 - prc: 0.4155 - val_loss: 0.4577 - val_tp: 22.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 69.0000 - val_accuracy: 0.8083 - val_precision: 0.4400 - val_recall: 0.2418 - val_auc: 0.6889 - val_prc: 0.3722\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - tp: 90.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 308.0000 - accuracy: 0.8103 - precision: 0.5422 - recall: 0.2261 - auc: 0.7214 - prc: 0.4110 - val_loss: 0.4589 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6892 - val_prc: 0.3738\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5749 - tp: 126.0000 - fp: 138.0000 - tn: 1488.0000 - fn: 272.0000 - accuracy: 0.7974 - precision: 0.4773 - recall: 0.3166 - auc: 0.7182 - prc: 0.3969 - val_loss: 0.4622 - val_tp: 25.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 66.0000 - val_accuracy: 0.8083 - val_precision: 0.4464 - val_recall: 0.2747 - val_auc: 0.6898 - val_prc: 0.3758\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5742 - tp: 82.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 316.0000 - accuracy: 0.8118 - precision: 0.5578 - recall: 0.2060 - auc: 0.7170 - prc: 0.4104 - val_loss: 0.4498 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6896 - val_prc: 0.3813\n",
      "Epoch 418/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 101.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 297.0000 - accuracy: 0.8088 - precision: 0.5288 - recall: 0.2538 - auc: 0.7222 - prc: 0.4152 - val_loss: 0.4630 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6909 - val_prc: 0.3745\n",
      "Epoch 419/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - tp: 101.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 297.0000 - accuracy: 0.8063 - precision: 0.5153 - recall: 0.2538 - auc: 0.7220 - prc: 0.4131 - val_loss: 0.4524 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6904 - val_prc: 0.3756\n",
      "Epoch 420/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - tp: 90.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 308.0000 - accuracy: 0.8127 - precision: 0.5590 - recall: 0.2261 - auc: 0.7220 - prc: 0.4104 - val_loss: 0.4557 - val_tp: 22.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 69.0000 - val_accuracy: 0.8123 - val_precision: 0.4583 - val_recall: 0.2418 - val_auc: 0.6899 - val_prc: 0.3728\n",
      "Epoch 421/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - tp: 92.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 306.0000 - accuracy: 0.8088 - precision: 0.5318 - recall: 0.2312 - auc: 0.7223 - prc: 0.4131 - val_loss: 0.4568 - val_tp: 22.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 69.0000 - val_accuracy: 0.8063 - val_precision: 0.4314 - val_recall: 0.2418 - val_auc: 0.6898 - val_prc: 0.3718\n",
      "Epoch 422/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5691 - tp: 97.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 301.0000 - accuracy: 0.8078 - precision: 0.5243 - recall: 0.2437 - auc: 0.7215 - prc: 0.4143 - val_loss: 0.4558 - val_tp: 22.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 69.0000 - val_accuracy: 0.8123 - val_precision: 0.4583 - val_recall: 0.2418 - val_auc: 0.6906 - val_prc: 0.3734\n",
      "Epoch 423/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - tp: 98.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 300.0000 - accuracy: 0.8078 - precision: 0.5241 - recall: 0.2462 - auc: 0.7224 - prc: 0.4123 - val_loss: 0.4569 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6903 - val_prc: 0.3724\n",
      "Epoch 424/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5693 - tp: 91.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 307.0000 - accuracy: 0.8113 - precision: 0.5482 - recall: 0.2286 - auc: 0.7213 - prc: 0.4052 - val_loss: 0.4555 - val_tp: 22.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 69.0000 - val_accuracy: 0.8123 - val_precision: 0.4583 - val_recall: 0.2418 - val_auc: 0.6902 - val_prc: 0.3772\n",
      "Epoch 425/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - tp: 99.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 299.0000 - accuracy: 0.8083 - precision: 0.5266 - recall: 0.2487 - auc: 0.7216 - prc: 0.4127 - val_loss: 0.4560 - val_tp: 22.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 69.0000 - val_accuracy: 0.8182 - val_precision: 0.4889 - val_recall: 0.2418 - val_auc: 0.6912 - val_prc: 0.3781\n",
      "Epoch 426/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - tp: 95.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 303.0000 - accuracy: 0.8103 - precision: 0.5398 - recall: 0.2387 - auc: 0.7222 - prc: 0.4151 - val_loss: 0.4561 - val_tp: 21.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 70.0000 - val_accuracy: 0.8162 - val_precision: 0.4773 - val_recall: 0.2308 - val_auc: 0.6920 - val_prc: 0.3784\n",
      "Epoch 427/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5695 - tp: 99.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 299.0000 - accuracy: 0.8078 - precision: 0.5238 - recall: 0.2487 - auc: 0.7211 - prc: 0.4111 - val_loss: 0.4538 - val_tp: 20.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 71.0000 - val_accuracy: 0.8123 - val_precision: 0.4545 - val_recall: 0.2198 - val_auc: 0.6899 - val_prc: 0.3822\n",
      "Epoch 428/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 89.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 309.0000 - accuracy: 0.8142 - precision: 0.5705 - recall: 0.2236 - auc: 0.7210 - prc: 0.4120 - val_loss: 0.4573 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6894 - val_prc: 0.3715\n",
      "Epoch 429/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5703 - tp: 113.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 285.0000 - accuracy: 0.8043 - precision: 0.5045 - recall: 0.2839 - auc: 0.7218 - prc: 0.4101 - val_loss: 0.4608 - val_tp: 25.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 66.0000 - val_accuracy: 0.8083 - val_precision: 0.4464 - val_recall: 0.2747 - val_auc: 0.6896 - val_prc: 0.3736\n",
      "Epoch 430/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5705 - tp: 87.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 311.0000 - accuracy: 0.8083 - precision: 0.5305 - recall: 0.2186 - auc: 0.7202 - prc: 0.4128 - val_loss: 0.4521 - val_tp: 19.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 72.0000 - val_accuracy: 0.8162 - val_precision: 0.4750 - val_recall: 0.2088 - val_auc: 0.6907 - val_prc: 0.3827\n",
      "Epoch 431/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 100.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 298.0000 - accuracy: 0.8058 - precision: 0.5128 - recall: 0.2513 - auc: 0.7221 - prc: 0.4125 - val_loss: 0.4587 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6912 - val_prc: 0.3730\n",
      "Epoch 432/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 95.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 303.0000 - accuracy: 0.8132 - precision: 0.5588 - recall: 0.2387 - auc: 0.7222 - prc: 0.4132 - val_loss: 0.4523 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6904 - val_prc: 0.3767\n",
      "Epoch 433/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 96.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 302.0000 - accuracy: 0.8108 - precision: 0.5424 - recall: 0.2412 - auc: 0.7224 - prc: 0.4139 - val_loss: 0.4571 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6901 - val_prc: 0.3730\n",
      "Epoch 434/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - tp: 95.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 303.0000 - accuracy: 0.8103 - precision: 0.5398 - recall: 0.2387 - auc: 0.7223 - prc: 0.4109 - val_loss: 0.4546 - val_tp: 20.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 71.0000 - val_accuracy: 0.8103 - val_precision: 0.4444 - val_recall: 0.2198 - val_auc: 0.6908 - val_prc: 0.3775\n",
      "Epoch 435/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - tp: 103.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 295.0000 - accuracy: 0.8068 - precision: 0.5176 - recall: 0.2588 - auc: 0.7226 - prc: 0.4151 - val_loss: 0.4565 - val_tp: 23.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 68.0000 - val_accuracy: 0.8142 - val_precision: 0.4694 - val_recall: 0.2527 - val_auc: 0.6910 - val_prc: 0.3731\n",
      "Epoch 436/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 89.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 309.0000 - accuracy: 0.8123 - precision: 0.5562 - recall: 0.2236 - auc: 0.7219 - prc: 0.4144 - val_loss: 0.4521 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6901 - val_prc: 0.3766\n",
      "Epoch 437/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5684 - tp: 94.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 304.0000 - accuracy: 0.8103 - precision: 0.5402 - recall: 0.2362 - auc: 0.7228 - prc: 0.4136 - val_loss: 0.4621 - val_tp: 28.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 63.0000 - val_accuracy: 0.8083 - val_precision: 0.4516 - val_recall: 0.3077 - val_auc: 0.6913 - val_prc: 0.3752\n",
      "Epoch 438/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 106.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 292.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.2663 - auc: 0.7221 - prc: 0.4140 - val_loss: 0.4506 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6912 - val_prc: 0.3723\n",
      "Epoch 439/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5715 - tp: 79.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 319.0000 - accuracy: 0.8137 - precision: 0.5766 - recall: 0.1985 - auc: 0.7203 - prc: 0.4161 - val_loss: 0.4580 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6906 - val_prc: 0.3710\n",
      "Epoch 440/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 116.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 282.0000 - accuracy: 0.8014 - precision: 0.4915 - recall: 0.2915 - auc: 0.7227 - prc: 0.4135 - val_loss: 0.4623 - val_tp: 26.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 65.0000 - val_accuracy: 0.8083 - val_precision: 0.4483 - val_recall: 0.2857 - val_auc: 0.6894 - val_prc: 0.3733\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 96.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 302.0000 - accuracy: 0.8073 - precision: 0.5217 - recall: 0.2412 - auc: 0.7221 - prc: 0.4117 - val_loss: 0.4511 - val_tp: 20.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 71.0000 - val_accuracy: 0.8162 - val_precision: 0.4762 - val_recall: 0.2198 - val_auc: 0.6907 - val_prc: 0.3817\n",
      "Epoch 442/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5687 - tp: 94.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 304.0000 - accuracy: 0.8093 - precision: 0.5341 - recall: 0.2362 - auc: 0.7223 - prc: 0.4113 - val_loss: 0.4552 - val_tp: 22.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 69.0000 - val_accuracy: 0.8063 - val_precision: 0.4314 - val_recall: 0.2418 - val_auc: 0.6913 - val_prc: 0.3718\n",
      "Epoch 443/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5695 - tp: 102.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 296.0000 - accuracy: 0.8078 - precision: 0.5231 - recall: 0.2563 - auc: 0.7211 - prc: 0.4121 - val_loss: 0.4566 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6925 - val_prc: 0.3819\n",
      "Epoch 444/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - tp: 92.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 306.0000 - accuracy: 0.8137 - precision: 0.5644 - recall: 0.2312 - auc: 0.7225 - prc: 0.4182 - val_loss: 0.4507 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6911 - val_prc: 0.3786\n",
      "Epoch 445/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5697 - tp: 103.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 295.0000 - accuracy: 0.8063 - precision: 0.5150 - recall: 0.2588 - auc: 0.7210 - prc: 0.4122 - val_loss: 0.4541 - val_tp: 22.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 69.0000 - val_accuracy: 0.8142 - val_precision: 0.4681 - val_recall: 0.2418 - val_auc: 0.6914 - val_prc: 0.3796\n",
      "Epoch 446/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - tp: 81.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 317.0000 - accuracy: 0.8123 - precision: 0.5625 - recall: 0.2035 - auc: 0.7233 - prc: 0.4177 - val_loss: 0.4499 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6905 - val_prc: 0.3770\n",
      "Epoch 447/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5693 - tp: 108.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 290.0000 - accuracy: 0.8053 - precision: 0.5094 - recall: 0.2714 - auc: 0.7214 - prc: 0.4105 - val_loss: 0.4646 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6902 - val_prc: 0.3756\n",
      "Epoch 448/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - tp: 113.0000 - fp: 108.0000 - tn: 1518.0000 - fn: 285.0000 - accuracy: 0.8058 - precision: 0.5113 - recall: 0.2839 - auc: 0.7224 - prc: 0.4152 - val_loss: 0.4540 - val_tp: 22.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 69.0000 - val_accuracy: 0.8103 - val_precision: 0.4490 - val_recall: 0.2418 - val_auc: 0.6918 - val_prc: 0.3780\n",
      "Epoch 449/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 92.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 306.0000 - accuracy: 0.8123 - precision: 0.5542 - recall: 0.2312 - auc: 0.7218 - prc: 0.4157 - val_loss: 0.4511 - val_tp: 20.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 71.0000 - val_accuracy: 0.8162 - val_precision: 0.4762 - val_recall: 0.2198 - val_auc: 0.6903 - val_prc: 0.3823\n",
      "Epoch 450/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - tp: 92.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 306.0000 - accuracy: 0.8113 - precision: 0.5476 - recall: 0.2312 - auc: 0.7221 - prc: 0.4126 - val_loss: 0.4527 - val_tp: 22.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 69.0000 - val_accuracy: 0.8083 - val_precision: 0.4400 - val_recall: 0.2418 - val_auc: 0.6903 - val_prc: 0.3813\n",
      "Epoch 451/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 98.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 300.0000 - accuracy: 0.8093 - precision: 0.5326 - recall: 0.2462 - auc: 0.7213 - prc: 0.4137 - val_loss: 0.4606 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6901 - val_prc: 0.3747\n",
      "Epoch 452/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5713 - tp: 122.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 276.0000 - accuracy: 0.8029 - precision: 0.4980 - recall: 0.3065 - auc: 0.7203 - prc: 0.4141 - val_loss: 0.4544 - val_tp: 22.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 69.0000 - val_accuracy: 0.8083 - val_precision: 0.4400 - val_recall: 0.2418 - val_auc: 0.6905 - val_prc: 0.3824\n",
      "Epoch 453/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5702 - tp: 85.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 313.0000 - accuracy: 0.8123 - precision: 0.5592 - recall: 0.2136 - auc: 0.7214 - prc: 0.4160 - val_loss: 0.4568 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6901 - val_prc: 0.3723\n",
      "Epoch 454/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5734 - tp: 128.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 270.0000 - accuracy: 0.8029 - precision: 0.4981 - recall: 0.3216 - auc: 0.7196 - prc: 0.4046 - val_loss: 0.4655 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6901 - val_prc: 0.3752\n",
      "Epoch 455/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 100.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 298.0000 - accuracy: 0.8058 - precision: 0.5128 - recall: 0.2513 - auc: 0.7193 - prc: 0.4071 - val_loss: 0.4581 - val_tp: 24.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 67.0000 - val_accuracy: 0.8063 - val_precision: 0.4364 - val_recall: 0.2637 - val_auc: 0.6900 - val_prc: 0.3730\n",
      "Epoch 456/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - tp: 95.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 303.0000 - accuracy: 0.8029 - precision: 0.4974 - recall: 0.2387 - auc: 0.7208 - prc: 0.4122 - val_loss: 0.4557 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6893 - val_prc: 0.3772\n",
      "Epoch 457/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - tp: 112.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 286.0000 - accuracy: 0.8058 - precision: 0.5114 - recall: 0.2814 - auc: 0.7209 - prc: 0.4130 - val_loss: 0.4530 - val_tp: 21.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 70.0000 - val_accuracy: 0.8123 - val_precision: 0.4565 - val_recall: 0.2308 - val_auc: 0.6907 - val_prc: 0.3834\n",
      "Epoch 458/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5715 - tp: 82.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 316.0000 - accuracy: 0.8147 - precision: 0.5816 - recall: 0.2060 - auc: 0.7200 - prc: 0.4175 - val_loss: 0.4536 - val_tp: 21.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 70.0000 - val_accuracy: 0.8103 - val_precision: 0.4468 - val_recall: 0.2308 - val_auc: 0.6901 - val_prc: 0.3779\n",
      "Epoch 459/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5677 - tp: 103.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 295.0000 - accuracy: 0.8063 - precision: 0.5150 - recall: 0.2588 - auc: 0.7239 - prc: 0.4168 - val_loss: 0.4640 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6910 - val_prc: 0.3760\n",
      "Epoch 460/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 103.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 295.0000 - accuracy: 0.8098 - precision: 0.5337 - recall: 0.2588 - auc: 0.7216 - prc: 0.4140 - val_loss: 0.4462 - val_tp: 18.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 73.0000 - val_accuracy: 0.8261 - val_precision: 0.5455 - val_recall: 0.1978 - val_auc: 0.6901 - val_prc: 0.3877\n",
      "Epoch 461/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - tp: 87.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 311.0000 - accuracy: 0.8123 - precision: 0.5577 - recall: 0.2186 - auc: 0.7226 - prc: 0.4176 - val_loss: 0.4613 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6905 - val_prc: 0.3755\n",
      "Epoch 462/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5711 - tp: 110.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 288.0000 - accuracy: 0.8024 - precision: 0.4955 - recall: 0.2764 - auc: 0.7189 - prc: 0.4118 - val_loss: 0.4566 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6914 - val_prc: 0.3785\n",
      "Epoch 463/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 92.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 306.0000 - accuracy: 0.8142 - precision: 0.5679 - recall: 0.2312 - auc: 0.7219 - prc: 0.4141 - val_loss: 0.4550 - val_tp: 22.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 69.0000 - val_accuracy: 0.8123 - val_precision: 0.4583 - val_recall: 0.2418 - val_auc: 0.6917 - val_prc: 0.3791\n",
      "Epoch 464/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5691 - tp: 112.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 286.0000 - accuracy: 0.8068 - precision: 0.5161 - recall: 0.2814 - auc: 0.7219 - prc: 0.4090 - val_loss: 0.4579 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6913 - val_prc: 0.3780\n",
      "Epoch 465/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - tp: 92.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 306.0000 - accuracy: 0.8132 - precision: 0.5610 - recall: 0.2312 - auc: 0.7200 - prc: 0.4061 - val_loss: 0.4528 - val_tp: 21.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 70.0000 - val_accuracy: 0.8103 - val_precision: 0.4468 - val_recall: 0.2308 - val_auc: 0.6907 - val_prc: 0.3826\n",
      "Epoch 466/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 111.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 287.0000 - accuracy: 0.8058 - precision: 0.5115 - recall: 0.2789 - auc: 0.7229 - prc: 0.4147 - val_loss: 0.4615 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6903 - val_prc: 0.3728\n",
      "Epoch 467/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - tp: 88.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 310.0000 - accuracy: 0.8147 - precision: 0.5752 - recall: 0.2211 - auc: 0.7203 - prc: 0.4172 - val_loss: 0.4480 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 72.0000 - val_accuracy: 0.8241 - val_precision: 0.5278 - val_recall: 0.2088 - val_auc: 0.6907 - val_prc: 0.3841\n",
      "Epoch 468/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5685 - tp: 98.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 300.0000 - accuracy: 0.8118 - precision: 0.5475 - recall: 0.2462 - auc: 0.7220 - prc: 0.4109 - val_loss: 0.4563 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6909 - val_prc: 0.3784\n",
      "Epoch 469/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 90.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 308.0000 - accuracy: 0.8118 - precision: 0.5521 - recall: 0.2261 - auc: 0.7215 - prc: 0.4131 - val_loss: 0.4524 - val_tp: 21.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 70.0000 - val_accuracy: 0.8123 - val_precision: 0.4565 - val_recall: 0.2308 - val_auc: 0.6909 - val_prc: 0.3838\n",
      "Epoch 470/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 102.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 296.0000 - accuracy: 0.8088 - precision: 0.5285 - recall: 0.2563 - auc: 0.7213 - prc: 0.4158 - val_loss: 0.4523 - val_tp: 21.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 70.0000 - val_accuracy: 0.8162 - val_precision: 0.4773 - val_recall: 0.2308 - val_auc: 0.6918 - val_prc: 0.3814\n",
      "Epoch 471/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5705 - tp: 86.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 312.0000 - accuracy: 0.8177 - precision: 0.6014 - recall: 0.2161 - auc: 0.7211 - prc: 0.4196 - val_loss: 0.4532 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6918 - val_prc: 0.3783\n",
      "Epoch 472/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - tp: 108.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 290.0000 - accuracy: 0.8078 - precision: 0.5217 - recall: 0.2714 - auc: 0.7227 - prc: 0.4168 - val_loss: 0.4593 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6912 - val_prc: 0.3722\n",
      "Epoch 473/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - tp: 90.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 308.0000 - accuracy: 0.8113 - precision: 0.5488 - recall: 0.2261 - auc: 0.7202 - prc: 0.4161 - val_loss: 0.4524 - val_tp: 21.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 70.0000 - val_accuracy: 0.8123 - val_precision: 0.4565 - val_recall: 0.2308 - val_auc: 0.6910 - val_prc: 0.3834\n",
      "Epoch 474/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5681 - tp: 107.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 291.0000 - accuracy: 0.8073 - precision: 0.5194 - recall: 0.2688 - auc: 0.7224 - prc: 0.4152 - val_loss: 0.4635 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6904 - val_prc: 0.3755\n",
      "Epoch 475/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5680 - tp: 110.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 288.0000 - accuracy: 0.8068 - precision: 0.5164 - recall: 0.2764 - auc: 0.7229 - prc: 0.4159 - val_loss: 0.4516 - val_tp: 21.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 70.0000 - val_accuracy: 0.8162 - val_precision: 0.4773 - val_recall: 0.2308 - val_auc: 0.6911 - val_prc: 0.3832\n",
      "Epoch 476/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - tp: 94.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 304.0000 - accuracy: 0.8147 - precision: 0.5697 - recall: 0.2362 - auc: 0.7219 - prc: 0.4197 - val_loss: 0.4569 - val_tp: 25.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 66.0000 - val_accuracy: 0.8103 - val_precision: 0.4545 - val_recall: 0.2747 - val_auc: 0.6909 - val_prc: 0.3793\n",
      "Epoch 477/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 112.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 286.0000 - accuracy: 0.8073 - precision: 0.5185 - recall: 0.2814 - auc: 0.7221 - prc: 0.4147 - val_loss: 0.4596 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6904 - val_prc: 0.3732\n",
      "Epoch 478/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - tp: 113.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 285.0000 - accuracy: 0.8078 - precision: 0.5207 - recall: 0.2839 - auc: 0.7217 - prc: 0.4151 - val_loss: 0.4516 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 70.0000 - val_accuracy: 0.8182 - val_precision: 0.4884 - val_recall: 0.2308 - val_auc: 0.6912 - val_prc: 0.3761\n",
      "Epoch 479/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - tp: 88.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 310.0000 - accuracy: 0.8137 - precision: 0.5677 - recall: 0.2211 - auc: 0.7214 - prc: 0.4216 - val_loss: 0.4579 - val_tp: 24.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 67.0000 - val_accuracy: 0.8083 - val_precision: 0.4444 - val_recall: 0.2637 - val_auc: 0.6914 - val_prc: 0.3789\n",
      "Epoch 480/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5686 - tp: 114.0000 - fp: 109.0000 - tn: 1517.0000 - fn: 284.0000 - accuracy: 0.8058 - precision: 0.5112 - recall: 0.2864 - auc: 0.7230 - prc: 0.4171 - val_loss: 0.4609 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6905 - val_prc: 0.3736\n",
      "Epoch 481/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - tp: 103.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 295.0000 - accuracy: 0.8088 - precision: 0.5282 - recall: 0.2588 - auc: 0.7210 - prc: 0.4161 - val_loss: 0.4513 - val_tp: 21.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 70.0000 - val_accuracy: 0.8123 - val_precision: 0.4565 - val_recall: 0.2308 - val_auc: 0.6904 - val_prc: 0.3867\n",
      "Epoch 482/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5683 - tp: 97.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 301.0000 - accuracy: 0.8073 - precision: 0.5215 - recall: 0.2437 - auc: 0.7226 - prc: 0.4140 - val_loss: 0.4647 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6903 - val_prc: 0.3761\n",
      "Epoch 483/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5684 - tp: 108.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 290.0000 - accuracy: 0.8058 - precision: 0.5118 - recall: 0.2714 - auc: 0.7224 - prc: 0.4113 - val_loss: 0.4520 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 70.0000 - val_accuracy: 0.8182 - val_precision: 0.4884 - val_recall: 0.2308 - val_auc: 0.6906 - val_prc: 0.3812\n",
      "Epoch 484/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - tp: 90.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 308.0000 - accuracy: 0.8152 - precision: 0.5769 - recall: 0.2261 - auc: 0.7216 - prc: 0.4225 - val_loss: 0.4552 - val_tp: 22.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 69.0000 - val_accuracy: 0.8063 - val_precision: 0.4314 - val_recall: 0.2418 - val_auc: 0.6921 - val_prc: 0.3782\n",
      "Epoch 485/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - tp: 116.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 282.0000 - accuracy: 0.8043 - precision: 0.5043 - recall: 0.2915 - auc: 0.7219 - prc: 0.4150 - val_loss: 0.4566 - val_tp: 24.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 67.0000 - val_accuracy: 0.8103 - val_precision: 0.4528 - val_recall: 0.2637 - val_auc: 0.6912 - val_prc: 0.3783\n",
      "Epoch 486/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5706 - tp: 82.0000 - fp: 60.0000 - tn: 1566.0000 - fn: 316.0000 - accuracy: 0.8142 - precision: 0.5775 - recall: 0.2060 - auc: 0.7213 - prc: 0.4218 - val_loss: 0.4468 - val_tp: 18.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 73.0000 - val_accuracy: 0.8261 - val_precision: 0.5455 - val_recall: 0.1978 - val_auc: 0.6907 - val_prc: 0.3859\n",
      "Epoch 487/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5676 - tp: 97.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 301.0000 - accuracy: 0.8083 - precision: 0.5272 - recall: 0.2437 - auc: 0.7232 - prc: 0.4152 - val_loss: 0.4613 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6911 - val_prc: 0.3742\n",
      "Epoch 488/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5686 - tp: 111.0000 - fp: 109.0000 - tn: 1517.0000 - fn: 287.0000 - accuracy: 0.8043 - precision: 0.5045 - recall: 0.2789 - auc: 0.7225 - prc: 0.4159 - val_loss: 0.4497 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 70.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2308 - val_auc: 0.6907 - val_prc: 0.3909\n",
      "Epoch 489/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5721 - tp: 80.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 318.0000 - accuracy: 0.8152 - precision: 0.5882 - recall: 0.2010 - auc: 0.7202 - prc: 0.4218 - val_loss: 0.4522 - val_tp: 21.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 70.0000 - val_accuracy: 0.8103 - val_precision: 0.4468 - val_recall: 0.2308 - val_auc: 0.6910 - val_prc: 0.3894\n",
      "Epoch 490/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5686 - tp: 109.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 289.0000 - accuracy: 0.8068 - precision: 0.5166 - recall: 0.2739 - auc: 0.7214 - prc: 0.4153 - val_loss: 0.4594 - val_tp: 25.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 66.0000 - val_accuracy: 0.8083 - val_precision: 0.4464 - val_recall: 0.2747 - val_auc: 0.6914 - val_prc: 0.3791\n",
      "Epoch 491/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5679 - tp: 103.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 295.0000 - accuracy: 0.8088 - precision: 0.5282 - recall: 0.2588 - auc: 0.7224 - prc: 0.4152 - val_loss: 0.4571 - val_tp: 24.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 67.0000 - val_accuracy: 0.8083 - val_precision: 0.4444 - val_recall: 0.2637 - val_auc: 0.6917 - val_prc: 0.3793\n",
      "Epoch 492/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5681 - tp: 97.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 301.0000 - accuracy: 0.8103 - precision: 0.5389 - recall: 0.2437 - auc: 0.7217 - prc: 0.4077 - val_loss: 0.4542 - val_tp: 22.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 69.0000 - val_accuracy: 0.8142 - val_precision: 0.4681 - val_recall: 0.2418 - val_auc: 0.6909 - val_prc: 0.3786\n",
      "Epoch 493/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5678 - tp: 94.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 304.0000 - accuracy: 0.8108 - precision: 0.5434 - recall: 0.2362 - auc: 0.7228 - prc: 0.4169 - val_loss: 0.4516 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6911 - val_prc: 0.3822\n",
      "Epoch 494/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5677 - tp: 95.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 303.0000 - accuracy: 0.8108 - precision: 0.5429 - recall: 0.2387 - auc: 0.7226 - prc: 0.4180 - val_loss: 0.4574 - val_tp: 23.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 68.0000 - val_accuracy: 0.8043 - val_precision: 0.4259 - val_recall: 0.2527 - val_auc: 0.6912 - val_prc: 0.3840\n",
      "Epoch 495/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - tp: 107.0000 - fp: 98.0000 - tn: 1528.0000 - fn: 291.0000 - accuracy: 0.8078 - precision: 0.5220 - recall: 0.2688 - auc: 0.7209 - prc: 0.4134 - val_loss: 0.4510 - val_tp: 21.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 70.0000 - val_accuracy: 0.8142 - val_precision: 0.4667 - val_recall: 0.2308 - val_auc: 0.6909 - val_prc: 0.3890\n",
      "Epoch 496/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5680 - tp: 95.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 303.0000 - accuracy: 0.8118 - precision: 0.5491 - recall: 0.2387 - auc: 0.7226 - prc: 0.4205 - val_loss: 0.4539 - val_tp: 22.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 69.0000 - val_accuracy: 0.8063 - val_precision: 0.4314 - val_recall: 0.2418 - val_auc: 0.6905 - val_prc: 0.3798\n",
      "Epoch 497/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5674 - tp: 98.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 300.0000 - accuracy: 0.8098 - precision: 0.5355 - recall: 0.2462 - auc: 0.7234 - prc: 0.4184 - val_loss: 0.4630 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6908 - val_prc: 0.3732\n",
      "Epoch 498/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - tp: 119.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 279.0000 - accuracy: 0.8039 - precision: 0.5021 - recall: 0.2990 - auc: 0.7211 - prc: 0.4137 - val_loss: 0.4534 - val_tp: 23.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 68.0000 - val_accuracy: 0.8103 - val_precision: 0.4510 - val_recall: 0.2527 - val_auc: 0.6906 - val_prc: 0.3830\n",
      "Epoch 499/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - tp: 92.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 306.0000 - accuracy: 0.8127 - precision: 0.5576 - recall: 0.2312 - auc: 0.7224 - prc: 0.4210 - val_loss: 0.4493 - val_tp: 21.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 70.0000 - val_accuracy: 0.8182 - val_precision: 0.4884 - val_recall: 0.2308 - val_auc: 0.6909 - val_prc: 0.3902\n",
      "Epoch 500/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5691 - tp: 90.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 308.0000 - accuracy: 0.8132 - precision: 0.5625 - recall: 0.2261 - auc: 0.7222 - prc: 0.4264 - val_loss: 0.4552 - val_tp: 23.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 68.0000 - val_accuracy: 0.8083 - val_precision: 0.4423 - val_recall: 0.2527 - val_auc: 0.6908 - val_prc: 0.3832\n",
      "3/3 [==============================] - 0s 894us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.8314 - tp: 23.0000 - fp: 29.0000 - tn: 2012.0000 - fn: 466.0000 - accuracy: 0.8043 - precision: 0.4423 - recall: 0.0470 - auc: 0.4899 - prc: 0.2236 - val_loss: 0.4719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4166 - val_prc: 0.1530\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8237 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4458 - prc: 0.1731 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4812 - val_prc: 0.1711\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8173 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4806 - prc: 0.1874 - val_loss: 0.4724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4993 - val_prc: 0.1796\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8125 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5029 - prc: 0.2008 - val_loss: 0.4726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4966 - val_prc: 0.1788\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8105 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5030 - prc: 0.1976 - val_loss: 0.4728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8089 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8074 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8061 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5071 - prc: 0.1990 - val_loss: 0.4736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8033 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4741 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8020 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4737 - prc: 0.1871 - val_loss: 0.4744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8008 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7995 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7982 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5034 - prc: 0.1983 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7957 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4893 - prc: 0.1887 - val_loss: 0.4764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7925 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4772 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7913 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4776 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7901 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4780 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7891 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7880 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7872 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4889 - prc: 0.1922 - val_loss: 0.4793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7862 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7852 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4802 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7842 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5197 - prc: 0.2097 - val_loss: 0.4807 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7832 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4812 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7814 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7799 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7782 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5051 - prc: 0.1989 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7775 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7767 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4852 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7761 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5069 - prc: 0.1991 - val_loss: 0.4861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4866 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7743 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4871 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7736 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005 - val_prc: 0.1800\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1971 - val_loss: 0.4883 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7724 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4888 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7719 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7713 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007 - prc: 0.1977 - val_loss: 0.4898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7708 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.4904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7702 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4910 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7697 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4916 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5190 - prc: 0.2060 - val_loss: 0.4922 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4928 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4936 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7676 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4942 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7671 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4948 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7667 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4953 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7663 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4958 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4964 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7657 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - prc: 0.1915 - val_loss: 0.4968 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7653 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4973 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7650 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4978 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7647 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4983 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7644 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4989 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7641 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5068 - prc: 0.1999 - val_loss: 0.4993 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7639 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7636 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5005 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7633 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5011 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7630 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5015 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7628 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4980 - prc: 0.1958 - val_loss: 0.5019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7626 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5025 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7623 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5030 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 70/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7621 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5035 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7619 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5040 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7617 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5017 - prc: 0.1976 - val_loss: 0.5045 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7615 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5050 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7613 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7612 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7610 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7609 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5068 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7607 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4882 - prc: 0.1916 - val_loss: 0.5074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7605 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5078 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7604 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7602 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5086 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7602 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5091 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7600 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7599 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5099 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7598 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4974 - prc: 0.1958 - val_loss: 0.5102 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7597 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7596 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7595 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7594 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5115 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7593 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7592 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7592 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7591 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - prc: 0.1969 - val_loss: 0.5130 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5135 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 95/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7756 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 159.0000 - fn: 41.0000 - accuracy: 0.7950 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.2050Restoring model weights from the end of the best epoch: 45.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5139 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 95: early stopping\n",
      "3/3 [==============================] - 0s 932us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.9988 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4545 - prc: 0.1787 - val_loss: 0.4719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4100 - val_prc: 0.1513\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9869 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4587 - prc: 0.1787 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4806 - val_prc: 0.1709\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4767 - prc: 0.1861 - val_loss: 0.4724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9705 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4974 - prc: 0.1950 - val_loss: 0.4726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5041 - val_prc: 0.1811\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9674 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4990 - prc: 0.1963 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9651 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9627 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4952 - prc: 0.1930 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9605 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9584 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9562 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - prc: 0.1973 - val_loss: 0.4742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9541 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9520 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9500 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9479 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4977 - prc: 0.1959 - val_loss: 0.4756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9458 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9438 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9418 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4772 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9380 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4776 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9361 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5008 - prc: 0.1969 - val_loss: 0.4780 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9342 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4785 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9323 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9303 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4796 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9283 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9266 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5067 - prc: 0.2080 - val_loss: 0.4806 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9248 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4812 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9230 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9214 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - prc: 0.1973 - val_loss: 0.4822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9199 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4828 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9183 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9167 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5051 - prc: 0.2050 - val_loss: 0.4840 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9151 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9135 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4853 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9119 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4994 - prc: 0.1963 - val_loss: 0.4860 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9087 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9072 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4935 - prc: 0.1938 - val_loss: 0.4881 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9058 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4887 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9045 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9032 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5046 - prc: 0.1989 - val_loss: 0.4901 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9020 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4907 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9008 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8997 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1978 - val_loss: 0.4921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4928 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8974 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4940 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8954 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4796 - prc: 0.1892 - val_loss: 0.4947 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4954 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8933 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4962 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8922 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - prc: 0.1969 - val_loss: 0.4969 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8911 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4977 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8901 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4984 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8892 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1951 - val_loss: 0.4992 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.8840 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 161.0000 - fn: 39.0000 - accuracy: 0.8050 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5031 - prc: 0.1960Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8883 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54: early stopping\n",
      "3/3 [==============================] - 0s 953us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.1659 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4391 - prc: 0.1750 - val_loss: 0.4719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4386 - val_prc: 0.1636\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1503 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4533 - prc: 0.1770 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4824 - val_prc: 0.1772\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1374 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5075 - prc: 0.2000 - val_loss: 0.4725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1281 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4975 - prc: 0.1953 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1243 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4994 - prc: 0.1964 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1212 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1181 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - prc: 0.1955 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1151 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1121 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1092 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4810 - prc: 0.1854 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1062 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1033 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1951 - val_loss: 0.4752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0980 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0951 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0923 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - prc: 0.1973 - val_loss: 0.4764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0894 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0867 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0838 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5140 - prc: 0.2083 - val_loss: 0.4777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4782 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0786 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0759 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5197 - prc: 0.2097 - val_loss: 0.4792 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0732 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0707 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4802 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5023 - prc: 0.1979 - val_loss: 0.4807 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0658 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4813 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0634 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4818 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0609 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5114 - prc: 0.2029 - val_loss: 0.4824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0587 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0564 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4836 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0539 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4825 - prc: 0.1892 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0516 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0492 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0469 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5144 - prc: 0.2021 - val_loss: 0.4863 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0423 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5108 - prc: 0.2003 - val_loss: 0.4884 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0381 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0362 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0343 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4977 - prc: 0.1959 - val_loss: 0.4904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0325 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4911 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4918 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0287 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4873 - prc: 0.1922 - val_loss: 0.4926 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0251 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4941 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0233 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4923 - prc: 0.1939 - val_loss: 0.4949 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0214 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4958 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0196 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0177 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.4974 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4982 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0144 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4991 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5008 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.0389 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 159.0000 - fn: 41.0000 - accuracy: 0.7950 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.2050Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0096 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.3326 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4593 - prc: 0.1802 - val_loss: 0.4719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4416 - val_prc: 0.1645\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3139 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4525 - prc: 0.1786 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4934 - val_prc: 0.1803\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2979 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4680 - prc: 0.1834 - val_loss: 0.4725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4969 - prc: 0.1947 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2815 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4844 - prc: 0.1873 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2700 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2660 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2621 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5041 - prc: 0.1992 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2583 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2545 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2507 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5042 - prc: 0.1989 - val_loss: 0.4753 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2472 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4757 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2435 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2397 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4890 - prc: 0.1915 - val_loss: 0.4766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2361 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2324 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2289 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4945 - prc: 0.1945 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2253 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2219 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2186 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4776 - prc: 0.1889 - val_loss: 0.4794 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2152 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2120 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2088 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4920 - prc: 0.1938 - val_loss: 0.4810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2055 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4828 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1957 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1925 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5041 - prc: 0.1992 - val_loss: 0.4841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1835 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4874 - prc: 0.1908 - val_loss: 0.4861 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1805 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1778 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1747 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5088 - prc: 0.2005 - val_loss: 0.4882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1719 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1662 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5135 - prc: 0.2015 - val_loss: 0.4904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1635 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4912 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1607 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - prc: 0.1973 - val_loss: 0.4920 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1580 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4928 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1554 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4936 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1528 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5028 - prc: 0.1984 - val_loss: 0.4945 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1502 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4953 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1476 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4962 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5034 - prc: 0.1983 - val_loss: 0.4970 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1426 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4979 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4988 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1378 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5136 - prc: 0.2022 - val_loss: 0.4997 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1356 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5005 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1334 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5014 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4834 - prc: 0.1905 - val_loss: 0.5023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.1233 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 161.0000 - fn: 39.0000 - accuracy: 0.8050 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5031 - prc: 0.1960Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1291 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54: early stopping\n",
      "3/3 [==============================] - 0s 964us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.5000 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4557 - prc: 0.1788 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4355 - val_prc: 0.1627\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4467 - prc: 0.1735 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4934 - val_prc: 0.1803\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4585 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4677 - prc: 0.1831 - val_loss: 0.4725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4444 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4859 - prc: 0.1881 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.4385 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997 - prc: 0.1965 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4336 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4732 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4287 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5136 - prc: 0.2042 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4240 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4192 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4148 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4880 - prc: 0.1903 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4057 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4010 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5062 - prc: 0.1996 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3965 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3922 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4762 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3878 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5345 - prc: 0.2124 - val_loss: 0.4766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3835 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3749 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4958 - prc: 0.1950 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3706 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3663 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3620 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5138 - prc: 0.2016 - val_loss: 0.4795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3577 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4800 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3536 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4805 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3497 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3458 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3419 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5051 - prc: 0.2050 - val_loss: 0.4822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3379 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4829 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3339 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4835 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3300 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5036 - prc: 0.1986 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3261 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3222 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3183 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4843 - prc: 0.1909 - val_loss: 0.4863 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3147 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4869 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3111 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3076 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4852 - prc: 0.1918 - val_loss: 0.4884 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3040 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3007 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2973 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4906 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4913 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2907 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4905 - prc: 0.1896 - val_loss: 0.4921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2873 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4929 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2841 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4937 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2810 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4916 - prc: 0.1915 - val_loss: 0.4945 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2778 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4953 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2746 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4962 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2714 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5031 - prc: 0.1981 - val_loss: 0.4971 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4980 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2652 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4989 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2621 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5175 - prc: 0.2033 - val_loss: 0.4997 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2593 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5006 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2564 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5016 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2536 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5024 - prc: 0.1974 - val_loss: 0.5025 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.3371 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 157.0000 - fn: 43.0000 - accuracy: 0.7850 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.2150Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2507 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5035 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.6674 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4487 - prc: 0.1769 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4428 - val_prc: 0.1648\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6405 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4732 - prc: 0.1855 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4868 - val_prc: 0.1839\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6186 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4838 - prc: 0.1898 - val_loss: 0.4725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6021 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010 - prc: 0.1972 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5954 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997 - prc: 0.1965 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4732 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5841 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5083 - prc: 0.2012 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5787 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5677 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5114 - prc: 0.2029 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5624 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5570 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5517 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1968 - val_loss: 0.4754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5463 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5411 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4762 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5359 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4935 - prc: 0.1938 - val_loss: 0.4766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5307 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4771 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5253 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5201 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5076 - prc: 0.1993 - val_loss: 0.4780 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5149 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4785 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5098 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5048 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4796 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4997 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4947 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4839 - prc: 0.1883 - val_loss: 0.4807 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4813 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4850 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4819 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4700 - prc: 0.1841 - val_loss: 0.4825 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4757 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4710 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4664 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4968 - prc: 0.1955 - val_loss: 0.4844 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4619 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4850 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4577 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4533 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4958 - prc: 0.1953 - val_loss: 0.4864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4488 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4871 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1951 - val_loss: 0.4878 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4885 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4358 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4862 - prc: 0.1902 - val_loss: 0.4902 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4271 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4909 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4231 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4917 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4191 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5039 - prc: 0.1982 - val_loss: 0.4925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4150 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4109 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4942 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4068 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4989 - prc: 0.1963 - val_loss: 0.4951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4960 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3989 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4950 - prc: 0.1936 - val_loss: 0.4969 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3950 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4978 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4987 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3870 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5293 - prc: 0.2088 - val_loss: 0.4997 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3832 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5008 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.3421 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 162.0000 - fn: 38.0000 - accuracy: 0.8100 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1900Restoring model weights from the end of the best epoch: 2.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3757 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.5027 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.9517 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4417 - prc: 0.1756 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4331 - val_prc: 0.1621\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9370 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4607 - prc: 0.1808 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4813 - val_prc: 0.1753\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9247 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4800 - prc: 0.1881 - val_loss: 0.4725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9158 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4847 - prc: 0.1874 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9122 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997 - prc: 0.1965 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9091 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5107 - prc: 0.2035 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9031 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9000 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4966 - prc: 0.1945 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8914 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4900 - prc: 0.1906 - val_loss: 0.4753 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8857 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4757 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8827 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8800 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4898 - prc: 0.1913 - val_loss: 0.4765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8772 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4769 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8745 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8718 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4827 - prc: 0.1886 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8664 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4788 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8637 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4807 - prc: 0.1884 - val_loss: 0.4793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8610 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8585 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8559 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4896 - prc: 0.1928 - val_loss: 0.4809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8534 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8509 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4821 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8483 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5076 - prc: 0.1993 - val_loss: 0.4827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8457 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4833 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8431 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4957 - prc: 0.1914 - val_loss: 0.4840 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8407 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8384 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4853 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8359 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5107 - prc: 0.2035 - val_loss: 0.4860 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8288 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5044 - prc: 0.1986 - val_loss: 0.4881 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8242 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8220 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4959 - prc: 0.1951 - val_loss: 0.4903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8199 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4912 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4919 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8155 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4980 - prc: 0.1960 - val_loss: 0.4927 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8135 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4936 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8112 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5046 - prc: 0.2003 - val_loss: 0.4944 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8092 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4952 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4961 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8050 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4854 - prc: 0.1890 - val_loss: 0.4970 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8030 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4978 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8010 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4988 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4927 - prc: 0.1937 - val_loss: 0.4997 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7969 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5007 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7950 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7930 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.5027 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7427 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 164.0000 - fn: 36.0000 - accuracy: 0.8200 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1800Restoring model weights from the end of the best epoch: 4.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7910 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.5037 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "# Create a dictionary mapping the class indices to their respective weights\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_values = [{0: 1, 1: 1+i/2} for i in range(1, 8)]  # list of class_weights dictionary\n",
    "class_weights_values.append(class_weights_dict)\n",
    "\n",
    "# Hyperparameter tuning for class weight\n",
    "coordinates = [[0,0]]\n",
    "for i in range(len(class_weights_values)):\n",
    "    class_weight = class_weights_values[i]\n",
    "    model = make_model(input_shape=X_train.shape[-1])\n",
    "    model.load_weights(initial_weights)\n",
    "    baseline_history = model.fit(X_train,\n",
    "                                y_train,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                class_weight=class_weight)\n",
    "    y_pred = (model.predict(X_val, batch_size=BATCH_SIZE) > 0.5).astype(int)\n",
    "    c_mat = confusion_matrix(y_val, y_pred)\n",
    "    # save the values of sensitivity and 1-specificity for ROC curve\n",
    "    sensitivity = c_mat[1,1]/np.sum(c_mat[1,:])\n",
    "    specificity = c_mat[0,0]/np.sum(c_mat[0,:])\n",
    "    coordinates.append([1-specificity,sensitivity])\n",
    "coordinates.append([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1386a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot roc curve\n",
    "coordinates_np = np.array(sorted(coordinates, key=lambda x: x[0]))  # first column: FP, second column: TP\n",
    "plt.plot(coordinates_np[:,0], coordinates_np[:,1], linewidth=2, marker='o')\n",
    "diag = np.linspace(0,1,20)\n",
    "plt.plot(diag, diag)\n",
    "plt.xlabel('False positives')\n",
    "plt.ylabel('True positives')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.grid(True)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38d4ceff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 1.5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use youden index to find the best class weight\n",
    "youden_np = (coordinates_np[:,1]-coordinates_np[:,0])\n",
    "optimal = coordinates_np[youden_np.argmax(), :]\n",
    "best_class_weight_idx = coordinates.index([optimal[0], optimal[1]])\n",
    "\n",
    "# -1 is needed because coordinates list began with [0,0]\n",
    "best_class_weight = class_weights_values[best_class_weight_idx-1]\n",
    "best_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d101bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.6645 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 2041.0000 - fn: 489.0000 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4384 - prc: 0.1738 - val_loss: 0.4719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3856 - val_prc: 0.1443\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6604 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4705 - prc: 0.1844 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4189 - val_prc: 0.1528\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4733 - prc: 0.1860 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4729 - val_prc: 0.1714\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6545 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6534 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5139 - prc: 0.2025 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005 - val_prc: 0.1800\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6529 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.4729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6522 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6516 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6511 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5054 - prc: 0.1984 - val_loss: 0.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6505 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6500 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6494 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5097 - prc: 0.2029 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6490 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6485 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4748 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6480 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4750 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6477 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4973 - prc: 0.1931 - val_loss: 0.4752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6472 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4755 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6468 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6464 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6460 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5032 - prc: 0.1986 - val_loss: 0.4764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6456 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5015 - prc: 0.1971 - val_loss: 0.4767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6449 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4776 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6443 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5085 - prc: 0.1997 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6441 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6437 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6434 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6432 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5194 - prc: 0.2054 - val_loss: 0.4792 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6430 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6427 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6425 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6423 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6421 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4944 - prc: 0.1947 - val_loss: 0.4808 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6419 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6418 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4812 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6416 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6415 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4818 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4821 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005 - val_prc: 0.1800\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6412 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4996 - prc: 0.1965 - val_loss: 0.4824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5024 - val_prc: 0.1806\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6410 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6409 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6408 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4833 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6406 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6405 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4839 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005 - val_prc: 0.1800\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6404 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5034 - prc: 0.1977 - val_loss: 0.4841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6404 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009 - prc: 0.1969 - val_loss: 0.4843 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6403 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6401 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4850 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6400 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4853 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6400 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4883 - prc: 0.1920 - val_loss: 0.4859 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5036 - val_prc: 0.1809\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6398 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4862 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6397 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6397 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4867 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4872 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6395 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5003 - prc: 0.1967 - val_loss: 0.4875 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6395 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5070 - prc: 0.2081 - val_loss: 0.4877 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4993 - val_prc: 0.1796\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.4882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6394 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1966 - val_loss: 0.4884 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - prc: 0.1970 - val_loss: 0.4887 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4887 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.1798\n",
      "Epoch 66/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.5241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 174.0000 - fn: 26.0000 - accuracy: 0.8700 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - prc: 0.1300Restoring model weights from the end of the best epoch: 16.\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5006 - prc: 0.1968 - val_loss: 0.4886 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5012 - val_prc: 0.1802\n",
      "Epoch 66: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train a NN model based on the best class weight found\n",
    "weighted_model = make_model(input_shape=X_train.shape[-1])\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=best_class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5fb7b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ecbd243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 691us/step\n",
      "4/4 [==============================] - 0s 969us/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5024e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5020103454589844\n",
      "tp :  0.0\n",
      "fp :  0.0\n",
      "tn :  506.0\n",
      "fn :  127.0\n",
      "accuracy :  0.7993680834770203\n",
      "precision :  0.0\n",
      "recall :  0.0\n",
      "auc :  0.5009881258010864\n",
      "prc :  0.20094937086105347\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  506\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  0\n",
      "Fraudulent Transactions Missed (False Negatives):  127\n",
      "Fraudulent Transactions Detected (True Positives):  0\n",
      "Total Fraudulent Transactions:  127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performance report\n",
    "weighted_results = weighted_model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa54be93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8033596837944664\n",
      "Testing Accuracy: 0.7993680884676145\n",
      "AUC: 0.5009881422924901\n",
      "Present F1 score: 0.0\n",
      "Absent F1 score: 0.8884986830553118\n",
      "Sensitivity: 0.0\n",
      "Speicificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "# detailed report of model performance\n",
    "train_pred = (train_predictions_weighted > 0.5).astype('int')\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, train_pred)}\")\n",
    "test_pred = (test_predictions_weighted > 0.5).astype('int')\n",
    "print(f\"Testing Accuracy: {accuracy_score(y_test, test_pred)}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, test_predictions_weighted)}\")\n",
    "print(f\"Present F1 score: {f1_score(y_test, test_pred)}\")\n",
    "print(f\"Absent F1 score: {f1_score(y_test, test_pred,pos_label=0)}\")\n",
    "print(f\"Sensitivity: {recall_score(y_test, test_pred)}\")\n",
    "print(f\"Speicificity: {recall_score(y_test, test_pred,pos_label=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f116354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Slope ',\n",
       " 'Hurst Exponent ',\n",
       " 'Left Slope ',\n",
       " 'Right Slope ',\n",
       " 'Left Tangent ',\n",
       " 'Left Tangent Point',\n",
       " 'Right Tangent Point']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using all features in the data\n",
    "target = data.columns[11]  # target variable name\n",
    "features = [col_name for col_name in data.columns[1:11]]  # predictor features name\n",
    "features.pop(features.index('ID'))  # remove patient ID from feature names list\n",
    "features.pop(features.index('Broadness'))\n",
    "features.pop(features.index('Right Tangent'))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7131dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing data\n",
    "X = data.loc[:, features]\n",
    "y = data.loc[:, target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# split data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "362f36d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "# setting up initial weights for a new model on different train features\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(X_train)\n",
    "val_features = scaler.transform(X_val)\n",
    "test_features = scaler.transform(X_test)\n",
    "'''\n",
    "model = make_model(input_shape=X_train.shape[-1], output_bias=initial_bias)\n",
    "model.predict(X_train[:10])\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5273cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 31ms/step - loss: 0.6574 - tp: 64.0000 - fp: 79.0000 - tn: 2053.0000 - fn: 461.0000 - accuracy: 0.7968 - precision: 0.4476 - recall: 0.1219 - auc: 0.5280 - prc: 0.2718 - val_loss: 0.4720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5431 - val_prc: 0.1944\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6556 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4982 - prc: 0.1973 - val_loss: 0.4723 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4970 - val_prc: 0.1755\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6543 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5173 - prc: 0.2119 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4996 - val_prc: 0.1782\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6517 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5370 - prc: 0.2254 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4988 - val_prc: 0.1899\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5653 - prc: 0.2479 - val_loss: 0.4741 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5309 - val_prc: 0.2068\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6462 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5819 - prc: 0.2745 - val_loss: 0.4752 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5856 - val_prc: 0.2296\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6428 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6262 - prc: 0.3142 - val_loss: 0.4765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5936 - val_prc: 0.2530\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6415 - prc: 0.3231 - val_loss: 0.4785 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6236 - val_prc: 0.2848\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6369 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6588 - prc: 0.3411 - val_loss: 0.4811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6262 - val_prc: 0.2845\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6342 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6724 - prc: 0.3542 - val_loss: 0.4840 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6284 - val_prc: 0.2717\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6323 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6739 - prc: 0.3654 - val_loss: 0.4874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6320 - val_prc: 0.2853\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6309 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6736 - prc: 0.3655 - val_loss: 0.4902 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6452 - val_prc: 0.2917\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6299 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6786 - prc: 0.3719 - val_loss: 0.4916 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6418 - val_prc: 0.2944\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6296 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6659 - prc: 0.3635 - val_loss: 0.4963 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6433 - val_prc: 0.2941\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6288 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6774 - prc: 0.3734 - val_loss: 0.4945 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6464 - val_prc: 0.2954\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6282 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6809 - prc: 0.3738 - val_loss: 0.4950 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6479 - val_prc: 0.2910\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6279 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6814 - prc: 0.3729 - val_loss: 0.4956 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6432 - val_prc: 0.2882\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6274 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6811 - prc: 0.3713 - val_loss: 0.4934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6442 - val_prc: 0.2908\n",
      "Epoch 19/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6270 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6810 - prc: 0.3729 - val_loss: 0.4923 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6467 - val_prc: 0.2881\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6866 - prc: 0.3777 - val_loss: 0.4916 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6492 - val_prc: 0.2944\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6262 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6864 - prc: 0.3770 - val_loss: 0.4920 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6529 - val_prc: 0.2979\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6256 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6852 - prc: 0.3796 - val_loss: 0.4921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6517 - val_prc: 0.2951\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6251 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6865 - prc: 0.3788 - val_loss: 0.4911 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6514 - val_prc: 0.2948\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6249 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6828 - prc: 0.3716 - val_loss: 0.4927 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6529 - val_prc: 0.2934\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6241 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6879 - prc: 0.3785 - val_loss: 0.4905 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6533 - val_prc: 0.2910\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6232 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6886 - prc: 0.3819 - val_loss: 0.4934 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6613 - val_prc: 0.2967\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6220 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6927 - prc: 0.3848 - val_loss: 0.4925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6593 - val_prc: 0.2967\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6204 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6943 - prc: 0.3951 - val_loss: 0.4902 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6555 - val_prc: 0.2989\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6186 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6927 - prc: 0.4025 - val_loss: 0.4862 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6576 - val_prc: 0.3133\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6165 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6877 - prc: 0.3948 - val_loss: 0.4854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6606 - val_prc: 0.3149\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6147 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6856 - prc: 0.3875 - val_loss: 0.4842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6610 - val_prc: 0.3189\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6131 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6867 - prc: 0.3921 - val_loss: 0.4797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6609 - val_prc: 0.3235\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6113 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6869 - prc: 0.3940 - val_loss: 0.4841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6653 - val_prc: 0.3252\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6102 - tp: 2.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 396.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0050 - auc: 0.6877 - prc: 0.3909 - val_loss: 0.4905 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6648 - val_prc: 0.3156\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6083 - tp: 3.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 395.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0075 - auc: 0.6898 - prc: 0.3959 - val_loss: 0.4828 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6658 - val_prc: 0.3283\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6059 - tp: 3.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 395.0000 - accuracy: 0.8039 - precision: 0.6000 - recall: 0.0075 - auc: 0.6903 - prc: 0.3977 - val_loss: 0.4782 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6662 - val_prc: 0.3317\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6045 - tp: 4.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 394.0000 - accuracy: 0.8039 - precision: 0.5714 - recall: 0.0101 - auc: 0.6910 - prc: 0.3954 - val_loss: 0.4822 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6674 - val_prc: 0.3263\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6031 - tp: 11.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 387.0000 - accuracy: 0.8058 - precision: 0.6471 - recall: 0.0276 - auc: 0.6945 - prc: 0.3999 - val_loss: 0.4858 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6698 - val_prc: 0.3261\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - tp: 16.0000 - fp: 5.0000 - tn: 1621.0000 - fn: 382.0000 - accuracy: 0.8088 - precision: 0.7619 - recall: 0.0402 - auc: 0.6959 - prc: 0.4010 - val_loss: 0.4795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6693 - val_prc: 0.3313\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5995 - tp: 18.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 380.0000 - accuracy: 0.8093 - precision: 0.7500 - recall: 0.0452 - auc: 0.6964 - prc: 0.4031 - val_loss: 0.4810 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6701 - val_prc: 0.3297\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5979 - tp: 18.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 380.0000 - accuracy: 0.8088 - precision: 0.7200 - recall: 0.0452 - auc: 0.6959 - prc: 0.4051 - val_loss: 0.4745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6705 - val_prc: 0.3366\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5971 - tp: 15.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 383.0000 - accuracy: 0.8078 - precision: 0.7143 - recall: 0.0377 - auc: 0.6953 - prc: 0.4055 - val_loss: 0.4697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6709 - val_prc: 0.3391\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5962 - tp: 15.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 383.0000 - accuracy: 0.8078 - precision: 0.7143 - recall: 0.0377 - auc: 0.6963 - prc: 0.4062 - val_loss: 0.4703 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6700 - val_prc: 0.3356\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5939 - tp: 25.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 373.0000 - accuracy: 0.8113 - precision: 0.7353 - recall: 0.0628 - auc: 0.6975 - prc: 0.4068 - val_loss: 0.4755 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 87.0000 - val_accuracy: 0.8241 - val_precision: 0.6667 - val_recall: 0.0440 - val_auc: 0.6728 - val_prc: 0.3357\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5925 - tp: 31.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 367.0000 - accuracy: 0.8142 - precision: 0.7750 - recall: 0.0779 - auc: 0.6986 - prc: 0.4088 - val_loss: 0.4744 - val_tp: 5.0000 - val_fp: 3.0000 - val_tn: 412.0000 - val_fn: 86.0000 - val_accuracy: 0.8241 - val_precision: 0.6250 - val_recall: 0.0549 - val_auc: 0.6719 - val_prc: 0.3369\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5911 - tp: 33.0000 - fp: 10.0000 - tn: 1616.0000 - fn: 365.0000 - accuracy: 0.8147 - precision: 0.7674 - recall: 0.0829 - auc: 0.6991 - prc: 0.4108 - val_loss: 0.4702 - val_tp: 4.0000 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 87.0000 - val_accuracy: 0.8261 - val_precision: 0.8000 - val_recall: 0.0440 - val_auc: 0.6699 - val_prc: 0.3385\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5901 - tp: 30.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 368.0000 - accuracy: 0.8137 - precision: 0.7692 - recall: 0.0754 - auc: 0.6987 - prc: 0.4115 - val_loss: 0.4685 - val_tp: 6.0000 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 85.0000 - val_accuracy: 0.8300 - val_precision: 0.8571 - val_recall: 0.0659 - val_auc: 0.6729 - val_prc: 0.3426\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5890 - tp: 39.0000 - fp: 13.0000 - tn: 1613.0000 - fn: 359.0000 - accuracy: 0.8162 - precision: 0.7500 - recall: 0.0980 - auc: 0.6989 - prc: 0.4131 - val_loss: 0.4723 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 85.0000 - val_accuracy: 0.8221 - val_precision: 0.5455 - val_recall: 0.0659 - val_auc: 0.6716 - val_prc: 0.3434\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5877 - tp: 45.0000 - fp: 14.0000 - tn: 1612.0000 - fn: 353.0000 - accuracy: 0.8187 - precision: 0.7627 - recall: 0.1131 - auc: 0.7007 - prc: 0.4151 - val_loss: 0.4716 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 85.0000 - val_accuracy: 0.8221 - val_precision: 0.5455 - val_recall: 0.0659 - val_auc: 0.6735 - val_prc: 0.3448\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5869 - tp: 48.0000 - fp: 19.0000 - tn: 1607.0000 - fn: 350.0000 - accuracy: 0.8177 - precision: 0.7164 - recall: 0.1206 - auc: 0.7004 - prc: 0.4156 - val_loss: 0.4695 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 85.0000 - val_accuracy: 0.8221 - val_precision: 0.5455 - val_recall: 0.0659 - val_auc: 0.6749 - val_prc: 0.3462\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5855 - tp: 40.0000 - fp: 12.0000 - tn: 1614.0000 - fn: 358.0000 - accuracy: 0.8172 - precision: 0.7692 - recall: 0.1005 - auc: 0.7005 - prc: 0.4188 - val_loss: 0.4644 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 85.0000 - val_accuracy: 0.8241 - val_precision: 0.6000 - val_recall: 0.0659 - val_auc: 0.6747 - val_prc: 0.3513\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5853 - tp: 42.0000 - fp: 12.0000 - tn: 1614.0000 - fn: 356.0000 - accuracy: 0.8182 - precision: 0.7778 - recall: 0.1055 - auc: 0.7000 - prc: 0.4200 - val_loss: 0.4682 - val_tp: 9.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 82.0000 - val_accuracy: 0.8261 - val_precision: 0.6000 - val_recall: 0.0989 - val_auc: 0.6773 - val_prc: 0.3534\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5834 - tp: 56.0000 - fp: 23.0000 - tn: 1603.0000 - fn: 342.0000 - accuracy: 0.8197 - precision: 0.7089 - recall: 0.1407 - auc: 0.7015 - prc: 0.4224 - val_loss: 0.4677 - val_tp: 10.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 81.0000 - val_accuracy: 0.8281 - val_precision: 0.6250 - val_recall: 0.1099 - val_auc: 0.6766 - val_prc: 0.3527\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5824 - tp: 57.0000 - fp: 21.0000 - tn: 1605.0000 - fn: 341.0000 - accuracy: 0.8211 - precision: 0.7308 - recall: 0.1432 - auc: 0.7026 - prc: 0.4229 - val_loss: 0.4677 - val_tp: 12.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 79.0000 - val_accuracy: 0.8281 - val_precision: 0.6000 - val_recall: 0.1319 - val_auc: 0.6768 - val_prc: 0.3558\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5824 - tp: 74.0000 - fp: 43.0000 - tn: 1583.0000 - fn: 324.0000 - accuracy: 0.8187 - precision: 0.6325 - recall: 0.1859 - auc: 0.7014 - prc: 0.4242 - val_loss: 0.4701 - val_tp: 12.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 79.0000 - val_accuracy: 0.8182 - val_precision: 0.4800 - val_recall: 0.1319 - val_auc: 0.6782 - val_prc: 0.3635\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5808 - tp: 58.0000 - fp: 20.0000 - tn: 1606.0000 - fn: 340.0000 - accuracy: 0.8221 - precision: 0.7436 - recall: 0.1457 - auc: 0.7016 - prc: 0.4277 - val_loss: 0.4575 - val_tp: 7.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 84.0000 - val_accuracy: 0.8261 - val_precision: 0.6364 - val_recall: 0.0769 - val_auc: 0.6747 - val_prc: 0.3800\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5810 - tp: 54.0000 - fp: 19.0000 - tn: 1607.0000 - fn: 344.0000 - accuracy: 0.8207 - precision: 0.7397 - recall: 0.1357 - auc: 0.6999 - prc: 0.4261 - val_loss: 0.4644 - val_tp: 12.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 79.0000 - val_accuracy: 0.8241 - val_precision: 0.5455 - val_recall: 0.1319 - val_auc: 0.6778 - val_prc: 0.3760\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5788 - tp: 72.0000 - fp: 32.0000 - tn: 1594.0000 - fn: 326.0000 - accuracy: 0.8231 - precision: 0.6923 - recall: 0.1809 - auc: 0.7022 - prc: 0.4317 - val_loss: 0.4639 - val_tp: 12.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 79.0000 - val_accuracy: 0.8241 - val_precision: 0.5455 - val_recall: 0.1319 - val_auc: 0.6789 - val_prc: 0.3815\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5786 - tp: 67.0000 - fp: 27.0000 - tn: 1599.0000 - fn: 331.0000 - accuracy: 0.8231 - precision: 0.7128 - recall: 0.1683 - auc: 0.7009 - prc: 0.4323 - val_loss: 0.4621 - val_tp: 12.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 79.0000 - val_accuracy: 0.8261 - val_precision: 0.5714 - val_recall: 0.1319 - val_auc: 0.6779 - val_prc: 0.3838\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5776 - tp: 68.0000 - fp: 26.0000 - tn: 1600.0000 - fn: 330.0000 - accuracy: 0.8241 - precision: 0.7234 - recall: 0.1709 - auc: 0.7024 - prc: 0.4346 - val_loss: 0.4601 - val_tp: 12.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 79.0000 - val_accuracy: 0.8261 - val_precision: 0.5714 - val_recall: 0.1319 - val_auc: 0.6753 - val_prc: 0.3830\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5776 - tp: 83.0000 - fp: 47.0000 - tn: 1579.0000 - fn: 315.0000 - accuracy: 0.8211 - precision: 0.6385 - recall: 0.2085 - auc: 0.7018 - prc: 0.4309 - val_loss: 0.4643 - val_tp: 14.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 77.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1538 - val_auc: 0.6782 - val_prc: 0.3822\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5758 - tp: 74.0000 - fp: 36.0000 - tn: 1590.0000 - fn: 324.0000 - accuracy: 0.8221 - precision: 0.6727 - recall: 0.1859 - auc: 0.7046 - prc: 0.4367 - val_loss: 0.4559 - val_tp: 12.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 79.0000 - val_accuracy: 0.8281 - val_precision: 0.6000 - val_recall: 0.1319 - val_auc: 0.6763 - val_prc: 0.3857\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5761 - tp: 74.0000 - fp: 33.0000 - tn: 1593.0000 - fn: 324.0000 - accuracy: 0.8236 - precision: 0.6916 - recall: 0.1859 - auc: 0.7035 - prc: 0.4340 - val_loss: 0.4587 - val_tp: 13.0000 - val_fp: 13.0000 - val_tn: 402.0000 - val_fn: 78.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1429 - val_auc: 0.6780 - val_prc: 0.3854\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5746 - tp: 78.0000 - fp: 42.0000 - tn: 1584.0000 - fn: 320.0000 - accuracy: 0.8211 - precision: 0.6500 - recall: 0.1960 - auc: 0.7048 - prc: 0.4375 - val_loss: 0.4624 - val_tp: 14.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 77.0000 - val_accuracy: 0.8182 - val_precision: 0.4828 - val_recall: 0.1538 - val_auc: 0.6781 - val_prc: 0.3788\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5745 - tp: 84.0000 - fp: 50.0000 - tn: 1576.0000 - fn: 314.0000 - accuracy: 0.8202 - precision: 0.6269 - recall: 0.2111 - auc: 0.7041 - prc: 0.4351 - val_loss: 0.4617 - val_tp: 14.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 77.0000 - val_accuracy: 0.8182 - val_precision: 0.4828 - val_recall: 0.1538 - val_auc: 0.6793 - val_prc: 0.3785\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5739 - tp: 81.0000 - fp: 49.0000 - tn: 1577.0000 - fn: 317.0000 - accuracy: 0.8192 - precision: 0.6231 - recall: 0.2035 - auc: 0.7049 - prc: 0.4367 - val_loss: 0.4590 - val_tp: 14.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 77.0000 - val_accuracy: 0.8182 - val_precision: 0.4828 - val_recall: 0.1538 - val_auc: 0.6783 - val_prc: 0.3852\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5738 - tp: 91.0000 - fp: 60.0000 - tn: 1566.0000 - fn: 307.0000 - accuracy: 0.8187 - precision: 0.6026 - recall: 0.2286 - auc: 0.7051 - prc: 0.4369 - val_loss: 0.4635 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 75.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1758 - val_auc: 0.6807 - val_prc: 0.3881\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5729 - tp: 88.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 310.0000 - accuracy: 0.8192 - precision: 0.6111 - recall: 0.2211 - auc: 0.7044 - prc: 0.4413 - val_loss: 0.4563 - val_tp: 14.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 77.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1538 - val_auc: 0.6807 - val_prc: 0.3910\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5728 - tp: 88.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 310.0000 - accuracy: 0.8187 - precision: 0.6069 - recall: 0.2211 - auc: 0.7038 - prc: 0.4400 - val_loss: 0.4579 - val_tp: 15.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 76.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1648 - val_auc: 0.6832 - val_prc: 0.3964\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5725 - tp: 76.0000 - fp: 35.0000 - tn: 1591.0000 - fn: 322.0000 - accuracy: 0.8236 - precision: 0.6847 - recall: 0.1910 - auc: 0.7045 - prc: 0.4432 - val_loss: 0.4507 - val_tp: 13.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 78.0000 - val_accuracy: 0.8281 - val_precision: 0.5909 - val_recall: 0.1429 - val_auc: 0.6779 - val_prc: 0.3983\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5723 - tp: 87.0000 - fp: 46.0000 - tn: 1580.0000 - fn: 311.0000 - accuracy: 0.8236 - precision: 0.6541 - recall: 0.2186 - auc: 0.7035 - prc: 0.4418 - val_loss: 0.4596 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 73.0000 - val_accuracy: 0.8221 - val_precision: 0.5143 - val_recall: 0.1978 - val_auc: 0.6833 - val_prc: 0.3938\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5712 - tp: 87.0000 - fp: 52.0000 - tn: 1574.0000 - fn: 311.0000 - accuracy: 0.8207 - precision: 0.6259 - recall: 0.2186 - auc: 0.7050 - prc: 0.4429 - val_loss: 0.4515 - val_tp: 14.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 77.0000 - val_accuracy: 0.8281 - val_precision: 0.5833 - val_recall: 0.1538 - val_auc: 0.6811 - val_prc: 0.4007\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5723 - tp: 75.0000 - fp: 36.0000 - tn: 1590.0000 - fn: 323.0000 - accuracy: 0.8226 - precision: 0.6757 - recall: 0.1884 - auc: 0.7000 - prc: 0.4438 - val_loss: 0.4542 - val_tp: 15.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 76.0000 - val_accuracy: 0.8221 - val_precision: 0.5172 - val_recall: 0.1648 - val_auc: 0.6820 - val_prc: 0.4003\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5714 - tp: 91.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 307.0000 - accuracy: 0.8172 - precision: 0.5909 - recall: 0.2286 - auc: 0.7025 - prc: 0.4425 - val_loss: 0.4593 - val_tp: 22.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 69.0000 - val_accuracy: 0.8221 - val_precision: 0.5116 - val_recall: 0.2418 - val_auc: 0.6832 - val_prc: 0.4014\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5707 - tp: 95.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 303.0000 - accuracy: 0.8167 - precision: 0.5828 - recall: 0.2387 - auc: 0.7055 - prc: 0.4453 - val_loss: 0.4572 - val_tp: 18.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 73.0000 - val_accuracy: 0.8182 - val_precision: 0.4865 - val_recall: 0.1978 - val_auc: 0.6845 - val_prc: 0.4017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5705 - tp: 96.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 302.0000 - accuracy: 0.8142 - precision: 0.5647 - recall: 0.2412 - auc: 0.7056 - prc: 0.4457 - val_loss: 0.4588 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6838 - val_prc: 0.3992\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5707 - tp: 98.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 300.0000 - accuracy: 0.8187 - precision: 0.5939 - recall: 0.2462 - auc: 0.7049 - prc: 0.4427 - val_loss: 0.4553 - val_tp: 18.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 73.0000 - val_accuracy: 0.8261 - val_precision: 0.5455 - val_recall: 0.1978 - val_auc: 0.6829 - val_prc: 0.3992\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5695 - tp: 99.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 299.0000 - accuracy: 0.8157 - precision: 0.5723 - recall: 0.2487 - auc: 0.7052 - prc: 0.4487 - val_loss: 0.4618 - val_tp: 23.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 68.0000 - val_accuracy: 0.8162 - val_precision: 0.4792 - val_recall: 0.2527 - val_auc: 0.6830 - val_prc: 0.4001\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5695 - tp: 106.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 292.0000 - accuracy: 0.8147 - precision: 0.5608 - recall: 0.2663 - auc: 0.7058 - prc: 0.4490 - val_loss: 0.4542 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6827 - val_prc: 0.4042\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - tp: 87.0000 - fp: 52.0000 - tn: 1574.0000 - fn: 311.0000 - accuracy: 0.8207 - precision: 0.6259 - recall: 0.2186 - auc: 0.7059 - prc: 0.4493 - val_loss: 0.4509 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 75.0000 - val_accuracy: 0.8221 - val_precision: 0.5161 - val_recall: 0.1758 - val_auc: 0.6827 - val_prc: 0.4041\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5686 - tp: 91.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 307.0000 - accuracy: 0.8207 - precision: 0.6190 - recall: 0.2286 - auc: 0.7063 - prc: 0.4503 - val_loss: 0.4541 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6833 - val_prc: 0.4054\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5686 - tp: 103.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 295.0000 - accuracy: 0.8172 - precision: 0.5787 - recall: 0.2588 - auc: 0.7072 - prc: 0.4489 - val_loss: 0.4562 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6838 - val_prc: 0.4042\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5680 - tp: 93.0000 - fp: 60.0000 - tn: 1566.0000 - fn: 305.0000 - accuracy: 0.8197 - precision: 0.6078 - recall: 0.2337 - auc: 0.7079 - prc: 0.4515 - val_loss: 0.4511 - val_tp: 17.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 74.0000 - val_accuracy: 0.8221 - val_precision: 0.5152 - val_recall: 0.1868 - val_auc: 0.6833 - val_prc: 0.4035\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5677 - tp: 90.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 308.0000 - accuracy: 0.8197 - precision: 0.6122 - recall: 0.2261 - auc: 0.7069 - prc: 0.4526 - val_loss: 0.4536 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6814 - val_prc: 0.4039\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5681 - tp: 105.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 293.0000 - accuracy: 0.8167 - precision: 0.5738 - recall: 0.2638 - auc: 0.7057 - prc: 0.4508 - val_loss: 0.4560 - val_tp: 23.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 68.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2527 - val_auc: 0.6854 - val_prc: 0.4059\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5675 - tp: 97.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 301.0000 - accuracy: 0.8197 - precision: 0.6025 - recall: 0.2437 - auc: 0.7081 - prc: 0.4522 - val_loss: 0.4518 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6832 - val_prc: 0.4077\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5675 - tp: 103.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 295.0000 - accuracy: 0.8177 - precision: 0.5819 - recall: 0.2588 - auc: 0.7104 - prc: 0.4540 - val_loss: 0.4551 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6873 - val_prc: 0.4092\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5671 - tp: 96.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 302.0000 - accuracy: 0.8167 - precision: 0.5818 - recall: 0.2412 - auc: 0.7079 - prc: 0.4538 - val_loss: 0.4498 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6827 - val_prc: 0.4075\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5668 - tp: 97.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 301.0000 - accuracy: 0.8192 - precision: 0.5988 - recall: 0.2437 - auc: 0.7088 - prc: 0.4559 - val_loss: 0.4519 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6861 - val_prc: 0.4075\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5666 - tp: 97.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 301.0000 - accuracy: 0.8187 - precision: 0.5951 - recall: 0.2437 - auc: 0.7086 - prc: 0.4554 - val_loss: 0.4515 - val_tp: 21.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 70.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2308 - val_auc: 0.6850 - val_prc: 0.4076\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5666 - tp: 103.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 295.0000 - accuracy: 0.8177 - precision: 0.5819 - recall: 0.2588 - auc: 0.7089 - prc: 0.4563 - val_loss: 0.4531 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6857 - val_prc: 0.4089\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5662 - tp: 95.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 303.0000 - accuracy: 0.8182 - precision: 0.5938 - recall: 0.2387 - auc: 0.7084 - prc: 0.4574 - val_loss: 0.4477 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6841 - val_prc: 0.4128\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5665 - tp: 99.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 299.0000 - accuracy: 0.8177 - precision: 0.5858 - recall: 0.2487 - auc: 0.7080 - prc: 0.4542 - val_loss: 0.4503 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6839 - val_prc: 0.4044\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5665 - tp: 88.0000 - fp: 52.0000 - tn: 1574.0000 - fn: 310.0000 - accuracy: 0.8211 - precision: 0.6286 - recall: 0.2211 - auc: 0.7086 - prc: 0.4565 - val_loss: 0.4455 - val_tp: 16.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 75.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1758 - val_auc: 0.6797 - val_prc: 0.4034\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5661 - tp: 99.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 299.0000 - accuracy: 0.8182 - precision: 0.5893 - recall: 0.2487 - auc: 0.7086 - prc: 0.4548 - val_loss: 0.4559 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6831 - val_prc: 0.4024\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5665 - tp: 91.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 307.0000 - accuracy: 0.8162 - precision: 0.5833 - recall: 0.2286 - auc: 0.7076 - prc: 0.4521 - val_loss: 0.4440 - val_tp: 16.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 75.0000 - val_accuracy: 0.8221 - val_precision: 0.5161 - val_recall: 0.1758 - val_auc: 0.6785 - val_prc: 0.4066\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5661 - tp: 89.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 309.0000 - accuracy: 0.8192 - precision: 0.6096 - recall: 0.2236 - auc: 0.7052 - prc: 0.4576 - val_loss: 0.4497 - val_tp: 23.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.5476 - val_recall: 0.2527 - val_auc: 0.6840 - val_prc: 0.4135\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5655 - tp: 100.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 298.0000 - accuracy: 0.8172 - precision: 0.5814 - recall: 0.2513 - auc: 0.7069 - prc: 0.4582 - val_loss: 0.4494 - val_tp: 23.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.5476 - val_recall: 0.2527 - val_auc: 0.6839 - val_prc: 0.4151\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5655 - tp: 97.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 301.0000 - accuracy: 0.8172 - precision: 0.5843 - recall: 0.2437 - auc: 0.7069 - prc: 0.4583 - val_loss: 0.4505 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6888 - val_prc: 0.4159\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5650 - tp: 102.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 296.0000 - accuracy: 0.8177 - precision: 0.5829 - recall: 0.2563 - auc: 0.7094 - prc: 0.4598 - val_loss: 0.4461 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6838 - val_prc: 0.4164\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5673 - tp: 83.0000 - fp: 45.0000 - tn: 1581.0000 - fn: 315.0000 - accuracy: 0.8221 - precision: 0.6484 - recall: 0.2085 - auc: 0.7041 - prc: 0.4573 - val_loss: 0.4422 - val_tp: 16.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 75.0000 - val_accuracy: 0.8241 - val_precision: 0.5333 - val_recall: 0.1758 - val_auc: 0.6823 - val_prc: 0.4145\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5648 - tp: 95.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 303.0000 - accuracy: 0.8157 - precision: 0.5758 - recall: 0.2387 - auc: 0.7104 - prc: 0.4591 - val_loss: 0.4566 - val_tp: 25.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 66.0000 - val_accuracy: 0.8162 - val_precision: 0.4808 - val_recall: 0.2747 - val_auc: 0.6868 - val_prc: 0.4070\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5652 - tp: 110.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 288.0000 - accuracy: 0.8152 - precision: 0.5612 - recall: 0.2764 - auc: 0.7079 - prc: 0.4588 - val_loss: 0.4493 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6843 - val_prc: 0.4100\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5647 - tp: 93.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 305.0000 - accuracy: 0.8162 - precision: 0.5813 - recall: 0.2337 - auc: 0.7079 - prc: 0.4600 - val_loss: 0.4486 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6828 - val_prc: 0.4131\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5648 - tp: 102.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 296.0000 - accuracy: 0.8157 - precision: 0.5698 - recall: 0.2563 - auc: 0.7084 - prc: 0.4595 - val_loss: 0.4505 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6893 - val_prc: 0.4174\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5643 - tp: 99.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 299.0000 - accuracy: 0.8187 - precision: 0.5928 - recall: 0.2487 - auc: 0.7091 - prc: 0.4618 - val_loss: 0.4444 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 72.0000 - val_accuracy: 0.8241 - val_precision: 0.5278 - val_recall: 0.2088 - val_auc: 0.6848 - val_prc: 0.4168\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5650 - tp: 86.0000 - fp: 54.0000 - tn: 1572.0000 - fn: 312.0000 - accuracy: 0.8192 - precision: 0.6143 - recall: 0.2161 - auc: 0.7091 - prc: 0.4611 - val_loss: 0.4463 - val_tp: 19.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 72.0000 - val_accuracy: 0.8182 - val_precision: 0.4872 - val_recall: 0.2088 - val_auc: 0.6835 - val_prc: 0.4127\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5645 - tp: 106.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 292.0000 - accuracy: 0.8157 - precision: 0.5668 - recall: 0.2663 - auc: 0.7091 - prc: 0.4596 - val_loss: 0.4541 - val_tp: 24.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 67.0000 - val_accuracy: 0.8162 - val_precision: 0.4800 - val_recall: 0.2637 - val_auc: 0.6875 - val_prc: 0.4117\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5643 - tp: 104.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 294.0000 - accuracy: 0.8177 - precision: 0.5810 - recall: 0.2613 - auc: 0.7091 - prc: 0.4601 - val_loss: 0.4466 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6833 - val_prc: 0.4133\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5655 - tp: 87.0000 - fp: 52.0000 - tn: 1574.0000 - fn: 311.0000 - accuracy: 0.8207 - precision: 0.6259 - recall: 0.2186 - auc: 0.7075 - prc: 0.4595 - val_loss: 0.4454 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6847 - val_prc: 0.4160\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5640 - tp: 111.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 287.0000 - accuracy: 0.8162 - precision: 0.5663 - recall: 0.2789 - auc: 0.7106 - prc: 0.4612 - val_loss: 0.4595 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6869 - val_prc: 0.4165\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5670 - tp: 127.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 271.0000 - accuracy: 0.8088 - precision: 0.5226 - recall: 0.3191 - auc: 0.7079 - prc: 0.4601 - val_loss: 0.4490 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6896 - val_prc: 0.4199\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5667 - tp: 83.0000 - fp: 51.0000 - tn: 1575.0000 - fn: 315.0000 - accuracy: 0.8192 - precision: 0.6194 - recall: 0.2085 - auc: 0.7046 - prc: 0.4568 - val_loss: 0.4378 - val_tp: 16.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 75.0000 - val_accuracy: 0.8340 - val_precision: 0.6400 - val_recall: 0.1758 - val_auc: 0.6812 - val_prc: 0.4239\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5642 - tp: 94.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 304.0000 - accuracy: 0.8177 - precision: 0.5912 - recall: 0.2362 - auc: 0.7094 - prc: 0.4616 - val_loss: 0.4511 - val_tp: 24.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 67.0000 - val_accuracy: 0.8182 - val_precision: 0.4898 - val_recall: 0.2637 - val_auc: 0.6897 - val_prc: 0.4181\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5635 - tp: 104.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 294.0000 - accuracy: 0.8167 - precision: 0.5746 - recall: 0.2613 - auc: 0.7105 - prc: 0.4626 - val_loss: 0.4477 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6904 - val_prc: 0.4185\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5633 - tp: 105.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 293.0000 - accuracy: 0.8157 - precision: 0.5676 - recall: 0.2638 - auc: 0.7102 - prc: 0.4626 - val_loss: 0.4506 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6891 - val_prc: 0.4173\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5636 - tp: 111.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 287.0000 - accuracy: 0.8167 - precision: 0.5692 - recall: 0.2789 - auc: 0.7099 - prc: 0.4625 - val_loss: 0.4505 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6889 - val_prc: 0.4155\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5631 - tp: 107.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 291.0000 - accuracy: 0.8167 - precision: 0.5722 - recall: 0.2688 - auc: 0.7105 - prc: 0.4632 - val_loss: 0.4475 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6893 - val_prc: 0.4179\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5635 - tp: 100.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 298.0000 - accuracy: 0.8177 - precision: 0.5848 - recall: 0.2513 - auc: 0.7100 - prc: 0.4623 - val_loss: 0.4453 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6905 - val_prc: 0.4219\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5654 - tp: 85.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 313.0000 - accuracy: 0.8172 - precision: 0.5986 - recall: 0.2136 - auc: 0.7071 - prc: 0.4580 - val_loss: 0.4416 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6858 - val_prc: 0.4221\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - tp: 93.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 305.0000 - accuracy: 0.8167 - precision: 0.5849 - recall: 0.2337 - auc: 0.7109 - prc: 0.4637 - val_loss: 0.4462 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6905 - val_prc: 0.4235\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5628 - tp: 100.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 298.0000 - accuracy: 0.8177 - precision: 0.5848 - recall: 0.2513 - auc: 0.7123 - prc: 0.4638 - val_loss: 0.4450 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6900 - val_prc: 0.4213\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - tp: 93.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 305.0000 - accuracy: 0.8207 - precision: 0.6159 - recall: 0.2337 - auc: 0.7115 - prc: 0.4633 - val_loss: 0.4471 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6897 - val_prc: 0.4161\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5660 - tp: 121.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 277.0000 - accuracy: 0.8123 - precision: 0.5402 - recall: 0.3040 - auc: 0.7075 - prc: 0.4575 - val_loss: 0.4573 - val_tp: 25.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 66.0000 - val_accuracy: 0.8162 - val_precision: 0.4808 - val_recall: 0.2747 - val_auc: 0.6839 - val_prc: 0.4082\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5638 - tp: 109.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 289.0000 - accuracy: 0.8187 - precision: 0.5829 - recall: 0.2739 - auc: 0.7090 - prc: 0.4600 - val_loss: 0.4418 - val_tp: 18.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 73.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1978 - val_auc: 0.6850 - val_prc: 0.4137\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5634 - tp: 89.0000 - fp: 55.0000 - tn: 1571.0000 - fn: 309.0000 - accuracy: 0.8202 - precision: 0.6181 - recall: 0.2236 - auc: 0.7101 - prc: 0.4625 - val_loss: 0.4460 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6906 - val_prc: 0.4150\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5627 - tp: 103.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 295.0000 - accuracy: 0.8172 - precision: 0.5787 - recall: 0.2588 - auc: 0.7097 - prc: 0.4617 - val_loss: 0.4460 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6901 - val_prc: 0.4169\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5630 - tp: 93.0000 - fp: 60.0000 - tn: 1566.0000 - fn: 305.0000 - accuracy: 0.8197 - precision: 0.6078 - recall: 0.2337 - auc: 0.7107 - prc: 0.4631 - val_loss: 0.4436 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6912 - val_prc: 0.4229\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5619 - tp: 104.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 294.0000 - accuracy: 0.8162 - precision: 0.5714 - recall: 0.2613 - auc: 0.7111 - prc: 0.4643 - val_loss: 0.4518 - val_tp: 24.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 67.0000 - val_accuracy: 0.8162 - val_precision: 0.4800 - val_recall: 0.2637 - val_auc: 0.6878 - val_prc: 0.4230\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5639 - tp: 123.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 275.0000 - accuracy: 0.8137 - precision: 0.5467 - recall: 0.3090 - auc: 0.7107 - prc: 0.4642 - val_loss: 0.4538 - val_tp: 24.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 67.0000 - val_accuracy: 0.8162 - val_precision: 0.4800 - val_recall: 0.2637 - val_auc: 0.6884 - val_prc: 0.4220\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5623 - tp: 106.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 292.0000 - accuracy: 0.8157 - precision: 0.5668 - recall: 0.2663 - auc: 0.7109 - prc: 0.4630 - val_loss: 0.4428 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6921 - val_prc: 0.4245\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5623 - tp: 95.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 303.0000 - accuracy: 0.8177 - precision: 0.5901 - recall: 0.2387 - auc: 0.7123 - prc: 0.4645 - val_loss: 0.4425 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6890 - val_prc: 0.4228\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5618 - tp: 103.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 295.0000 - accuracy: 0.8172 - precision: 0.5787 - recall: 0.2588 - auc: 0.7112 - prc: 0.4643 - val_loss: 0.4465 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6900 - val_prc: 0.4201\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5617 - tp: 102.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 296.0000 - accuracy: 0.8172 - precision: 0.5795 - recall: 0.2563 - auc: 0.7119 - prc: 0.4648 - val_loss: 0.4428 - val_tp: 19.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 72.0000 - val_accuracy: 0.8162 - val_precision: 0.4750 - val_recall: 0.2088 - val_auc: 0.6895 - val_prc: 0.4214\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5623 - tp: 107.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 291.0000 - accuracy: 0.8192 - precision: 0.5879 - recall: 0.2688 - auc: 0.7119 - prc: 0.4629 - val_loss: 0.4460 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6919 - val_prc: 0.4238\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5619 - tp: 107.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 291.0000 - accuracy: 0.8162 - precision: 0.5691 - recall: 0.2688 - auc: 0.7113 - prc: 0.4646 - val_loss: 0.4454 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6920 - val_prc: 0.4259\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5622 - tp: 98.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 300.0000 - accuracy: 0.8157 - precision: 0.5731 - recall: 0.2462 - auc: 0.7101 - prc: 0.4642 - val_loss: 0.4425 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6904 - val_prc: 0.4255\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5623 - tp: 111.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 287.0000 - accuracy: 0.8152 - precision: 0.5606 - recall: 0.2789 - auc: 0.7105 - prc: 0.4654 - val_loss: 0.4522 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6881 - val_prc: 0.4218\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5624 - tp: 117.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 281.0000 - accuracy: 0.8162 - precision: 0.5625 - recall: 0.2940 - auc: 0.7102 - prc: 0.4637 - val_loss: 0.4453 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6893 - val_prc: 0.4220\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5616 - tp: 108.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 290.0000 - accuracy: 0.8172 - precision: 0.5745 - recall: 0.2714 - auc: 0.7123 - prc: 0.4645 - val_loss: 0.4445 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6905 - val_prc: 0.4216\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5616 - tp: 101.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 297.0000 - accuracy: 0.8192 - precision: 0.5941 - recall: 0.2538 - auc: 0.7130 - prc: 0.4662 - val_loss: 0.4427 - val_tp: 22.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 69.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2418 - val_auc: 0.6893 - val_prc: 0.4228\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5613 - tp: 109.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 289.0000 - accuracy: 0.8152 - precision: 0.5619 - recall: 0.2739 - auc: 0.7125 - prc: 0.4657 - val_loss: 0.4474 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6890 - val_prc: 0.4233\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5625 - tp: 101.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 297.0000 - accuracy: 0.8187 - precision: 0.5906 - recall: 0.2538 - auc: 0.7116 - prc: 0.4640 - val_loss: 0.4422 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6913 - val_prc: 0.4255\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5625 - tp: 114.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 284.0000 - accuracy: 0.8103 - precision: 0.5327 - recall: 0.2864 - auc: 0.7109 - prc: 0.4629 - val_loss: 0.4511 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6863 - val_prc: 0.4169\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5621 - tp: 100.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 298.0000 - accuracy: 0.8187 - precision: 0.5917 - recall: 0.2513 - auc: 0.7109 - prc: 0.4639 - val_loss: 0.4396 - val_tp: 18.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 73.0000 - val_accuracy: 0.8221 - val_precision: 0.5143 - val_recall: 0.1978 - val_auc: 0.6905 - val_prc: 0.4225\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5621 - tp: 107.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 291.0000 - accuracy: 0.8157 - precision: 0.5661 - recall: 0.2688 - auc: 0.7102 - prc: 0.4635 - val_loss: 0.4508 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6868 - val_prc: 0.4180\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5625 - tp: 122.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 276.0000 - accuracy: 0.8132 - precision: 0.5446 - recall: 0.3065 - auc: 0.7123 - prc: 0.4654 - val_loss: 0.4492 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6873 - val_prc: 0.4189\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5614 - tp: 98.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 300.0000 - accuracy: 0.8162 - precision: 0.5765 - recall: 0.2462 - auc: 0.7121 - prc: 0.4664 - val_loss: 0.4382 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6901 - val_prc: 0.4265\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5623 - tp: 87.0000 - fp: 55.0000 - tn: 1571.0000 - fn: 311.0000 - accuracy: 0.8192 - precision: 0.6127 - recall: 0.2186 - auc: 0.7109 - prc: 0.4668 - val_loss: 0.4403 - val_tp: 18.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 73.0000 - val_accuracy: 0.8142 - val_precision: 0.4615 - val_recall: 0.1978 - val_auc: 0.6899 - val_prc: 0.4251\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5619 - tp: 115.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 283.0000 - accuracy: 0.8152 - precision: 0.5583 - recall: 0.2889 - auc: 0.7112 - prc: 0.4649 - val_loss: 0.4534 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6869 - val_prc: 0.4179\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5620 - tp: 119.0000 - fp: 94.0000 - tn: 1532.0000 - fn: 279.0000 - accuracy: 0.8157 - precision: 0.5587 - recall: 0.2990 - auc: 0.7120 - prc: 0.4655 - val_loss: 0.4443 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6889 - val_prc: 0.4232\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5613 - tp: 101.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 297.0000 - accuracy: 0.8221 - precision: 0.6159 - recall: 0.2538 - auc: 0.7116 - prc: 0.4667 - val_loss: 0.4367 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 73.0000 - val_accuracy: 0.8281 - val_precision: 0.5625 - val_recall: 0.1978 - val_auc: 0.6911 - val_prc: 0.4300\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5620 - tp: 87.0000 - fp: 54.0000 - tn: 1572.0000 - fn: 311.0000 - accuracy: 0.8197 - precision: 0.6170 - recall: 0.2186 - auc: 0.7107 - prc: 0.4677 - val_loss: 0.4402 - val_tp: 19.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 72.0000 - val_accuracy: 0.8182 - val_precision: 0.4872 - val_recall: 0.2088 - val_auc: 0.6915 - val_prc: 0.4283\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5605 - tp: 104.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 294.0000 - accuracy: 0.8152 - precision: 0.5652 - recall: 0.2613 - auc: 0.7120 - prc: 0.4693 - val_loss: 0.4474 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6878 - val_prc: 0.4229\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5613 - tp: 114.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 284.0000 - accuracy: 0.8152 - precision: 0.5588 - recall: 0.2864 - auc: 0.7106 - prc: 0.4661 - val_loss: 0.4414 - val_tp: 20.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 71.0000 - val_accuracy: 0.8182 - val_precision: 0.4878 - val_recall: 0.2198 - val_auc: 0.6911 - val_prc: 0.4256\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5626 - tp: 87.0000 - fp: 51.0000 - tn: 1575.0000 - fn: 311.0000 - accuracy: 0.8211 - precision: 0.6304 - recall: 0.2186 - auc: 0.7099 - prc: 0.4664 - val_loss: 0.4347 - val_tp: 17.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 74.0000 - val_accuracy: 0.8320 - val_precision: 0.6071 - val_recall: 0.1868 - val_auc: 0.6888 - val_prc: 0.4283\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5618 - tp: 94.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 304.0000 - accuracy: 0.8167 - precision: 0.5839 - recall: 0.2362 - auc: 0.7108 - prc: 0.4662 - val_loss: 0.4463 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6873 - val_prc: 0.4216\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5606 - tp: 110.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 288.0000 - accuracy: 0.8182 - precision: 0.5789 - recall: 0.2764 - auc: 0.7113 - prc: 0.4673 - val_loss: 0.4430 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6900 - val_prc: 0.4239\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5608 - tp: 100.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 298.0000 - accuracy: 0.8182 - precision: 0.5882 - recall: 0.2513 - auc: 0.7130 - prc: 0.4667 - val_loss: 0.4422 - val_tp: 23.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 68.0000 - val_accuracy: 0.8241 - val_precision: 0.5227 - val_recall: 0.2527 - val_auc: 0.6907 - val_prc: 0.4245\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - tp: 107.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 291.0000 - accuracy: 0.8162 - precision: 0.5691 - recall: 0.2688 - auc: 0.7130 - prc: 0.4669 - val_loss: 0.4471 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6893 - val_prc: 0.4211\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5608 - tp: 109.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 289.0000 - accuracy: 0.8162 - precision: 0.5677 - recall: 0.2739 - auc: 0.7115 - prc: 0.4660 - val_loss: 0.4442 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6892 - val_prc: 0.4227\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5608 - tp: 116.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 282.0000 - accuracy: 0.8167 - precision: 0.5659 - recall: 0.2915 - auc: 0.7109 - prc: 0.4670 - val_loss: 0.4512 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6899 - val_prc: 0.4197\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5611 - tp: 106.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 292.0000 - accuracy: 0.8167 - precision: 0.5730 - recall: 0.2663 - auc: 0.7115 - prc: 0.4648 - val_loss: 0.4412 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6912 - val_prc: 0.4272\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5603 - tp: 103.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 295.0000 - accuracy: 0.8162 - precision: 0.5722 - recall: 0.2588 - auc: 0.7113 - prc: 0.4685 - val_loss: 0.4454 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6880 - val_prc: 0.4268\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5618 - tp: 117.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 281.0000 - accuracy: 0.8108 - precision: 0.5342 - recall: 0.2940 - auc: 0.7122 - prc: 0.4661 - val_loss: 0.4538 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6927 - val_prc: 0.4214\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - tp: 112.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 286.0000 - accuracy: 0.8162 - precision: 0.5657 - recall: 0.2814 - auc: 0.7121 - prc: 0.4661 - val_loss: 0.4428 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6882 - val_prc: 0.4268\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5605 - tp: 100.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 298.0000 - accuracy: 0.8157 - precision: 0.5714 - recall: 0.2513 - auc: 0.7110 - prc: 0.4677 - val_loss: 0.4451 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6900 - val_prc: 0.4284\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - tp: 108.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 290.0000 - accuracy: 0.8157 - precision: 0.5654 - recall: 0.2714 - auc: 0.7116 - prc: 0.4681 - val_loss: 0.4463 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6929 - val_prc: 0.4281\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - tp: 101.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 297.0000 - accuracy: 0.8142 - precision: 0.5611 - recall: 0.2538 - auc: 0.7105 - prc: 0.4682 - val_loss: 0.4431 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6895 - val_prc: 0.4310\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5603 - tp: 112.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 286.0000 - accuracy: 0.8152 - precision: 0.5600 - recall: 0.2814 - auc: 0.7123 - prc: 0.4682 - val_loss: 0.4481 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6913 - val_prc: 0.4294\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - tp: 114.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 284.0000 - accuracy: 0.8147 - precision: 0.5561 - recall: 0.2864 - auc: 0.7127 - prc: 0.4686 - val_loss: 0.4444 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6889 - val_prc: 0.4304\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - tp: 100.0000 - fp: 64.0000 - tn: 1562.0000 - fn: 298.0000 - accuracy: 0.8211 - precision: 0.6098 - recall: 0.2513 - auc: 0.7106 - prc: 0.4692 - val_loss: 0.4376 - val_tp: 18.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 73.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1978 - val_auc: 0.6909 - val_prc: 0.4350\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5601 - tp: 102.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 296.0000 - accuracy: 0.8172 - precision: 0.5795 - recall: 0.2563 - auc: 0.7120 - prc: 0.4677 - val_loss: 0.4453 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6888 - val_prc: 0.4279\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5607 - tp: 116.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 282.0000 - accuracy: 0.8157 - precision: 0.5604 - recall: 0.2915 - auc: 0.7131 - prc: 0.4687 - val_loss: 0.4468 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6919 - val_prc: 0.4292\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5600 - tp: 100.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 298.0000 - accuracy: 0.8157 - precision: 0.5714 - recall: 0.2513 - auc: 0.7113 - prc: 0.4682 - val_loss: 0.4401 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6916 - val_prc: 0.4316\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5597 - tp: 103.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 295.0000 - accuracy: 0.8162 - precision: 0.5722 - recall: 0.2588 - auc: 0.7119 - prc: 0.4690 - val_loss: 0.4452 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6928 - val_prc: 0.4286\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5597 - tp: 105.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 293.0000 - accuracy: 0.8172 - precision: 0.5769 - recall: 0.2638 - auc: 0.7129 - prc: 0.4703 - val_loss: 0.4391 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6907 - val_prc: 0.4304\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5596 - tp: 110.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 288.0000 - accuracy: 0.8197 - precision: 0.5882 - recall: 0.2764 - auc: 0.7133 - prc: 0.4698 - val_loss: 0.4485 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6943 - val_prc: 0.4277\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5616 - tp: 123.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 275.0000 - accuracy: 0.8118 - precision: 0.5371 - recall: 0.3090 - auc: 0.7144 - prc: 0.4688 - val_loss: 0.4531 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6945 - val_prc: 0.4260\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5597 - tp: 105.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 293.0000 - accuracy: 0.8147 - precision: 0.5615 - recall: 0.2638 - auc: 0.7117 - prc: 0.4679 - val_loss: 0.4349 - val_tp: 18.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 73.0000 - val_accuracy: 0.8261 - val_precision: 0.5455 - val_recall: 0.1978 - val_auc: 0.6909 - val_prc: 0.4314\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5608 - tp: 90.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 308.0000 - accuracy: 0.8197 - precision: 0.6122 - recall: 0.2261 - auc: 0.7123 - prc: 0.4696 - val_loss: 0.4400 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6904 - val_prc: 0.4303\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5599 - tp: 116.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 282.0000 - accuracy: 0.8147 - precision: 0.5550 - recall: 0.2915 - auc: 0.7144 - prc: 0.4698 - val_loss: 0.4529 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6934 - val_prc: 0.4288\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5617 - tp: 121.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 277.0000 - accuracy: 0.8078 - precision: 0.5193 - recall: 0.3040 - auc: 0.7156 - prc: 0.4685 - val_loss: 0.4455 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6936 - val_prc: 0.4340\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5601 - tp: 101.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 297.0000 - accuracy: 0.8207 - precision: 0.6048 - recall: 0.2538 - auc: 0.7112 - prc: 0.4693 - val_loss: 0.4372 - val_tp: 18.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 73.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.1978 - val_auc: 0.6913 - val_prc: 0.4307\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5595 - tp: 105.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 293.0000 - accuracy: 0.8157 - precision: 0.5676 - recall: 0.2638 - auc: 0.7155 - prc: 0.4694 - val_loss: 0.4492 - val_tp: 25.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 66.0000 - val_accuracy: 0.8162 - val_precision: 0.4808 - val_recall: 0.2747 - val_auc: 0.6950 - val_prc: 0.4285\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5599 - tp: 104.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 294.0000 - accuracy: 0.8177 - precision: 0.5810 - recall: 0.2613 - auc: 0.7120 - prc: 0.4696 - val_loss: 0.4372 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6909 - val_prc: 0.4303\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5593 - tp: 98.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 300.0000 - accuracy: 0.8137 - precision: 0.5600 - recall: 0.2462 - auc: 0.7143 - prc: 0.4700 - val_loss: 0.4471 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6960 - val_prc: 0.4297\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5597 - tp: 117.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 281.0000 - accuracy: 0.8162 - precision: 0.5625 - recall: 0.2940 - auc: 0.7148 - prc: 0.4707 - val_loss: 0.4479 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6956 - val_prc: 0.4329\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5594 - tp: 115.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 283.0000 - accuracy: 0.8167 - precision: 0.5665 - recall: 0.2889 - auc: 0.7161 - prc: 0.4710 - val_loss: 0.4449 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6961 - val_prc: 0.4358\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5591 - tp: 107.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 291.0000 - accuracy: 0.8137 - precision: 0.5544 - recall: 0.2688 - auc: 0.7165 - prc: 0.4714 - val_loss: 0.4452 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6966 - val_prc: 0.4351\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5592 - tp: 114.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 284.0000 - accuracy: 0.8162 - precision: 0.5644 - recall: 0.2864 - auc: 0.7154 - prc: 0.4702 - val_loss: 0.4459 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6953 - val_prc: 0.4286\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5596 - tp: 102.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 296.0000 - accuracy: 0.8192 - precision: 0.5930 - recall: 0.2563 - auc: 0.7131 - prc: 0.4702 - val_loss: 0.4386 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6914 - val_prc: 0.4292\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5594 - tp: 99.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 299.0000 - accuracy: 0.8187 - precision: 0.5928 - recall: 0.2487 - auc: 0.7127 - prc: 0.4705 - val_loss: 0.4410 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6924 - val_prc: 0.4304\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5592 - tp: 110.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 288.0000 - accuracy: 0.8167 - precision: 0.5699 - recall: 0.2764 - auc: 0.7156 - prc: 0.4701 - val_loss: 0.4464 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6946 - val_prc: 0.4294\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5603 - tp: 121.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 277.0000 - accuracy: 0.8152 - precision: 0.5550 - recall: 0.3040 - auc: 0.7155 - prc: 0.4698 - val_loss: 0.4444 - val_tp: 25.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 66.0000 - val_accuracy: 0.8261 - val_precision: 0.5319 - val_recall: 0.2747 - val_auc: 0.6938 - val_prc: 0.4350\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5608 - tp: 93.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 305.0000 - accuracy: 0.8207 - precision: 0.6159 - recall: 0.2337 - auc: 0.7119 - prc: 0.4662 - val_loss: 0.4329 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 73.0000 - val_accuracy: 0.8281 - val_precision: 0.5625 - val_recall: 0.1978 - val_auc: 0.6928 - val_prc: 0.4403\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5596 - tp: 102.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 296.0000 - accuracy: 0.8167 - precision: 0.5763 - recall: 0.2563 - auc: 0.7111 - prc: 0.4699 - val_loss: 0.4467 - val_tp: 26.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 65.0000 - val_accuracy: 0.8241 - val_precision: 0.5200 - val_recall: 0.2857 - val_auc: 0.6912 - val_prc: 0.4292\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5591 - tp: 116.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 282.0000 - accuracy: 0.8157 - precision: 0.5604 - recall: 0.2915 - auc: 0.7136 - prc: 0.4716 - val_loss: 0.4417 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6909 - val_prc: 0.4319\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5595 - tp: 115.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 283.0000 - accuracy: 0.8127 - precision: 0.5450 - recall: 0.2889 - auc: 0.7150 - prc: 0.4700 - val_loss: 0.4464 - val_tp: 26.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 65.0000 - val_accuracy: 0.8261 - val_precision: 0.5306 - val_recall: 0.2857 - val_auc: 0.6935 - val_prc: 0.4312\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5583 - tp: 111.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 287.0000 - accuracy: 0.8172 - precision: 0.5722 - recall: 0.2789 - auc: 0.7141 - prc: 0.4715 - val_loss: 0.4396 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6916 - val_prc: 0.4303\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5584 - tp: 105.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 293.0000 - accuracy: 0.8197 - precision: 0.5932 - recall: 0.2638 - auc: 0.7142 - prc: 0.4714 - val_loss: 0.4444 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6916 - val_prc: 0.4287\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5599 - tp: 118.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 280.0000 - accuracy: 0.8108 - precision: 0.5339 - recall: 0.2965 - auc: 0.7162 - prc: 0.4716 - val_loss: 0.4518 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6948 - val_prc: 0.4285\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5591 - tp: 106.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 292.0000 - accuracy: 0.8172 - precision: 0.5761 - recall: 0.2663 - auc: 0.7144 - prc: 0.4708 - val_loss: 0.4379 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6925 - val_prc: 0.4351\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - tp: 114.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 284.0000 - accuracy: 0.8211 - precision: 0.5938 - recall: 0.2864 - auc: 0.7129 - prc: 0.4709 - val_loss: 0.4449 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6960 - val_prc: 0.4363\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - tp: 107.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 291.0000 - accuracy: 0.8192 - precision: 0.5879 - recall: 0.2688 - auc: 0.7157 - prc: 0.4713 - val_loss: 0.4440 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6961 - val_prc: 0.4358\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5597 - tp: 119.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 279.0000 - accuracy: 0.8108 - precision: 0.5336 - recall: 0.2990 - auc: 0.7180 - prc: 0.4699 - val_loss: 0.4561 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6937 - val_prc: 0.4255\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5598 - tp: 122.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 276.0000 - accuracy: 0.8127 - precision: 0.5422 - recall: 0.3065 - auc: 0.7161 - prc: 0.4722 - val_loss: 0.4452 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6961 - val_prc: 0.4286\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5581 - tp: 106.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 292.0000 - accuracy: 0.8152 - precision: 0.5638 - recall: 0.2663 - auc: 0.7170 - prc: 0.4731 - val_loss: 0.4422 - val_tp: 20.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 71.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2198 - val_auc: 0.6953 - val_prc: 0.4307\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5581 - tp: 105.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 293.0000 - accuracy: 0.8202 - precision: 0.5966 - recall: 0.2638 - auc: 0.7170 - prc: 0.4724 - val_loss: 0.4401 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6916 - val_prc: 0.4304\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5597 - tp: 93.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 305.0000 - accuracy: 0.8202 - precision: 0.6118 - recall: 0.2337 - auc: 0.7117 - prc: 0.4717 - val_loss: 0.4361 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6930 - val_prc: 0.4377\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - tp: 118.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 280.0000 - accuracy: 0.8157 - precision: 0.5592 - recall: 0.2965 - auc: 0.7124 - prc: 0.4679 - val_loss: 0.4540 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6943 - val_prc: 0.4356\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5597 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7164 - prc: 0.4678 - val_loss: 0.4392 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6924 - val_prc: 0.4380\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5586 - tp: 97.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 301.0000 - accuracy: 0.8202 - precision: 0.6062 - recall: 0.2437 - auc: 0.7145 - prc: 0.4737 - val_loss: 0.4380 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6930 - val_prc: 0.4374\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5579 - tp: 104.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 294.0000 - accuracy: 0.8177 - precision: 0.5810 - recall: 0.2613 - auc: 0.7174 - prc: 0.4731 - val_loss: 0.4453 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6955 - val_prc: 0.4359\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - tp: 108.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 290.0000 - accuracy: 0.8182 - precision: 0.5806 - recall: 0.2714 - auc: 0.7140 - prc: 0.4702 - val_loss: 0.4409 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6920 - val_prc: 0.4367\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5585 - tp: 119.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 279.0000 - accuracy: 0.8127 - precision: 0.5434 - recall: 0.2990 - auc: 0.7183 - prc: 0.4738 - val_loss: 0.4527 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6948 - val_prc: 0.4349\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5589 - tp: 119.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 279.0000 - accuracy: 0.8127 - precision: 0.5434 - recall: 0.2990 - auc: 0.7174 - prc: 0.4719 - val_loss: 0.4406 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6931 - val_prc: 0.4410\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5588 - tp: 102.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 296.0000 - accuracy: 0.8192 - precision: 0.5930 - recall: 0.2563 - auc: 0.7095 - prc: 0.4713 - val_loss: 0.4361 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6923 - val_prc: 0.4424\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5581 - tp: 104.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 294.0000 - accuracy: 0.8172 - precision: 0.5778 - recall: 0.2613 - auc: 0.7159 - prc: 0.4726 - val_loss: 0.4412 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6970 - val_prc: 0.4391\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5580 - tp: 113.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 285.0000 - accuracy: 0.8142 - precision: 0.5539 - recall: 0.2839 - auc: 0.7148 - prc: 0.4732 - val_loss: 0.4452 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6958 - val_prc: 0.4391\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5579 - tp: 117.0000 - fp: 94.0000 - tn: 1532.0000 - fn: 281.0000 - accuracy: 0.8147 - precision: 0.5545 - recall: 0.2940 - auc: 0.7171 - prc: 0.4743 - val_loss: 0.4428 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6964 - val_prc: 0.4382\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5576 - tp: 106.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 292.0000 - accuracy: 0.8142 - precision: 0.5579 - recall: 0.2663 - auc: 0.7177 - prc: 0.4741 - val_loss: 0.4405 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6971 - val_prc: 0.4386\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5577 - tp: 104.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 294.0000 - accuracy: 0.8187 - precision: 0.5876 - recall: 0.2613 - auc: 0.7175 - prc: 0.4744 - val_loss: 0.4382 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6980 - val_prc: 0.4410\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5578 - tp: 104.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 294.0000 - accuracy: 0.8192 - precision: 0.5909 - recall: 0.2613 - auc: 0.7169 - prc: 0.4736 - val_loss: 0.4423 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6965 - val_prc: 0.4386\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5591 - tp: 119.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 279.0000 - accuracy: 0.8142 - precision: 0.5509 - recall: 0.2990 - auc: 0.7156 - prc: 0.4722 - val_loss: 0.4485 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6942 - val_prc: 0.4294\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5582 - tp: 108.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 290.0000 - accuracy: 0.8197 - precision: 0.5902 - recall: 0.2714 - auc: 0.7175 - prc: 0.4721 - val_loss: 0.4389 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6967 - val_prc: 0.4315\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5583 - tp: 99.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 299.0000 - accuracy: 0.8202 - precision: 0.6037 - recall: 0.2487 - auc: 0.7170 - prc: 0.4730 - val_loss: 0.4410 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6958 - val_prc: 0.4325\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - tp: 111.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 287.0000 - accuracy: 0.8177 - precision: 0.5751 - recall: 0.2789 - auc: 0.7179 - prc: 0.4745 - val_loss: 0.4483 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6934 - val_prc: 0.4332\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5582 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7165 - prc: 0.4725 - val_loss: 0.4429 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6961 - val_prc: 0.4378\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - tp: 123.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 275.0000 - accuracy: 0.8132 - precision: 0.5442 - recall: 0.3090 - auc: 0.7187 - prc: 0.4722 - val_loss: 0.4503 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6937 - val_prc: 0.4361\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5577 - tp: 108.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 290.0000 - accuracy: 0.8152 - precision: 0.5625 - recall: 0.2714 - auc: 0.7176 - prc: 0.4733 - val_loss: 0.4389 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6977 - val_prc: 0.4382\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5575 - tp: 114.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 284.0000 - accuracy: 0.8157 - precision: 0.5616 - recall: 0.2864 - auc: 0.7177 - prc: 0.4733 - val_loss: 0.4459 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6951 - val_prc: 0.4368\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 115.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 283.0000 - accuracy: 0.8162 - precision: 0.5637 - recall: 0.2889 - auc: 0.7185 - prc: 0.4751 - val_loss: 0.4391 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6976 - val_prc: 0.4399\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5576 - tp: 105.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 293.0000 - accuracy: 0.8197 - precision: 0.5932 - recall: 0.2638 - auc: 0.7178 - prc: 0.4738 - val_loss: 0.4400 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6968 - val_prc: 0.4385\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5572 - tp: 106.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 292.0000 - accuracy: 0.8182 - precision: 0.5824 - recall: 0.2663 - auc: 0.7185 - prc: 0.4749 - val_loss: 0.4417 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6959 - val_prc: 0.4384\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5572 - tp: 110.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 288.0000 - accuracy: 0.8157 - precision: 0.5641 - recall: 0.2764 - auc: 0.7179 - prc: 0.4743 - val_loss: 0.4426 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6959 - val_prc: 0.4362\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5573 - tp: 106.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 292.0000 - accuracy: 0.8197 - precision: 0.5922 - recall: 0.2663 - auc: 0.7162 - prc: 0.4743 - val_loss: 0.4390 - val_tp: 21.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 70.0000 - val_accuracy: 0.8221 - val_precision: 0.5122 - val_recall: 0.2308 - val_auc: 0.6918 - val_prc: 0.4302\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 107.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 291.0000 - accuracy: 0.8167 - precision: 0.5722 - recall: 0.2688 - auc: 0.7176 - prc: 0.4750 - val_loss: 0.4424 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6962 - val_prc: 0.4312\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 107.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 291.0000 - accuracy: 0.8167 - precision: 0.5722 - recall: 0.2688 - auc: 0.7184 - prc: 0.4748 - val_loss: 0.4399 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6933 - val_prc: 0.4300\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5578 - tp: 100.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 298.0000 - accuracy: 0.8197 - precision: 0.5988 - recall: 0.2513 - auc: 0.7152 - prc: 0.4740 - val_loss: 0.4364 - val_tp: 19.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 72.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2088 - val_auc: 0.6893 - val_prc: 0.4282\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 109.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 289.0000 - accuracy: 0.8157 - precision: 0.5648 - recall: 0.2739 - auc: 0.7152 - prc: 0.4738 - val_loss: 0.4479 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6945 - val_prc: 0.4347\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5577 - tp: 114.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 284.0000 - accuracy: 0.8142 - precision: 0.5534 - recall: 0.2864 - auc: 0.7178 - prc: 0.4739 - val_loss: 0.4422 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6964 - val_prc: 0.4354\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5582 - tp: 122.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 276.0000 - accuracy: 0.8137 - precision: 0.5471 - recall: 0.3065 - auc: 0.7175 - prc: 0.4742 - val_loss: 0.4487 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6941 - val_prc: 0.4344\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5576 - tp: 107.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 291.0000 - accuracy: 0.8187 - precision: 0.5847 - recall: 0.2688 - auc: 0.7176 - prc: 0.4733 - val_loss: 0.4353 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6948 - val_prc: 0.4381\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5576 - tp: 97.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 301.0000 - accuracy: 0.8211 - precision: 0.6139 - recall: 0.2437 - auc: 0.7171 - prc: 0.4749 - val_loss: 0.4399 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6963 - val_prc: 0.4377\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5575 - tp: 115.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 283.0000 - accuracy: 0.8157 - precision: 0.5610 - recall: 0.2889 - auc: 0.7180 - prc: 0.4739 - val_loss: 0.4475 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6939 - val_prc: 0.4279\n",
      "Epoch 247/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5575 - tp: 120.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 278.0000 - accuracy: 0.8167 - precision: 0.5634 - recall: 0.3015 - auc: 0.7191 - prc: 0.4755 - val_loss: 0.4415 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6967 - val_prc: 0.4326\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 105.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 293.0000 - accuracy: 0.8187 - precision: 0.5866 - recall: 0.2638 - auc: 0.7183 - prc: 0.4747 - val_loss: 0.4400 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6944 - val_prc: 0.4283\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - tp: 123.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 275.0000 - accuracy: 0.8167 - precision: 0.5616 - recall: 0.3090 - auc: 0.7186 - prc: 0.4762 - val_loss: 0.4535 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6922 - val_prc: 0.4287\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 115.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 283.0000 - accuracy: 0.8182 - precision: 0.5750 - recall: 0.2889 - auc: 0.7184 - prc: 0.4739 - val_loss: 0.4371 - val_tp: 20.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 71.0000 - val_accuracy: 0.8221 - val_precision: 0.5128 - val_recall: 0.2198 - val_auc: 0.6967 - val_prc: 0.4352\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - tp: 106.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 292.0000 - accuracy: 0.8192 - precision: 0.5889 - recall: 0.2663 - auc: 0.7195 - prc: 0.4770 - val_loss: 0.4417 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6958 - val_prc: 0.4397\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5570 - tp: 111.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 287.0000 - accuracy: 0.8152 - precision: 0.5606 - recall: 0.2789 - auc: 0.7190 - prc: 0.4750 - val_loss: 0.4431 - val_tp: 27.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 64.0000 - val_accuracy: 0.8241 - val_precision: 0.5192 - val_recall: 0.2967 - val_auc: 0.6962 - val_prc: 0.4429\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5566 - tp: 111.0000 - fp: 81.0000 - tn: 1545.0000 - fn: 287.0000 - accuracy: 0.8182 - precision: 0.5781 - recall: 0.2789 - auc: 0.7179 - prc: 0.4750 - val_loss: 0.4375 - val_tp: 23.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.5476 - val_recall: 0.2527 - val_auc: 0.6944 - val_prc: 0.4390\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5568 - tp: 106.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 292.0000 - accuracy: 0.8177 - precision: 0.5792 - recall: 0.2663 - auc: 0.7176 - prc: 0.4747 - val_loss: 0.4408 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6949 - val_prc: 0.4353\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - tp: 106.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 292.0000 - accuracy: 0.8177 - precision: 0.5792 - recall: 0.2663 - auc: 0.7191 - prc: 0.4755 - val_loss: 0.4402 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6952 - val_prc: 0.4343\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5567 - tp: 112.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 286.0000 - accuracy: 0.8157 - precision: 0.5628 - recall: 0.2814 - auc: 0.7188 - prc: 0.4748 - val_loss: 0.4426 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6945 - val_prc: 0.4338\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5566 - tp: 116.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 282.0000 - accuracy: 0.8162 - precision: 0.5631 - recall: 0.2915 - auc: 0.7187 - prc: 0.4753 - val_loss: 0.4438 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6945 - val_prc: 0.4353\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5568 - tp: 117.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 281.0000 - accuracy: 0.8172 - precision: 0.5680 - recall: 0.2940 - auc: 0.7198 - prc: 0.4760 - val_loss: 0.4425 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6942 - val_prc: 0.4329\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5573 - tp: 99.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 299.0000 - accuracy: 0.8182 - precision: 0.5893 - recall: 0.2487 - auc: 0.7197 - prc: 0.4745 - val_loss: 0.4365 - val_tp: 19.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 72.0000 - val_accuracy: 0.8221 - val_precision: 0.5135 - val_recall: 0.2088 - val_auc: 0.6951 - val_prc: 0.4335\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5559 - tp: 110.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 288.0000 - accuracy: 0.8162 - precision: 0.5670 - recall: 0.2764 - auc: 0.7202 - prc: 0.4762 - val_loss: 0.4474 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6934 - val_prc: 0.4309\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5579 - tp: 104.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 294.0000 - accuracy: 0.8167 - precision: 0.5746 - recall: 0.2613 - auc: 0.7175 - prc: 0.4719 - val_loss: 0.4342 - val_tp: 19.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 72.0000 - val_accuracy: 0.8241 - val_precision: 0.5278 - val_recall: 0.2088 - val_auc: 0.6970 - val_prc: 0.4430\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5571 - tp: 103.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 295.0000 - accuracy: 0.8202 - precision: 0.5988 - recall: 0.2588 - auc: 0.7190 - prc: 0.4747 - val_loss: 0.4415 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6943 - val_prc: 0.4409\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5564 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7196 - prc: 0.4757 - val_loss: 0.4446 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6964 - val_prc: 0.4394\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5585 - tp: 127.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 271.0000 - accuracy: 0.8152 - precision: 0.5522 - recall: 0.3191 - auc: 0.7182 - prc: 0.4756 - val_loss: 0.4490 - val_tp: 27.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 64.0000 - val_accuracy: 0.8221 - val_precision: 0.5094 - val_recall: 0.2967 - val_auc: 0.6949 - val_prc: 0.4360\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5563 - tp: 110.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 288.0000 - accuracy: 0.8192 - precision: 0.5851 - recall: 0.2764 - auc: 0.7197 - prc: 0.4747 - val_loss: 0.4337 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 73.0000 - val_accuracy: 0.8281 - val_precision: 0.5625 - val_recall: 0.1978 - val_auc: 0.6959 - val_prc: 0.4389\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5575 - tp: 97.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 301.0000 - accuracy: 0.8202 - precision: 0.6062 - recall: 0.2437 - auc: 0.7191 - prc: 0.4744 - val_loss: 0.4377 - val_tp: 20.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 71.0000 - val_accuracy: 0.8261 - val_precision: 0.5405 - val_recall: 0.2198 - val_auc: 0.6941 - val_prc: 0.4372\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - tp: 103.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 295.0000 - accuracy: 0.8211 - precision: 0.6059 - recall: 0.2588 - auc: 0.7192 - prc: 0.4753 - val_loss: 0.4414 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6930 - val_prc: 0.4349\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - tp: 117.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 281.0000 - accuracy: 0.8157 - precision: 0.5598 - recall: 0.2940 - auc: 0.7182 - prc: 0.4746 - val_loss: 0.4493 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6935 - val_prc: 0.4269\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5581 - tp: 105.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 293.0000 - accuracy: 0.8172 - precision: 0.5769 - recall: 0.2638 - auc: 0.7184 - prc: 0.4700 - val_loss: 0.4355 - val_tp: 19.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 72.0000 - val_accuracy: 0.8261 - val_precision: 0.5429 - val_recall: 0.2088 - val_auc: 0.6947 - val_prc: 0.4332\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5561 - tp: 106.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 292.0000 - accuracy: 0.8187 - precision: 0.5856 - recall: 0.2663 - auc: 0.7202 - prc: 0.4763 - val_loss: 0.4443 - val_tp: 25.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 66.0000 - val_accuracy: 0.8241 - val_precision: 0.5208 - val_recall: 0.2747 - val_auc: 0.6929 - val_prc: 0.4328\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5568 - tp: 120.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 278.0000 - accuracy: 0.8157 - precision: 0.5581 - recall: 0.3015 - auc: 0.7203 - prc: 0.4760 - val_loss: 0.4473 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6948 - val_prc: 0.4318\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5567 - tp: 106.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 292.0000 - accuracy: 0.8172 - precision: 0.5761 - recall: 0.2663 - auc: 0.7188 - prc: 0.4745 - val_loss: 0.4365 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6954 - val_prc: 0.4362\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5563 - tp: 113.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 285.0000 - accuracy: 0.8147 - precision: 0.5567 - recall: 0.2839 - auc: 0.7197 - prc: 0.4754 - val_loss: 0.4477 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6947 - val_prc: 0.4310\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5566 - tp: 110.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 288.0000 - accuracy: 0.8192 - precision: 0.5851 - recall: 0.2764 - auc: 0.7201 - prc: 0.4732 - val_loss: 0.4371 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6944 - val_prc: 0.4302\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5563 - tp: 111.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 287.0000 - accuracy: 0.8177 - precision: 0.5751 - recall: 0.2789 - auc: 0.7199 - prc: 0.4755 - val_loss: 0.4447 - val_tp: 25.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 66.0000 - val_accuracy: 0.8221 - val_precision: 0.5102 - val_recall: 0.2747 - val_auc: 0.6946 - val_prc: 0.4308\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5559 - tp: 109.0000 - fp: 85.0000 - tn: 1541.0000 - fn: 289.0000 - accuracy: 0.8152 - precision: 0.5619 - recall: 0.2739 - auc: 0.7212 - prc: 0.4765 - val_loss: 0.4386 - val_tp: 24.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 67.0000 - val_accuracy: 0.8300 - val_precision: 0.5581 - val_recall: 0.2637 - val_auc: 0.6954 - val_prc: 0.4406\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5562 - tp: 104.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 294.0000 - accuracy: 0.8211 - precision: 0.6047 - recall: 0.2613 - auc: 0.7205 - prc: 0.4762 - val_loss: 0.4373 - val_tp: 22.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 69.0000 - val_accuracy: 0.8281 - val_precision: 0.5500 - val_recall: 0.2418 - val_auc: 0.6954 - val_prc: 0.4402\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5557 - tp: 111.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 287.0000 - accuracy: 0.8152 - precision: 0.5606 - recall: 0.2789 - auc: 0.7215 - prc: 0.4768 - val_loss: 0.4477 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6957 - val_prc: 0.4316\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5559 - tp: 115.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 283.0000 - accuracy: 0.8167 - precision: 0.5665 - recall: 0.2889 - auc: 0.7211 - prc: 0.4770 - val_loss: 0.4383 - val_tp: 23.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 68.0000 - val_accuracy: 0.8281 - val_precision: 0.5476 - val_recall: 0.2527 - val_auc: 0.6956 - val_prc: 0.4405\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5568 - tp: 97.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 301.0000 - accuracy: 0.8211 - precision: 0.6139 - recall: 0.2437 - auc: 0.7196 - prc: 0.4760 - val_loss: 0.4329 - val_tp: 19.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 72.0000 - val_accuracy: 0.8281 - val_precision: 0.5588 - val_recall: 0.2088 - val_auc: 0.6982 - val_prc: 0.4462\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5563 - tp: 106.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 292.0000 - accuracy: 0.8177 - precision: 0.5792 - recall: 0.2663 - auc: 0.7205 - prc: 0.4745 - val_loss: 0.4450 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6962 - val_prc: 0.4399\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5560 - tp: 115.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 283.0000 - accuracy: 0.8152 - precision: 0.5583 - recall: 0.2889 - auc: 0.7210 - prc: 0.4767 - val_loss: 0.4429 - val_tp: 24.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 67.0000 - val_accuracy: 0.8241 - val_precision: 0.5217 - val_recall: 0.2637 - val_auc: 0.6931 - val_prc: 0.4251\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5560 - tp: 115.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 283.0000 - accuracy: 0.8167 - precision: 0.5665 - recall: 0.2889 - auc: 0.7212 - prc: 0.4762 - val_loss: 0.4446 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6927 - val_prc: 0.4220\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5558 - tp: 108.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 290.0000 - accuracy: 0.8192 - precision: 0.5870 - recall: 0.2714 - auc: 0.7212 - prc: 0.4757 - val_loss: 0.4410 - val_tp: 23.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 68.0000 - val_accuracy: 0.8221 - val_precision: 0.5111 - val_recall: 0.2527 - val_auc: 0.6924 - val_prc: 0.4235\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5557 - tp: 116.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 282.0000 - accuracy: 0.8162 - precision: 0.5631 - recall: 0.2915 - auc: 0.7214 - prc: 0.4768 - val_loss: 0.4473 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6941 - val_prc: 0.4276\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5568 - tp: 125.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 273.0000 - accuracy: 0.8142 - precision: 0.5482 - recall: 0.3141 - auc: 0.7208 - prc: 0.4760 - val_loss: 0.4453 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6919 - val_prc: 0.4268\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5579 - tp: 99.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 299.0000 - accuracy: 0.8197 - precision: 0.6000 - recall: 0.2487 - auc: 0.7195 - prc: 0.4722 - val_loss: 0.4325 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 73.0000 - val_accuracy: 0.8281 - val_precision: 0.5625 - val_recall: 0.1978 - val_auc: 0.6958 - val_prc: 0.4324\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5566 - tp: 105.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 293.0000 - accuracy: 0.8216 - precision: 0.6069 - recall: 0.2638 - auc: 0.7194 - prc: 0.4749 - val_loss: 0.4450 - val_tp: 26.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 65.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.6944 - val_prc: 0.4312\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5555 - tp: 116.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 282.0000 - accuracy: 0.8162 - precision: 0.5631 - recall: 0.2915 - auc: 0.7212 - prc: 0.4772 - val_loss: 0.4412 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6939 - val_prc: 0.4321\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5557 - tp: 105.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 293.0000 - accuracy: 0.8172 - precision: 0.5769 - recall: 0.2638 - auc: 0.7214 - prc: 0.4768 - val_loss: 0.4360 - val_tp: 22.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 69.0000 - val_accuracy: 0.8281 - val_precision: 0.5500 - val_recall: 0.2418 - val_auc: 0.6959 - val_prc: 0.4358\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5555 - tp: 104.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 294.0000 - accuracy: 0.8192 - precision: 0.5909 - recall: 0.2613 - auc: 0.7208 - prc: 0.4775 - val_loss: 0.4400 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6941 - val_prc: 0.4343\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5556 - tp: 119.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 279.0000 - accuracy: 0.8147 - precision: 0.5535 - recall: 0.2990 - auc: 0.7229 - prc: 0.4772 - val_loss: 0.4465 - val_tp: 28.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 63.0000 - val_accuracy: 0.8241 - val_precision: 0.5185 - val_recall: 0.3077 - val_auc: 0.6954 - val_prc: 0.4364\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5559 - tp: 114.0000 - fp: 84.0000 - tn: 1542.0000 - fn: 284.0000 - accuracy: 0.8182 - precision: 0.5758 - recall: 0.2864 - auc: 0.7212 - prc: 0.4748 - val_loss: 0.4373 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6950 - val_prc: 0.4415\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5555 - tp: 109.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 289.0000 - accuracy: 0.8167 - precision: 0.5707 - recall: 0.2739 - auc: 0.7215 - prc: 0.4768 - val_loss: 0.4435 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6947 - val_prc: 0.4365\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5559 - tp: 120.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 278.0000 - accuracy: 0.8172 - precision: 0.5660 - recall: 0.3015 - auc: 0.7218 - prc: 0.4767 - val_loss: 0.4417 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6943 - val_prc: 0.4356\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5549 - tp: 106.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 292.0000 - accuracy: 0.8187 - precision: 0.5856 - recall: 0.2663 - auc: 0.7219 - prc: 0.4776 - val_loss: 0.4339 - val_tp: 20.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 71.0000 - val_accuracy: 0.8281 - val_precision: 0.5556 - val_recall: 0.2198 - val_auc: 0.6965 - val_prc: 0.4430\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5562 - tp: 100.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 298.0000 - accuracy: 0.8192 - precision: 0.5952 - recall: 0.2513 - auc: 0.7216 - prc: 0.4763 - val_loss: 0.4359 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6950 - val_prc: 0.4405\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5553 - tp: 109.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 289.0000 - accuracy: 0.8177 - precision: 0.5767 - recall: 0.2739 - auc: 0.7210 - prc: 0.4768 - val_loss: 0.4413 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6932 - val_prc: 0.4321\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5571 - tp: 123.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 275.0000 - accuracy: 0.8142 - precision: 0.5491 - recall: 0.3090 - auc: 0.7205 - prc: 0.4754 - val_loss: 0.4465 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6919 - val_prc: 0.4265\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - tp: 101.0000 - fp: 67.0000 - tn: 1559.0000 - fn: 297.0000 - accuracy: 0.8202 - precision: 0.6012 - recall: 0.2538 - auc: 0.7210 - prc: 0.4748 - val_loss: 0.4322 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 73.0000 - val_accuracy: 0.8281 - val_precision: 0.5625 - val_recall: 0.1978 - val_auc: 0.6946 - val_prc: 0.4334\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5562 - tp: 97.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 301.0000 - accuracy: 0.8207 - precision: 0.6101 - recall: 0.2437 - auc: 0.7225 - prc: 0.4771 - val_loss: 0.4416 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6940 - val_prc: 0.4326\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5553 - tp: 113.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 285.0000 - accuracy: 0.8152 - precision: 0.5594 - recall: 0.2839 - auc: 0.7215 - prc: 0.4771 - val_loss: 0.4449 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6924 - val_prc: 0.4304\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5554 - tp: 109.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 289.0000 - accuracy: 0.8177 - precision: 0.5767 - recall: 0.2739 - auc: 0.7214 - prc: 0.4770 - val_loss: 0.4386 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6960 - val_prc: 0.4389\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5551 - tp: 105.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 293.0000 - accuracy: 0.8182 - precision: 0.5833 - recall: 0.2638 - auc: 0.7228 - prc: 0.4768 - val_loss: 0.4361 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6965 - val_prc: 0.4457\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5555 - tp: 103.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 295.0000 - accuracy: 0.8192 - precision: 0.5920 - recall: 0.2588 - auc: 0.7227 - prc: 0.4770 - val_loss: 0.4372 - val_tp: 22.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 69.0000 - val_accuracy: 0.8261 - val_precision: 0.5366 - val_recall: 0.2418 - val_auc: 0.6963 - val_prc: 0.4417\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5570 - tp: 116.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 282.0000 - accuracy: 0.8157 - precision: 0.5604 - recall: 0.2915 - auc: 0.7202 - prc: 0.4737 - val_loss: 0.4452 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6934 - val_prc: 0.4373\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5557 - tp: 105.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 293.0000 - accuracy: 0.8177 - precision: 0.5801 - recall: 0.2638 - auc: 0.7213 - prc: 0.4756 - val_loss: 0.4351 - val_tp: 18.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 73.0000 - val_accuracy: 0.8241 - val_precision: 0.5294 - val_recall: 0.1978 - val_auc: 0.6947 - val_prc: 0.4379\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5561 - tp: 97.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 301.0000 - accuracy: 0.8211 - precision: 0.6139 - recall: 0.2437 - auc: 0.7226 - prc: 0.4776 - val_loss: 0.4369 - val_tp: 20.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 71.0000 - val_accuracy: 0.8241 - val_precision: 0.5263 - val_recall: 0.2198 - val_auc: 0.6931 - val_prc: 0.4307\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5570 - tp: 117.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 281.0000 - accuracy: 0.8132 - precision: 0.5467 - recall: 0.2940 - auc: 0.7198 - prc: 0.4746 - val_loss: 0.4507 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 63.0000 - val_accuracy: 0.8182 - val_precision: 0.4912 - val_recall: 0.3077 - val_auc: 0.6915 - val_prc: 0.4281\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - tp: 105.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 293.0000 - accuracy: 0.8147 - precision: 0.5615 - recall: 0.2638 - auc: 0.7192 - prc: 0.4719 - val_loss: 0.4319 - val_tp: 18.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 73.0000 - val_accuracy: 0.8281 - val_precision: 0.5625 - val_recall: 0.1978 - val_auc: 0.6956 - val_prc: 0.4404\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5555 - tp: 102.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 296.0000 - accuracy: 0.8157 - precision: 0.5698 - recall: 0.2563 - auc: 0.7228 - prc: 0.4755 - val_loss: 0.4386 - val_tp: 23.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 68.0000 - val_accuracy: 0.8261 - val_precision: 0.5349 - val_recall: 0.2527 - val_auc: 0.6942 - val_prc: 0.4379\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5547 - tp: 107.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 291.0000 - accuracy: 0.8172 - precision: 0.5753 - recall: 0.2688 - auc: 0.7231 - prc: 0.4778 - val_loss: 0.4377 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6939 - val_prc: 0.4356\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5551 - tp: 105.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 293.0000 - accuracy: 0.8187 - precision: 0.5866 - recall: 0.2638 - auc: 0.7228 - prc: 0.4779 - val_loss: 0.4357 - val_tp: 21.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 70.0000 - val_accuracy: 0.8261 - val_precision: 0.5385 - val_recall: 0.2308 - val_auc: 0.6946 - val_prc: 0.4364\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5550 - tp: 104.0000 - fp: 72.0000 - tn: 1554.0000 - fn: 294.0000 - accuracy: 0.8192 - precision: 0.5909 - recall: 0.2613 - auc: 0.7230 - prc: 0.4781 - val_loss: 0.4381 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6940 - val_prc: 0.4368\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5548 - tp: 107.0000 - fp: 78.0000 - tn: 1548.0000 - fn: 291.0000 - accuracy: 0.8177 - precision: 0.5784 - recall: 0.2688 - auc: 0.7231 - prc: 0.4773 - val_loss: 0.4417 - val_tp: 24.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 67.0000 - val_accuracy: 0.8182 - val_precision: 0.4898 - val_recall: 0.2637 - val_auc: 0.6940 - val_prc: 0.4343\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5546 - tp: 106.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 292.0000 - accuracy: 0.8162 - precision: 0.5699 - recall: 0.2663 - auc: 0.7231 - prc: 0.4772 - val_loss: 0.4378 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6948 - val_prc: 0.4424\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5554 - tp: 118.0000 - fp: 94.0000 - tn: 1532.0000 - fn: 280.0000 - accuracy: 0.8152 - precision: 0.5566 - recall: 0.2965 - auc: 0.7225 - prc: 0.4754 - val_loss: 0.4467 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 62.0000 - val_accuracy: 0.8221 - val_precision: 0.5088 - val_recall: 0.3187 - val_auc: 0.6946 - val_prc: 0.4437\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5551 - tp: 113.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 285.0000 - accuracy: 0.8167 - precision: 0.5678 - recall: 0.2839 - auc: 0.7231 - prc: 0.4757 - val_loss: 0.4353 - val_tp: 22.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 69.0000 - val_accuracy: 0.8281 - val_precision: 0.5500 - val_recall: 0.2418 - val_auc: 0.6965 - val_prc: 0.4433\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5548 - tp: 105.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 293.0000 - accuracy: 0.8182 - precision: 0.5833 - recall: 0.2638 - auc: 0.7234 - prc: 0.4781 - val_loss: 0.4385 - val_tp: 24.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 67.0000 - val_accuracy: 0.8281 - val_precision: 0.5455 - val_recall: 0.2637 - val_auc: 0.6948 - val_prc: 0.4396\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5554 - tp: 117.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 281.0000 - accuracy: 0.8152 - precision: 0.5571 - recall: 0.2940 - auc: 0.7227 - prc: 0.4756 - val_loss: 0.4431 - val_tp: 26.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 65.0000 - val_accuracy: 0.8221 - val_precision: 0.5098 - val_recall: 0.2857 - val_auc: 0.6943 - val_prc: 0.4340\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5545 - tp: 111.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 287.0000 - accuracy: 0.8137 - precision: 0.5522 - recall: 0.2789 - auc: 0.7236 - prc: 0.4779 - val_loss: 0.4401 - val_tp: 24.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 67.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2637 - val_auc: 0.6950 - val_prc: 0.4361\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5544 - tp: 112.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 286.0000 - accuracy: 0.8152 - precision: 0.5600 - recall: 0.2814 - auc: 0.7235 - prc: 0.4772 - val_loss: 0.4409 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6943 - val_prc: 0.4357\n",
      "Epoch 323/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5545 - tp: 112.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 286.0000 - accuracy: 0.8152 - precision: 0.5600 - recall: 0.2814 - auc: 0.7242 - prc: 0.4778 - val_loss: 0.4393 - val_tp: 24.0000 - val_fp: 23.0000 - val_tn: 392.0000 - val_fn: 67.0000 - val_accuracy: 0.8221 - val_precision: 0.5106 - val_recall: 0.2637 - val_auc: 0.6933 - val_prc: 0.4317\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5552 - tp: 104.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 294.0000 - accuracy: 0.8187 - precision: 0.5876 - recall: 0.2613 - auc: 0.7225 - prc: 0.4761 - val_loss: 0.4354 - val_tp: 21.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 70.0000 - val_accuracy: 0.8281 - val_precision: 0.5526 - val_recall: 0.2308 - val_auc: 0.6953 - val_prc: 0.4347\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5554 - tp: 111.0000 - fp: 88.0000 - tn: 1538.0000 - fn: 287.0000 - accuracy: 0.8147 - precision: 0.5578 - recall: 0.2789 - auc: 0.7227 - prc: 0.4751 - val_loss: 0.4418 - val_tp: 25.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 66.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2747 - val_auc: 0.6943 - val_prc: 0.4357\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5546 - tp: 106.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 292.0000 - accuracy: 0.8167 - precision: 0.5730 - recall: 0.2663 - auc: 0.7235 - prc: 0.4769 - val_loss: 0.4347 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6960 - val_prc: 0.4408\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5553 - tp: 111.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 287.0000 - accuracy: 0.8152 - precision: 0.5606 - recall: 0.2789 - auc: 0.7214 - prc: 0.4762 - val_loss: 0.4461 - val_tp: 28.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 63.0000 - val_accuracy: 0.8261 - val_precision: 0.5283 - val_recall: 0.3077 - val_auc: 0.6919 - val_prc: 0.4292\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5546 - tp: 111.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 287.0000 - accuracy: 0.8152 - precision: 0.5606 - recall: 0.2789 - auc: 0.7233 - prc: 0.4771 - val_loss: 0.4391 - val_tp: 22.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 69.0000 - val_accuracy: 0.8221 - val_precision: 0.5116 - val_recall: 0.2418 - val_auc: 0.6929 - val_prc: 0.4315\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5545 - tp: 107.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 291.0000 - accuracy: 0.8182 - precision: 0.5815 - recall: 0.2688 - auc: 0.7235 - prc: 0.4774 - val_loss: 0.4380 - val_tp: 22.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 69.0000 - val_accuracy: 0.8241 - val_precision: 0.5238 - val_recall: 0.2418 - val_auc: 0.6931 - val_prc: 0.4336\n",
      "Epoch 330/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.6182 - tp: 8.0000 - fp: 8.0000 - tn: 150.0000 - fn: 34.0000 - accuracy: 0.7900 - precision: 0.5000 - recall: 0.1905 - auc: 0.6615 - prc: 0.3984Restoring model weights from the end of the best epoch: 280.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5548 - tp: 107.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 291.0000 - accuracy: 0.8192 - precision: 0.5879 - recall: 0.2688 - auc: 0.7226 - prc: 0.4779 - val_loss: 0.4404 - val_tp: 24.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 67.0000 - val_accuracy: 0.8261 - val_precision: 0.5333 - val_recall: 0.2637 - val_auc: 0.6923 - val_prc: 0.4313\n",
      "Epoch 330: early stopping\n",
      "3/3 [==============================] - 0s 852us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.8185 - tp: 24.0000 - fp: 21.0000 - tn: 2020.0000 - fn: 465.0000 - accuracy: 0.8079 - precision: 0.5333 - recall: 0.0491 - auc: 0.5255 - prc: 0.2442 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5274 - val_prc: 0.1887\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8139 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5007 - prc: 0.1998 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4707 - val_prc: 0.1701\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8086 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5155 - prc: 0.2257 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5338 - val_prc: 0.1956\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8027 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5508 - prc: 0.2341 - val_loss: 0.4741 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5220 - val_prc: 0.2035\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7962 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5781 - prc: 0.2635 - val_loss: 0.4755 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5856 - val_prc: 0.2471\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7883 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6279 - prc: 0.2966 - val_loss: 0.4773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5998 - val_prc: 0.2591\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7809 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6457 - prc: 0.3168 - val_loss: 0.4797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6266 - val_prc: 0.2735\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7732 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6493 - prc: 0.3280 - val_loss: 0.4831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6243 - val_prc: 0.2689\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7654 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6618 - prc: 0.3460 - val_loss: 0.4876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6329 - val_prc: 0.2745\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7588 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6707 - prc: 0.3565 - val_loss: 0.4923 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6357 - val_prc: 0.2797\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7524 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6866 - prc: 0.3676 - val_loss: 0.4992 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6416 - val_prc: 0.2800\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7478 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6760 - prc: 0.3595 - val_loss: 0.5077 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6424 - val_prc: 0.2778\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7435 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6786 - prc: 0.3575 - val_loss: 0.5174 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6498 - val_prc: 0.2800\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7400 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1625.0000 - fn: 398.0000 - accuracy: 0.8029 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6878 - prc: 0.3712 - val_loss: 0.5253 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6505 - val_prc: 0.2815\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7389 - tp: 2.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 396.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0050 - auc: 0.6855 - prc: 0.3684 - val_loss: 0.5340 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6564 - val_prc: 0.2874\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7382 - tp: 2.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 396.0000 - accuracy: 0.8024 - precision: 0.3333 - recall: 0.0050 - auc: 0.6905 - prc: 0.3755 - val_loss: 0.5392 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6536 - val_prc: 0.2856\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7381 - tp: 3.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 395.0000 - accuracy: 0.8029 - precision: 0.4286 - recall: 0.0075 - auc: 0.6901 - prc: 0.3769 - val_loss: 0.5414 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6567 - val_prc: 0.2874\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7373 - tp: 3.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 395.0000 - accuracy: 0.8029 - precision: 0.4286 - recall: 0.0075 - auc: 0.6941 - prc: 0.3806 - val_loss: 0.5361 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6516 - val_prc: 0.2888\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7366 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6865 - prc: 0.3767 - val_loss: 0.5260 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6571 - val_prc: 0.2902\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7358 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6913 - prc: 0.3814 - val_loss: 0.5265 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6593 - val_prc: 0.2917\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7352 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6937 - prc: 0.3829 - val_loss: 0.5252 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6565 - val_prc: 0.2918\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7345 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6942 - prc: 0.3850 - val_loss: 0.5260 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6583 - val_prc: 0.2938\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7335 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6920 - prc: 0.3884 - val_loss: 0.5275 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6573 - val_prc: 0.2948\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7323 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6911 - prc: 0.3929 - val_loss: 0.5263 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6584 - val_prc: 0.3038\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7308 - tp: 2.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 396.0000 - accuracy: 0.8029 - precision: 0.4000 - recall: 0.0050 - auc: 0.6904 - prc: 0.3948 - val_loss: 0.5219 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6597 - val_prc: 0.3096\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7298 - tp: 2.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 396.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0050 - auc: 0.6857 - prc: 0.3891 - val_loss: 0.5153 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6576 - val_prc: 0.3095\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7283 - tp: 2.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 396.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0050 - auc: 0.6862 - prc: 0.3919 - val_loss: 0.5194 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6580 - val_prc: 0.3074\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7268 - tp: 4.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 394.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0101 - auc: 0.6879 - prc: 0.3889 - val_loss: 0.5231 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6596 - val_prc: 0.3123\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7254 - tp: 6.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 392.0000 - accuracy: 0.8043 - precision: 0.6000 - recall: 0.0151 - auc: 0.6883 - prc: 0.3915 - val_loss: 0.5208 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6592 - val_prc: 0.3141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7245 - tp: 9.0000 - fp: 5.0000 - tn: 1621.0000 - fn: 389.0000 - accuracy: 0.8053 - precision: 0.6429 - recall: 0.0226 - auc: 0.6877 - prc: 0.3898 - val_loss: 0.5244 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6615 - val_prc: 0.3159\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7234 - tp: 9.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 389.0000 - accuracy: 0.8058 - precision: 0.6923 - recall: 0.0226 - auc: 0.6840 - prc: 0.3871 - val_loss: 0.5156 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6587 - val_prc: 0.3178\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7213 - tp: 10.0000 - fp: 5.0000 - tn: 1621.0000 - fn: 388.0000 - accuracy: 0.8058 - precision: 0.6667 - recall: 0.0251 - auc: 0.6894 - prc: 0.3948 - val_loss: 0.5170 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6621 - val_prc: 0.3213\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7199 - tp: 14.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 384.0000 - accuracy: 0.8073 - precision: 0.7000 - recall: 0.0352 - auc: 0.6881 - prc: 0.3941 - val_loss: 0.5162 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6606 - val_prc: 0.3225\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7184 - tp: 19.0000 - fp: 8.0000 - tn: 1618.0000 - fn: 379.0000 - accuracy: 0.8088 - precision: 0.7037 - recall: 0.0477 - auc: 0.6888 - prc: 0.3950 - val_loss: 0.5177 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6626 - val_prc: 0.3271\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7168 - tp: 21.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 377.0000 - accuracy: 0.8093 - precision: 0.7000 - recall: 0.0528 - auc: 0.6898 - prc: 0.3965 - val_loss: 0.5111 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 91.0000 - val_accuracy: 0.8182 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6629 - val_prc: 0.3247\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7154 - tp: 23.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 375.0000 - accuracy: 0.8103 - precision: 0.7188 - recall: 0.0578 - auc: 0.6899 - prc: 0.3966 - val_loss: 0.5107 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 90.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0110 - val_auc: 0.6643 - val_prc: 0.3304\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7139 - tp: 26.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 372.0000 - accuracy: 0.8118 - precision: 0.7429 - recall: 0.0653 - auc: 0.6901 - prc: 0.3984 - val_loss: 0.5084 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 414.0000 - val_fn: 89.0000 - val_accuracy: 0.8221 - val_precision: 0.6667 - val_recall: 0.0220 - val_auc: 0.6656 - val_prc: 0.3342\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7120 - tp: 33.0000 - fp: 11.0000 - tn: 1615.0000 - fn: 365.0000 - accuracy: 0.8142 - precision: 0.7500 - recall: 0.0829 - auc: 0.6925 - prc: 0.4009 - val_loss: 0.5144 - val_tp: 7.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 84.0000 - val_accuracy: 0.8300 - val_precision: 0.7778 - val_recall: 0.0769 - val_auc: 0.6669 - val_prc: 0.3343\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7106 - tp: 37.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 361.0000 - accuracy: 0.8137 - precision: 0.6981 - recall: 0.0930 - auc: 0.6934 - prc: 0.4025 - val_loss: 0.5088 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 87.0000 - val_accuracy: 0.8241 - val_precision: 0.6667 - val_recall: 0.0440 - val_auc: 0.6701 - val_prc: 0.3377\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7088 - tp: 36.0000 - fp: 12.0000 - tn: 1614.0000 - fn: 362.0000 - accuracy: 0.8152 - precision: 0.7500 - recall: 0.0905 - auc: 0.6944 - prc: 0.4045 - val_loss: 0.5047 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 87.0000 - val_accuracy: 0.8241 - val_precision: 0.6667 - val_recall: 0.0440 - val_auc: 0.6698 - val_prc: 0.3366\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7076 - tp: 39.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 359.0000 - accuracy: 0.8147 - precision: 0.7091 - recall: 0.0980 - auc: 0.6944 - prc: 0.4031 - val_loss: 0.5098 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 83.0000 - val_accuracy: 0.8241 - val_precision: 0.5714 - val_recall: 0.0879 - val_auc: 0.6694 - val_prc: 0.3346\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7054 - tp: 45.0000 - fp: 20.0000 - tn: 1606.0000 - fn: 353.0000 - accuracy: 0.8157 - precision: 0.6923 - recall: 0.1131 - auc: 0.6964 - prc: 0.4068 - val_loss: 0.5040 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 83.0000 - val_accuracy: 0.8241 - val_precision: 0.5714 - val_recall: 0.0879 - val_auc: 0.6705 - val_prc: 0.3343\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7040 - tp: 44.0000 - fp: 19.0000 - tn: 1607.0000 - fn: 354.0000 - accuracy: 0.8157 - precision: 0.6984 - recall: 0.1106 - auc: 0.6968 - prc: 0.4070 - val_loss: 0.5047 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 83.0000 - val_accuracy: 0.8241 - val_precision: 0.5714 - val_recall: 0.0879 - val_auc: 0.6712 - val_prc: 0.3331\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7036 - tp: 61.0000 - fp: 45.0000 - tn: 1581.0000 - fn: 337.0000 - accuracy: 0.8113 - precision: 0.5755 - recall: 0.1533 - auc: 0.6945 - prc: 0.4015 - val_loss: 0.5139 - val_tp: 12.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 79.0000 - val_accuracy: 0.8162 - val_precision: 0.4615 - val_recall: 0.1319 - val_auc: 0.6721 - val_prc: 0.3310\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7032 - tp: 48.0000 - fp: 25.0000 - tn: 1601.0000 - fn: 350.0000 - accuracy: 0.8147 - precision: 0.6575 - recall: 0.1206 - auc: 0.6906 - prc: 0.4035 - val_loss: 0.4927 - val_tp: 8.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 83.0000 - val_accuracy: 0.8261 - val_precision: 0.6154 - val_recall: 0.0879 - val_auc: 0.6723 - val_prc: 0.3362\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6997 - tp: 55.0000 - fp: 29.0000 - tn: 1597.0000 - fn: 343.0000 - accuracy: 0.8162 - precision: 0.6548 - recall: 0.1382 - auc: 0.6970 - prc: 0.4083 - val_loss: 0.5095 - val_tp: 13.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 78.0000 - val_accuracy: 0.8162 - val_precision: 0.4643 - val_recall: 0.1429 - val_auc: 0.6706 - val_prc: 0.3370\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6986 - tp: 81.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 317.0000 - accuracy: 0.8147 - precision: 0.5827 - recall: 0.2035 - auc: 0.6991 - prc: 0.4118 - val_loss: 0.5037 - val_tp: 13.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 78.0000 - val_accuracy: 0.8162 - val_precision: 0.4643 - val_recall: 0.1429 - val_auc: 0.6729 - val_prc: 0.3396\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6976 - tp: 56.0000 - fp: 27.0000 - tn: 1599.0000 - fn: 342.0000 - accuracy: 0.8177 - precision: 0.6747 - recall: 0.1407 - auc: 0.6972 - prc: 0.4123 - val_loss: 0.4911 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 82.0000 - val_accuracy: 0.8221 - val_precision: 0.5294 - val_recall: 0.0989 - val_auc: 0.6749 - val_prc: 0.3453\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6947 - tp: 69.0000 - fp: 40.0000 - tn: 1586.0000 - fn: 329.0000 - accuracy: 0.8177 - precision: 0.6330 - recall: 0.1734 - auc: 0.7002 - prc: 0.4170 - val_loss: 0.5043 - val_tp: 15.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 76.0000 - val_accuracy: 0.8142 - val_precision: 0.4545 - val_recall: 0.1648 - val_auc: 0.6743 - val_prc: 0.3407\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6938 - tp: 82.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 316.0000 - accuracy: 0.8132 - precision: 0.5694 - recall: 0.2060 - auc: 0.7006 - prc: 0.4157 - val_loss: 0.5016 - val_tp: 15.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 76.0000 - val_accuracy: 0.8142 - val_precision: 0.4545 - val_recall: 0.1648 - val_auc: 0.6748 - val_prc: 0.3410\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6927 - tp: 85.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 313.0000 - accuracy: 0.8132 - precision: 0.5667 - recall: 0.2136 - auc: 0.7005 - prc: 0.4150 - val_loss: 0.5012 - val_tp: 16.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 75.0000 - val_accuracy: 0.8142 - val_precision: 0.4571 - val_recall: 0.1758 - val_auc: 0.6750 - val_prc: 0.3429\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6914 - tp: 75.0000 - fp: 44.0000 - tn: 1582.0000 - fn: 323.0000 - accuracy: 0.8187 - precision: 0.6303 - recall: 0.1884 - auc: 0.7008 - prc: 0.4184 - val_loss: 0.4894 - val_tp: 12.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 79.0000 - val_accuracy: 0.8162 - val_precision: 0.4615 - val_recall: 0.1319 - val_auc: 0.6744 - val_prc: 0.3435\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6900 - tp: 74.0000 - fp: 47.0000 - tn: 1579.0000 - fn: 324.0000 - accuracy: 0.8167 - precision: 0.6116 - recall: 0.1859 - auc: 0.7015 - prc: 0.4201 - val_loss: 0.4964 - val_tp: 17.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 74.0000 - val_accuracy: 0.8142 - val_precision: 0.4595 - val_recall: 0.1868 - val_auc: 0.6753 - val_prc: 0.3445\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6886 - tp: 85.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 313.0000 - accuracy: 0.8142 - precision: 0.5743 - recall: 0.2136 - auc: 0.7019 - prc: 0.4218 - val_loss: 0.4922 - val_tp: 16.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 75.0000 - val_accuracy: 0.8142 - val_precision: 0.4571 - val_recall: 0.1758 - val_auc: 0.6746 - val_prc: 0.3477\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6873 - tp: 86.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 312.0000 - accuracy: 0.8172 - precision: 0.5972 - recall: 0.2161 - auc: 0.7022 - prc: 0.4227 - val_loss: 0.4968 - val_tp: 19.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 72.0000 - val_accuracy: 0.8083 - val_precision: 0.4318 - val_recall: 0.2088 - val_auc: 0.6764 - val_prc: 0.3483\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6872 - tp: 107.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 291.0000 - accuracy: 0.8058 - precision: 0.5120 - recall: 0.2688 - auc: 0.7028 - prc: 0.4224 - val_loss: 0.5057 - val_tp: 26.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 65.0000 - val_accuracy: 0.8123 - val_precision: 0.4643 - val_recall: 0.2857 - val_auc: 0.6767 - val_prc: 0.3426\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6852 - tp: 100.0000 - fp: 87.0000 - tn: 1539.0000 - fn: 298.0000 - accuracy: 0.8098 - precision: 0.5348 - recall: 0.2513 - auc: 0.7041 - prc: 0.4216 - val_loss: 0.4860 - val_tp: 14.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 77.0000 - val_accuracy: 0.8103 - val_precision: 0.4242 - val_recall: 0.1538 - val_auc: 0.6771 - val_prc: 0.3494\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6847 - tp: 92.0000 - fp: 83.0000 - tn: 1543.0000 - fn: 306.0000 - accuracy: 0.8078 - precision: 0.5257 - recall: 0.2312 - auc: 0.7039 - prc: 0.4233 - val_loss: 0.5009 - val_tp: 26.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 65.0000 - val_accuracy: 0.8142 - val_precision: 0.4727 - val_recall: 0.2857 - val_auc: 0.6764 - val_prc: 0.3475\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6855 - tp: 125.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 273.0000 - accuracy: 0.8004 - precision: 0.4883 - recall: 0.3141 - auc: 0.7046 - prc: 0.4243 - val_loss: 0.5059 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6766 - val_prc: 0.3455\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6828 - tp: 105.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 293.0000 - accuracy: 0.8073 - precision: 0.5198 - recall: 0.2638 - auc: 0.7043 - prc: 0.4275 - val_loss: 0.4874 - val_tp: 19.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 72.0000 - val_accuracy: 0.8103 - val_precision: 0.4419 - val_recall: 0.2088 - val_auc: 0.6793 - val_prc: 0.3549\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6824 - tp: 102.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 296.0000 - accuracy: 0.8063 - precision: 0.5152 - recall: 0.2563 - auc: 0.7051 - prc: 0.4274 - val_loss: 0.4955 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6778 - val_prc: 0.3507\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6818 - tp: 105.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 293.0000 - accuracy: 0.8083 - precision: 0.5250 - recall: 0.2638 - auc: 0.7049 - prc: 0.4287 - val_loss: 0.4896 - val_tp: 22.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 69.0000 - val_accuracy: 0.8103 - val_precision: 0.4490 - val_recall: 0.2418 - val_auc: 0.6798 - val_prc: 0.3624\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6811 - tp: 101.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 297.0000 - accuracy: 0.8093 - precision: 0.5316 - recall: 0.2538 - auc: 0.7056 - prc: 0.4310 - val_loss: 0.4887 - val_tp: 23.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 68.0000 - val_accuracy: 0.8123 - val_precision: 0.4600 - val_recall: 0.2527 - val_auc: 0.6815 - val_prc: 0.3667\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6808 - tp: 104.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 294.0000 - accuracy: 0.8068 - precision: 0.5174 - recall: 0.2613 - auc: 0.7056 - prc: 0.4292 - val_loss: 0.4913 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6813 - val_prc: 0.3628\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6803 - tp: 114.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 284.0000 - accuracy: 0.8039 - precision: 0.5022 - recall: 0.2864 - auc: 0.7063 - prc: 0.4315 - val_loss: 0.4952 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6806 - val_prc: 0.3638\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6796 - tp: 117.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 281.0000 - accuracy: 0.8058 - precision: 0.5109 - recall: 0.2940 - auc: 0.7059 - prc: 0.4344 - val_loss: 0.4862 - val_tp: 24.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 67.0000 - val_accuracy: 0.8142 - val_precision: 0.4706 - val_recall: 0.2637 - val_auc: 0.6819 - val_prc: 0.3788\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6796 - tp: 101.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 297.0000 - accuracy: 0.8127 - precision: 0.5519 - recall: 0.2538 - auc: 0.7051 - prc: 0.4381 - val_loss: 0.4804 - val_tp: 22.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 69.0000 - val_accuracy: 0.8142 - val_precision: 0.4681 - val_recall: 0.2418 - val_auc: 0.6804 - val_prc: 0.3920\n",
      "Epoch 68/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6806 - tp: 91.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 307.0000 - accuracy: 0.8182 - precision: 0.5987 - recall: 0.2286 - auc: 0.7024 - prc: 0.4403 - val_loss: 0.4790 - val_tp: 22.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 69.0000 - val_accuracy: 0.8162 - val_precision: 0.4783 - val_recall: 0.2418 - val_auc: 0.6811 - val_prc: 0.3976\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6788 - tp: 111.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 287.0000 - accuracy: 0.8113 - precision: 0.5388 - recall: 0.2789 - auc: 0.7042 - prc: 0.4383 - val_loss: 0.4955 - val_tp: 28.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 63.0000 - val_accuracy: 0.8063 - val_precision: 0.4444 - val_recall: 0.3077 - val_auc: 0.6831 - val_prc: 0.3883\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6784 - tp: 131.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 267.0000 - accuracy: 0.8009 - precision: 0.4906 - recall: 0.3291 - auc: 0.7063 - prc: 0.4394 - val_loss: 0.4967 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6823 - val_prc: 0.3893\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6779 - tp: 121.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 277.0000 - accuracy: 0.8043 - precision: 0.5042 - recall: 0.3040 - auc: 0.7060 - prc: 0.4415 - val_loss: 0.4826 - val_tp: 26.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 65.0000 - val_accuracy: 0.8182 - val_precision: 0.4906 - val_recall: 0.2857 - val_auc: 0.6808 - val_prc: 0.3981\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6788 - tp: 98.0000 - fp: 75.0000 - tn: 1551.0000 - fn: 300.0000 - accuracy: 0.8147 - precision: 0.5665 - recall: 0.2462 - auc: 0.7038 - prc: 0.4423 - val_loss: 0.4731 - val_tp: 20.0000 - val_fp: 22.0000 - val_tn: 393.0000 - val_fn: 71.0000 - val_accuracy: 0.8162 - val_precision: 0.4762 - val_recall: 0.2198 - val_auc: 0.6843 - val_prc: 0.4012\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6767 - tp: 111.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 287.0000 - accuracy: 0.8142 - precision: 0.5550 - recall: 0.2789 - auc: 0.7049 - prc: 0.4442 - val_loss: 0.4925 - val_tp: 29.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 62.0000 - val_accuracy: 0.8083 - val_precision: 0.4531 - val_recall: 0.3187 - val_auc: 0.6813 - val_prc: 0.3968\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6777 - tp: 138.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 260.0000 - accuracy: 0.8004 - precision: 0.4894 - recall: 0.3467 - auc: 0.7064 - prc: 0.4408 - val_loss: 0.4954 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6809 - val_prc: 0.3931\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6760 - tp: 129.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 269.0000 - accuracy: 0.8083 - precision: 0.5202 - recall: 0.3241 - auc: 0.7058 - prc: 0.4433 - val_loss: 0.4798 - val_tp: 26.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 65.0000 - val_accuracy: 0.8142 - val_precision: 0.4727 - val_recall: 0.2857 - val_auc: 0.6849 - val_prc: 0.4021\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6761 - tp: 112.0000 - fp: 98.0000 - tn: 1528.0000 - fn: 286.0000 - accuracy: 0.8103 - precision: 0.5333 - recall: 0.2814 - auc: 0.7053 - prc: 0.4440 - val_loss: 0.4818 - val_tp: 26.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 65.0000 - val_accuracy: 0.8123 - val_precision: 0.4643 - val_recall: 0.2857 - val_auc: 0.6834 - val_prc: 0.3978\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6761 - tp: 109.0000 - fp: 98.0000 - tn: 1528.0000 - fn: 289.0000 - accuracy: 0.8088 - precision: 0.5266 - recall: 0.2739 - auc: 0.7046 - prc: 0.4448 - val_loss: 0.4780 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6847 - val_prc: 0.3997\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6756 - tp: 117.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 281.0000 - accuracy: 0.8083 - precision: 0.5223 - recall: 0.2940 - auc: 0.7043 - prc: 0.4455 - val_loss: 0.4859 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6835 - val_prc: 0.3992\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6754 - tp: 122.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 276.0000 - accuracy: 0.8073 - precision: 0.5169 - recall: 0.3065 - auc: 0.7056 - prc: 0.4440 - val_loss: 0.4813 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6854 - val_prc: 0.4017\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6745 - tp: 118.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 280.0000 - accuracy: 0.8098 - precision: 0.5291 - recall: 0.2965 - auc: 0.7051 - prc: 0.4461 - val_loss: 0.4816 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6830 - val_prc: 0.3926\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6753 - tp: 116.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 282.0000 - accuracy: 0.8098 - precision: 0.5297 - recall: 0.2915 - auc: 0.7044 - prc: 0.4423 - val_loss: 0.4811 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 65.0000 - val_accuracy: 0.8103 - val_precision: 0.4561 - val_recall: 0.2857 - val_auc: 0.6811 - val_prc: 0.3841\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6740 - tp: 125.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 273.0000 - accuracy: 0.8063 - precision: 0.5123 - recall: 0.3141 - auc: 0.7074 - prc: 0.4422 - val_loss: 0.4903 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6818 - val_prc: 0.3829\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6761 - tp: 142.0000 - fp: 156.0000 - tn: 1470.0000 - fn: 256.0000 - accuracy: 0.7964 - precision: 0.4765 - recall: 0.3568 - auc: 0.7072 - prc: 0.4394 - val_loss: 0.4896 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6820 - val_prc: 0.3838\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6739 - tp: 131.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 267.0000 - accuracy: 0.8053 - precision: 0.5078 - recall: 0.3291 - auc: 0.7067 - prc: 0.4431 - val_loss: 0.4822 - val_tp: 27.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 64.0000 - val_accuracy: 0.8083 - val_precision: 0.4500 - val_recall: 0.2967 - val_auc: 0.6842 - val_prc: 0.3922\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6746 - tp: 114.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 284.0000 - accuracy: 0.8073 - precision: 0.5182 - recall: 0.2864 - auc: 0.7055 - prc: 0.4443 - val_loss: 0.4767 - val_tp: 26.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 65.0000 - val_accuracy: 0.8142 - val_precision: 0.4727 - val_recall: 0.2857 - val_auc: 0.6848 - val_prc: 0.3994\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6734 - tp: 128.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 270.0000 - accuracy: 0.8078 - precision: 0.5182 - recall: 0.3216 - auc: 0.7072 - prc: 0.4468 - val_loss: 0.4864 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6838 - val_prc: 0.3979\n",
      "Epoch 87/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6733 - tp: 124.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 274.0000 - accuracy: 0.8063 - precision: 0.5124 - recall: 0.3116 - auc: 0.7071 - prc: 0.4470 - val_loss: 0.4806 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6861 - val_prc: 0.4028\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6733 - tp: 138.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 260.0000 - accuracy: 0.8024 - precision: 0.4964 - recall: 0.3467 - auc: 0.7073 - prc: 0.4484 - val_loss: 0.4889 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6841 - val_prc: 0.4015\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6738 - tp: 114.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 284.0000 - accuracy: 0.8103 - precision: 0.5327 - recall: 0.2864 - auc: 0.7061 - prc: 0.4460 - val_loss: 0.4696 - val_tp: 25.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 66.0000 - val_accuracy: 0.8162 - val_precision: 0.4808 - val_recall: 0.2747 - val_auc: 0.6854 - val_prc: 0.4073\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6730 - tp: 128.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 270.0000 - accuracy: 0.8039 - precision: 0.5020 - recall: 0.3216 - auc: 0.7065 - prc: 0.4471 - val_loss: 0.4918 - val_tp: 30.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 61.0000 - val_accuracy: 0.7984 - val_precision: 0.4225 - val_recall: 0.3297 - val_auc: 0.6848 - val_prc: 0.4049\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6719 - tp: 132.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 266.0000 - accuracy: 0.8073 - precision: 0.5156 - recall: 0.3317 - auc: 0.7081 - prc: 0.4515 - val_loss: 0.4716 - val_tp: 25.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 66.0000 - val_accuracy: 0.8123 - val_precision: 0.4630 - val_recall: 0.2747 - val_auc: 0.6843 - val_prc: 0.4106\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6726 - tp: 121.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 277.0000 - accuracy: 0.8123 - precision: 0.5402 - recall: 0.3040 - auc: 0.7058 - prc: 0.4514 - val_loss: 0.4776 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6856 - val_prc: 0.4126\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6719 - tp: 128.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 270.0000 - accuracy: 0.8108 - precision: 0.5311 - recall: 0.3216 - auc: 0.7066 - prc: 0.4527 - val_loss: 0.4793 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6853 - val_prc: 0.4129\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6716 - tp: 134.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 264.0000 - accuracy: 0.8098 - precision: 0.5255 - recall: 0.3367 - auc: 0.7070 - prc: 0.4528 - val_loss: 0.4868 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6850 - val_prc: 0.4119\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6724 - tp: 144.0000 - fp: 160.0000 - tn: 1466.0000 - fn: 254.0000 - accuracy: 0.7955 - precision: 0.4737 - recall: 0.3618 - auc: 0.7073 - prc: 0.4525 - val_loss: 0.4859 - val_tp: 30.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 61.0000 - val_accuracy: 0.8004 - val_precision: 0.4286 - val_recall: 0.3297 - val_auc: 0.6880 - val_prc: 0.4074\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6724 - tp: 121.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 277.0000 - accuracy: 0.8108 - precision: 0.5330 - recall: 0.3040 - auc: 0.7051 - prc: 0.4510 - val_loss: 0.4706 - val_tp: 25.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 66.0000 - val_accuracy: 0.8103 - val_precision: 0.4545 - val_recall: 0.2747 - val_auc: 0.6845 - val_prc: 0.4101\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6713 - tp: 126.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 272.0000 - accuracy: 0.8088 - precision: 0.5228 - recall: 0.3166 - auc: 0.7072 - prc: 0.4528 - val_loss: 0.4821 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6860 - val_prc: 0.4112\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6711 - tp: 127.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 271.0000 - accuracy: 0.8093 - precision: 0.5248 - recall: 0.3191 - auc: 0.7069 - prc: 0.4541 - val_loss: 0.4737 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6864 - val_prc: 0.4138\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6713 - tp: 130.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 268.0000 - accuracy: 0.8068 - precision: 0.5138 - recall: 0.3266 - auc: 0.7067 - prc: 0.4530 - val_loss: 0.4805 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6844 - val_prc: 0.4107\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6702 - tp: 131.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 267.0000 - accuracy: 0.8083 - precision: 0.5198 - recall: 0.3291 - auc: 0.7080 - prc: 0.4554 - val_loss: 0.4729 - val_tp: 28.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 63.0000 - val_accuracy: 0.8142 - val_precision: 0.4746 - val_recall: 0.3077 - val_auc: 0.6851 - val_prc: 0.4121\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6704 - tp: 126.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 272.0000 - accuracy: 0.8093 - precision: 0.5250 - recall: 0.3166 - auc: 0.7074 - prc: 0.4557 - val_loss: 0.4779 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6854 - val_prc: 0.4086\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6717 - tp: 141.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 257.0000 - accuracy: 0.8014 - precision: 0.4930 - recall: 0.3543 - auc: 0.7068 - prc: 0.4534 - val_loss: 0.4819 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6865 - val_prc: 0.4071\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6697 - tp: 130.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 268.0000 - accuracy: 0.8068 - precision: 0.5138 - recall: 0.3266 - auc: 0.7084 - prc: 0.4566 - val_loss: 0.4734 - val_tp: 28.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 63.0000 - val_accuracy: 0.8142 - val_precision: 0.4746 - val_recall: 0.3077 - val_auc: 0.6842 - val_prc: 0.4070\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6707 - tp: 133.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 265.0000 - accuracy: 0.8063 - precision: 0.5115 - recall: 0.3342 - auc: 0.7075 - prc: 0.4533 - val_loss: 0.4803 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6849 - val_prc: 0.4083\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6695 - tp: 131.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 267.0000 - accuracy: 0.8068 - precision: 0.5137 - recall: 0.3291 - auc: 0.7088 - prc: 0.4573 - val_loss: 0.4735 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6852 - val_prc: 0.4109\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6697 - tp: 131.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 267.0000 - accuracy: 0.8083 - precision: 0.5198 - recall: 0.3291 - auc: 0.7073 - prc: 0.4569 - val_loss: 0.4766 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6845 - val_prc: 0.4095\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6694 - tp: 126.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 272.0000 - accuracy: 0.8088 - precision: 0.5228 - recall: 0.3166 - auc: 0.7083 - prc: 0.4566 - val_loss: 0.4714 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6864 - val_prc: 0.4117\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6702 - tp: 139.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 259.0000 - accuracy: 0.8014 - precision: 0.4929 - recall: 0.3492 - auc: 0.7088 - prc: 0.4551 - val_loss: 0.4900 - val_tp: 32.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 59.0000 - val_accuracy: 0.7984 - val_precision: 0.4267 - val_recall: 0.3516 - val_auc: 0.6881 - val_prc: 0.4108\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6708 - tp: 127.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 271.0000 - accuracy: 0.8078 - precision: 0.5184 - recall: 0.3191 - auc: 0.7074 - prc: 0.4529 - val_loss: 0.4675 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6853 - val_prc: 0.4174\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6693 - tp: 126.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 272.0000 - accuracy: 0.8083 - precision: 0.5207 - recall: 0.3166 - auc: 0.7090 - prc: 0.4579 - val_loss: 0.4782 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6844 - val_prc: 0.4141\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6693 - tp: 127.0000 - fp: 117.0000 - tn: 1509.0000 - fn: 271.0000 - accuracy: 0.8083 - precision: 0.5205 - recall: 0.3191 - auc: 0.7074 - prc: 0.4584 - val_loss: 0.4747 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6851 - val_prc: 0.4142\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6694 - tp: 131.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 267.0000 - accuracy: 0.8093 - precision: 0.5240 - recall: 0.3291 - auc: 0.7038 - prc: 0.4585 - val_loss: 0.4786 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6847 - val_prc: 0.4136\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6690 - tp: 140.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 258.0000 - accuracy: 0.8068 - precision: 0.5128 - recall: 0.3518 - auc: 0.7089 - prc: 0.4593 - val_loss: 0.4786 - val_tp: 30.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 61.0000 - val_accuracy: 0.8043 - val_precision: 0.4412 - val_recall: 0.3297 - val_auc: 0.6851 - val_prc: 0.4136\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6687 - tp: 143.0000 - fp: 148.0000 - tn: 1478.0000 - fn: 255.0000 - accuracy: 0.8009 - precision: 0.4914 - recall: 0.3593 - auc: 0.7090 - prc: 0.4604 - val_loss: 0.4864 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6868 - val_prc: 0.4134\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6689 - tp: 141.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 257.0000 - accuracy: 0.8053 - precision: 0.5072 - recall: 0.3543 - auc: 0.7108 - prc: 0.4597 - val_loss: 0.4732 - val_tp: 29.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 62.0000 - val_accuracy: 0.8142 - val_precision: 0.4754 - val_recall: 0.3187 - val_auc: 0.6858 - val_prc: 0.4141\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6685 - tp: 131.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 267.0000 - accuracy: 0.8093 - precision: 0.5240 - recall: 0.3291 - auc: 0.7083 - prc: 0.4601 - val_loss: 0.4686 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6873 - val_prc: 0.4171\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6691 - tp: 126.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 272.0000 - accuracy: 0.8088 - precision: 0.5228 - recall: 0.3166 - auc: 0.7087 - prc: 0.4579 - val_loss: 0.4748 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6849 - val_prc: 0.4153\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6678 - tp: 132.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 266.0000 - accuracy: 0.8088 - precision: 0.5217 - recall: 0.3317 - auc: 0.7083 - prc: 0.4615 - val_loss: 0.4702 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6878 - val_prc: 0.4184\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6682 - tp: 126.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 272.0000 - accuracy: 0.8137 - precision: 0.5455 - recall: 0.3166 - auc: 0.7098 - prc: 0.4611 - val_loss: 0.4694 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6865 - val_prc: 0.4184\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6680 - tp: 131.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 267.0000 - accuracy: 0.8108 - precision: 0.5304 - recall: 0.3291 - auc: 0.7079 - prc: 0.4607 - val_loss: 0.4769 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6858 - val_prc: 0.4153\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6678 - tp: 138.0000 - fp: 126.0000 - tn: 1500.0000 - fn: 260.0000 - accuracy: 0.8093 - precision: 0.5227 - recall: 0.3467 - auc: 0.7079 - prc: 0.4613 - val_loss: 0.4747 - val_tp: 28.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 63.0000 - val_accuracy: 0.8063 - val_precision: 0.4444 - val_recall: 0.3077 - val_auc: 0.6860 - val_prc: 0.4143\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6679 - tp: 138.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 260.0000 - accuracy: 0.8083 - precision: 0.5188 - recall: 0.3467 - auc: 0.7077 - prc: 0.4606 - val_loss: 0.4738 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6860 - val_prc: 0.4171\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6686 - tp: 122.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 276.0000 - accuracy: 0.8118 - precision: 0.5374 - recall: 0.3065 - auc: 0.7091 - prc: 0.4605 - val_loss: 0.4692 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6874 - val_prc: 0.4165\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6685 - tp: 138.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 260.0000 - accuracy: 0.8073 - precision: 0.5149 - recall: 0.3467 - auc: 0.7069 - prc: 0.4595 - val_loss: 0.4866 - val_tp: 32.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 59.0000 - val_accuracy: 0.8004 - val_precision: 0.4324 - val_recall: 0.3516 - val_auc: 0.6885 - val_prc: 0.4191\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6685 - tp: 145.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 253.0000 - accuracy: 0.7989 - precision: 0.4849 - recall: 0.3643 - auc: 0.7099 - prc: 0.4624 - val_loss: 0.4744 - val_tp: 28.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 63.0000 - val_accuracy: 0.8063 - val_precision: 0.4444 - val_recall: 0.3077 - val_auc: 0.6876 - val_prc: 0.4219\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6680 - tp: 123.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 275.0000 - accuracy: 0.8113 - precision: 0.5348 - recall: 0.3090 - auc: 0.7096 - prc: 0.4629 - val_loss: 0.4663 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6890 - val_prc: 0.4237\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6673 - tp: 130.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 268.0000 - accuracy: 0.8093 - precision: 0.5242 - recall: 0.3266 - auc: 0.7078 - prc: 0.4615 - val_loss: 0.4756 - val_tp: 31.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 60.0000 - val_accuracy: 0.8083 - val_precision: 0.4559 - val_recall: 0.3407 - val_auc: 0.6863 - val_prc: 0.4183\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6674 - tp: 129.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 269.0000 - accuracy: 0.8108 - precision: 0.5309 - recall: 0.3241 - auc: 0.7093 - prc: 0.4624 - val_loss: 0.4663 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6890 - val_prc: 0.4262\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6673 - tp: 129.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 269.0000 - accuracy: 0.8113 - precision: 0.5331 - recall: 0.3241 - auc: 0.7102 - prc: 0.4630 - val_loss: 0.4737 - val_tp: 31.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 60.0000 - val_accuracy: 0.8103 - val_precision: 0.4627 - val_recall: 0.3407 - val_auc: 0.6890 - val_prc: 0.4234\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6673 - tp: 141.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 257.0000 - accuracy: 0.8083 - precision: 0.5184 - recall: 0.3543 - auc: 0.7077 - prc: 0.4618 - val_loss: 0.4756 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6864 - val_prc: 0.4202\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6670 - tp: 132.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 266.0000 - accuracy: 0.8123 - precision: 0.5366 - recall: 0.3317 - auc: 0.7089 - prc: 0.4630 - val_loss: 0.4718 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6877 - val_prc: 0.4245\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6680 - tp: 141.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 257.0000 - accuracy: 0.8024 - precision: 0.4965 - recall: 0.3543 - auc: 0.7072 - prc: 0.4608 - val_loss: 0.4866 - val_tp: 34.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 57.0000 - val_accuracy: 0.8004 - val_precision: 0.4359 - val_recall: 0.3736 - val_auc: 0.6918 - val_prc: 0.4214\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6665 - tp: 143.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 255.0000 - accuracy: 0.8068 - precision: 0.5125 - recall: 0.3593 - auc: 0.7102 - prc: 0.4645 - val_loss: 0.4711 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6881 - val_prc: 0.4248\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6668 - tp: 128.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 270.0000 - accuracy: 0.8103 - precision: 0.5289 - recall: 0.3216 - auc: 0.7083 - prc: 0.4637 - val_loss: 0.4698 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6876 - val_prc: 0.4248\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6667 - tp: 137.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 261.0000 - accuracy: 0.8078 - precision: 0.5170 - recall: 0.3442 - auc: 0.7092 - prc: 0.4630 - val_loss: 0.4783 - val_tp: 31.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 60.0000 - val_accuracy: 0.8024 - val_precision: 0.4366 - val_recall: 0.3407 - val_auc: 0.6873 - val_prc: 0.4208\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6660 - tp: 134.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 264.0000 - accuracy: 0.8088 - precision: 0.5214 - recall: 0.3367 - auc: 0.7100 - prc: 0.4636 - val_loss: 0.4669 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6887 - val_prc: 0.4226\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6667 - tp: 127.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 271.0000 - accuracy: 0.8093 - precision: 0.5248 - recall: 0.3191 - auc: 0.7101 - prc: 0.4632 - val_loss: 0.4714 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6877 - val_prc: 0.4183\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6667 - tp: 126.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 272.0000 - accuracy: 0.8103 - precision: 0.5294 - recall: 0.3166 - auc: 0.7109 - prc: 0.4639 - val_loss: 0.4712 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6876 - val_prc: 0.4177\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6680 - tp: 144.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 254.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3618 - auc: 0.7107 - prc: 0.4606 - val_loss: 0.4824 - val_tp: 33.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 58.0000 - val_accuracy: 0.8004 - val_precision: 0.4342 - val_recall: 0.3626 - val_auc: 0.6892 - val_prc: 0.4197\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6681 - tp: 123.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 275.0000 - accuracy: 0.8098 - precision: 0.5279 - recall: 0.3090 - auc: 0.7090 - prc: 0.4600 - val_loss: 0.4634 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6883 - val_prc: 0.4254\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6702 - tp: 144.0000 - fp: 153.0000 - tn: 1473.0000 - fn: 254.0000 - accuracy: 0.7989 - precision: 0.4848 - recall: 0.3618 - auc: 0.7072 - prc: 0.4606 - val_loss: 0.4970 - val_tp: 37.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 54.0000 - val_accuracy: 0.7945 - val_precision: 0.4253 - val_recall: 0.4066 - val_auc: 0.6916 - val_prc: 0.4216\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6690 - tp: 165.0000 - fp: 189.0000 - tn: 1437.0000 - fn: 233.0000 - accuracy: 0.7915 - precision: 0.4661 - recall: 0.4146 - auc: 0.7128 - prc: 0.4669 - val_loss: 0.4771 - val_tp: 31.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 60.0000 - val_accuracy: 0.8024 - val_precision: 0.4366 - val_recall: 0.3407 - val_auc: 0.6879 - val_prc: 0.4253\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6660 - tp: 127.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 271.0000 - accuracy: 0.8113 - precision: 0.5336 - recall: 0.3191 - auc: 0.7101 - prc: 0.4652 - val_loss: 0.4655 - val_tp: 26.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 65.0000 - val_accuracy: 0.8142 - val_precision: 0.4727 - val_recall: 0.2857 - val_auc: 0.6891 - val_prc: 0.4277\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6670 - tp: 135.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 263.0000 - accuracy: 0.8053 - precision: 0.5075 - recall: 0.3392 - auc: 0.7103 - prc: 0.4633 - val_loss: 0.4833 - val_tp: 34.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 57.0000 - val_accuracy: 0.8024 - val_precision: 0.4416 - val_recall: 0.3736 - val_auc: 0.6925 - val_prc: 0.4262\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6661 - tp: 142.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 256.0000 - accuracy: 0.8083 - precision: 0.5182 - recall: 0.3568 - auc: 0.7115 - prc: 0.4647 - val_loss: 0.4681 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6882 - val_prc: 0.4344\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6664 - tp: 125.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 273.0000 - accuracy: 0.8103 - precision: 0.5297 - recall: 0.3141 - auc: 0.7092 - prc: 0.4654 - val_loss: 0.4686 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6882 - val_prc: 0.4307\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6660 - tp: 133.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 265.0000 - accuracy: 0.8083 - precision: 0.5195 - recall: 0.3342 - auc: 0.7091 - prc: 0.4657 - val_loss: 0.4743 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6873 - val_prc: 0.4230\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6657 - tp: 140.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 258.0000 - accuracy: 0.8068 - precision: 0.5128 - recall: 0.3518 - auc: 0.7102 - prc: 0.4655 - val_loss: 0.4769 - val_tp: 30.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 61.0000 - val_accuracy: 0.8083 - val_precision: 0.4545 - val_recall: 0.3297 - val_auc: 0.6877 - val_prc: 0.4226\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6654 - tp: 127.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 271.0000 - accuracy: 0.8103 - precision: 0.5292 - recall: 0.3191 - auc: 0.7114 - prc: 0.4658 - val_loss: 0.4645 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6902 - val_prc: 0.4262\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6656 - tp: 134.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 264.0000 - accuracy: 0.8053 - precision: 0.5076 - recall: 0.3367 - auc: 0.7116 - prc: 0.4645 - val_loss: 0.4825 - val_tp: 34.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 57.0000 - val_accuracy: 0.8043 - val_precision: 0.4474 - val_recall: 0.3736 - val_auc: 0.6911 - val_prc: 0.4213\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6657 - tp: 134.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 264.0000 - accuracy: 0.8043 - precision: 0.5038 - recall: 0.3367 - auc: 0.7108 - prc: 0.4656 - val_loss: 0.4694 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6881 - val_prc: 0.4215\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6653 - tp: 130.0000 - fp: 117.0000 - tn: 1509.0000 - fn: 268.0000 - accuracy: 0.8098 - precision: 0.5263 - recall: 0.3266 - auc: 0.7116 - prc: 0.4656 - val_loss: 0.4725 - val_tp: 29.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 62.0000 - val_accuracy: 0.8083 - val_precision: 0.4531 - val_recall: 0.3187 - val_auc: 0.6874 - val_prc: 0.4233\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6652 - tp: 138.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 260.0000 - accuracy: 0.8078 - precision: 0.5169 - recall: 0.3467 - auc: 0.7110 - prc: 0.4658 - val_loss: 0.4711 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6882 - val_prc: 0.4235\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6651 - tp: 133.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 265.0000 - accuracy: 0.8088 - precision: 0.5216 - recall: 0.3342 - auc: 0.7113 - prc: 0.4663 - val_loss: 0.4674 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6893 - val_prc: 0.4261\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6673 - tp: 118.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 280.0000 - accuracy: 0.8137 - precision: 0.5488 - recall: 0.2965 - auc: 0.7117 - prc: 0.4634 - val_loss: 0.4606 - val_tp: 27.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 64.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.2967 - val_auc: 0.6891 - val_prc: 0.4291\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6658 - tp: 130.0000 - fp: 117.0000 - tn: 1509.0000 - fn: 268.0000 - accuracy: 0.8098 - precision: 0.5263 - recall: 0.3266 - auc: 0.7106 - prc: 0.4661 - val_loss: 0.4747 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6868 - val_prc: 0.4231\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6649 - tp: 136.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 262.0000 - accuracy: 0.8078 - precision: 0.5171 - recall: 0.3417 - auc: 0.7108 - prc: 0.4659 - val_loss: 0.4725 - val_tp: 29.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 62.0000 - val_accuracy: 0.8083 - val_precision: 0.4531 - val_recall: 0.3187 - val_auc: 0.6876 - val_prc: 0.4241\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6648 - tp: 140.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 258.0000 - accuracy: 0.8078 - precision: 0.5166 - recall: 0.3518 - auc: 0.7109 - prc: 0.4660 - val_loss: 0.4776 - val_tp: 32.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 59.0000 - val_accuracy: 0.8063 - val_precision: 0.4507 - val_recall: 0.3516 - val_auc: 0.6883 - val_prc: 0.4212\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6654 - tp: 147.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 251.0000 - accuracy: 0.8058 - precision: 0.5087 - recall: 0.3693 - auc: 0.7114 - prc: 0.4659 - val_loss: 0.4791 - val_tp: 33.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 58.0000 - val_accuracy: 0.8063 - val_precision: 0.4521 - val_recall: 0.3626 - val_auc: 0.6890 - val_prc: 0.4225\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6649 - tp: 141.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 257.0000 - accuracy: 0.8083 - precision: 0.5184 - recall: 0.3543 - auc: 0.7120 - prc: 0.4667 - val_loss: 0.4697 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6897 - val_prc: 0.4284\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6648 - tp: 139.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 259.0000 - accuracy: 0.8078 - precision: 0.5167 - recall: 0.3492 - auc: 0.7123 - prc: 0.4684 - val_loss: 0.4760 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6882 - val_prc: 0.4280\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6651 - tp: 145.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 253.0000 - accuracy: 0.8048 - precision: 0.5052 - recall: 0.3643 - auc: 0.7117 - prc: 0.4677 - val_loss: 0.4748 - val_tp: 32.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 59.0000 - val_accuracy: 0.8103 - val_precision: 0.4638 - val_recall: 0.3516 - val_auc: 0.6886 - val_prc: 0.4283\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6665 - tp: 123.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 275.0000 - accuracy: 0.8098 - precision: 0.5279 - recall: 0.3090 - auc: 0.7127 - prc: 0.4662 - val_loss: 0.4619 - val_tp: 27.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 64.0000 - val_accuracy: 0.8142 - val_precision: 0.4737 - val_recall: 0.2967 - val_auc: 0.6894 - val_prc: 0.4318\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6647 - tp: 130.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 268.0000 - accuracy: 0.8083 - precision: 0.5200 - recall: 0.3266 - auc: 0.7123 - prc: 0.4668 - val_loss: 0.4763 - val_tp: 32.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 59.0000 - val_accuracy: 0.8083 - val_precision: 0.4571 - val_recall: 0.3516 - val_auc: 0.6898 - val_prc: 0.4263\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6671 - tp: 122.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 276.0000 - accuracy: 0.8088 - precision: 0.5236 - recall: 0.3065 - auc: 0.7106 - prc: 0.4621 - val_loss: 0.4648 - val_tp: 27.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 64.0000 - val_accuracy: 0.8123 - val_precision: 0.4655 - val_recall: 0.2967 - val_auc: 0.6882 - val_prc: 0.4252\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6661 - tp: 145.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 253.0000 - accuracy: 0.8024 - precision: 0.4966 - recall: 0.3643 - auc: 0.7133 - prc: 0.4621 - val_loss: 0.4867 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6912 - val_prc: 0.4232\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6636 - tp: 138.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 260.0000 - accuracy: 0.8083 - precision: 0.5188 - recall: 0.3467 - auc: 0.7142 - prc: 0.4694 - val_loss: 0.4619 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6896 - val_prc: 0.4295\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6647 - tp: 122.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 276.0000 - accuracy: 0.8123 - precision: 0.5398 - recall: 0.3065 - auc: 0.7137 - prc: 0.4694 - val_loss: 0.4700 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6886 - val_prc: 0.4314\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6641 - tp: 137.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 261.0000 - accuracy: 0.8078 - precision: 0.5170 - recall: 0.3442 - auc: 0.7118 - prc: 0.4688 - val_loss: 0.4739 - val_tp: 32.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 59.0000 - val_accuracy: 0.8142 - val_precision: 0.4776 - val_recall: 0.3516 - val_auc: 0.6879 - val_prc: 0.4310\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6646 - tp: 138.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 260.0000 - accuracy: 0.8073 - precision: 0.5149 - recall: 0.3467 - auc: 0.7102 - prc: 0.4677 - val_loss: 0.4689 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6889 - val_prc: 0.4316\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6665 - tp: 120.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 278.0000 - accuracy: 0.8098 - precision: 0.5286 - recall: 0.3015 - auc: 0.7107 - prc: 0.4661 - val_loss: 0.4639 - val_tp: 28.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 63.0000 - val_accuracy: 0.8142 - val_precision: 0.4746 - val_recall: 0.3077 - val_auc: 0.6885 - val_prc: 0.4324\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6645 - tp: 135.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 263.0000 - accuracy: 0.8088 - precision: 0.5212 - recall: 0.3392 - auc: 0.7111 - prc: 0.4688 - val_loss: 0.4800 - val_tp: 33.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 58.0000 - val_accuracy: 0.8063 - val_precision: 0.4521 - val_recall: 0.3626 - val_auc: 0.6916 - val_prc: 0.4251\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6656 - tp: 148.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 250.0000 - accuracy: 0.8078 - precision: 0.5157 - recall: 0.3719 - auc: 0.7116 - prc: 0.4661 - val_loss: 0.4756 - val_tp: 31.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 60.0000 - val_accuracy: 0.8103 - val_precision: 0.4627 - val_recall: 0.3407 - val_auc: 0.6920 - val_prc: 0.4253\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6648 - tp: 129.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 269.0000 - accuracy: 0.8108 - precision: 0.5309 - recall: 0.3241 - auc: 0.7101 - prc: 0.4669 - val_loss: 0.4618 - val_tp: 27.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 64.0000 - val_accuracy: 0.8182 - val_precision: 0.4909 - val_recall: 0.2967 - val_auc: 0.6893 - val_prc: 0.4302\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6654 - tp: 119.0000 - fp: 97.0000 - tn: 1529.0000 - fn: 279.0000 - accuracy: 0.8142 - precision: 0.5509 - recall: 0.2990 - auc: 0.7120 - prc: 0.4688 - val_loss: 0.4629 - val_tp: 27.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 64.0000 - val_accuracy: 0.8162 - val_precision: 0.4821 - val_recall: 0.2967 - val_auc: 0.6889 - val_prc: 0.4297\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6641 - tp: 128.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 270.0000 - accuracy: 0.8123 - precision: 0.5378 - recall: 0.3216 - auc: 0.7119 - prc: 0.4707 - val_loss: 0.4737 - val_tp: 31.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 60.0000 - val_accuracy: 0.8103 - val_precision: 0.4627 - val_recall: 0.3407 - val_auc: 0.6931 - val_prc: 0.4282\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6640 - tp: 135.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 263.0000 - accuracy: 0.8083 - precision: 0.5192 - recall: 0.3392 - auc: 0.7103 - prc: 0.4684 - val_loss: 0.4727 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6916 - val_prc: 0.4293\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6638 - tp: 136.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 262.0000 - accuracy: 0.8073 - precision: 0.5152 - recall: 0.3417 - auc: 0.7109 - prc: 0.4701 - val_loss: 0.4735 - val_tp: 31.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8123 - val_precision: 0.4697 - val_recall: 0.3407 - val_auc: 0.6926 - val_prc: 0.4339\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6648 - tp: 128.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 270.0000 - accuracy: 0.8083 - precision: 0.5203 - recall: 0.3216 - auc: 0.7092 - prc: 0.4673 - val_loss: 0.4708 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6933 - val_prc: 0.4338\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6637 - tp: 131.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 267.0000 - accuracy: 0.8093 - precision: 0.5240 - recall: 0.3291 - auc: 0.7113 - prc: 0.4695 - val_loss: 0.4704 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6927 - val_prc: 0.4332\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6640 - tp: 136.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 262.0000 - accuracy: 0.8068 - precision: 0.5132 - recall: 0.3417 - auc: 0.7115 - prc: 0.4691 - val_loss: 0.4738 - val_tp: 31.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8123 - val_precision: 0.4697 - val_recall: 0.3407 - val_auc: 0.6931 - val_prc: 0.4356\n",
      "Epoch 182/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6640 - tp: 136.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 262.0000 - accuracy: 0.8073 - precision: 0.5152 - recall: 0.3417 - auc: 0.7107 - prc: 0.4698 - val_loss: 0.4696 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6916 - val_prc: 0.4354\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6642 - tp: 123.0000 - fp: 108.0000 - tn: 1518.0000 - fn: 275.0000 - accuracy: 0.8108 - precision: 0.5325 - recall: 0.3090 - auc: 0.7113 - prc: 0.4691 - val_loss: 0.4637 - val_tp: 28.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 63.0000 - val_accuracy: 0.8162 - val_precision: 0.4828 - val_recall: 0.3077 - val_auc: 0.6918 - val_prc: 0.4344\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6638 - tp: 127.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 271.0000 - accuracy: 0.8093 - precision: 0.5248 - recall: 0.3191 - auc: 0.7113 - prc: 0.4692 - val_loss: 0.4728 - val_tp: 31.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 60.0000 - val_accuracy: 0.8103 - val_precision: 0.4627 - val_recall: 0.3407 - val_auc: 0.6901 - val_prc: 0.4313\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6638 - tp: 146.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 252.0000 - accuracy: 0.8083 - precision: 0.5177 - recall: 0.3668 - auc: 0.7112 - prc: 0.4698 - val_loss: 0.4769 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6918 - val_prc: 0.4317\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6634 - tp: 133.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 265.0000 - accuracy: 0.8078 - precision: 0.5175 - recall: 0.3342 - auc: 0.7119 - prc: 0.4698 - val_loss: 0.4634 - val_tp: 28.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 63.0000 - val_accuracy: 0.8123 - val_precision: 0.4667 - val_recall: 0.3077 - val_auc: 0.6926 - val_prc: 0.4342\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6640 - tp: 128.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 270.0000 - accuracy: 0.8098 - precision: 0.5267 - recall: 0.3216 - auc: 0.7120 - prc: 0.4695 - val_loss: 0.4683 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6896 - val_prc: 0.4311\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6636 - tp: 125.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 273.0000 - accuracy: 0.8098 - precision: 0.5274 - recall: 0.3141 - auc: 0.7128 - prc: 0.4705 - val_loss: 0.4653 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6918 - val_prc: 0.4362\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6636 - tp: 130.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 268.0000 - accuracy: 0.8073 - precision: 0.5159 - recall: 0.3266 - auc: 0.7120 - prc: 0.4707 - val_loss: 0.4697 - val_tp: 31.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8123 - val_precision: 0.4697 - val_recall: 0.3407 - val_auc: 0.6898 - val_prc: 0.4381\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6632 - tp: 126.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 272.0000 - accuracy: 0.8098 - precision: 0.5272 - recall: 0.3166 - auc: 0.7132 - prc: 0.4715 - val_loss: 0.4631 - val_tp: 29.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 62.0000 - val_accuracy: 0.8142 - val_precision: 0.4754 - val_recall: 0.3187 - val_auc: 0.6903 - val_prc: 0.4353\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6630 - tp: 134.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 264.0000 - accuracy: 0.8108 - precision: 0.5296 - recall: 0.3367 - auc: 0.7126 - prc: 0.4713 - val_loss: 0.4708 - val_tp: 32.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 59.0000 - val_accuracy: 0.8123 - val_precision: 0.4706 - val_recall: 0.3516 - val_auc: 0.6896 - val_prc: 0.4340\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6631 - tp: 135.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 263.0000 - accuracy: 0.8073 - precision: 0.5153 - recall: 0.3392 - auc: 0.7128 - prc: 0.4709 - val_loss: 0.4663 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6912 - val_prc: 0.4394\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6631 - tp: 127.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 271.0000 - accuracy: 0.8088 - precision: 0.5226 - recall: 0.3191 - auc: 0.7134 - prc: 0.4712 - val_loss: 0.4647 - val_tp: 29.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 62.0000 - val_accuracy: 0.8162 - val_precision: 0.4833 - val_recall: 0.3187 - val_auc: 0.6914 - val_prc: 0.4383\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6632 - tp: 130.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 268.0000 - accuracy: 0.8078 - precision: 0.5179 - recall: 0.3266 - auc: 0.7128 - prc: 0.4708 - val_loss: 0.4684 - val_tp: 31.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 60.0000 - val_accuracy: 0.8182 - val_precision: 0.4921 - val_recall: 0.3407 - val_auc: 0.6905 - val_prc: 0.4407\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6631 - tp: 127.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 271.0000 - accuracy: 0.8098 - precision: 0.5270 - recall: 0.3191 - auc: 0.7125 - prc: 0.4718 - val_loss: 0.4620 - val_tp: 29.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 62.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3187 - val_auc: 0.6931 - val_prc: 0.4420\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6633 - tp: 123.0000 - fp: 109.0000 - tn: 1517.0000 - fn: 275.0000 - accuracy: 0.8103 - precision: 0.5302 - recall: 0.3090 - auc: 0.7131 - prc: 0.4713 - val_loss: 0.4687 - val_tp: 30.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 61.0000 - val_accuracy: 0.8103 - val_precision: 0.4615 - val_recall: 0.3297 - val_auc: 0.6905 - val_prc: 0.4346\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6635 - tp: 143.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 255.0000 - accuracy: 0.8078 - precision: 0.5162 - recall: 0.3593 - auc: 0.7124 - prc: 0.4701 - val_loss: 0.4761 - val_tp: 33.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 58.0000 - val_accuracy: 0.8083 - val_precision: 0.4583 - val_recall: 0.3626 - val_auc: 0.6943 - val_prc: 0.4322\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6634 - tp: 139.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 259.0000 - accuracy: 0.8093 - precision: 0.5226 - recall: 0.3492 - auc: 0.7125 - prc: 0.4702 - val_loss: 0.4728 - val_tp: 32.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 59.0000 - val_accuracy: 0.8123 - val_precision: 0.4706 - val_recall: 0.3516 - val_auc: 0.6907 - val_prc: 0.4341\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6649 - tp: 156.0000 - fp: 159.0000 - tn: 1467.0000 - fn: 242.0000 - accuracy: 0.8019 - precision: 0.4952 - recall: 0.3920 - auc: 0.7147 - prc: 0.4717 - val_loss: 0.4836 - val_tp: 35.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 56.0000 - val_accuracy: 0.8083 - val_precision: 0.4605 - val_recall: 0.3846 - val_auc: 0.6950 - val_prc: 0.4349\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6645 - tp: 129.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 269.0000 - accuracy: 0.8078 - precision: 0.5181 - recall: 0.3241 - auc: 0.7118 - prc: 0.4647 - val_loss: 0.4547 - val_tp: 24.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 67.0000 - val_accuracy: 0.8182 - val_precision: 0.4898 - val_recall: 0.2637 - val_auc: 0.6940 - val_prc: 0.4417\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6643 - tp: 118.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 280.0000 - accuracy: 0.8127 - precision: 0.5438 - recall: 0.2965 - auc: 0.7118 - prc: 0.4695 - val_loss: 0.4729 - val_tp: 33.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 58.0000 - val_accuracy: 0.8142 - val_precision: 0.4783 - val_recall: 0.3626 - val_auc: 0.6938 - val_prc: 0.4405\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6636 - tp: 149.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 249.0000 - accuracy: 0.8063 - precision: 0.5103 - recall: 0.3744 - auc: 0.7128 - prc: 0.4711 - val_loss: 0.4780 - val_tp: 34.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 57.0000 - val_accuracy: 0.8083 - val_precision: 0.4595 - val_recall: 0.3736 - val_auc: 0.6951 - val_prc: 0.4420\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6634 - tp: 147.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 251.0000 - accuracy: 0.8053 - precision: 0.5069 - recall: 0.3693 - auc: 0.7153 - prc: 0.4714 - val_loss: 0.4768 - val_tp: 33.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 58.0000 - val_accuracy: 0.8142 - val_precision: 0.4783 - val_recall: 0.3626 - val_auc: 0.6950 - val_prc: 0.4443\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6638 - tp: 139.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 259.0000 - accuracy: 0.8053 - precision: 0.5073 - recall: 0.3492 - auc: 0.7150 - prc: 0.4700 - val_loss: 0.4696 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6961 - val_prc: 0.4451\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6630 - tp: 130.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 268.0000 - accuracy: 0.8068 - precision: 0.5138 - recall: 0.3266 - auc: 0.7146 - prc: 0.4710 - val_loss: 0.4734 - val_tp: 32.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 59.0000 - val_accuracy: 0.8162 - val_precision: 0.4848 - val_recall: 0.3516 - val_auc: 0.6955 - val_prc: 0.4425\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6629 - tp: 144.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 254.0000 - accuracy: 0.8078 - precision: 0.5161 - recall: 0.3618 - auc: 0.7154 - prc: 0.4718 - val_loss: 0.4742 - val_tp: 32.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 59.0000 - val_accuracy: 0.8103 - val_precision: 0.4638 - val_recall: 0.3516 - val_auc: 0.6958 - val_prc: 0.4360\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6626 - tp: 137.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 261.0000 - accuracy: 0.8068 - precision: 0.5131 - recall: 0.3442 - auc: 0.7133 - prc: 0.4712 - val_loss: 0.4681 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6930 - val_prc: 0.4354\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6626 - tp: 133.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 265.0000 - accuracy: 0.8103 - precision: 0.5278 - recall: 0.3342 - auc: 0.7129 - prc: 0.4712 - val_loss: 0.4691 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6962 - val_prc: 0.4373\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6627 - tp: 122.0000 - fp: 109.0000 - tn: 1517.0000 - fn: 276.0000 - accuracy: 0.8098 - precision: 0.5281 - recall: 0.3065 - auc: 0.7138 - prc: 0.4716 - val_loss: 0.4650 - val_tp: 29.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 62.0000 - val_accuracy: 0.8123 - val_precision: 0.4677 - val_recall: 0.3187 - val_auc: 0.6905 - val_prc: 0.4368\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6625 - tp: 136.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 262.0000 - accuracy: 0.8078 - precision: 0.5171 - recall: 0.3417 - auc: 0.7127 - prc: 0.4703 - val_loss: 0.4772 - val_tp: 33.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 58.0000 - val_accuracy: 0.8083 - val_precision: 0.4583 - val_recall: 0.3626 - val_auc: 0.6945 - val_prc: 0.4343\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6635 - tp: 157.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 241.0000 - accuracy: 0.8029 - precision: 0.4984 - recall: 0.3945 - auc: 0.7164 - prc: 0.4721 - val_loss: 0.4814 - val_tp: 35.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 56.0000 - val_accuracy: 0.8083 - val_precision: 0.4605 - val_recall: 0.3846 - val_auc: 0.6957 - val_prc: 0.4380\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6620 - tp: 145.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 253.0000 - accuracy: 0.8073 - precision: 0.5142 - recall: 0.3643 - auc: 0.7164 - prc: 0.4731 - val_loss: 0.4647 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6927 - val_prc: 0.4407\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6637 - tp: 116.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 282.0000 - accuracy: 0.8108 - precision: 0.5346 - recall: 0.2915 - auc: 0.7149 - prc: 0.4706 - val_loss: 0.4615 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 62.0000 - val_accuracy: 0.8221 - val_precision: 0.5088 - val_recall: 0.3187 - val_auc: 0.6926 - val_prc: 0.4395\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6627 - tp: 134.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 264.0000 - accuracy: 0.8098 - precision: 0.5255 - recall: 0.3367 - auc: 0.7127 - prc: 0.4693 - val_loss: 0.4811 - val_tp: 36.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 55.0000 - val_accuracy: 0.8103 - val_precision: 0.4675 - val_recall: 0.3956 - val_auc: 0.6953 - val_prc: 0.4328\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6634 - tp: 156.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 242.0000 - accuracy: 0.8029 - precision: 0.4984 - recall: 0.3920 - auc: 0.7165 - prc: 0.4719 - val_loss: 0.4765 - val_tp: 34.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 57.0000 - val_accuracy: 0.8103 - val_precision: 0.4658 - val_recall: 0.3736 - val_auc: 0.6967 - val_prc: 0.4336\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6616 - tp: 129.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 269.0000 - accuracy: 0.8088 - precision: 0.5223 - recall: 0.3241 - auc: 0.7165 - prc: 0.4722 - val_loss: 0.4565 - val_tp: 28.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 63.0000 - val_accuracy: 0.8241 - val_precision: 0.5185 - val_recall: 0.3077 - val_auc: 0.6924 - val_prc: 0.4407\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6631 - tp: 117.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 281.0000 - accuracy: 0.8098 - precision: 0.5294 - recall: 0.2940 - auc: 0.7148 - prc: 0.4714 - val_loss: 0.4686 - val_tp: 32.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 59.0000 - val_accuracy: 0.8182 - val_precision: 0.4923 - val_recall: 0.3516 - val_auc: 0.6939 - val_prc: 0.4392\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6620 - tp: 141.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 257.0000 - accuracy: 0.8063 - precision: 0.5109 - recall: 0.3543 - auc: 0.7166 - prc: 0.4730 - val_loss: 0.4735 - val_tp: 34.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 57.0000 - val_accuracy: 0.8142 - val_precision: 0.4789 - val_recall: 0.3736 - val_auc: 0.6970 - val_prc: 0.4408\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6628 - tp: 154.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 244.0000 - accuracy: 0.8073 - precision: 0.5133 - recall: 0.3869 - auc: 0.7167 - prc: 0.4721 - val_loss: 0.4724 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6971 - val_prc: 0.4395\n",
      "Epoch 220/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6619 - tp: 130.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 268.0000 - accuracy: 0.8068 - precision: 0.5138 - recall: 0.3266 - auc: 0.7158 - prc: 0.4727 - val_loss: 0.4641 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6926 - val_prc: 0.4409\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6640 - tp: 148.0000 - fp: 145.0000 - tn: 1481.0000 - fn: 250.0000 - accuracy: 0.8048 - precision: 0.5051 - recall: 0.3719 - auc: 0.7145 - prc: 0.4699 - val_loss: 0.4729 - val_tp: 34.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 57.0000 - val_accuracy: 0.8142 - val_precision: 0.4789 - val_recall: 0.3736 - val_auc: 0.6949 - val_prc: 0.4398\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6618 - tp: 132.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 266.0000 - accuracy: 0.8058 - precision: 0.5097 - recall: 0.3317 - auc: 0.7175 - prc: 0.4732 - val_loss: 0.4641 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6937 - val_prc: 0.4424\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - tp: 140.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 258.0000 - accuracy: 0.8093 - precision: 0.5224 - recall: 0.3518 - auc: 0.7167 - prc: 0.4732 - val_loss: 0.4757 - val_tp: 34.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 57.0000 - val_accuracy: 0.8123 - val_precision: 0.4722 - val_recall: 0.3736 - val_auc: 0.6957 - val_prc: 0.4387\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - tp: 145.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 253.0000 - accuracy: 0.8073 - precision: 0.5142 - recall: 0.3643 - auc: 0.7168 - prc: 0.4731 - val_loss: 0.4680 - val_tp: 31.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 60.0000 - val_accuracy: 0.8182 - val_precision: 0.4921 - val_recall: 0.3407 - val_auc: 0.6957 - val_prc: 0.4414\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6616 - tp: 128.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 270.0000 - accuracy: 0.8103 - precision: 0.5289 - recall: 0.3216 - auc: 0.7174 - prc: 0.4736 - val_loss: 0.4658 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6960 - val_prc: 0.4423\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - tp: 139.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 259.0000 - accuracy: 0.8063 - precision: 0.5110 - recall: 0.3492 - auc: 0.7177 - prc: 0.4724 - val_loss: 0.4798 - val_tp: 35.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 56.0000 - val_accuracy: 0.8083 - val_precision: 0.4605 - val_recall: 0.3846 - val_auc: 0.6946 - val_prc: 0.4376\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6611 - tp: 142.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 256.0000 - accuracy: 0.8048 - precision: 0.5053 - recall: 0.3568 - auc: 0.7176 - prc: 0.4737 - val_loss: 0.4639 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6963 - val_prc: 0.4381\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6625 - tp: 118.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 280.0000 - accuracy: 0.8123 - precision: 0.5413 - recall: 0.2965 - auc: 0.7161 - prc: 0.4720 - val_loss: 0.4622 - val_tp: 30.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 61.0000 - val_accuracy: 0.8221 - val_precision: 0.5085 - val_recall: 0.3297 - val_auc: 0.6950 - val_prc: 0.4399\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - tp: 132.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 266.0000 - accuracy: 0.8127 - precision: 0.5388 - recall: 0.3317 - auc: 0.7182 - prc: 0.4731 - val_loss: 0.4696 - val_tp: 32.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 59.0000 - val_accuracy: 0.8182 - val_precision: 0.4923 - val_recall: 0.3516 - val_auc: 0.6967 - val_prc: 0.4395\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6613 - tp: 131.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 267.0000 - accuracy: 0.8098 - precision: 0.5261 - recall: 0.3291 - auc: 0.7171 - prc: 0.4727 - val_loss: 0.4680 - val_tp: 31.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 60.0000 - val_accuracy: 0.8182 - val_precision: 0.4921 - val_recall: 0.3407 - val_auc: 0.6977 - val_prc: 0.4401\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6611 - tp: 132.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 266.0000 - accuracy: 0.8073 - precision: 0.5156 - recall: 0.3317 - auc: 0.7179 - prc: 0.4734 - val_loss: 0.4778 - val_tp: 35.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 56.0000 - val_accuracy: 0.8103 - val_precision: 0.4667 - val_recall: 0.3846 - val_auc: 0.6953 - val_prc: 0.4401\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6638 - tp: 162.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 236.0000 - accuracy: 0.7974 - precision: 0.4821 - recall: 0.4070 - auc: 0.7174 - prc: 0.4735 - val_loss: 0.4824 - val_tp: 35.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 56.0000 - val_accuracy: 0.8083 - val_precision: 0.4605 - val_recall: 0.3846 - val_auc: 0.6945 - val_prc: 0.4403\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6620 - tp: 134.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 264.0000 - accuracy: 0.8063 - precision: 0.5115 - recall: 0.3367 - auc: 0.7181 - prc: 0.4712 - val_loss: 0.4583 - val_tp: 29.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 62.0000 - val_accuracy: 0.8241 - val_precision: 0.5179 - val_recall: 0.3187 - val_auc: 0.6914 - val_prc: 0.4397\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6626 - tp: 122.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 276.0000 - accuracy: 0.8108 - precision: 0.5328 - recall: 0.3065 - auc: 0.7146 - prc: 0.4715 - val_loss: 0.4635 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6950 - val_prc: 0.4386\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6620 - tp: 121.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 277.0000 - accuracy: 0.8132 - precision: 0.5450 - recall: 0.3040 - auc: 0.7163 - prc: 0.4727 - val_loss: 0.4595 - val_tp: 30.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 61.0000 - val_accuracy: 0.8221 - val_precision: 0.5085 - val_recall: 0.3297 - val_auc: 0.6893 - val_prc: 0.4386\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6620 - tp: 131.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 267.0000 - accuracy: 0.8088 - precision: 0.5219 - recall: 0.3291 - auc: 0.7170 - prc: 0.4715 - val_loss: 0.4692 - val_tp: 32.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 59.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3516 - val_auc: 0.6980 - val_prc: 0.4401\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6620 - tp: 121.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 277.0000 - accuracy: 0.8132 - precision: 0.5450 - recall: 0.3040 - auc: 0.7156 - prc: 0.4726 - val_loss: 0.4604 - val_tp: 30.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 61.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3297 - val_auc: 0.6913 - val_prc: 0.4406\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6615 - tp: 138.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 260.0000 - accuracy: 0.8058 - precision: 0.5092 - recall: 0.3467 - auc: 0.7167 - prc: 0.4728 - val_loss: 0.4794 - val_tp: 36.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 55.0000 - val_accuracy: 0.8142 - val_precision: 0.4800 - val_recall: 0.3956 - val_auc: 0.6952 - val_prc: 0.4376\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6614 - tp: 138.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 260.0000 - accuracy: 0.8103 - precision: 0.5267 - recall: 0.3467 - auc: 0.7169 - prc: 0.4708 - val_loss: 0.4677 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6969 - val_prc: 0.4372\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6609 - tp: 138.0000 - fp: 130.0000 - tn: 1496.0000 - fn: 260.0000 - accuracy: 0.8073 - precision: 0.5149 - recall: 0.3467 - auc: 0.7185 - prc: 0.4725 - val_loss: 0.4768 - val_tp: 34.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 57.0000 - val_accuracy: 0.8142 - val_precision: 0.4789 - val_recall: 0.3736 - val_auc: 0.6948 - val_prc: 0.4368\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6615 - tp: 146.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 252.0000 - accuracy: 0.8043 - precision: 0.5034 - recall: 0.3668 - auc: 0.7189 - prc: 0.4727 - val_loss: 0.4725 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6953 - val_prc: 0.4389\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6642 - tp: 116.0000 - fp: 98.0000 - tn: 1528.0000 - fn: 282.0000 - accuracy: 0.8123 - precision: 0.5421 - recall: 0.2915 - auc: 0.7138 - prc: 0.4704 - val_loss: 0.4597 - val_tp: 28.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 63.0000 - val_accuracy: 0.8221 - val_precision: 0.5091 - val_recall: 0.3077 - val_auc: 0.6994 - val_prc: 0.4449\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6612 - tp: 126.0000 - fp: 107.0000 - tn: 1519.0000 - fn: 272.0000 - accuracy: 0.8127 - precision: 0.5408 - recall: 0.3166 - auc: 0.7184 - prc: 0.4745 - val_loss: 0.4769 - val_tp: 33.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 58.0000 - val_accuracy: 0.8123 - val_precision: 0.4714 - val_recall: 0.3626 - val_auc: 0.6941 - val_prc: 0.4385\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6609 - tp: 141.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 257.0000 - accuracy: 0.8073 - precision: 0.5146 - recall: 0.3543 - auc: 0.7187 - prc: 0.4735 - val_loss: 0.4730 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6956 - val_prc: 0.4399\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6606 - tp: 137.0000 - fp: 124.0000 - tn: 1502.0000 - fn: 261.0000 - accuracy: 0.8098 - precision: 0.5249 - recall: 0.3442 - auc: 0.7187 - prc: 0.4740 - val_loss: 0.4688 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6964 - val_prc: 0.4412\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6608 - tp: 129.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 269.0000 - accuracy: 0.8103 - precision: 0.5287 - recall: 0.3241 - auc: 0.7179 - prc: 0.4740 - val_loss: 0.4665 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6967 - val_prc: 0.4461\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6607 - tp: 135.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 263.0000 - accuracy: 0.8093 - precision: 0.5233 - recall: 0.3392 - auc: 0.7192 - prc: 0.4746 - val_loss: 0.4741 - val_tp: 33.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 58.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3626 - val_auc: 0.6953 - val_prc: 0.4441\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6629 - tp: 119.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 279.0000 - accuracy: 0.8103 - precision: 0.5312 - recall: 0.2990 - auc: 0.7162 - prc: 0.4704 - val_loss: 0.4586 - val_tp: 29.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 62.0000 - val_accuracy: 0.8241 - val_precision: 0.5179 - val_recall: 0.3187 - val_auc: 0.6969 - val_prc: 0.4471\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6607 - tp: 128.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 270.0000 - accuracy: 0.8118 - precision: 0.5356 - recall: 0.3216 - auc: 0.7187 - prc: 0.4743 - val_loss: 0.4741 - val_tp: 33.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 58.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3626 - val_auc: 0.6950 - val_prc: 0.4409\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6608 - tp: 145.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 253.0000 - accuracy: 0.8073 - precision: 0.5142 - recall: 0.3643 - auc: 0.7189 - prc: 0.4733 - val_loss: 0.4753 - val_tp: 33.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 58.0000 - val_accuracy: 0.8182 - val_precision: 0.4925 - val_recall: 0.3626 - val_auc: 0.6950 - val_prc: 0.4370\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6605 - tp: 138.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 260.0000 - accuracy: 0.8088 - precision: 0.5208 - recall: 0.3467 - auc: 0.7187 - prc: 0.4735 - val_loss: 0.4728 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6957 - val_prc: 0.4407\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6610 - tp: 147.0000 - fp: 141.0000 - tn: 1485.0000 - fn: 251.0000 - accuracy: 0.8063 - precision: 0.5104 - recall: 0.3693 - auc: 0.7196 - prc: 0.4734 - val_loss: 0.4744 - val_tp: 33.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 58.0000 - val_accuracy: 0.8182 - val_precision: 0.4925 - val_recall: 0.3626 - val_auc: 0.6949 - val_prc: 0.4446\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6612 - tp: 131.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 267.0000 - accuracy: 0.8093 - precision: 0.5240 - recall: 0.3291 - auc: 0.7176 - prc: 0.4729 - val_loss: 0.4634 - val_tp: 30.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 61.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3297 - val_auc: 0.6983 - val_prc: 0.4473\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6606 - tp: 125.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 273.0000 - accuracy: 0.8088 - precision: 0.5230 - recall: 0.3141 - auc: 0.7184 - prc: 0.4747 - val_loss: 0.4620 - val_tp: 30.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 61.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3297 - val_auc: 0.6982 - val_prc: 0.4472\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6609 - tp: 123.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 275.0000 - accuracy: 0.8098 - precision: 0.5279 - recall: 0.3090 - auc: 0.7184 - prc: 0.4742 - val_loss: 0.4642 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6976 - val_prc: 0.4464\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6602 - tp: 137.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 261.0000 - accuracy: 0.8123 - precision: 0.5352 - recall: 0.3442 - auc: 0.7179 - prc: 0.4742 - val_loss: 0.4703 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6957 - val_prc: 0.4418\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6609 - tp: 132.0000 - fp: 112.0000 - tn: 1514.0000 - fn: 266.0000 - accuracy: 0.8132 - precision: 0.5410 - recall: 0.3317 - auc: 0.7170 - prc: 0.4733 - val_loss: 0.4643 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6971 - val_prc: 0.4403\n",
      "Epoch 258/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6603 - tp: 137.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 261.0000 - accuracy: 0.8123 - precision: 0.5352 - recall: 0.3442 - auc: 0.7185 - prc: 0.4743 - val_loss: 0.4725 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6954 - val_prc: 0.4366\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6603 - tp: 142.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 256.0000 - accuracy: 0.8048 - precision: 0.5053 - recall: 0.3568 - auc: 0.7192 - prc: 0.4740 - val_loss: 0.4741 - val_tp: 33.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 58.0000 - val_accuracy: 0.8182 - val_precision: 0.4925 - val_recall: 0.3626 - val_auc: 0.6946 - val_prc: 0.4364\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6601 - tp: 129.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 269.0000 - accuracy: 0.8108 - precision: 0.5309 - recall: 0.3241 - auc: 0.7192 - prc: 0.4740 - val_loss: 0.4614 - val_tp: 30.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 61.0000 - val_accuracy: 0.8221 - val_precision: 0.5085 - val_recall: 0.3297 - val_auc: 0.6972 - val_prc: 0.4400\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6606 - tp: 128.0000 - fp: 106.0000 - tn: 1520.0000 - fn: 270.0000 - accuracy: 0.8142 - precision: 0.5470 - recall: 0.3216 - auc: 0.7185 - prc: 0.4741 - val_loss: 0.4641 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6956 - val_prc: 0.4399\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6604 - tp: 134.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 264.0000 - accuracy: 0.8113 - precision: 0.5317 - recall: 0.3367 - auc: 0.7189 - prc: 0.4737 - val_loss: 0.4666 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6960 - val_prc: 0.4420\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6612 - tp: 122.0000 - fp: 102.0000 - tn: 1524.0000 - fn: 276.0000 - accuracy: 0.8132 - precision: 0.5446 - recall: 0.3065 - auc: 0.7177 - prc: 0.4729 - val_loss: 0.4617 - val_tp: 30.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 61.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.3297 - val_auc: 0.6967 - val_prc: 0.4419\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6609 - tp: 130.0000 - fp: 116.0000 - tn: 1510.0000 - fn: 268.0000 - accuracy: 0.8103 - precision: 0.5285 - recall: 0.3266 - auc: 0.7187 - prc: 0.4723 - val_loss: 0.4719 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6942 - val_prc: 0.4416\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6604 - tp: 138.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 260.0000 - accuracy: 0.8127 - precision: 0.5370 - recall: 0.3467 - auc: 0.7190 - prc: 0.4736 - val_loss: 0.4687 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6954 - val_prc: 0.4372\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6598 - tp: 133.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 265.0000 - accuracy: 0.8098 - precision: 0.5257 - recall: 0.3342 - auc: 0.7197 - prc: 0.4748 - val_loss: 0.4672 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6948 - val_prc: 0.4329\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6605 - tp: 128.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 270.0000 - accuracy: 0.8123 - precision: 0.5378 - recall: 0.3216 - auc: 0.7183 - prc: 0.4743 - val_loss: 0.4680 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6942 - val_prc: 0.4320\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6602 - tp: 143.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 255.0000 - accuracy: 0.8063 - precision: 0.5107 - recall: 0.3593 - auc: 0.7191 - prc: 0.4736 - val_loss: 0.4793 - val_tp: 33.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 58.0000 - val_accuracy: 0.8103 - val_precision: 0.4648 - val_recall: 0.3626 - val_auc: 0.6944 - val_prc: 0.4299\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6607 - tp: 131.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 267.0000 - accuracy: 0.8118 - precision: 0.5347 - recall: 0.3291 - auc: 0.7181 - prc: 0.4728 - val_loss: 0.4639 - val_tp: 30.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 61.0000 - val_accuracy: 0.8221 - val_precision: 0.5085 - val_recall: 0.3297 - val_auc: 0.6949 - val_prc: 0.4338\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6599 - tp: 133.0000 - fp: 120.0000 - tn: 1506.0000 - fn: 265.0000 - accuracy: 0.8098 - precision: 0.5257 - recall: 0.3342 - auc: 0.7208 - prc: 0.4734 - val_loss: 0.4747 - val_tp: 31.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 60.0000 - val_accuracy: 0.8123 - val_precision: 0.4697 - val_recall: 0.3407 - val_auc: 0.6957 - val_prc: 0.4305\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6597 - tp: 132.0000 - fp: 117.0000 - tn: 1509.0000 - fn: 266.0000 - accuracy: 0.8108 - precision: 0.5301 - recall: 0.3317 - auc: 0.7200 - prc: 0.4755 - val_loss: 0.4649 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6943 - val_prc: 0.4320\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6602 - tp: 128.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 270.0000 - accuracy: 0.8123 - precision: 0.5378 - recall: 0.3216 - auc: 0.7193 - prc: 0.4745 - val_loss: 0.4679 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6936 - val_prc: 0.4314\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 134.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 264.0000 - accuracy: 0.8098 - precision: 0.5255 - recall: 0.3367 - auc: 0.7194 - prc: 0.4745 - val_loss: 0.4753 - val_tp: 32.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 59.0000 - val_accuracy: 0.8142 - val_precision: 0.4776 - val_recall: 0.3516 - val_auc: 0.6954 - val_prc: 0.4290\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6597 - tp: 142.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 256.0000 - accuracy: 0.8083 - precision: 0.5182 - recall: 0.3568 - auc: 0.7202 - prc: 0.4750 - val_loss: 0.4747 - val_tp: 32.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 59.0000 - val_accuracy: 0.8142 - val_precision: 0.4776 - val_recall: 0.3516 - val_auc: 0.6941 - val_prc: 0.4250\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6593 - tp: 140.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 258.0000 - accuracy: 0.8098 - precision: 0.5243 - recall: 0.3518 - auc: 0.7203 - prc: 0.4752 - val_loss: 0.4741 - val_tp: 32.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 59.0000 - val_accuracy: 0.8142 - val_precision: 0.4776 - val_recall: 0.3516 - val_auc: 0.6957 - val_prc: 0.4303\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6597 - tp: 143.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 255.0000 - accuracy: 0.8048 - precision: 0.5053 - recall: 0.3593 - auc: 0.7200 - prc: 0.4745 - val_loss: 0.4754 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6950 - val_prc: 0.4345\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 143.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 255.0000 - accuracy: 0.8078 - precision: 0.5162 - recall: 0.3593 - auc: 0.7201 - prc: 0.4746 - val_loss: 0.4722 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6963 - val_prc: 0.4402\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6594 - tp: 141.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 257.0000 - accuracy: 0.8083 - precision: 0.5184 - recall: 0.3543 - auc: 0.7207 - prc: 0.4748 - val_loss: 0.4672 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6968 - val_prc: 0.4406\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6616 - tp: 113.0000 - fp: 91.0000 - tn: 1535.0000 - fn: 285.0000 - accuracy: 0.8142 - precision: 0.5539 - recall: 0.2839 - auc: 0.7211 - prc: 0.4731 - val_loss: 0.4548 - val_tp: 28.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 63.0000 - val_accuracy: 0.8261 - val_precision: 0.5283 - val_recall: 0.3077 - val_auc: 0.6981 - val_prc: 0.4468\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6602 - tp: 120.0000 - fp: 96.0000 - tn: 1530.0000 - fn: 278.0000 - accuracy: 0.8152 - precision: 0.5556 - recall: 0.3015 - auc: 0.7198 - prc: 0.4754 - val_loss: 0.4681 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6964 - val_prc: 0.4432\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6605 - tp: 152.0000 - fp: 148.0000 - tn: 1478.0000 - fn: 246.0000 - accuracy: 0.8053 - precision: 0.5067 - recall: 0.3819 - auc: 0.7202 - prc: 0.4736 - val_loss: 0.4762 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6962 - val_prc: 0.4442\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 135.0000 - fp: 123.0000 - tn: 1503.0000 - fn: 263.0000 - accuracy: 0.8093 - precision: 0.5233 - recall: 0.3392 - auc: 0.7206 - prc: 0.4737 - val_loss: 0.4599 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6972 - val_prc: 0.4450\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6601 - tp: 133.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 265.0000 - accuracy: 0.8108 - precision: 0.5299 - recall: 0.3342 - auc: 0.7189 - prc: 0.4728 - val_loss: 0.4666 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6949 - val_prc: 0.4448\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 137.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 261.0000 - accuracy: 0.8093 - precision: 0.5229 - recall: 0.3442 - auc: 0.7210 - prc: 0.4748 - val_loss: 0.4728 - val_tp: 32.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 59.0000 - val_accuracy: 0.8162 - val_precision: 0.4848 - val_recall: 0.3516 - val_auc: 0.6959 - val_prc: 0.4457\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6593 - tp: 142.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 256.0000 - accuracy: 0.8078 - precision: 0.5164 - recall: 0.3568 - auc: 0.7204 - prc: 0.4749 - val_loss: 0.4738 - val_tp: 32.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 59.0000 - val_accuracy: 0.8162 - val_precision: 0.4848 - val_recall: 0.3516 - val_auc: 0.6957 - val_prc: 0.4457\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6592 - tp: 144.0000 - fp: 133.0000 - tn: 1493.0000 - fn: 254.0000 - accuracy: 0.8088 - precision: 0.5199 - recall: 0.3618 - auc: 0.7209 - prc: 0.4751 - val_loss: 0.4691 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6954 - val_prc: 0.4375\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6593 - tp: 135.0000 - fp: 119.0000 - tn: 1507.0000 - fn: 263.0000 - accuracy: 0.8113 - precision: 0.5315 - recall: 0.3392 - auc: 0.7201 - prc: 0.4748 - val_loss: 0.4693 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6932 - val_prc: 0.4279\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6593 - tp: 141.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 257.0000 - accuracy: 0.8103 - precision: 0.5261 - recall: 0.3543 - auc: 0.7201 - prc: 0.4740 - val_loss: 0.4743 - val_tp: 32.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 59.0000 - val_accuracy: 0.8142 - val_precision: 0.4776 - val_recall: 0.3516 - val_auc: 0.6936 - val_prc: 0.4194\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6595 - tp: 137.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 261.0000 - accuracy: 0.8127 - precision: 0.5373 - recall: 0.3442 - auc: 0.7205 - prc: 0.4744 - val_loss: 0.4685 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6939 - val_prc: 0.4216\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6591 - tp: 138.0000 - fp: 125.0000 - tn: 1501.0000 - fn: 260.0000 - accuracy: 0.8098 - precision: 0.5247 - recall: 0.3467 - auc: 0.7201 - prc: 0.4745 - val_loss: 0.4744 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6925 - val_prc: 0.4206\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6589 - tp: 138.0000 - fp: 121.0000 - tn: 1505.0000 - fn: 260.0000 - accuracy: 0.8118 - precision: 0.5328 - recall: 0.3467 - auc: 0.7207 - prc: 0.4752 - val_loss: 0.4691 - val_tp: 31.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 60.0000 - val_accuracy: 0.8142 - val_precision: 0.4769 - val_recall: 0.3407 - val_auc: 0.6939 - val_prc: 0.4252\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 126.0000 - fp: 104.0000 - tn: 1522.0000 - fn: 272.0000 - accuracy: 0.8142 - precision: 0.5478 - recall: 0.3166 - auc: 0.7212 - prc: 0.4751 - val_loss: 0.4636 - val_tp: 30.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 61.0000 - val_accuracy: 0.8182 - val_precision: 0.4918 - val_recall: 0.3297 - val_auc: 0.6958 - val_prc: 0.4335\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6592 - tp: 128.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 270.0000 - accuracy: 0.8118 - precision: 0.5356 - recall: 0.3216 - auc: 0.7213 - prc: 0.4759 - val_loss: 0.4698 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6938 - val_prc: 0.4318\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6591 - tp: 147.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 251.0000 - accuracy: 0.8073 - precision: 0.5140 - recall: 0.3693 - auc: 0.7212 - prc: 0.4741 - val_loss: 0.4779 - val_tp: 35.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 56.0000 - val_accuracy: 0.8182 - val_precision: 0.4930 - val_recall: 0.3846 - val_auc: 0.6937 - val_prc: 0.4351\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6595 - tp: 138.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 260.0000 - accuracy: 0.8088 - precision: 0.5208 - recall: 0.3467 - auc: 0.7205 - prc: 0.4733 - val_loss: 0.4644 - val_tp: 30.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 61.0000 - val_accuracy: 0.8142 - val_precision: 0.4762 - val_recall: 0.3297 - val_auc: 0.6972 - val_prc: 0.4446\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 127.0000 - fp: 108.0000 - tn: 1518.0000 - fn: 271.0000 - accuracy: 0.8127 - precision: 0.5404 - recall: 0.3191 - auc: 0.7203 - prc: 0.4752 - val_loss: 0.4581 - val_tp: 29.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 62.0000 - val_accuracy: 0.8182 - val_precision: 0.4915 - val_recall: 0.3187 - val_auc: 0.6960 - val_prc: 0.4447\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6594 - tp: 129.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 269.0000 - accuracy: 0.8127 - precision: 0.5397 - recall: 0.3241 - auc: 0.7212 - prc: 0.4755 - val_loss: 0.4726 - val_tp: 32.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 59.0000 - val_accuracy: 0.8162 - val_precision: 0.4848 - val_recall: 0.3516 - val_auc: 0.6948 - val_prc: 0.4417\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6587 - tp: 138.0000 - fp: 127.0000 - tn: 1499.0000 - fn: 260.0000 - accuracy: 0.8088 - precision: 0.5208 - recall: 0.3467 - auc: 0.7220 - prc: 0.4753 - val_loss: 0.4695 - val_tp: 30.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 61.0000 - val_accuracy: 0.8123 - val_precision: 0.4688 - val_recall: 0.3297 - val_auc: 0.6955 - val_prc: 0.4427\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6587 - tp: 143.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 255.0000 - accuracy: 0.8078 - precision: 0.5162 - recall: 0.3593 - auc: 0.7215 - prc: 0.4757 - val_loss: 0.4764 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6936 - val_prc: 0.4321\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6596 - tp: 154.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 244.0000 - accuracy: 0.8073 - precision: 0.5133 - recall: 0.3869 - auc: 0.7206 - prc: 0.4750 - val_loss: 0.4762 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6935 - val_prc: 0.4338\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6634 - tp: 121.0000 - fp: 109.0000 - tn: 1517.0000 - fn: 277.0000 - accuracy: 0.8093 - precision: 0.5261 - recall: 0.3040 - auc: 0.7167 - prc: 0.4656 - val_loss: 0.4620 - val_tp: 30.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 61.0000 - val_accuracy: 0.8162 - val_precision: 0.4839 - val_recall: 0.3297 - val_auc: 0.6954 - val_prc: 0.4395\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - tp: 157.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 241.0000 - accuracy: 0.8029 - precision: 0.4984 - recall: 0.3945 - auc: 0.7196 - prc: 0.4713 - val_loss: 0.4941 - val_tp: 38.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 53.0000 - val_accuracy: 0.8004 - val_precision: 0.4419 - val_recall: 0.4176 - val_auc: 0.6907 - val_prc: 0.4206\n",
      "Epoch 303/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.6178 - tp: 16.0000 - fp: 18.0000 - tn: 148.0000 - fn: 18.0000 - accuracy: 0.8200 - precision: 0.4706 - recall: 0.4706 - auc: 0.7027 - prc: 0.5202Restoring model weights from the end of the best epoch: 253.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6600 - tp: 149.0000 - fp: 152.0000 - tn: 1474.0000 - fn: 249.0000 - accuracy: 0.8019 - precision: 0.4950 - recall: 0.3744 - auc: 0.7213 - prc: 0.4728 - val_loss: 0.4661 - val_tp: 31.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 60.0000 - val_accuracy: 0.8162 - val_precision: 0.4844 - val_recall: 0.3407 - val_auc: 0.6944 - val_prc: 0.4339\n",
      "Epoch 303: early stopping\n",
      "3/3 [==============================] - 0s 908us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.9799 - tp: 31.0000 - fp: 33.0000 - tn: 2008.0000 - fn: 458.0000 - accuracy: 0.8059 - precision: 0.4844 - recall: 0.0634 - auc: 0.5131 - prc: 0.2407 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203 - val_prc: 0.1863\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9721 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5049 - prc: 0.2032 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4740 - val_prc: 0.1720\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9637 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5238 - prc: 0.2108 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5006 - val_prc: 0.1905\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9537 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5520 - prc: 0.2400 - val_loss: 0.4745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5764 - val_prc: 0.2317\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9422 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6048 - prc: 0.2859 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5962 - val_prc: 0.2478\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9300 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6346 - prc: 0.3177 - val_loss: 0.4783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6364 - val_prc: 0.2787\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9168 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6480 - prc: 0.3327 - val_loss: 0.4815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6206 - val_prc: 0.2795\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6352 - prc: 0.3170 - val_loss: 0.4866 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6236 - val_prc: 0.2709\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6644 - prc: 0.3519 - val_loss: 0.4933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6326 - val_prc: 0.2785\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8735 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6589 - prc: 0.3412 - val_loss: 0.5032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6350 - val_prc: 0.2775\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6776 - prc: 0.3572 - val_loss: 0.5156 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6496 - val_prc: 0.2861\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8485 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6745 - prc: 0.3635 - val_loss: 0.5293 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6447 - val_prc: 0.2799\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8413 - tp: 1.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 397.0000 - accuracy: 0.8029 - precision: 0.3333 - recall: 0.0025 - auc: 0.6815 - prc: 0.3623 - val_loss: 0.5434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6462 - val_prc: 0.2821\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8372 - tp: 2.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 396.0000 - accuracy: 0.8024 - precision: 0.3333 - recall: 0.0050 - auc: 0.6850 - prc: 0.3706 - val_loss: 0.5523 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6475 - val_prc: 0.2837\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8352 - tp: 3.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 395.0000 - accuracy: 0.8019 - precision: 0.3333 - recall: 0.0075 - auc: 0.6869 - prc: 0.3723 - val_loss: 0.5630 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6478 - val_prc: 0.2831\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8341 - tp: 6.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 392.0000 - accuracy: 0.8029 - precision: 0.4615 - recall: 0.0151 - auc: 0.6854 - prc: 0.3716 - val_loss: 0.5637 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6501 - val_prc: 0.2852\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8332 - tp: 6.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 392.0000 - accuracy: 0.8029 - precision: 0.4615 - recall: 0.0151 - auc: 0.6859 - prc: 0.3747 - val_loss: 0.5617 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6498 - val_prc: 0.2860\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8324 - tp: 7.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 391.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0176 - auc: 0.6869 - prc: 0.3740 - val_loss: 0.5613 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6521 - val_prc: 0.2837\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8313 - tp: 10.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 388.0000 - accuracy: 0.8048 - precision: 0.5882 - recall: 0.0251 - auc: 0.6880 - prc: 0.3753 - val_loss: 0.5632 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6534 - val_prc: 0.2878\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8310 - tp: 28.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 370.0000 - accuracy: 0.8093 - precision: 0.6364 - recall: 0.0704 - auc: 0.6842 - prc: 0.3716 - val_loss: 0.5833 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 85.0000 - val_accuracy: 0.8142 - val_precision: 0.4000 - val_recall: 0.0659 - val_auc: 0.6579 - val_prc: 0.2926\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8301 - tp: 24.0000 - fp: 17.0000 - tn: 1609.0000 - fn: 374.0000 - accuracy: 0.8068 - precision: 0.5854 - recall: 0.0603 - auc: 0.6916 - prc: 0.3807 - val_loss: 0.5693 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 89.0000 - val_accuracy: 0.8162 - val_precision: 0.3333 - val_recall: 0.0220 - val_auc: 0.6558 - val_prc: 0.2903\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8293 - tp: 20.0000 - fp: 10.0000 - tn: 1616.0000 - fn: 378.0000 - accuracy: 0.8083 - precision: 0.6667 - recall: 0.0503 - auc: 0.6910 - prc: 0.3788 - val_loss: 0.5611 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6568 - val_prc: 0.2923\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8289 - tp: 15.0000 - fp: 8.0000 - tn: 1618.0000 - fn: 383.0000 - accuracy: 0.8068 - precision: 0.6522 - recall: 0.0377 - auc: 0.6913 - prc: 0.3810 - val_loss: 0.5608 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6587 - val_prc: 0.2936\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8282 - tp: 21.0000 - fp: 13.0000 - tn: 1613.0000 - fn: 377.0000 - accuracy: 0.8073 - precision: 0.6176 - recall: 0.0528 - auc: 0.6927 - prc: 0.3798 - val_loss: 0.5700 - val_tp: 2.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 89.0000 - val_accuracy: 0.8123 - val_precision: 0.2500 - val_recall: 0.0220 - val_auc: 0.6567 - val_prc: 0.2939\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8276 - tp: 24.0000 - fp: 15.0000 - tn: 1611.0000 - fn: 374.0000 - accuracy: 0.8078 - precision: 0.6154 - recall: 0.0603 - auc: 0.6931 - prc: 0.3843 - val_loss: 0.5693 - val_tp: 2.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 89.0000 - val_accuracy: 0.8123 - val_precision: 0.2500 - val_recall: 0.0220 - val_auc: 0.6574 - val_prc: 0.2954\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8271 - tp: 27.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 371.0000 - accuracy: 0.8088 - precision: 0.6279 - recall: 0.0678 - auc: 0.6932 - prc: 0.3850 - val_loss: 0.5722 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 88.0000 - val_accuracy: 0.8123 - val_precision: 0.3000 - val_recall: 0.0330 - val_auc: 0.6588 - val_prc: 0.2964\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8265 - tp: 28.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 370.0000 - accuracy: 0.8093 - precision: 0.6364 - recall: 0.0704 - auc: 0.6937 - prc: 0.3871 - val_loss: 0.5688 - val_tp: 2.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 89.0000 - val_accuracy: 0.8103 - val_precision: 0.2222 - val_recall: 0.0220 - val_auc: 0.6603 - val_prc: 0.2982\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8259 - tp: 27.0000 - fp: 17.0000 - tn: 1609.0000 - fn: 371.0000 - accuracy: 0.8083 - precision: 0.6136 - recall: 0.0678 - auc: 0.6939 - prc: 0.3863 - val_loss: 0.5679 - val_tp: 3.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 88.0000 - val_accuracy: 0.8123 - val_precision: 0.3000 - val_recall: 0.0330 - val_auc: 0.6578 - val_prc: 0.2959\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8251 - tp: 26.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 372.0000 - accuracy: 0.8083 - precision: 0.6190 - recall: 0.0653 - auc: 0.6955 - prc: 0.3878 - val_loss: 0.5617 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 89.0000 - val_accuracy: 0.8162 - val_precision: 0.3333 - val_recall: 0.0220 - val_auc: 0.6577 - val_prc: 0.2980\n",
      "Epoch 30/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8247 - tp: 24.0000 - fp: 14.0000 - tn: 1612.0000 - fn: 374.0000 - accuracy: 0.8083 - precision: 0.6316 - recall: 0.0603 - auc: 0.6956 - prc: 0.3894 - val_loss: 0.5607 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 411.0000 - val_fn: 89.0000 - val_accuracy: 0.8162 - val_precision: 0.3333 - val_recall: 0.0220 - val_auc: 0.6598 - val_prc: 0.2986\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8242 - tp: 24.0000 - fp: 14.0000 - tn: 1612.0000 - fn: 374.0000 - accuracy: 0.8083 - precision: 0.6316 - recall: 0.0603 - auc: 0.6953 - prc: 0.3887 - val_loss: 0.5610 - val_tp: 2.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 89.0000 - val_accuracy: 0.8123 - val_precision: 0.2500 - val_recall: 0.0220 - val_auc: 0.6587 - val_prc: 0.2981\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8235 - tp: 25.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 373.0000 - accuracy: 0.8078 - precision: 0.6098 - recall: 0.0628 - auc: 0.6960 - prc: 0.3906 - val_loss: 0.5614 - val_tp: 2.0000 - val_fp: 6.0000 - val_tn: 409.0000 - val_fn: 89.0000 - val_accuracy: 0.8123 - val_precision: 0.2500 - val_recall: 0.0220 - val_auc: 0.6602 - val_prc: 0.2991\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8232 - tp: 30.0000 - fp: 18.0000 - tn: 1608.0000 - fn: 368.0000 - accuracy: 0.8093 - precision: 0.6250 - recall: 0.0754 - auc: 0.6944 - prc: 0.3868 - val_loss: 0.5663 - val_tp: 6.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 85.0000 - val_accuracy: 0.8162 - val_precision: 0.4286 - val_recall: 0.0659 - val_auc: 0.6610 - val_prc: 0.3005\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8229 - tp: 31.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 367.0000 - accuracy: 0.8108 - precision: 0.6596 - recall: 0.0779 - auc: 0.6933 - prc: 0.3900 - val_loss: 0.5580 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 410.0000 - val_fn: 89.0000 - val_accuracy: 0.8142 - val_precision: 0.2857 - val_recall: 0.0220 - val_auc: 0.6587 - val_prc: 0.2999\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8217 - tp: 28.0000 - fp: 17.0000 - tn: 1609.0000 - fn: 370.0000 - accuracy: 0.8088 - precision: 0.6222 - recall: 0.0704 - auc: 0.6960 - prc: 0.3934 - val_loss: 0.5606 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 87.0000 - val_accuracy: 0.8142 - val_precision: 0.3636 - val_recall: 0.0440 - val_auc: 0.6604 - val_prc: 0.3017\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8213 - tp: 37.0000 - fp: 23.0000 - tn: 1603.0000 - fn: 361.0000 - accuracy: 0.8103 - precision: 0.6167 - recall: 0.0930 - auc: 0.6962 - prc: 0.3928 - val_loss: 0.5694 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 84.0000 - val_accuracy: 0.8162 - val_precision: 0.4375 - val_recall: 0.0769 - val_auc: 0.6619 - val_prc: 0.3032\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8203 - tp: 43.0000 - fp: 30.0000 - tn: 1596.0000 - fn: 355.0000 - accuracy: 0.8098 - precision: 0.5890 - recall: 0.1080 - auc: 0.6967 - prc: 0.3933 - val_loss: 0.5641 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 84.0000 - val_accuracy: 0.8162 - val_precision: 0.4375 - val_recall: 0.0769 - val_auc: 0.6627 - val_prc: 0.3034\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8195 - tp: 38.0000 - fp: 20.0000 - tn: 1606.0000 - fn: 360.0000 - accuracy: 0.8123 - precision: 0.6552 - recall: 0.0955 - auc: 0.6974 - prc: 0.3939 - val_loss: 0.5618 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 84.0000 - val_accuracy: 0.8162 - val_precision: 0.4375 - val_recall: 0.0769 - val_auc: 0.6619 - val_prc: 0.3044\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8187 - tp: 37.0000 - fp: 19.0000 - tn: 1607.0000 - fn: 361.0000 - accuracy: 0.8123 - precision: 0.6607 - recall: 0.0930 - auc: 0.6978 - prc: 0.3947 - val_loss: 0.5577 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 408.0000 - val_fn: 85.0000 - val_accuracy: 0.8182 - val_precision: 0.4615 - val_recall: 0.0659 - val_auc: 0.6606 - val_prc: 0.3045\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8181 - tp: 35.0000 - fp: 17.0000 - tn: 1609.0000 - fn: 363.0000 - accuracy: 0.8123 - precision: 0.6731 - recall: 0.0879 - auc: 0.6974 - prc: 0.3957 - val_loss: 0.5567 - val_tp: 7.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 84.0000 - val_accuracy: 0.8182 - val_precision: 0.4667 - val_recall: 0.0769 - val_auc: 0.6627 - val_prc: 0.3039\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8173 - tp: 37.0000 - fp: 18.0000 - tn: 1608.0000 - fn: 361.0000 - accuracy: 0.8127 - precision: 0.6727 - recall: 0.0930 - auc: 0.6985 - prc: 0.3955 - val_loss: 0.5571 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 84.0000 - val_accuracy: 0.8162 - val_precision: 0.4375 - val_recall: 0.0769 - val_auc: 0.6634 - val_prc: 0.3048\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8166 - tp: 40.0000 - fp: 25.0000 - tn: 1601.0000 - fn: 358.0000 - accuracy: 0.8108 - precision: 0.6154 - recall: 0.1005 - auc: 0.6989 - prc: 0.3955 - val_loss: 0.5611 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 82.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0989 - val_auc: 0.6633 - val_prc: 0.3048\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8158 - tp: 50.0000 - fp: 33.0000 - tn: 1593.0000 - fn: 348.0000 - accuracy: 0.8118 - precision: 0.6024 - recall: 0.1256 - auc: 0.6986 - prc: 0.3971 - val_loss: 0.5612 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 82.0000 - val_accuracy: 0.8182 - val_precision: 0.4737 - val_recall: 0.0989 - val_auc: 0.6636 - val_prc: 0.3062\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8149 - tp: 44.0000 - fp: 30.0000 - tn: 1596.0000 - fn: 354.0000 - accuracy: 0.8103 - precision: 0.5946 - recall: 0.1106 - auc: 0.6980 - prc: 0.3973 - val_loss: 0.5547 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 84.0000 - val_accuracy: 0.8162 - val_precision: 0.4375 - val_recall: 0.0769 - val_auc: 0.6661 - val_prc: 0.3086\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8141 - tp: 42.0000 - fp: 24.0000 - tn: 1602.0000 - fn: 356.0000 - accuracy: 0.8123 - precision: 0.6364 - recall: 0.1055 - auc: 0.6991 - prc: 0.4007 - val_loss: 0.5528 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 84.0000 - val_accuracy: 0.8162 - val_precision: 0.4375 - val_recall: 0.0769 - val_auc: 0.6645 - val_prc: 0.3093\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8132 - tp: 48.0000 - fp: 34.0000 - tn: 1592.0000 - fn: 350.0000 - accuracy: 0.8103 - precision: 0.5854 - recall: 0.1206 - auc: 0.6990 - prc: 0.4004 - val_loss: 0.5582 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 82.0000 - val_accuracy: 0.8182 - val_precision: 0.4737 - val_recall: 0.0989 - val_auc: 0.6659 - val_prc: 0.3099\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8122 - tp: 49.0000 - fp: 37.0000 - tn: 1589.0000 - fn: 349.0000 - accuracy: 0.8093 - precision: 0.5698 - recall: 0.1231 - auc: 0.6998 - prc: 0.4015 - val_loss: 0.5543 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 82.0000 - val_accuracy: 0.8182 - val_precision: 0.4737 - val_recall: 0.0989 - val_auc: 0.6646 - val_prc: 0.3095\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8117 - tp: 46.0000 - fp: 27.0000 - tn: 1599.0000 - fn: 352.0000 - accuracy: 0.8127 - precision: 0.6301 - recall: 0.1156 - auc: 0.6995 - prc: 0.4018 - val_loss: 0.5514 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 82.0000 - val_accuracy: 0.8182 - val_precision: 0.4737 - val_recall: 0.0989 - val_auc: 0.6672 - val_prc: 0.3143\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8107 - tp: 65.0000 - fp: 47.0000 - tn: 1579.0000 - fn: 333.0000 - accuracy: 0.8123 - precision: 0.5804 - recall: 0.1633 - auc: 0.6971 - prc: 0.4003 - val_loss: 0.5639 - val_tp: 12.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 79.0000 - val_accuracy: 0.8103 - val_precision: 0.4138 - val_recall: 0.1319 - val_auc: 0.6659 - val_prc: 0.3116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8098 - tp: 79.0000 - fp: 65.0000 - tn: 1561.0000 - fn: 319.0000 - accuracy: 0.8103 - precision: 0.5486 - recall: 0.1985 - auc: 0.6998 - prc: 0.4043 - val_loss: 0.5634 - val_tp: 12.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 79.0000 - val_accuracy: 0.8083 - val_precision: 0.4000 - val_recall: 0.1319 - val_auc: 0.6665 - val_prc: 0.3121\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8086 - tp: 79.0000 - fp: 63.0000 - tn: 1563.0000 - fn: 319.0000 - accuracy: 0.8113 - precision: 0.5563 - recall: 0.1985 - auc: 0.7004 - prc: 0.4055 - val_loss: 0.5592 - val_tp: 12.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 79.0000 - val_accuracy: 0.8123 - val_precision: 0.4286 - val_recall: 0.1319 - val_auc: 0.6675 - val_prc: 0.3146\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8071 - tp: 71.0000 - fp: 46.0000 - tn: 1580.0000 - fn: 327.0000 - accuracy: 0.8157 - precision: 0.6068 - recall: 0.1784 - auc: 0.7013 - prc: 0.4068 - val_loss: 0.5500 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 404.0000 - val_fn: 82.0000 - val_accuracy: 0.8162 - val_precision: 0.4500 - val_recall: 0.0989 - val_auc: 0.6679 - val_prc: 0.3151\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8069 - tp: 55.0000 - fp: 35.0000 - tn: 1591.0000 - fn: 343.0000 - accuracy: 0.8132 - precision: 0.6111 - recall: 0.1382 - auc: 0.7006 - prc: 0.4066 - val_loss: 0.5428 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 82.0000 - val_accuracy: 0.8182 - val_precision: 0.4737 - val_recall: 0.0989 - val_auc: 0.6669 - val_prc: 0.3170\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8057 - tp: 64.0000 - fp: 40.0000 - tn: 1586.0000 - fn: 334.0000 - accuracy: 0.8152 - precision: 0.6154 - recall: 0.1608 - auc: 0.7012 - prc: 0.4080 - val_loss: 0.5513 - val_tp: 10.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 81.0000 - val_accuracy: 0.8083 - val_precision: 0.3846 - val_recall: 0.1099 - val_auc: 0.6687 - val_prc: 0.3185\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8041 - tp: 77.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 321.0000 - accuracy: 0.8137 - precision: 0.5789 - recall: 0.1935 - auc: 0.7023 - prc: 0.4117 - val_loss: 0.5562 - val_tp: 14.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 77.0000 - val_accuracy: 0.8063 - val_precision: 0.4000 - val_recall: 0.1538 - val_auc: 0.6689 - val_prc: 0.3214\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8034 - tp: 90.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 308.0000 - accuracy: 0.8127 - precision: 0.5590 - recall: 0.2261 - auc: 0.7011 - prc: 0.4114 - val_loss: 0.5549 - val_tp: 16.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 75.0000 - val_accuracy: 0.8103 - val_precision: 0.4324 - val_recall: 0.1758 - val_auc: 0.6693 - val_prc: 0.3225\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8022 - tp: 88.0000 - fp: 71.0000 - tn: 1555.0000 - fn: 310.0000 - accuracy: 0.8118 - precision: 0.5535 - recall: 0.2211 - auc: 0.7022 - prc: 0.4136 - val_loss: 0.5522 - val_tp: 16.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 75.0000 - val_accuracy: 0.8123 - val_precision: 0.4444 - val_recall: 0.1758 - val_auc: 0.6680 - val_prc: 0.3232\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8016 - tp: 81.0000 - fp: 53.0000 - tn: 1573.0000 - fn: 317.0000 - accuracy: 0.8172 - precision: 0.6045 - recall: 0.2035 - auc: 0.7006 - prc: 0.4124 - val_loss: 0.5414 - val_tp: 10.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 81.0000 - val_accuracy: 0.8103 - val_precision: 0.4000 - val_recall: 0.1099 - val_auc: 0.6684 - val_prc: 0.3242\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8010 - tp: 69.0000 - fp: 45.0000 - tn: 1581.0000 - fn: 329.0000 - accuracy: 0.8152 - precision: 0.6053 - recall: 0.1734 - auc: 0.7017 - prc: 0.4143 - val_loss: 0.5418 - val_tp: 10.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 81.0000 - val_accuracy: 0.8083 - val_precision: 0.3846 - val_recall: 0.1099 - val_auc: 0.6685 - val_prc: 0.3242\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7996 - tp: 86.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 312.0000 - accuracy: 0.8123 - precision: 0.5584 - recall: 0.2161 - auc: 0.7022 - prc: 0.4110 - val_loss: 0.5549 - val_tp: 21.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 70.0000 - val_accuracy: 0.8083 - val_precision: 0.4375 - val_recall: 0.2308 - val_auc: 0.6703 - val_prc: 0.3265\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7983 - tp: 99.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 299.0000 - accuracy: 0.8098 - precision: 0.5351 - recall: 0.2487 - auc: 0.7025 - prc: 0.4153 - val_loss: 0.5511 - val_tp: 20.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 71.0000 - val_accuracy: 0.8123 - val_precision: 0.4545 - val_recall: 0.2198 - val_auc: 0.6706 - val_prc: 0.3252\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7974 - tp: 89.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 309.0000 - accuracy: 0.8147 - precision: 0.5742 - recall: 0.2236 - auc: 0.7019 - prc: 0.4129 - val_loss: 0.5408 - val_tp: 13.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 78.0000 - val_accuracy: 0.8083 - val_precision: 0.4062 - val_recall: 0.1429 - val_auc: 0.6692 - val_prc: 0.3238\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7967 - tp: 78.0000 - fp: 51.0000 - tn: 1575.0000 - fn: 320.0000 - accuracy: 0.8167 - precision: 0.6047 - recall: 0.1960 - auc: 0.7027 - prc: 0.4164 - val_loss: 0.5331 - val_tp: 10.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 81.0000 - val_accuracy: 0.8083 - val_precision: 0.3846 - val_recall: 0.1099 - val_auc: 0.6700 - val_prc: 0.3282\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7955 - tp: 79.0000 - fp: 53.0000 - tn: 1573.0000 - fn: 319.0000 - accuracy: 0.8162 - precision: 0.5985 - recall: 0.1985 - auc: 0.7038 - prc: 0.4180 - val_loss: 0.5392 - val_tp: 16.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 75.0000 - val_accuracy: 0.8123 - val_precision: 0.4444 - val_recall: 0.1758 - val_auc: 0.6715 - val_prc: 0.3318\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7941 - tp: 89.0000 - fp: 70.0000 - tn: 1556.0000 - fn: 309.0000 - accuracy: 0.8127 - precision: 0.5597 - recall: 0.2236 - auc: 0.7033 - prc: 0.4191 - val_loss: 0.5440 - val_tp: 21.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 70.0000 - val_accuracy: 0.8103 - val_precision: 0.4468 - val_recall: 0.2308 - val_auc: 0.6710 - val_prc: 0.3314\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7934 - tp: 111.0000 - fp: 98.0000 - tn: 1528.0000 - fn: 287.0000 - accuracy: 0.8098 - precision: 0.5311 - recall: 0.2789 - auc: 0.7026 - prc: 0.4165 - val_loss: 0.5501 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6709 - val_prc: 0.3311\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7916 - tp: 101.0000 - fp: 90.0000 - tn: 1536.0000 - fn: 297.0000 - accuracy: 0.8088 - precision: 0.5288 - recall: 0.2538 - auc: 0.7032 - prc: 0.4186 - val_loss: 0.5396 - val_tp: 20.0000 - val_fp: 26.0000 - val_tn: 389.0000 - val_fn: 71.0000 - val_accuracy: 0.8083 - val_precision: 0.4348 - val_recall: 0.2198 - val_auc: 0.6715 - val_prc: 0.3316\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7906 - tp: 101.0000 - fp: 89.0000 - tn: 1537.0000 - fn: 297.0000 - accuracy: 0.8093 - precision: 0.5316 - recall: 0.2538 - auc: 0.7031 - prc: 0.4190 - val_loss: 0.5451 - val_tp: 26.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 65.0000 - val_accuracy: 0.8162 - val_precision: 0.4815 - val_recall: 0.2857 - val_auc: 0.6718 - val_prc: 0.3328\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7895 - tp: 103.0000 - fp: 92.0000 - tn: 1534.0000 - fn: 295.0000 - accuracy: 0.8088 - precision: 0.5282 - recall: 0.2588 - auc: 0.7030 - prc: 0.4193 - val_loss: 0.5393 - val_tp: 25.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 66.0000 - val_accuracy: 0.8142 - val_precision: 0.4717 - val_recall: 0.2747 - val_auc: 0.6731 - val_prc: 0.3351\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7883 - tp: 122.0000 - fp: 111.0000 - tn: 1515.0000 - fn: 276.0000 - accuracy: 0.8088 - precision: 0.5236 - recall: 0.3065 - auc: 0.7030 - prc: 0.4214 - val_loss: 0.5536 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6730 - val_prc: 0.3362\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7877 - tp: 129.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 269.0000 - accuracy: 0.7979 - precision: 0.4796 - recall: 0.3241 - auc: 0.7037 - prc: 0.4245 - val_loss: 0.5464 - val_tp: 28.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 63.0000 - val_accuracy: 0.8103 - val_precision: 0.4590 - val_recall: 0.3077 - val_auc: 0.6730 - val_prc: 0.3373\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7861 - tp: 111.0000 - fp: 100.0000 - tn: 1526.0000 - fn: 287.0000 - accuracy: 0.8088 - precision: 0.5261 - recall: 0.2789 - auc: 0.7044 - prc: 0.4278 - val_loss: 0.5322 - val_tp: 24.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 67.0000 - val_accuracy: 0.8123 - val_precision: 0.4615 - val_recall: 0.2637 - val_auc: 0.6742 - val_prc: 0.3437\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7849 - tp: 123.0000 - fp: 114.0000 - tn: 1512.0000 - fn: 275.0000 - accuracy: 0.8078 - precision: 0.5190 - recall: 0.3090 - auc: 0.7052 - prc: 0.4303 - val_loss: 0.5451 - val_tp: 29.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 62.0000 - val_accuracy: 0.8063 - val_precision: 0.4462 - val_recall: 0.3187 - val_auc: 0.6742 - val_prc: 0.3448\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7842 - tp: 124.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 274.0000 - accuracy: 0.8009 - precision: 0.4901 - recall: 0.3116 - auc: 0.7046 - prc: 0.4294 - val_loss: 0.5381 - val_tp: 27.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 64.0000 - val_accuracy: 0.8103 - val_precision: 0.4576 - val_recall: 0.2967 - val_auc: 0.6750 - val_prc: 0.3435\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7832 - tp: 129.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 269.0000 - accuracy: 0.7969 - precision: 0.4760 - recall: 0.3241 - auc: 0.7045 - prc: 0.4278 - val_loss: 0.5449 - val_tp: 29.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 62.0000 - val_accuracy: 0.8024 - val_precision: 0.4328 - val_recall: 0.3187 - val_auc: 0.6748 - val_prc: 0.3409\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7820 - tp: 133.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 265.0000 - accuracy: 0.7955 - precision: 0.4716 - recall: 0.3342 - auc: 0.7063 - prc: 0.4279 - val_loss: 0.5418 - val_tp: 29.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 62.0000 - val_accuracy: 0.8043 - val_precision: 0.4394 - val_recall: 0.3187 - val_auc: 0.6753 - val_prc: 0.3420\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7806 - tp: 122.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 276.0000 - accuracy: 0.8004 - precision: 0.4880 - recall: 0.3065 - auc: 0.7062 - prc: 0.4279 - val_loss: 0.5299 - val_tp: 26.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 65.0000 - val_accuracy: 0.8123 - val_precision: 0.4643 - val_recall: 0.2857 - val_auc: 0.6752 - val_prc: 0.3432\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7802 - tp: 113.0000 - fp: 103.0000 - tn: 1523.0000 - fn: 285.0000 - accuracy: 0.8083 - precision: 0.5231 - recall: 0.2839 - auc: 0.7068 - prc: 0.4299 - val_loss: 0.5213 - val_tp: 24.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 67.0000 - val_accuracy: 0.8123 - val_precision: 0.4615 - val_recall: 0.2637 - val_auc: 0.6766 - val_prc: 0.3454\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7805 - tp: 100.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 298.0000 - accuracy: 0.8152 - precision: 0.5682 - recall: 0.2513 - auc: 0.7066 - prc: 0.4293 - val_loss: 0.5197 - val_tp: 24.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 67.0000 - val_accuracy: 0.8123 - val_precision: 0.4615 - val_recall: 0.2637 - val_auc: 0.6770 - val_prc: 0.3471\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7778 - tp: 123.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 275.0000 - accuracy: 0.8073 - precision: 0.5168 - recall: 0.3090 - auc: 0.7077 - prc: 0.4304 - val_loss: 0.5400 - val_tp: 31.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 60.0000 - val_accuracy: 0.8004 - val_precision: 0.4306 - val_recall: 0.3407 - val_auc: 0.6766 - val_prc: 0.3469\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7779 - tp: 150.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 248.0000 - accuracy: 0.7890 - precision: 0.4559 - recall: 0.3769 - auc: 0.7062 - prc: 0.4303 - val_loss: 0.5399 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6773 - val_prc: 0.3482\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7768 - tp: 124.0000 - fp: 110.0000 - tn: 1516.0000 - fn: 274.0000 - accuracy: 0.8103 - precision: 0.5299 - recall: 0.3116 - auc: 0.7068 - prc: 0.4330 - val_loss: 0.5098 - val_tp: 23.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 68.0000 - val_accuracy: 0.8162 - val_precision: 0.4792 - val_recall: 0.2527 - val_auc: 0.6789 - val_prc: 0.3562\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7776 - tp: 102.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 296.0000 - accuracy: 0.8157 - precision: 0.5698 - recall: 0.2563 - auc: 0.7078 - prc: 0.4356 - val_loss: 0.5164 - val_tp: 25.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 66.0000 - val_accuracy: 0.8123 - val_precision: 0.4630 - val_recall: 0.2747 - val_auc: 0.6775 - val_prc: 0.3503\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7747 - tp: 132.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 266.0000 - accuracy: 0.8009 - precision: 0.4907 - recall: 0.3317 - auc: 0.7068 - prc: 0.4331 - val_loss: 0.5360 - val_tp: 32.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 59.0000 - val_accuracy: 0.7964 - val_precision: 0.4211 - val_recall: 0.3516 - val_auc: 0.6775 - val_prc: 0.3490\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7741 - tp: 139.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 259.0000 - accuracy: 0.7994 - precision: 0.4860 - recall: 0.3492 - auc: 0.7071 - prc: 0.4346 - val_loss: 0.5295 - val_tp: 30.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 61.0000 - val_accuracy: 0.7984 - val_precision: 0.4225 - val_recall: 0.3297 - val_auc: 0.6781 - val_prc: 0.3614\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7731 - tp: 145.0000 - fp: 163.0000 - tn: 1463.0000 - fn: 253.0000 - accuracy: 0.7945 - precision: 0.4708 - recall: 0.3643 - auc: 0.7078 - prc: 0.4334 - val_loss: 0.5334 - val_tp: 32.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 59.0000 - val_accuracy: 0.7964 - val_precision: 0.4211 - val_recall: 0.3516 - val_auc: 0.6783 - val_prc: 0.3609\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7719 - tp: 142.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 256.0000 - accuracy: 0.7999 - precision: 0.4880 - recall: 0.3568 - auc: 0.7087 - prc: 0.4367 - val_loss: 0.5203 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6789 - val_prc: 0.3666\n",
      "Epoch 88/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7721 - tp: 136.0000 - fp: 136.0000 - tn: 1490.0000 - fn: 262.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3417 - auc: 0.7075 - prc: 0.4340 - val_loss: 0.5229 - val_tp: 30.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 61.0000 - val_accuracy: 0.8024 - val_precision: 0.4348 - val_recall: 0.3297 - val_auc: 0.6786 - val_prc: 0.3652\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7720 - tp: 125.0000 - fp: 129.0000 - tn: 1497.0000 - fn: 273.0000 - accuracy: 0.8014 - precision: 0.4921 - recall: 0.3141 - auc: 0.7077 - prc: 0.4344 - val_loss: 0.5171 - val_tp: 29.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 62.0000 - val_accuracy: 0.8103 - val_precision: 0.4603 - val_recall: 0.3187 - val_auc: 0.6789 - val_prc: 0.3688\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7703 - tp: 133.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 265.0000 - accuracy: 0.8024 - precision: 0.4963 - recall: 0.3342 - auc: 0.7099 - prc: 0.4372 - val_loss: 0.5236 - val_tp: 30.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 61.0000 - val_accuracy: 0.7984 - val_precision: 0.4225 - val_recall: 0.3297 - val_auc: 0.6787 - val_prc: 0.3638\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7696 - tp: 145.0000 - fp: 162.0000 - tn: 1464.0000 - fn: 253.0000 - accuracy: 0.7950 - precision: 0.4723 - recall: 0.3643 - auc: 0.7106 - prc: 0.4357 - val_loss: 0.5319 - val_tp: 32.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 59.0000 - val_accuracy: 0.7905 - val_precision: 0.4051 - val_recall: 0.3516 - val_auc: 0.6774 - val_prc: 0.3632\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7711 - tp: 162.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 236.0000 - accuracy: 0.7762 - precision: 0.4274 - recall: 0.4070 - auc: 0.7094 - prc: 0.4329 - val_loss: 0.5428 - val_tp: 33.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 58.0000 - val_accuracy: 0.7767 - val_precision: 0.3750 - val_recall: 0.3626 - val_auc: 0.6778 - val_prc: 0.3675\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7691 - tp: 159.0000 - fp: 206.0000 - tn: 1420.0000 - fn: 239.0000 - accuracy: 0.7801 - precision: 0.4356 - recall: 0.3995 - auc: 0.7098 - prc: 0.4366 - val_loss: 0.5238 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6796 - val_prc: 0.3763\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7691 - tp: 134.0000 - fp: 137.0000 - tn: 1489.0000 - fn: 264.0000 - accuracy: 0.8019 - precision: 0.4945 - recall: 0.3367 - auc: 0.7094 - prc: 0.4405 - val_loss: 0.5172 - val_tp: 31.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 60.0000 - val_accuracy: 0.8004 - val_precision: 0.4306 - val_recall: 0.3407 - val_auc: 0.6803 - val_prc: 0.3805\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7678 - tp: 152.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 246.0000 - accuracy: 0.7841 - precision: 0.4431 - recall: 0.3819 - auc: 0.7103 - prc: 0.4412 - val_loss: 0.5356 - val_tp: 32.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 59.0000 - val_accuracy: 0.7787 - val_precision: 0.3765 - val_recall: 0.3516 - val_auc: 0.6792 - val_prc: 0.3781\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7679 - tp: 154.0000 - fp: 177.0000 - tn: 1449.0000 - fn: 244.0000 - accuracy: 0.7920 - precision: 0.4653 - recall: 0.3869 - auc: 0.7091 - prc: 0.4394 - val_loss: 0.5180 - val_tp: 31.0000 - val_fp: 41.0000 - val_tn: 374.0000 - val_fn: 60.0000 - val_accuracy: 0.8004 - val_precision: 0.4306 - val_recall: 0.3407 - val_auc: 0.6797 - val_prc: 0.3810\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7663 - tp: 151.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 247.0000 - accuracy: 0.7895 - precision: 0.4576 - recall: 0.3794 - auc: 0.7104 - prc: 0.4422 - val_loss: 0.5250 - val_tp: 31.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 60.0000 - val_accuracy: 0.7846 - val_precision: 0.3875 - val_recall: 0.3407 - val_auc: 0.6795 - val_prc: 0.3785\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7660 - tp: 140.0000 - fp: 151.0000 - tn: 1475.0000 - fn: 258.0000 - accuracy: 0.7979 - precision: 0.4811 - recall: 0.3518 - auc: 0.7118 - prc: 0.4422 - val_loss: 0.5106 - val_tp: 30.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 61.0000 - val_accuracy: 0.8063 - val_precision: 0.4478 - val_recall: 0.3297 - val_auc: 0.6802 - val_prc: 0.3781\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7648 - tp: 146.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 252.0000 - accuracy: 0.7994 - precision: 0.4867 - recall: 0.3668 - auc: 0.7123 - prc: 0.4441 - val_loss: 0.5246 - val_tp: 32.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 59.0000 - val_accuracy: 0.7846 - val_precision: 0.3902 - val_recall: 0.3516 - val_auc: 0.6808 - val_prc: 0.3792\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7651 - tp: 150.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 248.0000 - accuracy: 0.7890 - precision: 0.4559 - recall: 0.3769 - auc: 0.7117 - prc: 0.4425 - val_loss: 0.5176 - val_tp: 31.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 60.0000 - val_accuracy: 0.7885 - val_precision: 0.3974 - val_recall: 0.3407 - val_auc: 0.6801 - val_prc: 0.3890\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7643 - tp: 159.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 239.0000 - accuracy: 0.7821 - precision: 0.4404 - recall: 0.3995 - auc: 0.7125 - prc: 0.4459 - val_loss: 0.5319 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6810 - val_prc: 0.3905\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7642 - tp: 162.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 236.0000 - accuracy: 0.7782 - precision: 0.4320 - recall: 0.4070 - auc: 0.7125 - prc: 0.4458 - val_loss: 0.5254 - val_tp: 32.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 59.0000 - val_accuracy: 0.7806 - val_precision: 0.3810 - val_recall: 0.3516 - val_auc: 0.6801 - val_prc: 0.3851\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7640 - tp: 145.0000 - fp: 162.0000 - tn: 1464.0000 - fn: 253.0000 - accuracy: 0.7950 - precision: 0.4723 - recall: 0.3643 - auc: 0.7117 - prc: 0.4426 - val_loss: 0.5083 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6802 - val_prc: 0.3804\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7633 - tp: 144.0000 - fp: 150.0000 - tn: 1476.0000 - fn: 254.0000 - accuracy: 0.8004 - precision: 0.4898 - recall: 0.3618 - auc: 0.7134 - prc: 0.4437 - val_loss: 0.5115 - val_tp: 31.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 60.0000 - val_accuracy: 0.8024 - val_precision: 0.4366 - val_recall: 0.3407 - val_auc: 0.6792 - val_prc: 0.3802\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7634 - tp: 143.0000 - fp: 143.0000 - tn: 1483.0000 - fn: 255.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3593 - auc: 0.7131 - prc: 0.4460 - val_loss: 0.5106 - val_tp: 31.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 60.0000 - val_accuracy: 0.8024 - val_precision: 0.4366 - val_recall: 0.3407 - val_auc: 0.6800 - val_prc: 0.3843\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7631 - tp: 169.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 229.0000 - accuracy: 0.7841 - precision: 0.4483 - recall: 0.4246 - auc: 0.7126 - prc: 0.4421 - val_loss: 0.5392 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6795 - val_prc: 0.3811\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7632 - tp: 167.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 231.0000 - accuracy: 0.7787 - precision: 0.4349 - recall: 0.4196 - auc: 0.7128 - prc: 0.4441 - val_loss: 0.5117 - val_tp: 31.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 60.0000 - val_accuracy: 0.7925 - val_precision: 0.4079 - val_recall: 0.3407 - val_auc: 0.6807 - val_prc: 0.3892\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7621 - tp: 143.0000 - fp: 140.0000 - tn: 1486.0000 - fn: 255.0000 - accuracy: 0.8048 - precision: 0.5053 - recall: 0.3593 - auc: 0.7141 - prc: 0.4501 - val_loss: 0.5028 - val_tp: 31.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 60.0000 - val_accuracy: 0.8083 - val_precision: 0.4559 - val_recall: 0.3407 - val_auc: 0.6819 - val_prc: 0.3995\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7615 - tp: 151.0000 - fp: 163.0000 - tn: 1463.0000 - fn: 247.0000 - accuracy: 0.7974 - precision: 0.4809 - recall: 0.3794 - auc: 0.7132 - prc: 0.4494 - val_loss: 0.5221 - val_tp: 33.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 58.0000 - val_accuracy: 0.7826 - val_precision: 0.3882 - val_recall: 0.3626 - val_auc: 0.6795 - val_prc: 0.3930\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7625 - tp: 170.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 228.0000 - accuracy: 0.7772 - precision: 0.4326 - recall: 0.4271 - auc: 0.7130 - prc: 0.4474 - val_loss: 0.5365 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6811 - val_prc: 0.3932\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7620 - tp: 172.0000 - fp: 237.0000 - tn: 1389.0000 - fn: 226.0000 - accuracy: 0.7712 - precision: 0.4205 - recall: 0.4322 - auc: 0.7137 - prc: 0.4504 - val_loss: 0.5235 - val_tp: 35.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 56.0000 - val_accuracy: 0.7846 - val_precision: 0.3977 - val_recall: 0.3846 - val_auc: 0.6816 - val_prc: 0.3999\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7597 - tp: 154.0000 - fp: 179.0000 - tn: 1447.0000 - fn: 244.0000 - accuracy: 0.7910 - precision: 0.4625 - recall: 0.3869 - auc: 0.7154 - prc: 0.4523 - val_loss: 0.5088 - val_tp: 31.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 60.0000 - val_accuracy: 0.7945 - val_precision: 0.4133 - val_recall: 0.3407 - val_auc: 0.6818 - val_prc: 0.4020\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7596 - tp: 154.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 244.0000 - accuracy: 0.7885 - precision: 0.4556 - recall: 0.3869 - auc: 0.7146 - prc: 0.4528 - val_loss: 0.5226 - val_tp: 35.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 56.0000 - val_accuracy: 0.7846 - val_precision: 0.3977 - val_recall: 0.3846 - val_auc: 0.6801 - val_prc: 0.3936\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7589 - tp: 158.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 240.0000 - accuracy: 0.7821 - precision: 0.4401 - recall: 0.3970 - auc: 0.7152 - prc: 0.4540 - val_loss: 0.5166 - val_tp: 32.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 59.0000 - val_accuracy: 0.7826 - val_precision: 0.3855 - val_recall: 0.3516 - val_auc: 0.6815 - val_prc: 0.3986\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7585 - tp: 157.0000 - fp: 192.0000 - tn: 1434.0000 - fn: 241.0000 - accuracy: 0.7861 - precision: 0.4499 - recall: 0.3945 - auc: 0.7157 - prc: 0.4541 - val_loss: 0.5138 - val_tp: 32.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 59.0000 - val_accuracy: 0.7846 - val_precision: 0.3902 - val_recall: 0.3516 - val_auc: 0.6818 - val_prc: 0.4008\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7589 - tp: 149.0000 - fp: 162.0000 - tn: 1464.0000 - fn: 249.0000 - accuracy: 0.7969 - precision: 0.4791 - recall: 0.3744 - auc: 0.7158 - prc: 0.4547 - val_loss: 0.5056 - val_tp: 31.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 60.0000 - val_accuracy: 0.7964 - val_precision: 0.4189 - val_recall: 0.3407 - val_auc: 0.6811 - val_prc: 0.4001\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7592 - tp: 160.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 238.0000 - accuracy: 0.7856 - precision: 0.4494 - recall: 0.4020 - auc: 0.7148 - prc: 0.4511 - val_loss: 0.5238 - val_tp: 35.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 56.0000 - val_accuracy: 0.7846 - val_precision: 0.3977 - val_recall: 0.3846 - val_auc: 0.6811 - val_prc: 0.3908\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7588 - tp: 150.0000 - fp: 173.0000 - tn: 1453.0000 - fn: 248.0000 - accuracy: 0.7920 - precision: 0.4644 - recall: 0.3769 - auc: 0.7153 - prc: 0.4551 - val_loss: 0.5007 - val_tp: 31.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 60.0000 - val_accuracy: 0.8043 - val_precision: 0.4429 - val_recall: 0.3407 - val_auc: 0.6815 - val_prc: 0.3941\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7573 - tp: 155.0000 - fp: 162.0000 - tn: 1464.0000 - fn: 243.0000 - accuracy: 0.7999 - precision: 0.4890 - recall: 0.3894 - auc: 0.7168 - prc: 0.4563 - val_loss: 0.5229 - val_tp: 35.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 56.0000 - val_accuracy: 0.7846 - val_precision: 0.3977 - val_recall: 0.3846 - val_auc: 0.6811 - val_prc: 0.3914\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7584 - tp: 174.0000 - fp: 225.0000 - tn: 1401.0000 - fn: 224.0000 - accuracy: 0.7782 - precision: 0.4361 - recall: 0.4372 - auc: 0.7156 - prc: 0.4550 - val_loss: 0.5244 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6808 - val_prc: 0.3992\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7584 - tp: 150.0000 - fp: 165.0000 - tn: 1461.0000 - fn: 248.0000 - accuracy: 0.7959 - precision: 0.4762 - recall: 0.3769 - auc: 0.7157 - prc: 0.4547 - val_loss: 0.4983 - val_tp: 31.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 60.0000 - val_accuracy: 0.8063 - val_precision: 0.4493 - val_recall: 0.3407 - val_auc: 0.6813 - val_prc: 0.4040\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7573 - tp: 147.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 251.0000 - accuracy: 0.8058 - precision: 0.5087 - recall: 0.3693 - auc: 0.7170 - prc: 0.4604 - val_loss: 0.5109 - val_tp: 32.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 59.0000 - val_accuracy: 0.7866 - val_precision: 0.3951 - val_recall: 0.3516 - val_auc: 0.6830 - val_prc: 0.4073\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7561 - tp: 160.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 238.0000 - accuracy: 0.7831 - precision: 0.4432 - recall: 0.4020 - auc: 0.7167 - prc: 0.4626 - val_loss: 0.5276 - val_tp: 37.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 54.0000 - val_accuracy: 0.7767 - val_precision: 0.3854 - val_recall: 0.4066 - val_auc: 0.6825 - val_prc: 0.4050\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7567 - tp: 173.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 225.0000 - accuracy: 0.7762 - precision: 0.4314 - recall: 0.4347 - auc: 0.7168 - prc: 0.4598 - val_loss: 0.5210 - val_tp: 35.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 56.0000 - val_accuracy: 0.7826 - val_precision: 0.3933 - val_recall: 0.3846 - val_auc: 0.6820 - val_prc: 0.3967\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7563 - tp: 170.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 228.0000 - accuracy: 0.7777 - precision: 0.4337 - recall: 0.4271 - auc: 0.7169 - prc: 0.4588 - val_loss: 0.5240 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6811 - val_prc: 0.3926\n",
      "Epoch 126/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7554 - tp: 161.0000 - fp: 207.0000 - tn: 1419.0000 - fn: 237.0000 - accuracy: 0.7806 - precision: 0.4375 - recall: 0.4045 - auc: 0.7177 - prc: 0.4569 - val_loss: 0.5091 - val_tp: 32.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 59.0000 - val_accuracy: 0.7925 - val_precision: 0.4103 - val_recall: 0.3516 - val_auc: 0.6813 - val_prc: 0.3930\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7537 - tp: 155.0000 - fp: 165.0000 - tn: 1461.0000 - fn: 243.0000 - accuracy: 0.7984 - precision: 0.4844 - recall: 0.3894 - auc: 0.7192 - prc: 0.4605 - val_loss: 0.5105 - val_tp: 36.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 55.0000 - val_accuracy: 0.7945 - val_precision: 0.4235 - val_recall: 0.3956 - val_auc: 0.6833 - val_prc: 0.3998\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7536 - tp: 159.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 239.0000 - accuracy: 0.7910 - precision: 0.4636 - recall: 0.3995 - auc: 0.7173 - prc: 0.4626 - val_loss: 0.4991 - val_tp: 34.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 57.0000 - val_accuracy: 0.7964 - val_precision: 0.4250 - val_recall: 0.3736 - val_auc: 0.6863 - val_prc: 0.4188\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7525 - tp: 158.0000 - fp: 177.0000 - tn: 1449.0000 - fn: 240.0000 - accuracy: 0.7940 - precision: 0.4716 - recall: 0.3970 - auc: 0.7191 - prc: 0.4664 - val_loss: 0.5105 - val_tp: 37.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 54.0000 - val_accuracy: 0.7925 - val_precision: 0.4205 - val_recall: 0.4066 - val_auc: 0.6869 - val_prc: 0.4210\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7509 - tp: 161.0000 - fp: 181.0000 - tn: 1445.0000 - fn: 237.0000 - accuracy: 0.7935 - precision: 0.4708 - recall: 0.4045 - auc: 0.7203 - prc: 0.4686 - val_loss: 0.4998 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6857 - val_prc: 0.4187\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7513 - tp: 155.0000 - fp: 160.0000 - tn: 1466.0000 - fn: 243.0000 - accuracy: 0.8009 - precision: 0.4921 - recall: 0.3894 - auc: 0.7196 - prc: 0.4682 - val_loss: 0.5044 - val_tp: 36.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 55.0000 - val_accuracy: 0.7964 - val_precision: 0.4286 - val_recall: 0.3956 - val_auc: 0.6872 - val_prc: 0.4200\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7508 - tp: 160.0000 - fp: 177.0000 - tn: 1449.0000 - fn: 238.0000 - accuracy: 0.7950 - precision: 0.4748 - recall: 0.4020 - auc: 0.7204 - prc: 0.4686 - val_loss: 0.5151 - val_tp: 38.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 53.0000 - val_accuracy: 0.7885 - val_precision: 0.4130 - val_recall: 0.4176 - val_auc: 0.6867 - val_prc: 0.4216\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7517 - tp: 165.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 233.0000 - accuracy: 0.7885 - precision: 0.4583 - recall: 0.4146 - auc: 0.7180 - prc: 0.4678 - val_loss: 0.5179 - val_tp: 38.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 53.0000 - val_accuracy: 0.7866 - val_precision: 0.4086 - val_recall: 0.4176 - val_auc: 0.6848 - val_prc: 0.4131\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7561 - tp: 188.0000 - fp: 265.0000 - tn: 1361.0000 - fn: 210.0000 - accuracy: 0.7653 - precision: 0.4150 - recall: 0.4724 - auc: 0.7183 - prc: 0.4642 - val_loss: 0.5129 - val_tp: 36.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 55.0000 - val_accuracy: 0.7866 - val_precision: 0.4045 - val_recall: 0.3956 - val_auc: 0.6847 - val_prc: 0.4120\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7543 - tp: 143.0000 - fp: 144.0000 - tn: 1482.0000 - fn: 255.0000 - accuracy: 0.8029 - precision: 0.4983 - recall: 0.3593 - auc: 0.7196 - prc: 0.4647 - val_loss: 0.4878 - val_tp: 32.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 59.0000 - val_accuracy: 0.8103 - val_precision: 0.4638 - val_recall: 0.3516 - val_auc: 0.6866 - val_prc: 0.4174\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7493 - tp: 150.0000 - fp: 165.0000 - tn: 1461.0000 - fn: 248.0000 - accuracy: 0.7959 - precision: 0.4762 - recall: 0.3769 - auc: 0.7231 - prc: 0.4693 - val_loss: 0.5235 - val_tp: 39.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 52.0000 - val_accuracy: 0.7866 - val_precision: 0.4105 - val_recall: 0.4286 - val_auc: 0.6832 - val_prc: 0.4084\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7527 - tp: 184.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 214.0000 - accuracy: 0.7722 - precision: 0.4269 - recall: 0.4623 - auc: 0.7212 - prc: 0.4680 - val_loss: 0.5195 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6865 - val_prc: 0.4211\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7490 - tp: 162.0000 - fp: 185.0000 - tn: 1441.0000 - fn: 236.0000 - accuracy: 0.7920 - precision: 0.4669 - recall: 0.4070 - auc: 0.7225 - prc: 0.4718 - val_loss: 0.5005 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6872 - val_prc: 0.4292\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7490 - tp: 153.0000 - fp: 153.0000 - tn: 1473.0000 - fn: 245.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3844 - auc: 0.7225 - prc: 0.4736 - val_loss: 0.5040 - val_tp: 36.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 55.0000 - val_accuracy: 0.7984 - val_precision: 0.4337 - val_recall: 0.3956 - val_auc: 0.6878 - val_prc: 0.4297\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7503 - tp: 178.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 220.0000 - accuracy: 0.7762 - precision: 0.4331 - recall: 0.4472 - auc: 0.7209 - prc: 0.4722 - val_loss: 0.5181 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6890 - val_prc: 0.4271\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7478 - tp: 170.0000 - fp: 192.0000 - tn: 1434.0000 - fn: 228.0000 - accuracy: 0.7925 - precision: 0.4696 - recall: 0.4271 - auc: 0.7236 - prc: 0.4732 - val_loss: 0.4962 - val_tp: 36.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 55.0000 - val_accuracy: 0.8083 - val_precision: 0.4615 - val_recall: 0.3956 - val_auc: 0.6884 - val_prc: 0.4275\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7484 - tp: 155.0000 - fp: 159.0000 - tn: 1467.0000 - fn: 243.0000 - accuracy: 0.8014 - precision: 0.4936 - recall: 0.3894 - auc: 0.7222 - prc: 0.4754 - val_loss: 0.5086 - val_tp: 37.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 54.0000 - val_accuracy: 0.7905 - val_precision: 0.4157 - val_recall: 0.4066 - val_auc: 0.6883 - val_prc: 0.4311\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7481 - tp: 159.0000 - fp: 175.0000 - tn: 1451.0000 - fn: 239.0000 - accuracy: 0.7955 - precision: 0.4760 - recall: 0.3995 - auc: 0.7226 - prc: 0.4729 - val_loss: 0.5129 - val_tp: 38.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 53.0000 - val_accuracy: 0.7905 - val_precision: 0.4176 - val_recall: 0.4176 - val_auc: 0.6900 - val_prc: 0.4295\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7505 - tp: 186.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 212.0000 - accuracy: 0.7732 - precision: 0.4296 - recall: 0.4673 - auc: 0.7220 - prc: 0.4739 - val_loss: 0.5199 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6878 - val_prc: 0.4230\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7478 - tp: 158.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 240.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3970 - auc: 0.7228 - prc: 0.4749 - val_loss: 0.4902 - val_tp: 33.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 58.0000 - val_accuracy: 0.8083 - val_precision: 0.4583 - val_recall: 0.3626 - val_auc: 0.6894 - val_prc: 0.4307\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7479 - tp: 151.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 247.0000 - accuracy: 0.8014 - precision: 0.4935 - recall: 0.3794 - auc: 0.7235 - prc: 0.4760 - val_loss: 0.5061 - val_tp: 36.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 55.0000 - val_accuracy: 0.7964 - val_precision: 0.4286 - val_recall: 0.3956 - val_auc: 0.6862 - val_prc: 0.4213\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7469 - tp: 160.0000 - fp: 180.0000 - tn: 1446.0000 - fn: 238.0000 - accuracy: 0.7935 - precision: 0.4706 - recall: 0.4020 - auc: 0.7234 - prc: 0.4754 - val_loss: 0.5053 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6865 - val_prc: 0.4236\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7466 - tp: 163.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 235.0000 - accuracy: 0.7935 - precision: 0.4711 - recall: 0.4095 - auc: 0.7234 - prc: 0.4755 - val_loss: 0.5110 - val_tp: 37.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 54.0000 - val_accuracy: 0.7866 - val_precision: 0.4066 - val_recall: 0.4066 - val_auc: 0.6865 - val_prc: 0.4257\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7463 - tp: 170.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 228.0000 - accuracy: 0.7910 - precision: 0.4658 - recall: 0.4271 - auc: 0.7239 - prc: 0.4770 - val_loss: 0.5057 - val_tp: 36.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 55.0000 - val_accuracy: 0.7964 - val_precision: 0.4286 - val_recall: 0.3956 - val_auc: 0.6865 - val_prc: 0.4277\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7471 - tp: 152.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 246.0000 - accuracy: 0.8004 - precision: 0.4903 - recall: 0.3819 - auc: 0.7245 - prc: 0.4752 - val_loss: 0.4968 - val_tp: 36.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 55.0000 - val_accuracy: 0.8043 - val_precision: 0.4500 - val_recall: 0.3956 - val_auc: 0.6898 - val_prc: 0.4357\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7462 - tp: 162.0000 - fp: 168.0000 - tn: 1458.0000 - fn: 236.0000 - accuracy: 0.8004 - precision: 0.4909 - recall: 0.4070 - auc: 0.7245 - prc: 0.4765 - val_loss: 0.5037 - val_tp: 36.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 55.0000 - val_accuracy: 0.7984 - val_precision: 0.4337 - val_recall: 0.3956 - val_auc: 0.6891 - val_prc: 0.4341\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7468 - tp: 158.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 240.0000 - accuracy: 0.8039 - precision: 0.5016 - recall: 0.3970 - auc: 0.7241 - prc: 0.4757 - val_loss: 0.4955 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6876 - val_prc: 0.4272\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7466 - tp: 153.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 245.0000 - accuracy: 0.8029 - precision: 0.4984 - recall: 0.3844 - auc: 0.7244 - prc: 0.4773 - val_loss: 0.5066 - val_tp: 36.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 55.0000 - val_accuracy: 0.7945 - val_precision: 0.4235 - val_recall: 0.3956 - val_auc: 0.6875 - val_prc: 0.4275\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7470 - tp: 174.0000 - fp: 202.0000 - tn: 1424.0000 - fn: 224.0000 - accuracy: 0.7895 - precision: 0.4628 - recall: 0.4372 - auc: 0.7235 - prc: 0.4757 - val_loss: 0.5019 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6876 - val_prc: 0.4284\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7455 - tp: 160.0000 - fp: 167.0000 - tn: 1459.0000 - fn: 238.0000 - accuracy: 0.7999 - precision: 0.4893 - recall: 0.4020 - auc: 0.7253 - prc: 0.4784 - val_loss: 0.5009 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6857 - val_prc: 0.4200\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7470 - tp: 149.0000 - fp: 153.0000 - tn: 1473.0000 - fn: 249.0000 - accuracy: 0.8014 - precision: 0.4934 - recall: 0.3744 - auc: 0.7242 - prc: 0.4773 - val_loss: 0.5006 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6847 - val_prc: 0.4198\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7452 - tp: 158.0000 - fp: 164.0000 - tn: 1462.0000 - fn: 240.0000 - accuracy: 0.8004 - precision: 0.4907 - recall: 0.3970 - auc: 0.7250 - prc: 0.4785 - val_loss: 0.5098 - val_tp: 36.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 55.0000 - val_accuracy: 0.7905 - val_precision: 0.4138 - val_recall: 0.3956 - val_auc: 0.6867 - val_prc: 0.4219\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7469 - tp: 186.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 212.0000 - accuracy: 0.7801 - precision: 0.4439 - recall: 0.4673 - auc: 0.7247 - prc: 0.4783 - val_loss: 0.5195 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6853 - val_prc: 0.4211\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7439 - tp: 154.0000 - fp: 151.0000 - tn: 1475.0000 - fn: 244.0000 - accuracy: 0.8048 - precision: 0.5049 - recall: 0.3869 - auc: 0.7275 - prc: 0.4801 - val_loss: 0.4840 - val_tp: 31.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 60.0000 - val_accuracy: 0.8103 - val_precision: 0.4627 - val_recall: 0.3407 - val_auc: 0.6855 - val_prc: 0.4215\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7495 - tp: 136.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 262.0000 - accuracy: 0.8123 - precision: 0.5354 - recall: 0.3417 - auc: 0.7257 - prc: 0.4776 - val_loss: 0.4915 - val_tp: 33.0000 - val_fp: 39.0000 - val_tn: 376.0000 - val_fn: 58.0000 - val_accuracy: 0.8083 - val_precision: 0.4583 - val_recall: 0.3626 - val_auc: 0.6873 - val_prc: 0.4253\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7472 - tp: 162.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 236.0000 - accuracy: 0.7974 - precision: 0.4821 - recall: 0.4070 - auc: 0.7237 - prc: 0.4748 - val_loss: 0.5089 - val_tp: 36.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 55.0000 - val_accuracy: 0.7945 - val_precision: 0.4235 - val_recall: 0.3956 - val_auc: 0.6867 - val_prc: 0.4288\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7454 - tp: 154.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 244.0000 - accuracy: 0.8019 - precision: 0.4952 - recall: 0.3869 - auc: 0.7259 - prc: 0.4787 - val_loss: 0.4964 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6882 - val_prc: 0.4329\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7448 - tp: 152.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 246.0000 - accuracy: 0.8048 - precision: 0.5050 - recall: 0.3819 - auc: 0.7260 - prc: 0.4800 - val_loss: 0.4999 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6880 - val_prc: 0.4325\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7448 - tp: 168.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 230.0000 - accuracy: 0.7910 - precision: 0.4654 - recall: 0.4221 - auc: 0.7257 - prc: 0.4782 - val_loss: 0.5124 - val_tp: 38.0000 - val_fp: 53.0000 - val_tn: 362.0000 - val_fn: 53.0000 - val_accuracy: 0.7905 - val_precision: 0.4176 - val_recall: 0.4176 - val_auc: 0.6853 - val_prc: 0.4212\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7460 - tp: 151.0000 - fp: 154.0000 - tn: 1472.0000 - fn: 247.0000 - accuracy: 0.8019 - precision: 0.4951 - recall: 0.3794 - auc: 0.7245 - prc: 0.4773 - val_loss: 0.4944 - val_tp: 35.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 56.0000 - val_accuracy: 0.8063 - val_precision: 0.4545 - val_recall: 0.3846 - val_auc: 0.6863 - val_prc: 0.4232\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7450 - tp: 172.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 226.0000 - accuracy: 0.7910 - precision: 0.4661 - recall: 0.4322 - auc: 0.7253 - prc: 0.4783 - val_loss: 0.5155 - val_tp: 38.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 53.0000 - val_accuracy: 0.7866 - val_precision: 0.4086 - val_recall: 0.4176 - val_auc: 0.6869 - val_prc: 0.4315\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7446 - tp: 166.0000 - fp: 184.0000 - tn: 1442.0000 - fn: 232.0000 - accuracy: 0.7945 - precision: 0.4743 - recall: 0.4171 - auc: 0.7262 - prc: 0.4766 - val_loss: 0.4955 - val_tp: 36.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 55.0000 - val_accuracy: 0.8083 - val_precision: 0.4615 - val_recall: 0.3956 - val_auc: 0.6884 - val_prc: 0.4383\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7442 - tp: 157.0000 - fp: 155.0000 - tn: 1471.0000 - fn: 241.0000 - accuracy: 0.8043 - precision: 0.5032 - recall: 0.3945 - auc: 0.7261 - prc: 0.4793 - val_loss: 0.5011 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6878 - val_prc: 0.4314\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7438 - tp: 175.0000 - fp: 200.0000 - tn: 1426.0000 - fn: 223.0000 - accuracy: 0.7910 - precision: 0.4667 - recall: 0.4397 - auc: 0.7267 - prc: 0.4803 - val_loss: 0.5150 - val_tp: 38.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 53.0000 - val_accuracy: 0.7866 - val_precision: 0.4086 - val_recall: 0.4176 - val_auc: 0.6886 - val_prc: 0.4326\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7448 - tp: 176.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 222.0000 - accuracy: 0.7950 - precision: 0.4770 - recall: 0.4422 - auc: 0.7252 - prc: 0.4782 - val_loss: 0.5006 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6888 - val_prc: 0.4300\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7460 - tp: 177.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 221.0000 - accuracy: 0.7841 - precision: 0.4504 - recall: 0.4447 - auc: 0.7252 - prc: 0.4776 - val_loss: 0.5169 - val_tp: 38.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 53.0000 - val_accuracy: 0.7826 - val_precision: 0.4000 - val_recall: 0.4176 - val_auc: 0.6894 - val_prc: 0.4318\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7445 - tp: 161.0000 - fp: 175.0000 - tn: 1451.0000 - fn: 237.0000 - accuracy: 0.7964 - precision: 0.4792 - recall: 0.4045 - auc: 0.7265 - prc: 0.4781 - val_loss: 0.4942 - val_tp: 36.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 55.0000 - val_accuracy: 0.8083 - val_precision: 0.4615 - val_recall: 0.3956 - val_auc: 0.6884 - val_prc: 0.4293\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7433 - tp: 157.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 241.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3945 - auc: 0.7274 - prc: 0.4804 - val_loss: 0.4999 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6886 - val_prc: 0.4300\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7433 - tp: 156.0000 - fp: 156.0000 - tn: 1470.0000 - fn: 242.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3920 - auc: 0.7274 - prc: 0.4802 - val_loss: 0.5013 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6887 - val_prc: 0.4306\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7431 - tp: 168.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 230.0000 - accuracy: 0.7935 - precision: 0.4719 - recall: 0.4221 - auc: 0.7271 - prc: 0.4799 - val_loss: 0.5024 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6886 - val_prc: 0.4295\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7434 - tp: 156.0000 - fp: 166.0000 - tn: 1460.0000 - fn: 242.0000 - accuracy: 0.7984 - precision: 0.4845 - recall: 0.3920 - auc: 0.7272 - prc: 0.4803 - val_loss: 0.5047 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6879 - val_prc: 0.4261\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7430 - tp: 179.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 219.0000 - accuracy: 0.7910 - precision: 0.4674 - recall: 0.4497 - auc: 0.7274 - prc: 0.4815 - val_loss: 0.5204 - val_tp: 40.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 51.0000 - val_accuracy: 0.7846 - val_precision: 0.4082 - val_recall: 0.4396 - val_auc: 0.6870 - val_prc: 0.4272\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7438 - tp: 177.0000 - fp: 201.0000 - tn: 1425.0000 - fn: 221.0000 - accuracy: 0.7915 - precision: 0.4683 - recall: 0.4447 - auc: 0.7265 - prc: 0.4790 - val_loss: 0.4993 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6896 - val_prc: 0.4336\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7425 - tp: 159.0000 - fp: 169.0000 - tn: 1457.0000 - fn: 239.0000 - accuracy: 0.7984 - precision: 0.4848 - recall: 0.3995 - auc: 0.7281 - prc: 0.4805 - val_loss: 0.4994 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6888 - val_prc: 0.4285\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7427 - tp: 155.0000 - fp: 157.0000 - tn: 1469.0000 - fn: 243.0000 - accuracy: 0.8024 - precision: 0.4968 - recall: 0.3894 - auc: 0.7285 - prc: 0.4814 - val_loss: 0.5024 - val_tp: 36.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 55.0000 - val_accuracy: 0.8043 - val_precision: 0.4500 - val_recall: 0.3956 - val_auc: 0.6889 - val_prc: 0.4293\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7426 - tp: 177.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 221.0000 - accuracy: 0.7945 - precision: 0.4758 - recall: 0.4447 - auc: 0.7278 - prc: 0.4807 - val_loss: 0.5149 - val_tp: 38.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 53.0000 - val_accuracy: 0.7964 - val_precision: 0.4318 - val_recall: 0.4176 - val_auc: 0.6880 - val_prc: 0.4300\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7426 - tp: 171.0000 - fp: 188.0000 - tn: 1438.0000 - fn: 227.0000 - accuracy: 0.7950 - precision: 0.4763 - recall: 0.4296 - auc: 0.7282 - prc: 0.4802 - val_loss: 0.5007 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6891 - val_prc: 0.4308\n",
      "Epoch 183/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7420 - tp: 164.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 234.0000 - accuracy: 0.7984 - precision: 0.4852 - recall: 0.4121 - auc: 0.7287 - prc: 0.4824 - val_loss: 0.5072 - val_tp: 37.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 54.0000 - val_accuracy: 0.7984 - val_precision: 0.4353 - val_recall: 0.4066 - val_auc: 0.6883 - val_prc: 0.4287\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7421 - tp: 164.0000 - fp: 176.0000 - tn: 1450.0000 - fn: 234.0000 - accuracy: 0.7974 - precision: 0.4824 - recall: 0.4121 - auc: 0.7286 - prc: 0.4811 - val_loss: 0.5037 - val_tp: 36.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 55.0000 - val_accuracy: 0.8024 - val_precision: 0.4444 - val_recall: 0.3956 - val_auc: 0.6878 - val_prc: 0.4282\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7420 - tp: 166.0000 - fp: 181.0000 - tn: 1445.0000 - fn: 232.0000 - accuracy: 0.7959 - precision: 0.4784 - recall: 0.4171 - auc: 0.7283 - prc: 0.4819 - val_loss: 0.5046 - val_tp: 36.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 55.0000 - val_accuracy: 0.7984 - val_precision: 0.4337 - val_recall: 0.3956 - val_auc: 0.6892 - val_prc: 0.4305\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7420 - tp: 166.0000 - fp: 186.0000 - tn: 1440.0000 - fn: 232.0000 - accuracy: 0.7935 - precision: 0.4716 - recall: 0.4171 - auc: 0.7285 - prc: 0.4808 - val_loss: 0.5005 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6901 - val_prc: 0.4320\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7419 - tp: 159.0000 - fp: 161.0000 - tn: 1465.0000 - fn: 239.0000 - accuracy: 0.8024 - precision: 0.4969 - recall: 0.3995 - auc: 0.7287 - prc: 0.4821 - val_loss: 0.4978 - val_tp: 36.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 55.0000 - val_accuracy: 0.8063 - val_precision: 0.4557 - val_recall: 0.3956 - val_auc: 0.6908 - val_prc: 0.4328\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7421 - tp: 166.0000 - fp: 176.0000 - tn: 1450.0000 - fn: 232.0000 - accuracy: 0.7984 - precision: 0.4854 - recall: 0.4171 - auc: 0.7284 - prc: 0.4815 - val_loss: 0.5070 - val_tp: 37.0000 - val_fp: 48.0000 - val_tn: 367.0000 - val_fn: 54.0000 - val_accuracy: 0.7984 - val_precision: 0.4353 - val_recall: 0.4066 - val_auc: 0.6903 - val_prc: 0.4324\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7436 - tp: 186.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 212.0000 - accuracy: 0.7890 - precision: 0.4638 - recall: 0.4673 - auc: 0.7273 - prc: 0.4802 - val_loss: 0.5132 - val_tp: 37.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 54.0000 - val_accuracy: 0.7925 - val_precision: 0.4205 - val_recall: 0.4066 - val_auc: 0.6879 - val_prc: 0.4259\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7446 - tp: 146.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 252.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3668 - auc: 0.7275 - prc: 0.4798 - val_loss: 0.4923 - val_tp: 34.0000 - val_fp: 36.0000 - val_tn: 379.0000 - val_fn: 57.0000 - val_accuracy: 0.8162 - val_precision: 0.4857 - val_recall: 0.3736 - val_auc: 0.6877 - val_prc: 0.4240\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7419 - tp: 168.0000 - fp: 182.0000 - tn: 1444.0000 - fn: 230.0000 - accuracy: 0.7964 - precision: 0.4800 - recall: 0.4221 - auc: 0.7288 - prc: 0.4812 - val_loss: 0.5160 - val_tp: 38.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 53.0000 - val_accuracy: 0.7925 - val_precision: 0.4222 - val_recall: 0.4176 - val_auc: 0.6875 - val_prc: 0.4262\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7419 - tp: 178.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 220.0000 - accuracy: 0.7959 - precision: 0.4798 - recall: 0.4472 - auc: 0.7279 - prc: 0.4835 - val_loss: 0.4963 - val_tp: 35.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 56.0000 - val_accuracy: 0.8063 - val_precision: 0.4545 - val_recall: 0.3846 - val_auc: 0.6891 - val_prc: 0.4313\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7415 - tp: 162.0000 - fp: 172.0000 - tn: 1454.0000 - fn: 236.0000 - accuracy: 0.7984 - precision: 0.4850 - recall: 0.4070 - auc: 0.7287 - prc: 0.4820 - val_loss: 0.4998 - val_tp: 36.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 55.0000 - val_accuracy: 0.8043 - val_precision: 0.4500 - val_recall: 0.3956 - val_auc: 0.6881 - val_prc: 0.4298\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7422 - tp: 173.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 225.0000 - accuracy: 0.7935 - precision: 0.4727 - recall: 0.4347 - auc: 0.7282 - prc: 0.4809 - val_loss: 0.5031 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6889 - val_prc: 0.4305\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7434 - tp: 146.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 252.0000 - accuracy: 0.8068 - precision: 0.5123 - recall: 0.3668 - auc: 0.7298 - prc: 0.4806 - val_loss: 0.4862 - val_tp: 33.0000 - val_fp: 34.0000 - val_tn: 381.0000 - val_fn: 58.0000 - val_accuracy: 0.8182 - val_precision: 0.4925 - val_recall: 0.3626 - val_auc: 0.6901 - val_prc: 0.4302\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7423 - tp: 149.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 249.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.3744 - auc: 0.7299 - prc: 0.4805 - val_loss: 0.5051 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6883 - val_prc: 0.4294\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7414 - tp: 171.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 227.0000 - accuracy: 0.7935 - precision: 0.4724 - recall: 0.4296 - auc: 0.7289 - prc: 0.4825 - val_loss: 0.5061 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6894 - val_prc: 0.4303\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7413 - tp: 165.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 233.0000 - accuracy: 0.7945 - precision: 0.4741 - recall: 0.4146 - auc: 0.7289 - prc: 0.4823 - val_loss: 0.5021 - val_tp: 36.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 55.0000 - val_accuracy: 0.8004 - val_precision: 0.4390 - val_recall: 0.3956 - val_auc: 0.6886 - val_prc: 0.4329\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7409 - tp: 170.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 228.0000 - accuracy: 0.7969 - precision: 0.4816 - recall: 0.4271 - auc: 0.7298 - prc: 0.4816 - val_loss: 0.5048 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6910 - val_prc: 0.4325\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7410 - tp: 170.0000 - fp: 187.0000 - tn: 1439.0000 - fn: 228.0000 - accuracy: 0.7950 - precision: 0.4762 - recall: 0.4271 - auc: 0.7290 - prc: 0.4824 - val_loss: 0.5056 - val_tp: 36.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 55.0000 - val_accuracy: 0.7984 - val_precision: 0.4337 - val_recall: 0.3956 - val_auc: 0.6868 - val_prc: 0.4241\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7430 - tp: 182.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 216.0000 - accuracy: 0.7925 - precision: 0.4715 - recall: 0.4573 - auc: 0.7278 - prc: 0.4795 - val_loss: 0.5156 - val_tp: 38.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 53.0000 - val_accuracy: 0.7945 - val_precision: 0.4270 - val_recall: 0.4176 - val_auc: 0.6870 - val_prc: 0.4230\n",
      "Epoch 202/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7417 - tp: 160.0000 - fp: 163.0000 - tn: 1463.0000 - fn: 238.0000 - accuracy: 0.8019 - precision: 0.4954 - recall: 0.4020 - auc: 0.7287 - prc: 0.4824 - val_loss: 0.4880 - val_tp: 34.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 57.0000 - val_accuracy: 0.8182 - val_precision: 0.4928 - val_recall: 0.3736 - val_auc: 0.6890 - val_prc: 0.4294\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7425 - tp: 146.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 252.0000 - accuracy: 0.8103 - precision: 0.5252 - recall: 0.3668 - auc: 0.7305 - prc: 0.4834 - val_loss: 0.4981 - val_tp: 36.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 55.0000 - val_accuracy: 0.8043 - val_precision: 0.4500 - val_recall: 0.3956 - val_auc: 0.6887 - val_prc: 0.4313\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7408 - tp: 178.0000 - fp: 197.0000 - tn: 1429.0000 - fn: 220.0000 - accuracy: 0.7940 - precision: 0.4747 - recall: 0.4472 - auc: 0.7291 - prc: 0.4833 - val_loss: 0.5149 - val_tp: 40.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 51.0000 - val_accuracy: 0.7964 - val_precision: 0.4348 - val_recall: 0.4396 - val_auc: 0.6874 - val_prc: 0.4239\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7413 - tp: 176.0000 - fp: 193.0000 - tn: 1433.0000 - fn: 222.0000 - accuracy: 0.7950 - precision: 0.4770 - recall: 0.4422 - auc: 0.7290 - prc: 0.4829 - val_loss: 0.4995 - val_tp: 36.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 55.0000 - val_accuracy: 0.8083 - val_precision: 0.4615 - val_recall: 0.3956 - val_auc: 0.6880 - val_prc: 0.4238\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7423 - tp: 145.0000 - fp: 135.0000 - tn: 1491.0000 - fn: 253.0000 - accuracy: 0.8083 - precision: 0.5179 - recall: 0.3643 - auc: 0.7300 - prc: 0.4827 - val_loss: 0.4892 - val_tp: 33.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 58.0000 - val_accuracy: 0.8162 - val_precision: 0.4853 - val_recall: 0.3626 - val_auc: 0.6909 - val_prc: 0.4338\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7404 - tp: 160.0000 - fp: 167.0000 - tn: 1459.0000 - fn: 238.0000 - accuracy: 0.7999 - precision: 0.4893 - recall: 0.4020 - auc: 0.7299 - prc: 0.4832 - val_loss: 0.5128 - val_tp: 38.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 53.0000 - val_accuracy: 0.7984 - val_precision: 0.4368 - val_recall: 0.4176 - val_auc: 0.6884 - val_prc: 0.4259\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7405 - tp: 174.0000 - fp: 191.0000 - tn: 1435.0000 - fn: 224.0000 - accuracy: 0.7950 - precision: 0.4767 - recall: 0.4372 - auc: 0.7301 - prc: 0.4828 - val_loss: 0.5028 - val_tp: 37.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 54.0000 - val_accuracy: 0.8024 - val_precision: 0.4458 - val_recall: 0.4066 - val_auc: 0.6893 - val_prc: 0.4334\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7416 - tp: 150.0000 - fp: 151.0000 - tn: 1475.0000 - fn: 248.0000 - accuracy: 0.8029 - precision: 0.4983 - recall: 0.3769 - auc: 0.7301 - prc: 0.4825 - val_loss: 0.4932 - val_tp: 34.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 57.0000 - val_accuracy: 0.8142 - val_precision: 0.4789 - val_recall: 0.3736 - val_auc: 0.6907 - val_prc: 0.4337\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7418 - tp: 175.0000 - fp: 189.0000 - tn: 1437.0000 - fn: 223.0000 - accuracy: 0.7964 - precision: 0.4808 - recall: 0.4397 - auc: 0.7274 - prc: 0.4820 - val_loss: 0.5200 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6898 - val_prc: 0.4328\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7409 - tp: 183.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 215.0000 - accuracy: 0.7910 - precision: 0.4680 - recall: 0.4598 - auc: 0.7304 - prc: 0.4834 - val_loss: 0.5066 - val_tp: 37.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 54.0000 - val_accuracy: 0.8004 - val_precision: 0.4405 - val_recall: 0.4066 - val_auc: 0.6874 - val_prc: 0.4257\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7402 - tp: 163.0000 - fp: 175.0000 - tn: 1451.0000 - fn: 235.0000 - accuracy: 0.7974 - precision: 0.4822 - recall: 0.4095 - auc: 0.7304 - prc: 0.4835 - val_loss: 0.4949 - val_tp: 34.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 57.0000 - val_accuracy: 0.8123 - val_precision: 0.4722 - val_recall: 0.3736 - val_auc: 0.6889 - val_prc: 0.4253\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7414 - tp: 151.0000 - fp: 147.0000 - tn: 1479.0000 - fn: 247.0000 - accuracy: 0.8053 - precision: 0.5067 - recall: 0.3794 - auc: 0.7305 - prc: 0.4826 - val_loss: 0.4941 - val_tp: 34.0000 - val_fp: 38.0000 - val_tn: 377.0000 - val_fn: 57.0000 - val_accuracy: 0.8123 - val_precision: 0.4722 - val_recall: 0.3736 - val_auc: 0.6885 - val_prc: 0.4258\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7406 - tp: 155.0000 - fp: 152.0000 - tn: 1474.0000 - fn: 243.0000 - accuracy: 0.8048 - precision: 0.5049 - recall: 0.3894 - auc: 0.7307 - prc: 0.4833 - val_loss: 0.5018 - val_tp: 35.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 56.0000 - val_accuracy: 0.8004 - val_precision: 0.4375 - val_recall: 0.3846 - val_auc: 0.6903 - val_prc: 0.4324\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7400 - tp: 171.0000 - fp: 183.0000 - tn: 1443.0000 - fn: 227.0000 - accuracy: 0.7974 - precision: 0.4831 - recall: 0.4296 - auc: 0.7305 - prc: 0.4828 - val_loss: 0.5089 - val_tp: 38.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 53.0000 - val_accuracy: 0.8024 - val_precision: 0.4471 - val_recall: 0.4176 - val_auc: 0.6896 - val_prc: 0.4257\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7398 - tp: 164.0000 - fp: 176.0000 - tn: 1450.0000 - fn: 234.0000 - accuracy: 0.7974 - precision: 0.4824 - recall: 0.4121 - auc: 0.7304 - prc: 0.4845 - val_loss: 0.4959 - val_tp: 34.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 57.0000 - val_accuracy: 0.8083 - val_precision: 0.4595 - val_recall: 0.3736 - val_auc: 0.6895 - val_prc: 0.4264\n",
      "Epoch 217/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7317 - tp: 12.0000 - fp: 15.0000 - tn: 147.0000 - fn: 26.0000 - accuracy: 0.7950 - precision: 0.4444 - recall: 0.3158 - auc: 0.7524 - prc: 0.4485Restoring model weights from the end of the best epoch: 167.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7403 - tp: 151.0000 - fp: 148.0000 - tn: 1478.0000 - fn: 247.0000 - accuracy: 0.8048 - precision: 0.5050 - recall: 0.3794 - auc: 0.7309 - prc: 0.4841 - val_loss: 0.4977 - val_tp: 35.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 56.0000 - val_accuracy: 0.8024 - val_precision: 0.4430 - val_recall: 0.3846 - val_auc: 0.6899 - val_prc: 0.4337\n",
      "Epoch 217: early stopping\n",
      "3/3 [==============================] - 0s 958us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.1409 - tp: 35.0000 - fp: 44.0000 - tn: 1997.0000 - fn: 454.0000 - accuracy: 0.8032 - precision: 0.4430 - recall: 0.0716 - auc: 0.5117 - prc: 0.2398 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5156 - val_prc: 0.1821\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1307 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4848 - prc: 0.1891 - val_loss: 0.4728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4865 - val_prc: 0.1744\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1195 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5405 - prc: 0.2245 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4959 - val_prc: 0.1865\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5715 - prc: 0.2383 - val_loss: 0.4745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5895 - val_prc: 0.2432\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0917 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5903 - prc: 0.2669 - val_loss: 0.4761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6127 - val_prc: 0.2701\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0743 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6406 - prc: 0.3157 - val_loss: 0.4783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6324 - val_prc: 0.2760\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0560 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6347 - prc: 0.3166 - val_loss: 0.4817 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6223 - val_prc: 0.2734\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0351 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6740 - prc: 0.3556 - val_loss: 0.4866 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6272 - val_prc: 0.2767\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0151 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6368 - prc: 0.3069 - val_loss: 0.4948 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6371 - val_prc: 0.2785\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9907 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6679 - prc: 0.3403 - val_loss: 0.5052 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6377 - val_prc: 0.2813\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9675 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6863 - prc: 0.3558 - val_loss: 0.5203 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6473 - val_prc: 0.2852\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9482 - tp: 1.0000 - fp: 1.0000 - tn: 1625.0000 - fn: 397.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0025 - auc: 0.6626 - prc: 0.3438 - val_loss: 0.5422 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6449 - val_prc: 0.2780\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9311 - tp: 2.0000 - fp: 7.0000 - tn: 1619.0000 - fn: 396.0000 - accuracy: 0.8009 - precision: 0.2222 - recall: 0.0050 - auc: 0.6713 - prc: 0.3442 - val_loss: 0.5686 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6476 - val_prc: 0.2742\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9194 - tp: 25.0000 - fp: 20.0000 - tn: 1606.0000 - fn: 373.0000 - accuracy: 0.8058 - precision: 0.5556 - recall: 0.0628 - auc: 0.6762 - prc: 0.3559 - val_loss: 0.6008 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 403.0000 - val_fn: 83.0000 - val_accuracy: 0.8123 - val_precision: 0.4000 - val_recall: 0.0879 - val_auc: 0.6496 - val_prc: 0.2773\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9156 - tp: 70.0000 - fp: 58.0000 - tn: 1568.0000 - fn: 328.0000 - accuracy: 0.8093 - precision: 0.5469 - recall: 0.1759 - auc: 0.6900 - prc: 0.3688 - val_loss: 0.6137 - val_tp: 11.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 80.0000 - val_accuracy: 0.8004 - val_precision: 0.3438 - val_recall: 0.1209 - val_auc: 0.6493 - val_prc: 0.2812\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9151 - tp: 81.0000 - fp: 76.0000 - tn: 1550.0000 - fn: 317.0000 - accuracy: 0.8058 - precision: 0.5159 - recall: 0.2035 - auc: 0.6904 - prc: 0.3736 - val_loss: 0.6112 - val_tp: 11.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 80.0000 - val_accuracy: 0.8024 - val_precision: 0.3548 - val_recall: 0.1209 - val_auc: 0.6549 - val_prc: 0.2849\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9141 - tp: 75.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 323.0000 - accuracy: 0.8078 - precision: 0.5319 - recall: 0.1884 - auc: 0.6902 - prc: 0.3772 - val_loss: 0.6043 - val_tp: 10.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 81.0000 - val_accuracy: 0.8103 - val_precision: 0.4000 - val_recall: 0.1099 - val_auc: 0.6549 - val_prc: 0.2886\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9132 - tp: 62.0000 - fp: 47.0000 - tn: 1579.0000 - fn: 336.0000 - accuracy: 0.8108 - precision: 0.5688 - recall: 0.1558 - auc: 0.6914 - prc: 0.3778 - val_loss: 0.5995 - val_tp: 10.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 81.0000 - val_accuracy: 0.8123 - val_precision: 0.4167 - val_recall: 0.1099 - val_auc: 0.6552 - val_prc: 0.2879\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9125 - tp: 71.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 327.0000 - accuracy: 0.8103 - precision: 0.5547 - recall: 0.1784 - auc: 0.6933 - prc: 0.3812 - val_loss: 0.6079 - val_tp: 12.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 79.0000 - val_accuracy: 0.8063 - val_precision: 0.3871 - val_recall: 0.1319 - val_auc: 0.6557 - val_prc: 0.2904\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9122 - tp: 92.0000 - fp: 93.0000 - tn: 1533.0000 - fn: 306.0000 - accuracy: 0.8029 - precision: 0.4973 - recall: 0.2312 - auc: 0.6903 - prc: 0.3786 - val_loss: 0.6150 - val_tp: 15.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 76.0000 - val_accuracy: 0.7905 - val_precision: 0.3333 - val_recall: 0.1648 - val_auc: 0.6566 - val_prc: 0.2911\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9113 - tp: 83.0000 - fp: 77.0000 - tn: 1549.0000 - fn: 315.0000 - accuracy: 0.8063 - precision: 0.5188 - recall: 0.2085 - auc: 0.6904 - prc: 0.3811 - val_loss: 0.5982 - val_tp: 10.0000 - val_fp: 15.0000 - val_tn: 400.0000 - val_fn: 81.0000 - val_accuracy: 0.8103 - val_precision: 0.4000 - val_recall: 0.1099 - val_auc: 0.6579 - val_prc: 0.2916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9105 - tp: 71.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 327.0000 - accuracy: 0.8103 - precision: 0.5547 - recall: 0.1784 - auc: 0.6930 - prc: 0.3843 - val_loss: 0.6034 - val_tp: 11.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 80.0000 - val_accuracy: 0.8043 - val_precision: 0.3667 - val_recall: 0.1209 - val_auc: 0.6567 - val_prc: 0.2932\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9100 - tp: 86.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 312.0000 - accuracy: 0.8068 - precision: 0.5212 - recall: 0.2161 - auc: 0.6938 - prc: 0.3844 - val_loss: 0.6081 - val_tp: 13.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 78.0000 - val_accuracy: 0.7964 - val_precision: 0.3421 - val_recall: 0.1429 - val_auc: 0.6562 - val_prc: 0.2925\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9094 - tp: 92.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 306.0000 - accuracy: 0.8083 - precision: 0.5287 - recall: 0.2312 - auc: 0.6946 - prc: 0.3859 - val_loss: 0.6068 - val_tp: 13.0000 - val_fp: 25.0000 - val_tn: 390.0000 - val_fn: 78.0000 - val_accuracy: 0.7964 - val_precision: 0.3421 - val_recall: 0.1429 - val_auc: 0.6577 - val_prc: 0.2944\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9088 - tp: 84.0000 - fp: 74.0000 - tn: 1552.0000 - fn: 314.0000 - accuracy: 0.8083 - precision: 0.5316 - recall: 0.2111 - auc: 0.6929 - prc: 0.3863 - val_loss: 0.5995 - val_tp: 12.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 79.0000 - val_accuracy: 0.8083 - val_precision: 0.4000 - val_recall: 0.1319 - val_auc: 0.6589 - val_prc: 0.2964\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9081 - tp: 77.0000 - fp: 66.0000 - tn: 1560.0000 - fn: 321.0000 - accuracy: 0.8088 - precision: 0.5385 - recall: 0.1935 - auc: 0.6946 - prc: 0.3864 - val_loss: 0.6002 - val_tp: 12.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 79.0000 - val_accuracy: 0.8043 - val_precision: 0.3750 - val_recall: 0.1319 - val_auc: 0.6585 - val_prc: 0.2964\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9073 - tp: 83.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 315.0000 - accuracy: 0.8083 - precision: 0.5321 - recall: 0.2085 - auc: 0.6949 - prc: 0.3881 - val_loss: 0.6011 - val_tp: 13.0000 - val_fp: 21.0000 - val_tn: 394.0000 - val_fn: 78.0000 - val_accuracy: 0.8043 - val_precision: 0.3824 - val_recall: 0.1429 - val_auc: 0.6597 - val_prc: 0.2983\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9068 - tp: 93.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 305.0000 - accuracy: 0.8098 - precision: 0.5376 - recall: 0.2337 - auc: 0.6945 - prc: 0.3883 - val_loss: 0.6036 - val_tp: 13.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 78.0000 - val_accuracy: 0.7925 - val_precision: 0.3250 - val_recall: 0.1429 - val_auc: 0.6594 - val_prc: 0.2991\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9059 - tp: 99.0000 - fp: 86.0000 - tn: 1540.0000 - fn: 299.0000 - accuracy: 0.8098 - precision: 0.5351 - recall: 0.2487 - auc: 0.6946 - prc: 0.3896 - val_loss: 0.6051 - val_tp: 19.0000 - val_fp: 28.0000 - val_tn: 387.0000 - val_fn: 72.0000 - val_accuracy: 0.8024 - val_precision: 0.4043 - val_recall: 0.2088 - val_auc: 0.6602 - val_prc: 0.3004\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9052 - tp: 98.0000 - fp: 82.0000 - tn: 1544.0000 - fn: 300.0000 - accuracy: 0.8113 - precision: 0.5444 - recall: 0.2462 - auc: 0.6949 - prc: 0.3909 - val_loss: 0.6015 - val_tp: 14.0000 - val_fp: 27.0000 - val_tn: 388.0000 - val_fn: 77.0000 - val_accuracy: 0.7945 - val_precision: 0.3415 - val_recall: 0.1538 - val_auc: 0.6610 - val_prc: 0.3015\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9038 - tp: 104.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 294.0000 - accuracy: 0.8078 - precision: 0.5226 - recall: 0.2613 - auc: 0.6963 - prc: 0.3965 - val_loss: 0.6059 - val_tp: 25.0000 - val_fp: 32.0000 - val_tn: 383.0000 - val_fn: 66.0000 - val_accuracy: 0.8063 - val_precision: 0.4386 - val_recall: 0.2747 - val_auc: 0.6628 - val_prc: 0.3043\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9028 - tp: 109.0000 - fp: 105.0000 - tn: 1521.0000 - fn: 289.0000 - accuracy: 0.8053 - precision: 0.5093 - recall: 0.2739 - auc: 0.6961 - prc: 0.3986 - val_loss: 0.6014 - val_tp: 24.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 67.0000 - val_accuracy: 0.8083 - val_precision: 0.4444 - val_recall: 0.2637 - val_auc: 0.6601 - val_prc: 0.3041\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9018 - tp: 99.0000 - fp: 95.0000 - tn: 1531.0000 - fn: 299.0000 - accuracy: 0.8053 - precision: 0.5103 - recall: 0.2487 - auc: 0.6930 - prc: 0.3987 - val_loss: 0.5946 - val_tp: 20.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 71.0000 - val_accuracy: 0.8024 - val_precision: 0.4082 - val_recall: 0.2198 - val_auc: 0.6614 - val_prc: 0.3104\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9001 - tp: 118.0000 - fp: 146.0000 - tn: 1480.0000 - fn: 280.0000 - accuracy: 0.7895 - precision: 0.4470 - recall: 0.2965 - auc: 0.6931 - prc: 0.3959 - val_loss: 0.6067 - val_tp: 30.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 61.0000 - val_accuracy: 0.7708 - val_precision: 0.3529 - val_recall: 0.3297 - val_auc: 0.6625 - val_prc: 0.3141\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8978 - tp: 147.0000 - fp: 196.0000 - tn: 1430.0000 - fn: 251.0000 - accuracy: 0.7792 - precision: 0.4286 - recall: 0.3693 - auc: 0.6930 - prc: 0.3989 - val_loss: 0.5966 - val_tp: 28.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 63.0000 - val_accuracy: 0.7925 - val_precision: 0.4000 - val_recall: 0.3077 - val_auc: 0.6621 - val_prc: 0.3138\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8962 - tp: 111.0000 - fp: 128.0000 - tn: 1498.0000 - fn: 287.0000 - accuracy: 0.7950 - precision: 0.4644 - recall: 0.2789 - auc: 0.6901 - prc: 0.3978 - val_loss: 0.5809 - val_tp: 21.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 70.0000 - val_accuracy: 0.8024 - val_precision: 0.4118 - val_recall: 0.2308 - val_auc: 0.6621 - val_prc: 0.3190\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8948 - tp: 113.0000 - fp: 139.0000 - tn: 1487.0000 - fn: 285.0000 - accuracy: 0.7905 - precision: 0.4484 - recall: 0.2839 - auc: 0.6900 - prc: 0.3991 - val_loss: 0.5910 - val_tp: 27.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 64.0000 - val_accuracy: 0.7945 - val_precision: 0.4030 - val_recall: 0.2967 - val_auc: 0.6629 - val_prc: 0.3209\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8931 - tp: 130.0000 - fp: 165.0000 - tn: 1461.0000 - fn: 268.0000 - accuracy: 0.7861 - precision: 0.4407 - recall: 0.3266 - auc: 0.6917 - prc: 0.3990 - val_loss: 0.5900 - val_tp: 28.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 63.0000 - val_accuracy: 0.7905 - val_precision: 0.3944 - val_recall: 0.3077 - val_auc: 0.6636 - val_prc: 0.3228\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8916 - tp: 135.0000 - fp: 175.0000 - tn: 1451.0000 - fn: 263.0000 - accuracy: 0.7836 - precision: 0.4355 - recall: 0.3392 - auc: 0.6920 - prc: 0.3996 - val_loss: 0.5916 - val_tp: 29.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 62.0000 - val_accuracy: 0.7787 - val_precision: 0.3671 - val_recall: 0.3187 - val_auc: 0.6625 - val_prc: 0.3214\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8904 - tp: 151.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 247.0000 - accuracy: 0.7727 - precision: 0.4148 - recall: 0.3794 - auc: 0.6917 - prc: 0.3992 - val_loss: 0.5945 - val_tp: 32.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 59.0000 - val_accuracy: 0.7688 - val_precision: 0.3556 - val_recall: 0.3516 - val_auc: 0.6651 - val_prc: 0.3275\n",
      "Epoch 41/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8887 - tp: 146.0000 - fp: 204.0000 - tn: 1422.0000 - fn: 252.0000 - accuracy: 0.7747 - precision: 0.4171 - recall: 0.3668 - auc: 0.6921 - prc: 0.4009 - val_loss: 0.5846 - val_tp: 29.0000 - val_fp: 46.0000 - val_tn: 369.0000 - val_fn: 62.0000 - val_accuracy: 0.7866 - val_precision: 0.3867 - val_recall: 0.3187 - val_auc: 0.6642 - val_prc: 0.3286\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8875 - tp: 136.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 262.0000 - accuracy: 0.7846 - precision: 0.4387 - recall: 0.3417 - auc: 0.6926 - prc: 0.4027 - val_loss: 0.5794 - val_tp: 28.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 63.0000 - val_accuracy: 0.7905 - val_precision: 0.3944 - val_recall: 0.3077 - val_auc: 0.6655 - val_prc: 0.3309\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8871 - tp: 117.0000 - fp: 134.0000 - tn: 1492.0000 - fn: 281.0000 - accuracy: 0.7950 - precision: 0.4661 - recall: 0.2940 - auc: 0.6928 - prc: 0.4012 - val_loss: 0.5692 - val_tp: 25.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 66.0000 - val_accuracy: 0.8103 - val_precision: 0.4545 - val_recall: 0.2747 - val_auc: 0.6664 - val_prc: 0.3336\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8858 - tp: 111.0000 - fp: 122.0000 - tn: 1504.0000 - fn: 287.0000 - accuracy: 0.7979 - precision: 0.4764 - recall: 0.2789 - auc: 0.6931 - prc: 0.4042 - val_loss: 0.5700 - val_tp: 26.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 65.0000 - val_accuracy: 0.8024 - val_precision: 0.4262 - val_recall: 0.2857 - val_auc: 0.6668 - val_prc: 0.3353\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8836 - tp: 133.0000 - fp: 172.0000 - tn: 1454.0000 - fn: 265.0000 - accuracy: 0.7841 - precision: 0.4361 - recall: 0.3342 - auc: 0.6941 - prc: 0.4053 - val_loss: 0.5866 - val_tp: 35.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 56.0000 - val_accuracy: 0.7688 - val_precision: 0.3646 - val_recall: 0.3846 - val_auc: 0.6671 - val_prc: 0.3349\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8822 - tp: 154.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 244.0000 - accuracy: 0.7727 - precision: 0.4162 - recall: 0.3869 - auc: 0.6940 - prc: 0.4066 - val_loss: 0.5847 - val_tp: 34.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 57.0000 - val_accuracy: 0.7628 - val_precision: 0.3505 - val_recall: 0.3736 - val_auc: 0.6670 - val_prc: 0.3364\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8808 - tp: 161.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 237.0000 - accuracy: 0.7708 - precision: 0.4149 - recall: 0.4045 - auc: 0.6945 - prc: 0.4077 - val_loss: 0.5798 - val_tp: 32.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 59.0000 - val_accuracy: 0.7727 - val_precision: 0.3636 - val_recall: 0.3516 - val_auc: 0.6674 - val_prc: 0.3386\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8805 - tp: 135.0000 - fp: 165.0000 - tn: 1461.0000 - fn: 263.0000 - accuracy: 0.7885 - precision: 0.4500 - recall: 0.3392 - auc: 0.6945 - prc: 0.4073 - val_loss: 0.5617 - val_tp: 27.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 64.0000 - val_accuracy: 0.8004 - val_precision: 0.4219 - val_recall: 0.2967 - val_auc: 0.6692 - val_prc: 0.3524\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8801 - tp: 117.0000 - fp: 132.0000 - tn: 1494.0000 - fn: 281.0000 - accuracy: 0.7959 - precision: 0.4699 - recall: 0.2940 - auc: 0.6947 - prc: 0.4084 - val_loss: 0.5657 - val_tp: 28.0000 - val_fp: 43.0000 - val_tn: 372.0000 - val_fn: 63.0000 - val_accuracy: 0.7905 - val_precision: 0.3944 - val_recall: 0.3077 - val_auc: 0.6685 - val_prc: 0.3439\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8775 - tp: 159.0000 - fp: 237.0000 - tn: 1389.0000 - fn: 239.0000 - accuracy: 0.7648 - precision: 0.4015 - recall: 0.3995 - auc: 0.6936 - prc: 0.4053 - val_loss: 0.5945 - val_tp: 41.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 50.0000 - val_accuracy: 0.7273 - val_precision: 0.3178 - val_recall: 0.4505 - val_auc: 0.6700 - val_prc: 0.3395\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8780 - tp: 197.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 201.0000 - accuracy: 0.7347 - precision: 0.3696 - recall: 0.4950 - auc: 0.6958 - prc: 0.4092 - val_loss: 0.5920 - val_tp: 41.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 50.0000 - val_accuracy: 0.7273 - val_precision: 0.3178 - val_recall: 0.4505 - val_auc: 0.6701 - val_prc: 0.3411\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8754 - tp: 159.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 239.0000 - accuracy: 0.7727 - precision: 0.4184 - recall: 0.3995 - auc: 0.6956 - prc: 0.4054 - val_loss: 0.5618 - val_tp: 29.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 62.0000 - val_accuracy: 0.7885 - val_precision: 0.3919 - val_recall: 0.3187 - val_auc: 0.6709 - val_prc: 0.3553\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8747 - tp: 145.0000 - fp: 195.0000 - tn: 1431.0000 - fn: 253.0000 - accuracy: 0.7787 - precision: 0.4265 - recall: 0.3643 - auc: 0.6968 - prc: 0.4105 - val_loss: 0.5759 - val_tp: 35.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 56.0000 - val_accuracy: 0.7648 - val_precision: 0.3571 - val_recall: 0.3846 - val_auc: 0.6714 - val_prc: 0.3446\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8731 - tp: 164.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 234.0000 - accuracy: 0.7698 - precision: 0.4141 - recall: 0.4121 - auc: 0.6967 - prc: 0.4101 - val_loss: 0.5782 - val_tp: 36.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 55.0000 - val_accuracy: 0.7490 - val_precision: 0.3333 - val_recall: 0.3956 - val_auc: 0.6712 - val_prc: 0.3425\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8721 - tp: 163.0000 - fp: 229.0000 - tn: 1397.0000 - fn: 235.0000 - accuracy: 0.7708 - precision: 0.4158 - recall: 0.4095 - auc: 0.6971 - prc: 0.4107 - val_loss: 0.5712 - val_tp: 33.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 58.0000 - val_accuracy: 0.7648 - val_precision: 0.3511 - val_recall: 0.3626 - val_auc: 0.6713 - val_prc: 0.3428\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8706 - tp: 163.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 235.0000 - accuracy: 0.7732 - precision: 0.4212 - recall: 0.4095 - auc: 0.6982 - prc: 0.4148 - val_loss: 0.5787 - val_tp: 37.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 54.0000 - val_accuracy: 0.7431 - val_precision: 0.3274 - val_recall: 0.4066 - val_auc: 0.6723 - val_prc: 0.3442\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8695 - tp: 188.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 210.0000 - accuracy: 0.7530 - precision: 0.3933 - recall: 0.4724 - auc: 0.7002 - prc: 0.4159 - val_loss: 0.5913 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6717 - val_prc: 0.3420\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8699 - tp: 187.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 211.0000 - accuracy: 0.7470 - precision: 0.3832 - recall: 0.4698 - auc: 0.6973 - prc: 0.4144 - val_loss: 0.5809 - val_tp: 37.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 54.0000 - val_accuracy: 0.7352 - val_precision: 0.3162 - val_recall: 0.4066 - val_auc: 0.6717 - val_prc: 0.3429\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8691 - tp: 196.0000 - fp: 337.0000 - tn: 1289.0000 - fn: 202.0000 - accuracy: 0.7337 - precision: 0.3677 - recall: 0.4925 - auc: 0.6996 - prc: 0.4153 - val_loss: 0.5964 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6741 - val_prc: 0.3450\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8667 - tp: 190.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 208.0000 - accuracy: 0.7525 - precision: 0.3934 - recall: 0.4774 - auc: 0.7013 - prc: 0.4157 - val_loss: 0.5653 - val_tp: 33.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 58.0000 - val_accuracy: 0.7609 - val_precision: 0.3438 - val_recall: 0.3626 - val_auc: 0.6740 - val_prc: 0.3571\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8655 - tp: 170.0000 - fp: 237.0000 - tn: 1389.0000 - fn: 228.0000 - accuracy: 0.7703 - precision: 0.4177 - recall: 0.4271 - auc: 0.7009 - prc: 0.4204 - val_loss: 0.5650 - val_tp: 33.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 58.0000 - val_accuracy: 0.7569 - val_precision: 0.3367 - val_recall: 0.3626 - val_auc: 0.6750 - val_prc: 0.3527\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8644 - tp: 176.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 222.0000 - accuracy: 0.7619 - precision: 0.4037 - recall: 0.4422 - auc: 0.7008 - prc: 0.4195 - val_loss: 0.5703 - val_tp: 37.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 54.0000 - val_accuracy: 0.7411 - val_precision: 0.3246 - val_recall: 0.4066 - val_auc: 0.6748 - val_prc: 0.3498\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8633 - tp: 169.0000 - fp: 244.0000 - tn: 1382.0000 - fn: 229.0000 - accuracy: 0.7663 - precision: 0.4092 - recall: 0.4246 - auc: 0.7014 - prc: 0.4195 - val_loss: 0.5610 - val_tp: 31.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 60.0000 - val_accuracy: 0.7628 - val_precision: 0.3407 - val_recall: 0.3407 - val_auc: 0.6747 - val_prc: 0.3464\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8620 - tp: 168.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 230.0000 - accuracy: 0.7673 - precision: 0.4108 - recall: 0.4221 - auc: 0.7027 - prc: 0.4189 - val_loss: 0.5645 - val_tp: 35.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 56.0000 - val_accuracy: 0.7569 - val_precision: 0.3431 - val_recall: 0.3846 - val_auc: 0.6755 - val_prc: 0.3468\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8616 - tp: 160.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 238.0000 - accuracy: 0.7717 - precision: 0.4167 - recall: 0.4020 - auc: 0.7023 - prc: 0.4212 - val_loss: 0.5534 - val_tp: 32.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 59.0000 - val_accuracy: 0.7767 - val_precision: 0.3721 - val_recall: 0.3516 - val_auc: 0.6767 - val_prc: 0.3492\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8624 - tp: 185.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 213.0000 - accuracy: 0.7554 - precision: 0.3961 - recall: 0.4648 - auc: 0.6990 - prc: 0.4165 - val_loss: 0.5830 - val_tp: 44.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 47.0000 - val_accuracy: 0.7292 - val_precision: 0.3284 - val_recall: 0.4835 - val_auc: 0.6776 - val_prc: 0.3526\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8596 - tp: 201.0000 - fp: 323.0000 - tn: 1303.0000 - fn: 197.0000 - accuracy: 0.7431 - precision: 0.3836 - recall: 0.5050 - auc: 0.7040 - prc: 0.4234 - val_loss: 0.5716 - val_tp: 43.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 48.0000 - val_accuracy: 0.7431 - val_precision: 0.3440 - val_recall: 0.4725 - val_auc: 0.6786 - val_prc: 0.3638\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8577 - tp: 180.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 218.0000 - accuracy: 0.7579 - precision: 0.3982 - recall: 0.4523 - auc: 0.7045 - prc: 0.4277 - val_loss: 0.5578 - val_tp: 35.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 56.0000 - val_accuracy: 0.7628 - val_precision: 0.3535 - val_recall: 0.3846 - val_auc: 0.6786 - val_prc: 0.3723\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8573 - tp: 166.0000 - fp: 230.0000 - tn: 1396.0000 - fn: 232.0000 - accuracy: 0.7717 - precision: 0.4192 - recall: 0.4171 - auc: 0.7047 - prc: 0.4287 - val_loss: 0.5524 - val_tp: 34.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 57.0000 - val_accuracy: 0.7648 - val_precision: 0.3542 - val_recall: 0.3736 - val_auc: 0.6787 - val_prc: 0.3722\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8566 - tp: 168.0000 - fp: 230.0000 - tn: 1396.0000 - fn: 230.0000 - accuracy: 0.7727 - precision: 0.4221 - recall: 0.4221 - auc: 0.7051 - prc: 0.4285 - val_loss: 0.5578 - val_tp: 35.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 56.0000 - val_accuracy: 0.7569 - val_precision: 0.3431 - val_recall: 0.3846 - val_auc: 0.6788 - val_prc: 0.3720\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8568 - tp: 189.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 209.0000 - accuracy: 0.7475 - precision: 0.3849 - recall: 0.4749 - auc: 0.7037 - prc: 0.4256 - val_loss: 0.5728 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6795 - val_prc: 0.3709\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8555 - tp: 176.0000 - fp: 250.0000 - tn: 1376.0000 - fn: 222.0000 - accuracy: 0.7668 - precision: 0.4131 - recall: 0.4422 - auc: 0.7040 - prc: 0.4296 - val_loss: 0.5486 - val_tp: 35.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 56.0000 - val_accuracy: 0.7727 - val_precision: 0.3723 - val_recall: 0.3846 - val_auc: 0.6798 - val_prc: 0.3771\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8540 - tp: 183.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 215.0000 - accuracy: 0.7559 - precision: 0.3961 - recall: 0.4598 - auc: 0.7056 - prc: 0.4302 - val_loss: 0.5696 - val_tp: 42.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 49.0000 - val_accuracy: 0.7411 - val_precision: 0.3387 - val_recall: 0.4615 - val_auc: 0.6800 - val_prc: 0.3723\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8536 - tp: 190.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 208.0000 - accuracy: 0.7500 - precision: 0.3893 - recall: 0.4774 - auc: 0.7059 - prc: 0.4299 - val_loss: 0.5584 - val_tp: 39.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 52.0000 - val_accuracy: 0.7569 - val_precision: 0.3545 - val_recall: 0.4286 - val_auc: 0.6791 - val_prc: 0.3743\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8530 - tp: 173.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 225.0000 - accuracy: 0.7648 - precision: 0.4080 - recall: 0.4347 - auc: 0.7057 - prc: 0.4313 - val_loss: 0.5566 - val_tp: 39.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 52.0000 - val_accuracy: 0.7589 - val_precision: 0.3578 - val_recall: 0.4286 - val_auc: 0.6799 - val_prc: 0.3733\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8519 - tp: 187.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 211.0000 - accuracy: 0.7515 - precision: 0.3904 - recall: 0.4698 - auc: 0.7064 - prc: 0.4340 - val_loss: 0.5702 - val_tp: 44.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 47.0000 - val_accuracy: 0.7372 - val_precision: 0.3385 - val_recall: 0.4835 - val_auc: 0.6802 - val_prc: 0.3771\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8521 - tp: 198.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 200.0000 - accuracy: 0.7396 - precision: 0.3771 - recall: 0.4975 - auc: 0.7064 - prc: 0.4321 - val_loss: 0.5699 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6803 - val_prc: 0.3693\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8519 - tp: 202.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 196.0000 - accuracy: 0.7381 - precision: 0.3769 - recall: 0.5075 - auc: 0.7068 - prc: 0.4304 - val_loss: 0.5647 - val_tp: 42.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 49.0000 - val_accuracy: 0.7549 - val_precision: 0.3590 - val_recall: 0.4615 - val_auc: 0.6806 - val_prc: 0.3659\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8500 - tp: 185.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 213.0000 - accuracy: 0.7604 - precision: 0.4048 - recall: 0.4648 - auc: 0.7081 - prc: 0.4315 - val_loss: 0.5470 - val_tp: 35.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 56.0000 - val_accuracy: 0.7708 - val_precision: 0.3684 - val_recall: 0.3846 - val_auc: 0.6806 - val_prc: 0.3634\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8504 - tp: 172.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 226.0000 - accuracy: 0.7624 - precision: 0.4028 - recall: 0.4322 - auc: 0.7066 - prc: 0.4316 - val_loss: 0.5548 - val_tp: 39.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 52.0000 - val_accuracy: 0.7609 - val_precision: 0.3611 - val_recall: 0.4286 - val_auc: 0.6807 - val_prc: 0.3732\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8495 - tp: 177.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 221.0000 - accuracy: 0.7609 - precision: 0.4023 - recall: 0.4447 - auc: 0.7076 - prc: 0.4364 - val_loss: 0.5555 - val_tp: 40.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 51.0000 - val_accuracy: 0.7549 - val_precision: 0.3540 - val_recall: 0.4396 - val_auc: 0.6811 - val_prc: 0.3810\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8494 - tp: 199.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 199.0000 - accuracy: 0.7431 - precision: 0.3827 - recall: 0.5000 - auc: 0.7078 - prc: 0.4375 - val_loss: 0.5694 - val_tp: 45.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 46.0000 - val_accuracy: 0.7292 - val_precision: 0.3309 - val_recall: 0.4945 - val_auc: 0.6818 - val_prc: 0.3826\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8486 - tp: 196.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 202.0000 - accuracy: 0.7456 - precision: 0.3851 - recall: 0.4925 - auc: 0.7082 - prc: 0.4390 - val_loss: 0.5511 - val_tp: 39.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 52.0000 - val_accuracy: 0.7628 - val_precision: 0.3645 - val_recall: 0.4286 - val_auc: 0.6826 - val_prc: 0.3851\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8490 - tp: 170.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 228.0000 - accuracy: 0.7727 - precision: 0.4229 - recall: 0.4271 - auc: 0.7075 - prc: 0.4398 - val_loss: 0.5410 - val_tp: 35.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 56.0000 - val_accuracy: 0.7747 - val_precision: 0.3763 - val_recall: 0.3846 - val_auc: 0.6821 - val_prc: 0.3863\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8480 - tp: 186.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 212.0000 - accuracy: 0.7505 - precision: 0.3883 - recall: 0.4673 - auc: 0.7085 - prc: 0.4332 - val_loss: 0.5656 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6807 - val_prc: 0.3736\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8476 - tp: 182.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 216.0000 - accuracy: 0.7589 - precision: 0.4009 - recall: 0.4573 - auc: 0.7079 - prc: 0.4358 - val_loss: 0.5464 - val_tp: 38.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 53.0000 - val_accuracy: 0.7609 - val_precision: 0.3585 - val_recall: 0.4176 - val_auc: 0.6819 - val_prc: 0.3765\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8467 - tp: 173.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 225.0000 - accuracy: 0.7643 - precision: 0.4071 - recall: 0.4347 - auc: 0.7086 - prc: 0.4409 - val_loss: 0.5399 - val_tp: 35.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 56.0000 - val_accuracy: 0.7708 - val_precision: 0.3684 - val_recall: 0.3846 - val_auc: 0.6825 - val_prc: 0.3890\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8491 - tp: 162.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 236.0000 - accuracy: 0.7792 - precision: 0.4343 - recall: 0.4070 - auc: 0.7071 - prc: 0.4401 - val_loss: 0.5395 - val_tp: 35.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 56.0000 - val_accuracy: 0.7708 - val_precision: 0.3684 - val_recall: 0.3846 - val_auc: 0.6831 - val_prc: 0.3845\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8460 - tp: 171.0000 - fp: 237.0000 - tn: 1389.0000 - fn: 227.0000 - accuracy: 0.7708 - precision: 0.4191 - recall: 0.4296 - auc: 0.7090 - prc: 0.4419 - val_loss: 0.5501 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6824 - val_prc: 0.3853\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8452 - tp: 200.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 198.0000 - accuracy: 0.7490 - precision: 0.3922 - recall: 0.5025 - auc: 0.7097 - prc: 0.4424 - val_loss: 0.5632 - val_tp: 44.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 47.0000 - val_accuracy: 0.7470 - val_precision: 0.3520 - val_recall: 0.4835 - val_auc: 0.6824 - val_prc: 0.3855\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8450 - tp: 185.0000 - fp: 277.0000 - tn: 1349.0000 - fn: 213.0000 - accuracy: 0.7579 - precision: 0.4004 - recall: 0.4648 - auc: 0.7088 - prc: 0.4416 - val_loss: 0.5456 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6831 - val_prc: 0.3864\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8455 - tp: 191.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 207.0000 - accuracy: 0.7505 - precision: 0.3906 - recall: 0.4799 - auc: 0.7079 - prc: 0.4422 - val_loss: 0.5618 - val_tp: 44.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 47.0000 - val_accuracy: 0.7470 - val_precision: 0.3520 - val_recall: 0.4835 - val_auc: 0.6825 - val_prc: 0.3906\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8468 - tp: 211.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 187.0000 - accuracy: 0.7248 - precision: 0.3632 - recall: 0.5302 - auc: 0.7092 - prc: 0.4407 - val_loss: 0.5730 - val_tp: 46.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 45.0000 - val_accuracy: 0.7292 - val_precision: 0.3333 - val_recall: 0.5055 - val_auc: 0.6834 - val_prc: 0.3881\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8448 - tp: 198.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 200.0000 - accuracy: 0.7381 - precision: 0.3750 - recall: 0.4975 - auc: 0.7088 - prc: 0.4446 - val_loss: 0.5453 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6840 - val_prc: 0.3972\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8436 - tp: 186.0000 - fp: 280.0000 - tn: 1346.0000 - fn: 212.0000 - accuracy: 0.7569 - precision: 0.3991 - recall: 0.4673 - auc: 0.7094 - prc: 0.4484 - val_loss: 0.5506 - val_tp: 42.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 49.0000 - val_accuracy: 0.7648 - val_precision: 0.3750 - val_recall: 0.4615 - val_auc: 0.6838 - val_prc: 0.3997\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8435 - tp: 186.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 212.0000 - accuracy: 0.7579 - precision: 0.4009 - recall: 0.4673 - auc: 0.7099 - prc: 0.4485 - val_loss: 0.5532 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6848 - val_prc: 0.3961\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8440 - tp: 210.0000 - fp: 353.0000 - tn: 1273.0000 - fn: 188.0000 - accuracy: 0.7327 - precision: 0.3730 - recall: 0.5276 - auc: 0.7105 - prc: 0.4477 - val_loss: 0.5700 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6838 - val_prc: 0.3988\n",
      "Epoch 98/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8441 - tp: 186.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 212.0000 - accuracy: 0.7589 - precision: 0.4026 - recall: 0.4673 - auc: 0.7090 - prc: 0.4475 - val_loss: 0.5319 - val_tp: 35.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 56.0000 - val_accuracy: 0.7727 - val_precision: 0.3723 - val_recall: 0.3846 - val_auc: 0.6853 - val_prc: 0.4007\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8428 - tp: 181.0000 - fp: 281.0000 - tn: 1345.0000 - fn: 217.0000 - accuracy: 0.7540 - precision: 0.3918 - recall: 0.4548 - auc: 0.7098 - prc: 0.4482 - val_loss: 0.5710 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6840 - val_prc: 0.3967\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8460 - tp: 218.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 180.0000 - accuracy: 0.7090 - precision: 0.3477 - recall: 0.5477 - auc: 0.7109 - prc: 0.4492 - val_loss: 0.5813 - val_tp: 48.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 43.0000 - val_accuracy: 0.7115 - val_precision: 0.3179 - val_recall: 0.5275 - val_auc: 0.6838 - val_prc: 0.3973\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8432 - tp: 197.0000 - fp: 322.0000 - tn: 1304.0000 - fn: 201.0000 - accuracy: 0.7416 - precision: 0.3796 - recall: 0.4950 - auc: 0.7103 - prc: 0.4446 - val_loss: 0.5390 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6840 - val_prc: 0.3913\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8426 - tp: 171.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 227.0000 - accuracy: 0.7683 - precision: 0.4140 - recall: 0.4296 - auc: 0.7113 - prc: 0.4473 - val_loss: 0.5412 - val_tp: 40.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 51.0000 - val_accuracy: 0.7708 - val_precision: 0.3810 - val_recall: 0.4396 - val_auc: 0.6837 - val_prc: 0.3881\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8416 - tp: 183.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 215.0000 - accuracy: 0.7594 - precision: 0.4022 - recall: 0.4598 - auc: 0.7117 - prc: 0.4466 - val_loss: 0.5535 - val_tp: 42.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 49.0000 - val_accuracy: 0.7648 - val_precision: 0.3750 - val_recall: 0.4615 - val_auc: 0.6835 - val_prc: 0.3868\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8413 - tp: 184.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 214.0000 - accuracy: 0.7569 - precision: 0.3983 - recall: 0.4623 - auc: 0.7116 - prc: 0.4458 - val_loss: 0.5469 - val_tp: 42.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 49.0000 - val_accuracy: 0.7688 - val_precision: 0.3818 - val_recall: 0.4615 - val_auc: 0.6836 - val_prc: 0.3849\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8410 - tp: 180.0000 - fp: 264.0000 - tn: 1362.0000 - fn: 218.0000 - accuracy: 0.7619 - precision: 0.4054 - recall: 0.4523 - auc: 0.7123 - prc: 0.4491 - val_loss: 0.5429 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6843 - val_prc: 0.3898\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8407 - tp: 194.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 204.0000 - accuracy: 0.7584 - precision: 0.4050 - recall: 0.4874 - auc: 0.7118 - prc: 0.4496 - val_loss: 0.5596 - val_tp: 44.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 47.0000 - val_accuracy: 0.7510 - val_precision: 0.3577 - val_recall: 0.4835 - val_auc: 0.6840 - val_prc: 0.3935\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8405 - tp: 201.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 197.0000 - accuracy: 0.7500 - precision: 0.3941 - recall: 0.5050 - auc: 0.7122 - prc: 0.4510 - val_loss: 0.5501 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6853 - val_prc: 0.3927\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8409 - tp: 178.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 220.0000 - accuracy: 0.7648 - precision: 0.4101 - recall: 0.4472 - auc: 0.7119 - prc: 0.4506 - val_loss: 0.5399 - val_tp: 39.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 52.0000 - val_accuracy: 0.7668 - val_precision: 0.3714 - val_recall: 0.4286 - val_auc: 0.6858 - val_prc: 0.4023\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8400 - tp: 181.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 217.0000 - accuracy: 0.7609 - precision: 0.4040 - recall: 0.4548 - auc: 0.7126 - prc: 0.4537 - val_loss: 0.5472 - val_tp: 41.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 50.0000 - val_accuracy: 0.7628 - val_precision: 0.3694 - val_recall: 0.4505 - val_auc: 0.6859 - val_prc: 0.4049\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8396 - tp: 194.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 204.0000 - accuracy: 0.7564 - precision: 0.4017 - recall: 0.4874 - auc: 0.7127 - prc: 0.4539 - val_loss: 0.5526 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6856 - val_prc: 0.4044\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8396 - tp: 198.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 200.0000 - accuracy: 0.7500 - precision: 0.3929 - recall: 0.4975 - auc: 0.7132 - prc: 0.4533 - val_loss: 0.5557 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6851 - val_prc: 0.4022\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8398 - tp: 189.0000 - fp: 281.0000 - tn: 1345.0000 - fn: 209.0000 - accuracy: 0.7579 - precision: 0.4021 - recall: 0.4749 - auc: 0.7120 - prc: 0.4522 - val_loss: 0.5414 - val_tp: 42.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 49.0000 - val_accuracy: 0.7727 - val_precision: 0.3889 - val_recall: 0.4615 - val_auc: 0.6859 - val_prc: 0.4000\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8395 - tp: 196.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 202.0000 - accuracy: 0.7569 - precision: 0.4033 - recall: 0.4925 - auc: 0.7127 - prc: 0.4546 - val_loss: 0.5501 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6863 - val_prc: 0.4061\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8400 - tp: 177.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 221.0000 - accuracy: 0.7668 - precision: 0.4136 - recall: 0.4447 - auc: 0.7126 - prc: 0.4547 - val_loss: 0.5311 - val_tp: 38.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 53.0000 - val_accuracy: 0.7747 - val_precision: 0.3838 - val_recall: 0.4176 - val_auc: 0.6878 - val_prc: 0.4085\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8383 - tp: 178.0000 - fp: 257.0000 - tn: 1369.0000 - fn: 220.0000 - accuracy: 0.7643 - precision: 0.4092 - recall: 0.4472 - auc: 0.7135 - prc: 0.4584 - val_loss: 0.5501 - val_tp: 42.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 49.0000 - val_accuracy: 0.7589 - val_precision: 0.3652 - val_recall: 0.4615 - val_auc: 0.6868 - val_prc: 0.4099\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8384 - tp: 194.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 204.0000 - accuracy: 0.7574 - precision: 0.4033 - recall: 0.4874 - auc: 0.7131 - prc: 0.4572 - val_loss: 0.5487 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6869 - val_prc: 0.4093\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8379 - tp: 195.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 203.0000 - accuracy: 0.7559 - precision: 0.4012 - recall: 0.4899 - auc: 0.7138 - prc: 0.4577 - val_loss: 0.5465 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6865 - val_prc: 0.4069\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8386 - tp: 181.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 217.0000 - accuracy: 0.7663 - precision: 0.4142 - recall: 0.4548 - auc: 0.7129 - prc: 0.4575 - val_loss: 0.5420 - val_tp: 42.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 49.0000 - val_accuracy: 0.7708 - val_precision: 0.3853 - val_recall: 0.4615 - val_auc: 0.6868 - val_prc: 0.4074\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8372 - tp: 192.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 206.0000 - accuracy: 0.7584 - precision: 0.4042 - recall: 0.4824 - auc: 0.7142 - prc: 0.4586 - val_loss: 0.5533 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6852 - val_prc: 0.4034\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8380 - tp: 203.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 195.0000 - accuracy: 0.7490 - precision: 0.3934 - recall: 0.5101 - auc: 0.7139 - prc: 0.4572 - val_loss: 0.5504 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6862 - val_prc: 0.4068\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8371 - tp: 186.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 212.0000 - accuracy: 0.7624 - precision: 0.4088 - recall: 0.4673 - auc: 0.7141 - prc: 0.4583 - val_loss: 0.5336 - val_tp: 40.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 51.0000 - val_accuracy: 0.7708 - val_precision: 0.3810 - val_recall: 0.4396 - val_auc: 0.6872 - val_prc: 0.4111\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8376 - tp: 175.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 223.0000 - accuracy: 0.7708 - precision: 0.4207 - recall: 0.4397 - auc: 0.7147 - prc: 0.4596 - val_loss: 0.5393 - val_tp: 41.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 50.0000 - val_accuracy: 0.7688 - val_precision: 0.3796 - val_recall: 0.4505 - val_auc: 0.6874 - val_prc: 0.4124\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8374 - tp: 203.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 195.0000 - accuracy: 0.7460 - precision: 0.3889 - recall: 0.5101 - auc: 0.7140 - prc: 0.4587 - val_loss: 0.5647 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6869 - val_prc: 0.4120\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8380 - tp: 196.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 202.0000 - accuracy: 0.7569 - precision: 0.4033 - recall: 0.4925 - auc: 0.7133 - prc: 0.4585 - val_loss: 0.5334 - val_tp: 40.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 51.0000 - val_accuracy: 0.7727 - val_precision: 0.3846 - val_recall: 0.4396 - val_auc: 0.6869 - val_prc: 0.4157\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8386 - tp: 202.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 196.0000 - accuracy: 0.7505 - precision: 0.3953 - recall: 0.5075 - auc: 0.7127 - prc: 0.4554 - val_loss: 0.5607 - val_tp: 44.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 47.0000 - val_accuracy: 0.7451 - val_precision: 0.3492 - val_recall: 0.4835 - val_auc: 0.6844 - val_prc: 0.3922\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8373 - tp: 189.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 209.0000 - accuracy: 0.7574 - precision: 0.4013 - recall: 0.4749 - auc: 0.7143 - prc: 0.4555 - val_loss: 0.5354 - val_tp: 40.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 51.0000 - val_accuracy: 0.7727 - val_precision: 0.3846 - val_recall: 0.4396 - val_auc: 0.6837 - val_prc: 0.3917\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8367 - tp: 183.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 215.0000 - accuracy: 0.7638 - precision: 0.4103 - recall: 0.4598 - auc: 0.7154 - prc: 0.4567 - val_loss: 0.5457 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6858 - val_prc: 0.4025\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8360 - tp: 186.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 212.0000 - accuracy: 0.7604 - precision: 0.4052 - recall: 0.4673 - auc: 0.7156 - prc: 0.4599 - val_loss: 0.5433 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6877 - val_prc: 0.4127\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8364 - tp: 187.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 211.0000 - accuracy: 0.7658 - precision: 0.4156 - recall: 0.4698 - auc: 0.7154 - prc: 0.4617 - val_loss: 0.5426 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6876 - val_prc: 0.4151\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8359 - tp: 204.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 194.0000 - accuracy: 0.7559 - precision: 0.4048 - recall: 0.5126 - auc: 0.7150 - prc: 0.4633 - val_loss: 0.5536 - val_tp: 44.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 47.0000 - val_accuracy: 0.7530 - val_precision: 0.3607 - val_recall: 0.4835 - val_auc: 0.6874 - val_prc: 0.4124\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8356 - tp: 203.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 195.0000 - accuracy: 0.7569 - precision: 0.4060 - recall: 0.5101 - auc: 0.7157 - prc: 0.4624 - val_loss: 0.5449 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6874 - val_prc: 0.4155\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8350 - tp: 188.0000 - fp: 271.0000 - tn: 1355.0000 - fn: 210.0000 - accuracy: 0.7624 - precision: 0.4096 - recall: 0.4724 - auc: 0.7161 - prc: 0.4630 - val_loss: 0.5386 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6862 - val_prc: 0.4155\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8357 - tp: 184.0000 - fp: 261.0000 - tn: 1365.0000 - fn: 214.0000 - accuracy: 0.7653 - precision: 0.4135 - recall: 0.4623 - auc: 0.7154 - prc: 0.4629 - val_loss: 0.5475 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6875 - val_prc: 0.4146\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8370 - tp: 214.0000 - fp: 356.0000 - tn: 1270.0000 - fn: 184.0000 - accuracy: 0.7332 - precision: 0.3754 - recall: 0.5377 - auc: 0.7159 - prc: 0.4621 - val_loss: 0.5696 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6861 - val_prc: 0.4080\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8369 - tp: 197.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 201.0000 - accuracy: 0.7540 - precision: 0.3988 - recall: 0.4950 - auc: 0.7138 - prc: 0.4592 - val_loss: 0.5347 - val_tp: 40.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 51.0000 - val_accuracy: 0.7688 - val_precision: 0.3774 - val_recall: 0.4396 - val_auc: 0.6866 - val_prc: 0.4152\n",
      "Epoch 136/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8350 - tp: 183.0000 - fp: 261.0000 - tn: 1365.0000 - fn: 215.0000 - accuracy: 0.7648 - precision: 0.4122 - recall: 0.4598 - auc: 0.7162 - prc: 0.4640 - val_loss: 0.5461 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6881 - val_prc: 0.4153\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8368 - tp: 209.0000 - fp: 344.0000 - tn: 1282.0000 - fn: 189.0000 - accuracy: 0.7367 - precision: 0.3779 - recall: 0.5251 - auc: 0.7151 - prc: 0.4626 - val_loss: 0.5634 - val_tp: 47.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 44.0000 - val_accuracy: 0.7292 - val_precision: 0.3357 - val_recall: 0.5165 - val_auc: 0.6885 - val_prc: 0.4212\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8353 - tp: 207.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 191.0000 - accuracy: 0.7456 - precision: 0.3898 - recall: 0.5201 - auc: 0.7163 - prc: 0.4658 - val_loss: 0.5440 - val_tp: 42.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 49.0000 - val_accuracy: 0.7589 - val_precision: 0.3652 - val_recall: 0.4615 - val_auc: 0.6886 - val_prc: 0.4219\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8362 - tp: 178.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 220.0000 - accuracy: 0.7717 - precision: 0.4238 - recall: 0.4472 - auc: 0.7156 - prc: 0.4635 - val_loss: 0.5322 - val_tp: 39.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 52.0000 - val_accuracy: 0.7668 - val_precision: 0.3714 - val_recall: 0.4286 - val_auc: 0.6879 - val_prc: 0.4205\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8342 - tp: 201.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 197.0000 - accuracy: 0.7594 - precision: 0.4094 - recall: 0.5050 - auc: 0.7162 - prc: 0.4664 - val_loss: 0.5608 - val_tp: 45.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 46.0000 - val_accuracy: 0.7372 - val_precision: 0.3409 - val_recall: 0.4945 - val_auc: 0.6877 - val_prc: 0.4188\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8351 - tp: 205.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 193.0000 - accuracy: 0.7500 - precision: 0.3958 - recall: 0.5151 - auc: 0.7159 - prc: 0.4641 - val_loss: 0.5380 - val_tp: 42.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 49.0000 - val_accuracy: 0.7648 - val_precision: 0.3750 - val_recall: 0.4615 - val_auc: 0.6882 - val_prc: 0.4206\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8371 - tp: 176.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 222.0000 - accuracy: 0.7796 - precision: 0.4400 - recall: 0.4422 - auc: 0.7148 - prc: 0.4643 - val_loss: 0.5255 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6879 - val_prc: 0.4171\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8349 - tp: 176.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 222.0000 - accuracy: 0.7777 - precision: 0.4356 - recall: 0.4422 - auc: 0.7168 - prc: 0.4650 - val_loss: 0.5406 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6889 - val_prc: 0.4158\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8351 - tp: 204.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 194.0000 - accuracy: 0.7485 - precision: 0.3931 - recall: 0.5126 - auc: 0.7161 - prc: 0.4649 - val_loss: 0.5589 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6882 - val_prc: 0.4213\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8336 - tp: 206.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 192.0000 - accuracy: 0.7569 - precision: 0.4071 - recall: 0.5176 - auc: 0.7175 - prc: 0.4672 - val_loss: 0.5409 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6898 - val_prc: 0.4233\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8341 - tp: 187.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 211.0000 - accuracy: 0.7683 - precision: 0.4202 - recall: 0.4698 - auc: 0.7161 - prc: 0.4671 - val_loss: 0.5387 - val_tp: 41.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 50.0000 - val_accuracy: 0.7668 - val_precision: 0.3761 - val_recall: 0.4505 - val_auc: 0.6872 - val_prc: 0.4154\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8334 - tp: 193.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 205.0000 - accuracy: 0.7663 - precision: 0.4187 - recall: 0.4849 - auc: 0.7171 - prc: 0.4655 - val_loss: 0.5453 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6881 - val_prc: 0.4149\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8336 - tp: 202.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 196.0000 - accuracy: 0.7584 - precision: 0.4081 - recall: 0.5075 - auc: 0.7171 - prc: 0.4656 - val_loss: 0.5436 - val_tp: 42.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 49.0000 - val_accuracy: 0.7589 - val_precision: 0.3652 - val_recall: 0.4615 - val_auc: 0.6889 - val_prc: 0.4164\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8348 - tp: 181.0000 - fp: 245.0000 - tn: 1381.0000 - fn: 217.0000 - accuracy: 0.7717 - precision: 0.4249 - recall: 0.4548 - auc: 0.7165 - prc: 0.4650 - val_loss: 0.5352 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6881 - val_prc: 0.4225\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8334 - tp: 199.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 199.0000 - accuracy: 0.7594 - precision: 0.4086 - recall: 0.5000 - auc: 0.7167 - prc: 0.4667 - val_loss: 0.5497 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6889 - val_prc: 0.4180\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8335 - tp: 199.0000 - fp: 280.0000 - tn: 1346.0000 - fn: 199.0000 - accuracy: 0.7633 - precision: 0.4154 - recall: 0.5000 - auc: 0.7176 - prc: 0.4656 - val_loss: 0.5342 - val_tp: 40.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 51.0000 - val_accuracy: 0.7668 - val_precision: 0.3738 - val_recall: 0.4396 - val_auc: 0.6872 - val_prc: 0.4223\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8334 - tp: 182.0000 - fp: 246.0000 - tn: 1380.0000 - fn: 216.0000 - accuracy: 0.7717 - precision: 0.4252 - recall: 0.4573 - auc: 0.7169 - prc: 0.4673 - val_loss: 0.5425 - val_tp: 42.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 49.0000 - val_accuracy: 0.7569 - val_precision: 0.3621 - val_recall: 0.4615 - val_auc: 0.6876 - val_prc: 0.4186\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8326 - tp: 201.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 197.0000 - accuracy: 0.7535 - precision: 0.3996 - recall: 0.5050 - auc: 0.7180 - prc: 0.4672 - val_loss: 0.5519 - val_tp: 45.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 46.0000 - val_accuracy: 0.7530 - val_precision: 0.3629 - val_recall: 0.4945 - val_auc: 0.6889 - val_prc: 0.4218\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8322 - tp: 206.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 192.0000 - accuracy: 0.7564 - precision: 0.4063 - recall: 0.5176 - auc: 0.7183 - prc: 0.4685 - val_loss: 0.5384 - val_tp: 41.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 50.0000 - val_accuracy: 0.7628 - val_precision: 0.3694 - val_recall: 0.4505 - val_auc: 0.6877 - val_prc: 0.4230\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8337 - tp: 179.0000 - fp: 236.0000 - tn: 1390.0000 - fn: 219.0000 - accuracy: 0.7752 - precision: 0.4313 - recall: 0.4497 - auc: 0.7174 - prc: 0.4684 - val_loss: 0.5262 - val_tp: 39.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 52.0000 - val_accuracy: 0.7767 - val_precision: 0.3900 - val_recall: 0.4286 - val_auc: 0.6891 - val_prc: 0.4297\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8324 - tp: 196.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 202.0000 - accuracy: 0.7638 - precision: 0.4153 - recall: 0.4925 - auc: 0.7179 - prc: 0.4691 - val_loss: 0.5538 - val_tp: 45.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 46.0000 - val_accuracy: 0.7451 - val_precision: 0.3516 - val_recall: 0.4945 - val_auc: 0.6904 - val_prc: 0.4277\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8324 - tp: 204.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 194.0000 - accuracy: 0.7544 - precision: 0.4024 - recall: 0.5126 - auc: 0.7182 - prc: 0.4687 - val_loss: 0.5434 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6873 - val_prc: 0.4197\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8322 - tp: 184.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 214.0000 - accuracy: 0.7742 - precision: 0.4309 - recall: 0.4623 - auc: 0.7182 - prc: 0.4706 - val_loss: 0.5296 - val_tp: 40.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 51.0000 - val_accuracy: 0.7747 - val_precision: 0.3883 - val_recall: 0.4396 - val_auc: 0.6882 - val_prc: 0.4244\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8310 - tp: 190.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 208.0000 - accuracy: 0.7712 - precision: 0.4270 - recall: 0.4774 - auc: 0.7193 - prc: 0.4696 - val_loss: 0.5523 - val_tp: 45.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 46.0000 - val_accuracy: 0.7510 - val_precision: 0.3600 - val_recall: 0.4945 - val_auc: 0.6869 - val_prc: 0.4200\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8322 - tp: 209.0000 - fp: 323.0000 - tn: 1303.0000 - fn: 189.0000 - accuracy: 0.7470 - precision: 0.3929 - recall: 0.5251 - auc: 0.7186 - prc: 0.4682 - val_loss: 0.5515 - val_tp: 45.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 46.0000 - val_accuracy: 0.7470 - val_precision: 0.3543 - val_recall: 0.4945 - val_auc: 0.6878 - val_prc: 0.4232\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8325 - tp: 210.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 188.0000 - accuracy: 0.7470 - precision: 0.3933 - recall: 0.5276 - auc: 0.7178 - prc: 0.4691 - val_loss: 0.5460 - val_tp: 44.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 47.0000 - val_accuracy: 0.7549 - val_precision: 0.3636 - val_recall: 0.4835 - val_auc: 0.6880 - val_prc: 0.4251\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8321 - tp: 193.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 205.0000 - accuracy: 0.7693 - precision: 0.4242 - recall: 0.4849 - auc: 0.7179 - prc: 0.4706 - val_loss: 0.5351 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6889 - val_prc: 0.4297\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8316 - tp: 204.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 194.0000 - accuracy: 0.7554 - precision: 0.4040 - recall: 0.5126 - auc: 0.7184 - prc: 0.4690 - val_loss: 0.5575 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6875 - val_prc: 0.4263\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8330 - tp: 216.0000 - fp: 362.0000 - tn: 1264.0000 - fn: 182.0000 - accuracy: 0.7312 - precision: 0.3737 - recall: 0.5427 - auc: 0.7190 - prc: 0.4695 - val_loss: 0.5502 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6889 - val_prc: 0.4335\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8314 - tp: 192.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 206.0000 - accuracy: 0.7762 - precision: 0.4374 - recall: 0.4824 - auc: 0.7192 - prc: 0.4706 - val_loss: 0.5203 - val_tp: 39.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 52.0000 - val_accuracy: 0.7846 - val_precision: 0.4062 - val_recall: 0.4286 - val_auc: 0.6885 - val_prc: 0.4308\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8307 - tp: 191.0000 - fp: 261.0000 - tn: 1365.0000 - fn: 207.0000 - accuracy: 0.7688 - precision: 0.4226 - recall: 0.4799 - auc: 0.7202 - prc: 0.4699 - val_loss: 0.5528 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6880 - val_prc: 0.4311\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8322 - tp: 215.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 183.0000 - accuracy: 0.7357 - precision: 0.3792 - recall: 0.5402 - auc: 0.7193 - prc: 0.4709 - val_loss: 0.5504 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6888 - val_prc: 0.4312\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8332 - tp: 180.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 218.0000 - accuracy: 0.7796 - precision: 0.4412 - recall: 0.4523 - auc: 0.7182 - prc: 0.4691 - val_loss: 0.5140 - val_tp: 38.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 53.0000 - val_accuracy: 0.7925 - val_precision: 0.4222 - val_recall: 0.4176 - val_auc: 0.6903 - val_prc: 0.4363\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8322 - tp: 189.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 209.0000 - accuracy: 0.7712 - precision: 0.4266 - recall: 0.4749 - auc: 0.7178 - prc: 0.4685 - val_loss: 0.5559 - val_tp: 45.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 46.0000 - val_accuracy: 0.7490 - val_precision: 0.3571 - val_recall: 0.4945 - val_auc: 0.6869 - val_prc: 0.4158\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8306 - tp: 205.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 193.0000 - accuracy: 0.7604 - precision: 0.4125 - recall: 0.5151 - auc: 0.7199 - prc: 0.4690 - val_loss: 0.5402 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6866 - val_prc: 0.4164\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8321 - tp: 182.0000 - fp: 225.0000 - tn: 1401.0000 - fn: 216.0000 - accuracy: 0.7821 - precision: 0.4472 - recall: 0.4573 - auc: 0.7188 - prc: 0.4686 - val_loss: 0.5275 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6868 - val_prc: 0.4211\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8301 - tp: 195.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 203.0000 - accuracy: 0.7747 - precision: 0.4353 - recall: 0.4899 - auc: 0.7199 - prc: 0.4703 - val_loss: 0.5481 - val_tp: 45.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 46.0000 - val_accuracy: 0.7589 - val_precision: 0.3719 - val_recall: 0.4945 - val_auc: 0.6893 - val_prc: 0.4197\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8309 - tp: 210.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 188.0000 - accuracy: 0.7485 - precision: 0.3955 - recall: 0.5276 - auc: 0.7202 - prc: 0.4713 - val_loss: 0.5550 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6901 - val_prc: 0.4209\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8296 - tp: 197.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 201.0000 - accuracy: 0.7708 - precision: 0.4283 - recall: 0.4950 - auc: 0.7205 - prc: 0.4720 - val_loss: 0.5284 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6875 - val_prc: 0.4216\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8311 - tp: 174.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 224.0000 - accuracy: 0.7866 - precision: 0.4555 - recall: 0.4372 - auc: 0.7207 - prc: 0.4720 - val_loss: 0.5242 - val_tp: 40.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 51.0000 - val_accuracy: 0.7885 - val_precision: 0.4167 - val_recall: 0.4396 - val_auc: 0.6877 - val_prc: 0.4207\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8297 - tp: 197.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 201.0000 - accuracy: 0.7688 - precision: 0.4246 - recall: 0.4950 - auc: 0.7201 - prc: 0.4706 - val_loss: 0.5556 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6893 - val_prc: 0.4206\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8301 - tp: 210.0000 - fp: 314.0000 - tn: 1312.0000 - fn: 188.0000 - accuracy: 0.7520 - precision: 0.4008 - recall: 0.5276 - auc: 0.7207 - prc: 0.4708 - val_loss: 0.5436 - val_tp: 44.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 47.0000 - val_accuracy: 0.7628 - val_precision: 0.3761 - val_recall: 0.4835 - val_auc: 0.6898 - val_prc: 0.4252\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8290 - tp: 192.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 206.0000 - accuracy: 0.7727 - precision: 0.4305 - recall: 0.4824 - auc: 0.7211 - prc: 0.4725 - val_loss: 0.5269 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6887 - val_prc: 0.4295\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8300 - tp: 184.0000 - fp: 231.0000 - tn: 1395.0000 - fn: 214.0000 - accuracy: 0.7801 - precision: 0.4434 - recall: 0.4623 - auc: 0.7215 - prc: 0.4711 - val_loss: 0.5320 - val_tp: 41.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 50.0000 - val_accuracy: 0.7727 - val_precision: 0.3868 - val_recall: 0.4505 - val_auc: 0.6875 - val_prc: 0.4294\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8293 - tp: 194.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 204.0000 - accuracy: 0.7742 - precision: 0.4340 - recall: 0.4874 - auc: 0.7216 - prc: 0.4711 - val_loss: 0.5377 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6903 - val_prc: 0.4309\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8291 - tp: 196.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 202.0000 - accuracy: 0.7737 - precision: 0.4336 - recall: 0.4925 - auc: 0.7215 - prc: 0.4718 - val_loss: 0.5423 - val_tp: 42.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 49.0000 - val_accuracy: 0.7648 - val_precision: 0.3750 - val_recall: 0.4615 - val_auc: 0.6897 - val_prc: 0.4274\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8292 - tp: 197.0000 - fp: 257.0000 - tn: 1369.0000 - fn: 201.0000 - accuracy: 0.7737 - precision: 0.4339 - recall: 0.4950 - auc: 0.7208 - prc: 0.4709 - val_loss: 0.5387 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6877 - val_prc: 0.4233\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8286 - tp: 192.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 206.0000 - accuracy: 0.7742 - precision: 0.4334 - recall: 0.4824 - auc: 0.7216 - prc: 0.4716 - val_loss: 0.5292 - val_tp: 40.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 51.0000 - val_accuracy: 0.7787 - val_precision: 0.3960 - val_recall: 0.4396 - val_auc: 0.6882 - val_prc: 0.4281\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8300 - tp: 178.0000 - fp: 211.0000 - tn: 1415.0000 - fn: 220.0000 - accuracy: 0.7871 - precision: 0.4576 - recall: 0.4472 - auc: 0.7217 - prc: 0.4724 - val_loss: 0.5269 - val_tp: 40.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 51.0000 - val_accuracy: 0.7846 - val_precision: 0.4082 - val_recall: 0.4396 - val_auc: 0.6888 - val_prc: 0.4263\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8294 - tp: 205.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 193.0000 - accuracy: 0.7480 - precision: 0.3927 - recall: 0.5151 - auc: 0.7214 - prc: 0.4712 - val_loss: 0.5655 - val_tp: 47.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 44.0000 - val_accuracy: 0.7332 - val_precision: 0.3406 - val_recall: 0.5165 - val_auc: 0.6875 - val_prc: 0.4174\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8279 - tp: 206.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 192.0000 - accuracy: 0.7638 - precision: 0.4187 - recall: 0.5176 - auc: 0.7227 - prc: 0.4725 - val_loss: 0.5278 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6884 - val_prc: 0.4256\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8286 - tp: 187.0000 - fp: 229.0000 - tn: 1397.0000 - fn: 211.0000 - accuracy: 0.7826 - precision: 0.4495 - recall: 0.4698 - auc: 0.7224 - prc: 0.4730 - val_loss: 0.5337 - val_tp: 41.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 50.0000 - val_accuracy: 0.7708 - val_precision: 0.3832 - val_recall: 0.4505 - val_auc: 0.6877 - val_prc: 0.4252\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8275 - tp: 198.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 200.0000 - accuracy: 0.7693 - precision: 0.4258 - recall: 0.4975 - auc: 0.7223 - prc: 0.4726 - val_loss: 0.5466 - val_tp: 44.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 47.0000 - val_accuracy: 0.7569 - val_precision: 0.3667 - val_recall: 0.4835 - val_auc: 0.6860 - val_prc: 0.4198\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8280 - tp: 200.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 198.0000 - accuracy: 0.7678 - precision: 0.4237 - recall: 0.5025 - auc: 0.7221 - prc: 0.4714 - val_loss: 0.5422 - val_tp: 44.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 47.0000 - val_accuracy: 0.7648 - val_precision: 0.3793 - val_recall: 0.4835 - val_auc: 0.6864 - val_prc: 0.4217\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8286 - tp: 211.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 187.0000 - accuracy: 0.7495 - precision: 0.3974 - recall: 0.5302 - auc: 0.7226 - prc: 0.4710 - val_loss: 0.5534 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6882 - val_prc: 0.4242\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8290 - tp: 192.0000 - fp: 245.0000 - tn: 1381.0000 - fn: 206.0000 - accuracy: 0.7772 - precision: 0.4394 - recall: 0.4824 - auc: 0.7209 - prc: 0.4727 - val_loss: 0.5253 - val_tp: 40.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 51.0000 - val_accuracy: 0.7826 - val_precision: 0.4040 - val_recall: 0.4396 - val_auc: 0.6893 - val_prc: 0.4278\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8285 - tp: 206.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 192.0000 - accuracy: 0.7678 - precision: 0.4256 - recall: 0.5176 - auc: 0.7212 - prc: 0.4736 - val_loss: 0.5564 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6878 - val_prc: 0.4281\n",
      "Epoch 193/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8288 - tp: 217.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 181.0000 - accuracy: 0.7456 - precision: 0.3938 - recall: 0.5452 - auc: 0.7227 - prc: 0.4722 - val_loss: 0.5532 - val_tp: 47.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 44.0000 - val_accuracy: 0.7451 - val_precision: 0.3561 - val_recall: 0.5165 - val_auc: 0.6875 - val_prc: 0.4268\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8297 - tp: 216.0000 - fp: 351.0000 - tn: 1275.0000 - fn: 182.0000 - accuracy: 0.7367 - precision: 0.3810 - recall: 0.5427 - auc: 0.7224 - prc: 0.4706 - val_loss: 0.5633 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6850 - val_prc: 0.4148\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8291 - tp: 201.0000 - fp: 277.0000 - tn: 1349.0000 - fn: 197.0000 - accuracy: 0.7658 - precision: 0.4205 - recall: 0.5050 - auc: 0.7210 - prc: 0.4704 - val_loss: 0.5287 - val_tp: 41.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 50.0000 - val_accuracy: 0.7885 - val_precision: 0.4184 - val_recall: 0.4505 - val_auc: 0.6865 - val_prc: 0.4185\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8277 - tp: 190.0000 - fp: 239.0000 - tn: 1387.0000 - fn: 208.0000 - accuracy: 0.7792 - precision: 0.4429 - recall: 0.4774 - auc: 0.7238 - prc: 0.4716 - val_loss: 0.5363 - val_tp: 41.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 50.0000 - val_accuracy: 0.7668 - val_precision: 0.3761 - val_recall: 0.4505 - val_auc: 0.6870 - val_prc: 0.4229\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8271 - tp: 195.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 203.0000 - accuracy: 0.7752 - precision: 0.4362 - recall: 0.4899 - auc: 0.7238 - prc: 0.4739 - val_loss: 0.5381 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6868 - val_prc: 0.4249\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8268 - tp: 196.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 202.0000 - accuracy: 0.7757 - precision: 0.4375 - recall: 0.4925 - auc: 0.7238 - prc: 0.4736 - val_loss: 0.5408 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6864 - val_prc: 0.4227\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8266 - tp: 200.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 198.0000 - accuracy: 0.7693 - precision: 0.4264 - recall: 0.5025 - auc: 0.7236 - prc: 0.4737 - val_loss: 0.5484 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6872 - val_prc: 0.4245\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8267 - tp: 205.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 193.0000 - accuracy: 0.7653 - precision: 0.4209 - recall: 0.5151 - auc: 0.7236 - prc: 0.4744 - val_loss: 0.5463 - val_tp: 45.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 46.0000 - val_accuracy: 0.7609 - val_precision: 0.3750 - val_recall: 0.4945 - val_auc: 0.6880 - val_prc: 0.4304\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8270 - tp: 193.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 205.0000 - accuracy: 0.7742 - precision: 0.4337 - recall: 0.4849 - auc: 0.7237 - prc: 0.4728 - val_loss: 0.5302 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6895 - val_prc: 0.4331\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8266 - tp: 194.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 204.0000 - accuracy: 0.7767 - precision: 0.4389 - recall: 0.4874 - auc: 0.7239 - prc: 0.4743 - val_loss: 0.5362 - val_tp: 44.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 47.0000 - val_accuracy: 0.7727 - val_precision: 0.3929 - val_recall: 0.4835 - val_auc: 0.6909 - val_prc: 0.4371\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8266 - tp: 197.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 201.0000 - accuracy: 0.7762 - precision: 0.4388 - recall: 0.4950 - auc: 0.7238 - prc: 0.4742 - val_loss: 0.5347 - val_tp: 43.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 48.0000 - val_accuracy: 0.7727 - val_precision: 0.3909 - val_recall: 0.4725 - val_auc: 0.6905 - val_prc: 0.4373\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8265 - tp: 202.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 196.0000 - accuracy: 0.7653 - precision: 0.4200 - recall: 0.5075 - auc: 0.7239 - prc: 0.4734 - val_loss: 0.5485 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6886 - val_prc: 0.4305\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8255 - tp: 199.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 199.0000 - accuracy: 0.7762 - precision: 0.4393 - recall: 0.5000 - auc: 0.7257 - prc: 0.4739 - val_loss: 0.5266 - val_tp: 41.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 50.0000 - val_accuracy: 0.7866 - val_precision: 0.4141 - val_recall: 0.4505 - val_auc: 0.6891 - val_prc: 0.4267\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8268 - tp: 186.0000 - fp: 230.0000 - tn: 1396.0000 - fn: 212.0000 - accuracy: 0.7816 - precision: 0.4471 - recall: 0.4673 - auc: 0.7246 - prc: 0.4742 - val_loss: 0.5353 - val_tp: 41.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 50.0000 - val_accuracy: 0.7708 - val_precision: 0.3832 - val_recall: 0.4505 - val_auc: 0.6874 - val_prc: 0.4245\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8265 - tp: 192.0000 - fp: 239.0000 - tn: 1387.0000 - fn: 206.0000 - accuracy: 0.7801 - precision: 0.4455 - recall: 0.4824 - auc: 0.7243 - prc: 0.4739 - val_loss: 0.5422 - val_tp: 44.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 47.0000 - val_accuracy: 0.7668 - val_precision: 0.3826 - val_recall: 0.4835 - val_auc: 0.6874 - val_prc: 0.4263\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8256 - tp: 198.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 200.0000 - accuracy: 0.7717 - precision: 0.4304 - recall: 0.4975 - auc: 0.7248 - prc: 0.4745 - val_loss: 0.5416 - val_tp: 43.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 48.0000 - val_accuracy: 0.7668 - val_precision: 0.3805 - val_recall: 0.4725 - val_auc: 0.6882 - val_prc: 0.4287\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8255 - tp: 210.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 188.0000 - accuracy: 0.7604 - precision: 0.4142 - recall: 0.5276 - auc: 0.7254 - prc: 0.4757 - val_loss: 0.5605 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6892 - val_prc: 0.4258\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8258 - tp: 207.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 191.0000 - accuracy: 0.7584 - precision: 0.4099 - recall: 0.5201 - auc: 0.7245 - prc: 0.4755 - val_loss: 0.5323 - val_tp: 41.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 50.0000 - val_accuracy: 0.7727 - val_precision: 0.3868 - val_recall: 0.4505 - val_auc: 0.6898 - val_prc: 0.4315\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8258 - tp: 194.0000 - fp: 238.0000 - tn: 1388.0000 - fn: 204.0000 - accuracy: 0.7816 - precision: 0.4491 - recall: 0.4874 - auc: 0.7246 - prc: 0.4745 - val_loss: 0.5315 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6887 - val_prc: 0.4282\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8258 - tp: 191.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 207.0000 - accuracy: 0.7831 - precision: 0.4515 - recall: 0.4799 - auc: 0.7253 - prc: 0.4753 - val_loss: 0.5393 - val_tp: 43.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 48.0000 - val_accuracy: 0.7708 - val_precision: 0.3874 - val_recall: 0.4725 - val_auc: 0.6886 - val_prc: 0.4242\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - tp: 208.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 190.0000 - accuracy: 0.7584 - precision: 0.4103 - recall: 0.5226 - auc: 0.7254 - prc: 0.4758 - val_loss: 0.5535 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6880 - val_prc: 0.4246\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8257 - tp: 195.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 203.0000 - accuracy: 0.7752 - precision: 0.4362 - recall: 0.4899 - auc: 0.7253 - prc: 0.4729 - val_loss: 0.5262 - val_tp: 41.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 50.0000 - val_accuracy: 0.7866 - val_precision: 0.4141 - val_recall: 0.4505 - val_auc: 0.6897 - val_prc: 0.4288\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8275 - tp: 204.0000 - fp: 277.0000 - tn: 1349.0000 - fn: 194.0000 - accuracy: 0.7673 - precision: 0.4241 - recall: 0.5126 - auc: 0.7227 - prc: 0.4725 - val_loss: 0.5527 - val_tp: 46.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 45.0000 - val_accuracy: 0.7530 - val_precision: 0.3651 - val_recall: 0.5055 - val_auc: 0.6875 - val_prc: 0.4229\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8252 - tp: 203.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 195.0000 - accuracy: 0.7708 - precision: 0.4301 - recall: 0.5101 - auc: 0.7258 - prc: 0.4746 - val_loss: 0.5293 - val_tp: 41.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 50.0000 - val_accuracy: 0.7787 - val_precision: 0.3981 - val_recall: 0.4505 - val_auc: 0.6890 - val_prc: 0.4242\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - tp: 192.0000 - fp: 231.0000 - tn: 1395.0000 - fn: 206.0000 - accuracy: 0.7841 - precision: 0.4539 - recall: 0.4824 - auc: 0.7257 - prc: 0.4747 - val_loss: 0.5351 - val_tp: 41.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 50.0000 - val_accuracy: 0.7708 - val_precision: 0.3832 - val_recall: 0.4505 - val_auc: 0.6879 - val_prc: 0.4237\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - tp: 203.0000 - fp: 264.0000 - tn: 1362.0000 - fn: 195.0000 - accuracy: 0.7732 - precision: 0.4347 - recall: 0.5101 - auc: 0.7257 - prc: 0.4743 - val_loss: 0.5414 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6880 - val_prc: 0.4243\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8247 - tp: 198.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 200.0000 - accuracy: 0.7747 - precision: 0.4361 - recall: 0.4975 - auc: 0.7264 - prc: 0.4754 - val_loss: 0.5341 - val_tp: 41.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 50.0000 - val_accuracy: 0.7708 - val_precision: 0.3832 - val_recall: 0.4505 - val_auc: 0.6888 - val_prc: 0.4268\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8246 - tp: 195.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 203.0000 - accuracy: 0.7811 - precision: 0.4483 - recall: 0.4899 - auc: 0.7265 - prc: 0.4751 - val_loss: 0.5263 - val_tp: 41.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 50.0000 - val_accuracy: 0.7787 - val_precision: 0.3981 - val_recall: 0.4505 - val_auc: 0.6906 - val_prc: 0.4319\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8256 - tp: 186.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 212.0000 - accuracy: 0.7856 - precision: 0.4559 - recall: 0.4673 - auc: 0.7268 - prc: 0.4754 - val_loss: 0.5322 - val_tp: 41.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 50.0000 - val_accuracy: 0.7727 - val_precision: 0.3868 - val_recall: 0.4505 - val_auc: 0.6898 - val_prc: 0.4294\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8272 - tp: 213.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 185.0000 - accuracy: 0.7520 - precision: 0.4019 - recall: 0.5352 - auc: 0.7238 - prc: 0.4738 - val_loss: 0.5613 - val_tp: 46.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 45.0000 - val_accuracy: 0.7372 - val_precision: 0.3433 - val_recall: 0.5055 - val_auc: 0.6880 - val_prc: 0.4259\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8247 - tp: 206.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 192.0000 - accuracy: 0.7643 - precision: 0.4196 - recall: 0.5176 - auc: 0.7269 - prc: 0.4743 - val_loss: 0.5322 - val_tp: 41.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 50.0000 - val_accuracy: 0.7747 - val_precision: 0.3905 - val_recall: 0.4505 - val_auc: 0.6888 - val_prc: 0.4299\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8244 - tp: 198.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 200.0000 - accuracy: 0.7767 - precision: 0.4400 - recall: 0.4975 - auc: 0.7269 - prc: 0.4750 - val_loss: 0.5415 - val_tp: 44.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 47.0000 - val_accuracy: 0.7688 - val_precision: 0.3860 - val_recall: 0.4835 - val_auc: 0.6882 - val_prc: 0.4294\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8246 - tp: 211.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 187.0000 - accuracy: 0.7609 - precision: 0.4154 - recall: 0.5302 - auc: 0.7261 - prc: 0.4754 - val_loss: 0.5473 - val_tp: 45.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 46.0000 - val_accuracy: 0.7549 - val_precision: 0.3659 - val_recall: 0.4945 - val_auc: 0.6875 - val_prc: 0.4276\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8245 - tp: 198.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 200.0000 - accuracy: 0.7792 - precision: 0.4449 - recall: 0.4975 - auc: 0.7264 - prc: 0.4749 - val_loss: 0.5387 - val_tp: 44.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 47.0000 - val_accuracy: 0.7727 - val_precision: 0.3929 - val_recall: 0.4835 - val_auc: 0.6885 - val_prc: 0.4276\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8267 - tp: 217.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 181.0000 - accuracy: 0.7451 - precision: 0.3931 - recall: 0.5452 - auc: 0.7254 - prc: 0.4745 - val_loss: 0.5747 - val_tp: 48.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 43.0000 - val_accuracy: 0.7194 - val_precision: 0.3265 - val_recall: 0.5275 - val_auc: 0.6873 - val_prc: 0.4273\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8250 - tp: 216.0000 - fp: 325.0000 - tn: 1301.0000 - fn: 182.0000 - accuracy: 0.7495 - precision: 0.3993 - recall: 0.5427 - auc: 0.7266 - prc: 0.4750 - val_loss: 0.5351 - val_tp: 44.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 47.0000 - val_accuracy: 0.7747 - val_precision: 0.3964 - val_recall: 0.4835 - val_auc: 0.6911 - val_prc: 0.4323\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8256 - tp: 183.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 215.0000 - accuracy: 0.7841 - precision: 0.4519 - recall: 0.4598 - auc: 0.7270 - prc: 0.4750 - val_loss: 0.5251 - val_tp: 42.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 49.0000 - val_accuracy: 0.7885 - val_precision: 0.4200 - val_recall: 0.4615 - val_auc: 0.6910 - val_prc: 0.4319\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8248 - tp: 185.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 213.0000 - accuracy: 0.7890 - precision: 0.4637 - recall: 0.4648 - auc: 0.7273 - prc: 0.4754 - val_loss: 0.5419 - val_tp: 45.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 46.0000 - val_accuracy: 0.7708 - val_precision: 0.3913 - val_recall: 0.4945 - val_auc: 0.6872 - val_prc: 0.4226\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8240 - tp: 211.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 187.0000 - accuracy: 0.7579 - precision: 0.4105 - recall: 0.5302 - auc: 0.7272 - prc: 0.4753 - val_loss: 0.5576 - val_tp: 46.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 45.0000 - val_accuracy: 0.7451 - val_precision: 0.3538 - val_recall: 0.5055 - val_auc: 0.6862 - val_prc: 0.4231\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8238 - tp: 211.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 187.0000 - accuracy: 0.7678 - precision: 0.4271 - recall: 0.5302 - auc: 0.7269 - prc: 0.4768 - val_loss: 0.5402 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6883 - val_prc: 0.4256\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8238 - tp: 209.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 189.0000 - accuracy: 0.7673 - precision: 0.4257 - recall: 0.5251 - auc: 0.7274 - prc: 0.4760 - val_loss: 0.5475 - val_tp: 46.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 45.0000 - val_accuracy: 0.7609 - val_precision: 0.3770 - val_recall: 0.5055 - val_auc: 0.6882 - val_prc: 0.4283\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8235 - tp: 207.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 191.0000 - accuracy: 0.7698 - precision: 0.4295 - recall: 0.5201 - auc: 0.7277 - prc: 0.4758 - val_loss: 0.5407 - val_tp: 44.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 47.0000 - val_accuracy: 0.7688 - val_precision: 0.3860 - val_recall: 0.4835 - val_auc: 0.6891 - val_prc: 0.4317\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8242 - tp: 199.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 199.0000 - accuracy: 0.7777 - precision: 0.4422 - recall: 0.5000 - auc: 0.7274 - prc: 0.4749 - val_loss: 0.5367 - val_tp: 41.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 50.0000 - val_accuracy: 0.7727 - val_precision: 0.3868 - val_recall: 0.4505 - val_auc: 0.6871 - val_prc: 0.4210\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8241 - tp: 191.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 207.0000 - accuracy: 0.7792 - precision: 0.4432 - recall: 0.4799 - auc: 0.7278 - prc: 0.4749 - val_loss: 0.5394 - val_tp: 43.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 48.0000 - val_accuracy: 0.7708 - val_precision: 0.3874 - val_recall: 0.4725 - val_auc: 0.6878 - val_prc: 0.4232\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8235 - tp: 208.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 190.0000 - accuracy: 0.7619 - precision: 0.4160 - recall: 0.5226 - auc: 0.7276 - prc: 0.4756 - val_loss: 0.5605 - val_tp: 46.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 45.0000 - val_accuracy: 0.7451 - val_precision: 0.3538 - val_recall: 0.5055 - val_auc: 0.6862 - val_prc: 0.4135\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8241 - tp: 196.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 202.0000 - accuracy: 0.7737 - precision: 0.4336 - recall: 0.4925 - auc: 0.7274 - prc: 0.4741 - val_loss: 0.5317 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6885 - val_prc: 0.4225\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8233 - tp: 197.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 201.0000 - accuracy: 0.7732 - precision: 0.4330 - recall: 0.4950 - auc: 0.7277 - prc: 0.4761 - val_loss: 0.5487 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6873 - val_prc: 0.4235\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8242 - tp: 214.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 184.0000 - accuracy: 0.7564 - precision: 0.4092 - recall: 0.5377 - auc: 0.7278 - prc: 0.4752 - val_loss: 0.5468 - val_tp: 46.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 45.0000 - val_accuracy: 0.7668 - val_precision: 0.3866 - val_recall: 0.5055 - val_auc: 0.6882 - val_prc: 0.4266\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8247 - tp: 189.0000 - fp: 234.0000 - tn: 1392.0000 - fn: 209.0000 - accuracy: 0.7811 - precision: 0.4468 - recall: 0.4749 - auc: 0.7277 - prc: 0.4714 - val_loss: 0.5258 - val_tp: 41.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 50.0000 - val_accuracy: 0.7826 - val_precision: 0.4059 - val_recall: 0.4505 - val_auc: 0.6893 - val_prc: 0.4279\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8232 - tp: 198.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 200.0000 - accuracy: 0.7757 - precision: 0.4381 - recall: 0.4975 - auc: 0.7287 - prc: 0.4746 - val_loss: 0.5549 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6870 - val_prc: 0.4253\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8244 - tp: 209.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 189.0000 - accuracy: 0.7648 - precision: 0.4214 - recall: 0.5251 - auc: 0.7261 - prc: 0.4744 - val_loss: 0.5508 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6869 - val_prc: 0.4245\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8236 - tp: 213.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 185.0000 - accuracy: 0.7609 - precision: 0.4160 - recall: 0.5352 - auc: 0.7279 - prc: 0.4759 - val_loss: 0.5471 - val_tp: 45.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 46.0000 - val_accuracy: 0.7569 - val_precision: 0.3689 - val_recall: 0.4945 - val_auc: 0.6877 - val_prc: 0.4263\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8238 - tp: 211.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 187.0000 - accuracy: 0.7540 - precision: 0.4042 - recall: 0.5302 - auc: 0.7282 - prc: 0.4754 - val_loss: 0.5555 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6878 - val_prc: 0.4279\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8229 - tp: 207.0000 - fp: 288.0000 - tn: 1338.0000 - fn: 191.0000 - accuracy: 0.7633 - precision: 0.4182 - recall: 0.5201 - auc: 0.7288 - prc: 0.4751 - val_loss: 0.5393 - val_tp: 43.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 48.0000 - val_accuracy: 0.7727 - val_precision: 0.3909 - val_recall: 0.4725 - val_auc: 0.6887 - val_prc: 0.4299\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8235 - tp: 187.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 211.0000 - accuracy: 0.7841 - precision: 0.4528 - recall: 0.4698 - auc: 0.7294 - prc: 0.4754 - val_loss: 0.5325 - val_tp: 43.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 48.0000 - val_accuracy: 0.7787 - val_precision: 0.4019 - val_recall: 0.4725 - val_auc: 0.6882 - val_prc: 0.4293\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8227 - tp: 211.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 187.0000 - accuracy: 0.7643 - precision: 0.4212 - recall: 0.5302 - auc: 0.7289 - prc: 0.4761 - val_loss: 0.5571 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6876 - val_prc: 0.4292\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8230 - tp: 202.0000 - fp: 249.0000 - tn: 1377.0000 - fn: 196.0000 - accuracy: 0.7801 - precision: 0.4479 - recall: 0.5075 - auc: 0.7280 - prc: 0.4756 - val_loss: 0.5234 - val_tp: 41.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 50.0000 - val_accuracy: 0.7866 - val_precision: 0.4141 - val_recall: 0.4505 - val_auc: 0.6890 - val_prc: 0.4321\n",
      "Epoch 250/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8241 - tp: 187.0000 - fp: 217.0000 - tn: 1409.0000 - fn: 211.0000 - accuracy: 0.7885 - precision: 0.4629 - recall: 0.4698 - auc: 0.7285 - prc: 0.4752 - val_loss: 0.5377 - val_tp: 43.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 48.0000 - val_accuracy: 0.7747 - val_precision: 0.3945 - val_recall: 0.4725 - val_auc: 0.6889 - val_prc: 0.4251\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8222 - tp: 202.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 196.0000 - accuracy: 0.7737 - precision: 0.4353 - recall: 0.5075 - auc: 0.7293 - prc: 0.4773 - val_loss: 0.5559 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6891 - val_prc: 0.4286\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8269 - tp: 229.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 169.0000 - accuracy: 0.7238 - precision: 0.3700 - recall: 0.5754 - auc: 0.7282 - prc: 0.4783 - val_loss: 0.5799 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6882 - val_prc: 0.4277\n",
      "Epoch 253/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.7840 - tp: 24.0000 - fp: 39.0000 - tn: 123.0000 - fn: 14.0000 - accuracy: 0.7350 - precision: 0.3810 - recall: 0.6316 - auc: 0.7531 - prc: 0.5668Restoring model weights from the end of the best epoch: 203.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8252 - tp: 204.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 194.0000 - accuracy: 0.7584 - precision: 0.4088 - recall: 0.5126 - auc: 0.7259 - prc: 0.4730 - val_loss: 0.5217 - val_tp: 41.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 50.0000 - val_accuracy: 0.7846 - val_precision: 0.4100 - val_recall: 0.4505 - val_auc: 0.6902 - val_prc: 0.4305\n",
      "Epoch 253: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.3021 - tp: 41.0000 - fp: 59.0000 - tn: 1982.0000 - fn: 448.0000 - accuracy: 0.7996 - precision: 0.4100 - recall: 0.0838 - auc: 0.4988 - prc: 0.2362 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5191 - val_prc: 0.1859\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2895 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4903 - prc: 0.1949 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4797 - val_prc: 0.1738\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2758 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5143 - prc: 0.2064 - val_loss: 0.4734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5029 - val_prc: 0.1912\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2596 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5678 - prc: 0.2418 - val_loss: 0.4744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5922 - val_prc: 0.2552\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2411 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5966 - prc: 0.2793 - val_loss: 0.4760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6170 - val_prc: 0.2732\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2201 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6078 - prc: 0.2797 - val_loss: 0.4783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6306 - val_prc: 0.2720\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1964 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6412 - prc: 0.3359 - val_loss: 0.4814 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6243 - val_prc: 0.2806\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1716 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6517 - prc: 0.3239 - val_loss: 0.4864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6270 - val_prc: 0.2668\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1439 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6518 - prc: 0.3307 - val_loss: 0.4939 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6367 - val_prc: 0.2822\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1135 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6597 - prc: 0.3484 - val_loss: 0.5043 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6408 - val_prc: 0.2841\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0821 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6691 - prc: 0.3455 - val_loss: 0.5201 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6454 - val_prc: 0.2881\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0497 - tp: 1.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 397.0000 - accuracy: 0.8029 - precision: 0.3333 - recall: 0.0025 - auc: 0.6760 - prc: 0.3609 - val_loss: 0.5431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6471 - val_prc: 0.2850\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0217 - tp: 4.0000 - fp: 6.0000 - tn: 1620.0000 - fn: 394.0000 - accuracy: 0.8024 - precision: 0.4000 - recall: 0.0101 - auc: 0.6737 - prc: 0.3508 - val_loss: 0.5748 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6444 - val_prc: 0.2798\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0024 - tp: 23.0000 - fp: 16.0000 - tn: 1610.0000 - fn: 375.0000 - accuracy: 0.8068 - precision: 0.5897 - recall: 0.0578 - auc: 0.6774 - prc: 0.3616 - val_loss: 0.6077 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 83.0000 - val_accuracy: 0.8083 - val_precision: 0.3636 - val_recall: 0.0879 - val_auc: 0.6490 - val_prc: 0.2779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9917 - tp: 92.0000 - fp: 99.0000 - tn: 1527.0000 - fn: 306.0000 - accuracy: 0.7999 - precision: 0.4817 - recall: 0.2312 - auc: 0.6880 - prc: 0.3670 - val_loss: 0.6435 - val_tp: 33.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 58.0000 - val_accuracy: 0.7628 - val_precision: 0.3474 - val_recall: 0.3626 - val_auc: 0.6510 - val_prc: 0.2773\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9891 - tp: 189.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 209.0000 - accuracy: 0.7288 - precision: 0.3573 - recall: 0.4749 - auc: 0.6917 - prc: 0.3690 - val_loss: 0.6638 - val_tp: 48.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 43.0000 - val_accuracy: 0.6798 - val_precision: 0.2874 - val_recall: 0.5275 - val_auc: 0.6518 - val_prc: 0.2803\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9897 - tp: 227.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 171.0000 - accuracy: 0.6793 - precision: 0.3220 - recall: 0.5704 - auc: 0.6901 - prc: 0.3727 - val_loss: 0.6624 - val_tp: 48.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 43.0000 - val_accuracy: 0.6838 - val_precision: 0.2909 - val_recall: 0.5275 - val_auc: 0.6539 - val_prc: 0.2851\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9886 - tp: 203.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 195.0000 - accuracy: 0.7189 - precision: 0.3518 - recall: 0.5101 - auc: 0.6888 - prc: 0.3737 - val_loss: 0.6445 - val_tp: 35.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 56.0000 - val_accuracy: 0.7411 - val_precision: 0.3182 - val_recall: 0.3846 - val_auc: 0.6556 - val_prc: 0.2873\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9870 - tp: 164.0000 - fp: 236.0000 - tn: 1390.0000 - fn: 234.0000 - accuracy: 0.7678 - precision: 0.4100 - recall: 0.4121 - auc: 0.6923 - prc: 0.3791 - val_loss: 0.6374 - val_tp: 31.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 60.0000 - val_accuracy: 0.7549 - val_precision: 0.3263 - val_recall: 0.3407 - val_auc: 0.6534 - val_prc: 0.2875\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9861 - tp: 161.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 237.0000 - accuracy: 0.7609 - precision: 0.3946 - recall: 0.4045 - auc: 0.6927 - prc: 0.3809 - val_loss: 0.6435 - val_tp: 37.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 54.0000 - val_accuracy: 0.7411 - val_precision: 0.3246 - val_recall: 0.4066 - val_auc: 0.6565 - val_prc: 0.2919\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9855 - tp: 181.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 217.0000 - accuracy: 0.7549 - precision: 0.3935 - recall: 0.4548 - auc: 0.6922 - prc: 0.3812 - val_loss: 0.6438 - val_tp: 37.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 54.0000 - val_accuracy: 0.7411 - val_precision: 0.3246 - val_recall: 0.4066 - val_auc: 0.6566 - val_prc: 0.2920\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9847 - tp: 185.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 213.0000 - accuracy: 0.7470 - precision: 0.3822 - recall: 0.4648 - auc: 0.6938 - prc: 0.3831 - val_loss: 0.6474 - val_tp: 42.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 49.0000 - val_accuracy: 0.7312 - val_precision: 0.3256 - val_recall: 0.4615 - val_auc: 0.6587 - val_prc: 0.2949\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9842 - tp: 188.0000 - fp: 309.0000 - tn: 1317.0000 - fn: 210.0000 - accuracy: 0.7436 - precision: 0.3783 - recall: 0.4724 - auc: 0.6934 - prc: 0.3825 - val_loss: 0.6429 - val_tp: 38.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 53.0000 - val_accuracy: 0.7391 - val_precision: 0.3248 - val_recall: 0.4176 - val_auc: 0.6563 - val_prc: 0.2925\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9836 - tp: 176.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 222.0000 - accuracy: 0.7559 - precision: 0.3929 - recall: 0.4422 - auc: 0.6937 - prc: 0.3842 - val_loss: 0.6344 - val_tp: 31.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 60.0000 - val_accuracy: 0.7510 - val_precision: 0.3196 - val_recall: 0.3407 - val_auc: 0.6585 - val_prc: 0.2948\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9831 - tp: 156.0000 - fp: 210.0000 - tn: 1416.0000 - fn: 242.0000 - accuracy: 0.7767 - precision: 0.4262 - recall: 0.3920 - auc: 0.6932 - prc: 0.3839 - val_loss: 0.6280 - val_tp: 28.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 63.0000 - val_accuracy: 0.7747 - val_precision: 0.3544 - val_recall: 0.3077 - val_auc: 0.6586 - val_prc: 0.2952\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9831 - tp: 134.0000 - fp: 167.0000 - tn: 1459.0000 - fn: 264.0000 - accuracy: 0.7871 - precision: 0.4452 - recall: 0.3367 - auc: 0.6941 - prc: 0.3855 - val_loss: 0.6248 - val_tp: 28.0000 - val_fp: 49.0000 - val_tn: 366.0000 - val_fn: 63.0000 - val_accuracy: 0.7787 - val_precision: 0.3636 - val_recall: 0.3077 - val_auc: 0.6576 - val_prc: 0.2951\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9823 - tp: 166.0000 - fp: 234.0000 - tn: 1392.0000 - fn: 232.0000 - accuracy: 0.7698 - precision: 0.4150 - recall: 0.4171 - auc: 0.6922 - prc: 0.3827 - val_loss: 0.6393 - val_tp: 36.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 55.0000 - val_accuracy: 0.7352 - val_precision: 0.3130 - val_recall: 0.3956 - val_auc: 0.6589 - val_prc: 0.2959\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9807 - tp: 201.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 197.0000 - accuracy: 0.7307 - precision: 0.3661 - recall: 0.5050 - auc: 0.6948 - prc: 0.3859 - val_loss: 0.6526 - val_tp: 48.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 43.0000 - val_accuracy: 0.6917 - val_precision: 0.2981 - val_recall: 0.5275 - val_auc: 0.6595 - val_prc: 0.2970\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9805 - tp: 226.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 172.0000 - accuracy: 0.7134 - precision: 0.3565 - recall: 0.5678 - auc: 0.6952 - prc: 0.3877 - val_loss: 0.6518 - val_tp: 48.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 43.0000 - val_accuracy: 0.6937 - val_precision: 0.3000 - val_recall: 0.5275 - val_auc: 0.6587 - val_prc: 0.2972\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9796 - tp: 208.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 190.0000 - accuracy: 0.7199 - precision: 0.3556 - recall: 0.5226 - auc: 0.6955 - prc: 0.3887 - val_loss: 0.6446 - val_tp: 44.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 47.0000 - val_accuracy: 0.7253 - val_precision: 0.3235 - val_recall: 0.4835 - val_auc: 0.6585 - val_prc: 0.2979\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9787 - tp: 185.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 213.0000 - accuracy: 0.7490 - precision: 0.3854 - recall: 0.4648 - auc: 0.6951 - prc: 0.3895 - val_loss: 0.6344 - val_tp: 35.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 56.0000 - val_accuracy: 0.7352 - val_precision: 0.3097 - val_recall: 0.3846 - val_auc: 0.6610 - val_prc: 0.3008\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9782 - tp: 179.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 219.0000 - accuracy: 0.7594 - precision: 0.4004 - recall: 0.4497 - auc: 0.6956 - prc: 0.3907 - val_loss: 0.6351 - val_tp: 36.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 55.0000 - val_accuracy: 0.7372 - val_precision: 0.3158 - val_recall: 0.3956 - val_auc: 0.6625 - val_prc: 0.3028\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9781 - tp: 210.0000 - fp: 364.0000 - tn: 1262.0000 - fn: 188.0000 - accuracy: 0.7273 - precision: 0.3659 - recall: 0.5276 - auc: 0.6933 - prc: 0.3878 - val_loss: 0.6546 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6625 - val_prc: 0.3030\n",
      "Epoch 34/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9770 - tp: 231.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 167.0000 - accuracy: 0.7011 - precision: 0.3453 - recall: 0.5804 - auc: 0.6974 - prc: 0.3932 - val_loss: 0.6493 - val_tp: 48.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 43.0000 - val_accuracy: 0.6937 - val_precision: 0.3000 - val_recall: 0.5275 - val_auc: 0.6627 - val_prc: 0.3026\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9756 - tp: 196.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 202.0000 - accuracy: 0.7376 - precision: 0.3733 - recall: 0.4925 - auc: 0.6974 - prc: 0.3928 - val_loss: 0.6305 - val_tp: 35.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 56.0000 - val_accuracy: 0.7391 - val_precision: 0.3153 - val_recall: 0.3846 - val_auc: 0.6622 - val_prc: 0.3030\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9755 - tp: 175.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 223.0000 - accuracy: 0.7619 - precision: 0.4032 - recall: 0.4397 - auc: 0.6969 - prc: 0.3919 - val_loss: 0.6329 - val_tp: 37.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 54.0000 - val_accuracy: 0.7391 - val_precision: 0.3217 - val_recall: 0.4066 - val_auc: 0.6617 - val_prc: 0.3020\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9758 - tp: 222.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 176.0000 - accuracy: 0.7134 - precision: 0.3546 - recall: 0.5578 - auc: 0.6954 - prc: 0.3850 - val_loss: 0.6560 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6636 - val_prc: 0.3046\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9744 - tp: 234.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 164.0000 - accuracy: 0.6976 - precision: 0.3431 - recall: 0.5879 - auc: 0.6979 - prc: 0.3941 - val_loss: 0.6478 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6636 - val_prc: 0.3053\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9732 - tp: 209.0000 - fp: 360.0000 - tn: 1266.0000 - fn: 189.0000 - accuracy: 0.7288 - precision: 0.3673 - recall: 0.5251 - auc: 0.6980 - prc: 0.3957 - val_loss: 0.6370 - val_tp: 44.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 47.0000 - val_accuracy: 0.7273 - val_precision: 0.3259 - val_recall: 0.4835 - val_auc: 0.6623 - val_prc: 0.3049\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9726 - tp: 193.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 205.0000 - accuracy: 0.7426 - precision: 0.3792 - recall: 0.4849 - auc: 0.6975 - prc: 0.3957 - val_loss: 0.6364 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6627 - val_prc: 0.3055\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9719 - tp: 195.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 203.0000 - accuracy: 0.7386 - precision: 0.3743 - recall: 0.4899 - auc: 0.6987 - prc: 0.3966 - val_loss: 0.6371 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6629 - val_prc: 0.3060\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9715 - tp: 188.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 210.0000 - accuracy: 0.7446 - precision: 0.3798 - recall: 0.4724 - auc: 0.6983 - prc: 0.3977 - val_loss: 0.6323 - val_tp: 43.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 48.0000 - val_accuracy: 0.7372 - val_precision: 0.3359 - val_recall: 0.4725 - val_auc: 0.6634 - val_prc: 0.3063\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9719 - tp: 220.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 178.0000 - accuracy: 0.7100 - precision: 0.3498 - recall: 0.5528 - auc: 0.6964 - prc: 0.3927 - val_loss: 0.6515 - val_tp: 53.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 38.0000 - val_accuracy: 0.6700 - val_precision: 0.2912 - val_recall: 0.5824 - val_auc: 0.6649 - val_prc: 0.3073\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9702 - tp: 216.0000 - fp: 375.0000 - tn: 1251.0000 - fn: 182.0000 - accuracy: 0.7248 - precision: 0.3655 - recall: 0.5427 - auc: 0.6972 - prc: 0.3986 - val_loss: 0.6342 - val_tp: 45.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 46.0000 - val_accuracy: 0.7273 - val_precision: 0.3285 - val_recall: 0.4945 - val_auc: 0.6656 - val_prc: 0.3094\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9692 - tp: 195.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 203.0000 - accuracy: 0.7381 - precision: 0.3736 - recall: 0.4899 - auc: 0.6993 - prc: 0.4013 - val_loss: 0.6357 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6648 - val_prc: 0.3087\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9698 - tp: 222.0000 - fp: 399.0000 - tn: 1227.0000 - fn: 176.0000 - accuracy: 0.7159 - precision: 0.3575 - recall: 0.5578 - auc: 0.6961 - prc: 0.3986 - val_loss: 0.6428 - val_tp: 51.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 40.0000 - val_accuracy: 0.7036 - val_precision: 0.3168 - val_recall: 0.5604 - val_auc: 0.6650 - val_prc: 0.3099\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9680 - tp: 204.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 194.0000 - accuracy: 0.7362 - precision: 0.3750 - recall: 0.5126 - auc: 0.6980 - prc: 0.4018 - val_loss: 0.6283 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6649 - val_prc: 0.3094\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9673 - tp: 205.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 193.0000 - accuracy: 0.7337 - precision: 0.3721 - recall: 0.5151 - auc: 0.6978 - prc: 0.4027 - val_loss: 0.6399 - val_tp: 51.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 40.0000 - val_accuracy: 0.7075 - val_precision: 0.3208 - val_recall: 0.5604 - val_auc: 0.6669 - val_prc: 0.3123\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9673 - tp: 238.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 160.0000 - accuracy: 0.6986 - precision: 0.3459 - recall: 0.5980 - auc: 0.6984 - prc: 0.4001 - val_loss: 0.6472 - val_tp: 51.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 40.0000 - val_accuracy: 0.6700 - val_precision: 0.2865 - val_recall: 0.5604 - val_auc: 0.6653 - val_prc: 0.3107\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9660 - tp: 207.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 191.0000 - accuracy: 0.7302 - precision: 0.3683 - recall: 0.5201 - auc: 0.7001 - prc: 0.4001 - val_loss: 0.6233 - val_tp: 40.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 51.0000 - val_accuracy: 0.7391 - val_precision: 0.3306 - val_recall: 0.4396 - val_auc: 0.6663 - val_prc: 0.3125\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9653 - tp: 187.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 211.0000 - accuracy: 0.7520 - precision: 0.3912 - recall: 0.4698 - auc: 0.7007 - prc: 0.4057 - val_loss: 0.6250 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6661 - val_prc: 0.3125\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9643 - tp: 190.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 208.0000 - accuracy: 0.7500 - precision: 0.3893 - recall: 0.4774 - auc: 0.7005 - prc: 0.4055 - val_loss: 0.6235 - val_tp: 42.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 49.0000 - val_accuracy: 0.7332 - val_precision: 0.3281 - val_recall: 0.4615 - val_auc: 0.6671 - val_prc: 0.3137\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9635 - tp: 200.0000 - fp: 321.0000 - tn: 1305.0000 - fn: 198.0000 - accuracy: 0.7436 - precision: 0.3839 - recall: 0.5025 - auc: 0.7008 - prc: 0.4045 - val_loss: 0.6341 - val_tp: 51.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 40.0000 - val_accuracy: 0.7194 - val_precision: 0.3333 - val_recall: 0.5604 - val_auc: 0.6654 - val_prc: 0.3126\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9626 - tp: 222.0000 - fp: 382.0000 - tn: 1244.0000 - fn: 176.0000 - accuracy: 0.7243 - precision: 0.3675 - recall: 0.5578 - auc: 0.7006 - prc: 0.4067 - val_loss: 0.6382 - val_tp: 51.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 40.0000 - val_accuracy: 0.6996 - val_precision: 0.3129 - val_recall: 0.5604 - val_auc: 0.6661 - val_prc: 0.3138\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9626 - tp: 234.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 164.0000 - accuracy: 0.7026 - precision: 0.3482 - recall: 0.5879 - auc: 0.6993 - prc: 0.4053 - val_loss: 0.6401 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6675 - val_prc: 0.3166\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9616 - tp: 214.0000 - fp: 368.0000 - tn: 1258.0000 - fn: 184.0000 - accuracy: 0.7273 - precision: 0.3677 - recall: 0.5377 - auc: 0.6998 - prc: 0.4054 - val_loss: 0.6254 - val_tp: 44.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 47.0000 - val_accuracy: 0.7154 - val_precision: 0.3121 - val_recall: 0.4835 - val_auc: 0.6677 - val_prc: 0.3175\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9604 - tp: 199.0000 - fp: 331.0000 - tn: 1295.0000 - fn: 199.0000 - accuracy: 0.7381 - precision: 0.3755 - recall: 0.5000 - auc: 0.7010 - prc: 0.4079 - val_loss: 0.6232 - val_tp: 44.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 47.0000 - val_accuracy: 0.7194 - val_precision: 0.3165 - val_recall: 0.4835 - val_auc: 0.6672 - val_prc: 0.3173\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9597 - tp: 183.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 215.0000 - accuracy: 0.7520 - precision: 0.3894 - recall: 0.4598 - auc: 0.7011 - prc: 0.4085 - val_loss: 0.6101 - val_tp: 34.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 57.0000 - val_accuracy: 0.7549 - val_precision: 0.3366 - val_recall: 0.3736 - val_auc: 0.6677 - val_prc: 0.3174\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9600 - tp: 179.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 219.0000 - accuracy: 0.7594 - precision: 0.4004 - recall: 0.4497 - auc: 0.7006 - prc: 0.4068 - val_loss: 0.6164 - val_tp: 41.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 50.0000 - val_accuracy: 0.7411 - val_precision: 0.3361 - val_recall: 0.4505 - val_auc: 0.6681 - val_prc: 0.3188\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9582 - tp: 191.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 207.0000 - accuracy: 0.7515 - precision: 0.3922 - recall: 0.4799 - auc: 0.7011 - prc: 0.4092 - val_loss: 0.6193 - val_tp: 43.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 48.0000 - val_accuracy: 0.7213 - val_precision: 0.3162 - val_recall: 0.4725 - val_auc: 0.6678 - val_prc: 0.3187\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9570 - tp: 204.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 194.0000 - accuracy: 0.7391 - precision: 0.3792 - recall: 0.5126 - auc: 0.7015 - prc: 0.4108 - val_loss: 0.6302 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6684 - val_prc: 0.3192\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9565 - tp: 223.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 175.0000 - accuracy: 0.7125 - precision: 0.3540 - recall: 0.5603 - auc: 0.7013 - prc: 0.4095 - val_loss: 0.6361 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6693 - val_prc: 0.3200\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9555 - tp: 227.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 171.0000 - accuracy: 0.7065 - precision: 0.3492 - recall: 0.5704 - auc: 0.7018 - prc: 0.4109 - val_loss: 0.6347 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6699 - val_prc: 0.3214\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9547 - tp: 230.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 168.0000 - accuracy: 0.7036 - precision: 0.3474 - recall: 0.5779 - auc: 0.7019 - prc: 0.4117 - val_loss: 0.6362 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6688 - val_prc: 0.3196\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9542 - tp: 243.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 155.0000 - accuracy: 0.6892 - precision: 0.3389 - recall: 0.6106 - auc: 0.7025 - prc: 0.4112 - val_loss: 0.6401 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6695 - val_prc: 0.3209\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9528 - tp: 227.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 171.0000 - accuracy: 0.7065 - precision: 0.3492 - recall: 0.5704 - auc: 0.7020 - prc: 0.4128 - val_loss: 0.6251 - val_tp: 50.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 41.0000 - val_accuracy: 0.7115 - val_precision: 0.3226 - val_recall: 0.5495 - val_auc: 0.6693 - val_prc: 0.3225\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9516 - tp: 222.0000 - fp: 385.0000 - tn: 1241.0000 - fn: 176.0000 - accuracy: 0.7228 - precision: 0.3657 - recall: 0.5578 - auc: 0.7030 - prc: 0.4143 - val_loss: 0.6291 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6695 - val_prc: 0.3213\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9511 - tp: 223.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 175.0000 - accuracy: 0.7100 - precision: 0.3512 - recall: 0.5603 - auc: 0.7024 - prc: 0.4148 - val_loss: 0.6240 - val_tp: 50.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 41.0000 - val_accuracy: 0.7075 - val_precision: 0.3185 - val_recall: 0.5495 - val_auc: 0.6702 - val_prc: 0.3254\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9498 - tp: 212.0000 - fp: 351.0000 - tn: 1275.0000 - fn: 186.0000 - accuracy: 0.7347 - precision: 0.3766 - recall: 0.5327 - auc: 0.7035 - prc: 0.4166 - val_loss: 0.6139 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6712 - val_prc: 0.3252\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9493 - tp: 199.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 199.0000 - accuracy: 0.7446 - precision: 0.3849 - recall: 0.5000 - auc: 0.7032 - prc: 0.4161 - val_loss: 0.6107 - val_tp: 44.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 47.0000 - val_accuracy: 0.7332 - val_precision: 0.3333 - val_recall: 0.4835 - val_auc: 0.6700 - val_prc: 0.3235\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9485 - tp: 204.0000 - fp: 328.0000 - tn: 1298.0000 - fn: 194.0000 - accuracy: 0.7421 - precision: 0.3835 - recall: 0.5126 - auc: 0.7028 - prc: 0.4161 - val_loss: 0.6148 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6702 - val_prc: 0.3242\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9481 - tp: 196.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 202.0000 - accuracy: 0.7470 - precision: 0.3874 - recall: 0.4925 - auc: 0.7037 - prc: 0.4158 - val_loss: 0.6096 - val_tp: 44.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 47.0000 - val_accuracy: 0.7292 - val_precision: 0.3284 - val_recall: 0.4835 - val_auc: 0.6718 - val_prc: 0.3268\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9473 - tp: 226.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 172.0000 - accuracy: 0.7115 - precision: 0.3542 - recall: 0.5678 - auc: 0.7032 - prc: 0.4147 - val_loss: 0.6365 - val_tp: 51.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 40.0000 - val_accuracy: 0.6739 - val_precision: 0.2898 - val_recall: 0.5604 - val_auc: 0.6718 - val_prc: 0.3262\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9462 - tp: 234.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 164.0000 - accuracy: 0.6932 - precision: 0.3386 - recall: 0.5879 - auc: 0.7035 - prc: 0.4166 - val_loss: 0.6273 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6724 - val_prc: 0.3286\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9449 - tp: 223.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 175.0000 - accuracy: 0.7115 - precision: 0.3528 - recall: 0.5603 - auc: 0.7041 - prc: 0.4195 - val_loss: 0.6200 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6728 - val_prc: 0.3335\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9442 - tp: 221.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 177.0000 - accuracy: 0.7208 - precision: 0.3629 - recall: 0.5553 - auc: 0.7040 - prc: 0.4219 - val_loss: 0.6211 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6734 - val_prc: 0.3351\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9436 - tp: 226.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 172.0000 - accuracy: 0.7065 - precision: 0.3488 - recall: 0.5678 - auc: 0.7043 - prc: 0.4237 - val_loss: 0.6247 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6738 - val_prc: 0.3358\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9427 - tp: 229.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 169.0000 - accuracy: 0.7060 - precision: 0.3496 - recall: 0.5754 - auc: 0.7051 - prc: 0.4236 - val_loss: 0.6195 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6741 - val_prc: 0.3357\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9418 - tp: 220.0000 - fp: 376.0000 - tn: 1250.0000 - fn: 178.0000 - accuracy: 0.7263 - precision: 0.3691 - recall: 0.5528 - auc: 0.7050 - prc: 0.4225 - val_loss: 0.6086 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6736 - val_prc: 0.3359\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9412 - tp: 204.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 194.0000 - accuracy: 0.7431 - precision: 0.3849 - recall: 0.5126 - auc: 0.7052 - prc: 0.4235 - val_loss: 0.6100 - val_tp: 46.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 45.0000 - val_accuracy: 0.7095 - val_precision: 0.3108 - val_recall: 0.5055 - val_auc: 0.6751 - val_prc: 0.3368\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9394 - tp: 218.0000 - fp: 389.0000 - tn: 1237.0000 - fn: 180.0000 - accuracy: 0.7189 - precision: 0.3591 - recall: 0.5477 - auc: 0.7062 - prc: 0.4241 - val_loss: 0.6250 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6742 - val_prc: 0.3359\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9394 - tp: 237.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 161.0000 - accuracy: 0.6877 - precision: 0.3347 - recall: 0.5955 - auc: 0.7061 - prc: 0.4237 - val_loss: 0.6297 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6747 - val_prc: 0.3386\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9387 - tp: 238.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 160.0000 - accuracy: 0.6818 - precision: 0.3296 - recall: 0.5980 - auc: 0.7059 - prc: 0.4238 - val_loss: 0.6218 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6750 - val_prc: 0.3402\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9375 - tp: 207.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 191.0000 - accuracy: 0.7337 - precision: 0.3730 - recall: 0.5201 - auc: 0.7045 - prc: 0.4264 - val_loss: 0.5925 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6752 - val_prc: 0.3423\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9375 - tp: 181.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 217.0000 - accuracy: 0.7554 - precision: 0.3943 - recall: 0.4548 - auc: 0.7064 - prc: 0.4280 - val_loss: 0.5933 - val_tp: 44.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 47.0000 - val_accuracy: 0.7510 - val_precision: 0.3577 - val_recall: 0.4835 - val_auc: 0.6756 - val_prc: 0.3434\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9351 - tp: 210.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 188.0000 - accuracy: 0.7342 - precision: 0.3750 - recall: 0.5276 - auc: 0.7067 - prc: 0.4256 - val_loss: 0.6129 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6764 - val_prc: 0.3430\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9342 - tp: 222.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 176.0000 - accuracy: 0.7154 - precision: 0.3569 - recall: 0.5578 - auc: 0.7066 - prc: 0.4286 - val_loss: 0.6153 - val_tp: 52.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 39.0000 - val_accuracy: 0.6996 - val_precision: 0.3152 - val_recall: 0.5714 - val_auc: 0.6754 - val_prc: 0.3434\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9340 - tp: 232.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 166.0000 - accuracy: 0.6937 - precision: 0.3382 - recall: 0.5829 - auc: 0.7070 - prc: 0.4303 - val_loss: 0.6241 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6769 - val_prc: 0.3456\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9328 - tp: 229.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 169.0000 - accuracy: 0.7011 - precision: 0.3444 - recall: 0.5754 - auc: 0.7063 - prc: 0.4299 - val_loss: 0.6127 - val_tp: 52.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 39.0000 - val_accuracy: 0.7036 - val_precision: 0.3190 - val_recall: 0.5714 - val_auc: 0.6758 - val_prc: 0.3449\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9317 - tp: 229.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 169.0000 - accuracy: 0.7065 - precision: 0.3502 - recall: 0.5754 - auc: 0.7075 - prc: 0.4293 - val_loss: 0.6174 - val_tp: 52.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 39.0000 - val_accuracy: 0.6917 - val_precision: 0.3077 - val_recall: 0.5714 - val_auc: 0.6773 - val_prc: 0.3456\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9313 - tp: 222.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 176.0000 - accuracy: 0.7154 - precision: 0.3569 - recall: 0.5578 - auc: 0.7074 - prc: 0.4291 - val_loss: 0.6060 - val_tp: 47.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 44.0000 - val_accuracy: 0.7115 - val_precision: 0.3154 - val_recall: 0.5165 - val_auc: 0.6778 - val_prc: 0.3469\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9304 - tp: 221.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 177.0000 - accuracy: 0.7139 - precision: 0.3547 - recall: 0.5553 - auc: 0.7072 - prc: 0.4301 - val_loss: 0.6046 - val_tp: 47.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 44.0000 - val_accuracy: 0.7134 - val_precision: 0.3176 - val_recall: 0.5165 - val_auc: 0.6772 - val_prc: 0.3493\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9312 - tp: 196.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 202.0000 - accuracy: 0.7490 - precision: 0.3904 - recall: 0.4925 - auc: 0.7064 - prc: 0.4303 - val_loss: 0.5809 - val_tp: 41.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 50.0000 - val_accuracy: 0.7569 - val_precision: 0.3596 - val_recall: 0.4505 - val_auc: 0.6782 - val_prc: 0.3603\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9295 - tp: 199.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 199.0000 - accuracy: 0.7485 - precision: 0.3910 - recall: 0.5000 - auc: 0.7080 - prc: 0.4344 - val_loss: 0.5989 - val_tp: 46.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 45.0000 - val_accuracy: 0.7154 - val_precision: 0.3172 - val_recall: 0.5055 - val_auc: 0.6778 - val_prc: 0.3563\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9280 - tp: 217.0000 - fp: 390.0000 - tn: 1236.0000 - fn: 181.0000 - accuracy: 0.7179 - precision: 0.3575 - recall: 0.5452 - auc: 0.7080 - prc: 0.4329 - val_loss: 0.6125 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6781 - val_prc: 0.3497\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9295 - tp: 242.0000 - fp: 499.0000 - tn: 1127.0000 - fn: 156.0000 - accuracy: 0.6764 - precision: 0.3266 - recall: 0.6080 - auc: 0.7078 - prc: 0.4293 - val_loss: 0.6310 - val_tp: 53.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 38.0000 - val_accuracy: 0.6640 - val_precision: 0.2865 - val_recall: 0.5824 - val_auc: 0.6778 - val_prc: 0.3467\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9279 - tp: 235.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 163.0000 - accuracy: 0.6813 - precision: 0.3278 - recall: 0.5905 - auc: 0.7084 - prc: 0.4319 - val_loss: 0.6058 - val_tp: 46.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 45.0000 - val_accuracy: 0.7115 - val_precision: 0.3129 - val_recall: 0.5055 - val_auc: 0.6780 - val_prc: 0.3573\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9260 - tp: 209.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 189.0000 - accuracy: 0.7337 - precision: 0.3739 - recall: 0.5251 - auc: 0.7093 - prc: 0.4329 - val_loss: 0.5820 - val_tp: 42.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 49.0000 - val_accuracy: 0.7490 - val_precision: 0.3500 - val_recall: 0.4615 - val_auc: 0.6784 - val_prc: 0.3601\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9271 - tp: 193.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 205.0000 - accuracy: 0.7589 - precision: 0.4055 - recall: 0.4849 - auc: 0.7095 - prc: 0.4329 - val_loss: 0.5891 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6789 - val_prc: 0.3622\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9253 - tp: 226.0000 - fp: 429.0000 - tn: 1197.0000 - fn: 172.0000 - accuracy: 0.7031 - precision: 0.3450 - recall: 0.5678 - auc: 0.7089 - prc: 0.4333 - val_loss: 0.6249 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6782 - val_prc: 0.3581\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9255 - tp: 230.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 168.0000 - accuracy: 0.6902 - precision: 0.3338 - recall: 0.5779 - auc: 0.7090 - prc: 0.4317 - val_loss: 0.6065 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6784 - val_prc: 0.3635\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9231 - tp: 212.0000 - fp: 379.0000 - tn: 1247.0000 - fn: 186.0000 - accuracy: 0.7208 - precision: 0.3587 - recall: 0.5327 - auc: 0.7108 - prc: 0.4348 - val_loss: 0.5875 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6784 - val_prc: 0.3658\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9229 - tp: 211.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 187.0000 - accuracy: 0.7238 - precision: 0.3619 - recall: 0.5302 - auc: 0.7099 - prc: 0.4346 - val_loss: 0.6021 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6785 - val_prc: 0.3670\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9223 - tp: 218.0000 - fp: 395.0000 - tn: 1231.0000 - fn: 180.0000 - accuracy: 0.7159 - precision: 0.3556 - recall: 0.5477 - auc: 0.7103 - prc: 0.4358 - val_loss: 0.6006 - val_tp: 47.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 44.0000 - val_accuracy: 0.7115 - val_precision: 0.3154 - val_recall: 0.5165 - val_auc: 0.6794 - val_prc: 0.3688\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9218 - tp: 222.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 176.0000 - accuracy: 0.7060 - precision: 0.3463 - recall: 0.5578 - auc: 0.7102 - prc: 0.4369 - val_loss: 0.6046 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6784 - val_prc: 0.3702\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9212 - tp: 223.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 175.0000 - accuracy: 0.7031 - precision: 0.3436 - recall: 0.5603 - auc: 0.7099 - prc: 0.4379 - val_loss: 0.6069 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6785 - val_prc: 0.3691\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9215 - tp: 235.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 163.0000 - accuracy: 0.6877 - precision: 0.3338 - recall: 0.5905 - auc: 0.7101 - prc: 0.4388 - val_loss: 0.6194 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6783 - val_prc: 0.3689\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9212 - tp: 220.0000 - fp: 413.0000 - tn: 1213.0000 - fn: 178.0000 - accuracy: 0.7080 - precision: 0.3476 - recall: 0.5528 - auc: 0.7087 - prc: 0.4353 - val_loss: 0.5928 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6782 - val_prc: 0.3723\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9197 - tp: 223.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 175.0000 - accuracy: 0.7100 - precision: 0.3512 - recall: 0.5603 - auc: 0.7104 - prc: 0.4375 - val_loss: 0.6095 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6777 - val_prc: 0.3680\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9193 - tp: 230.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 168.0000 - accuracy: 0.6887 - precision: 0.3324 - recall: 0.5779 - auc: 0.7120 - prc: 0.4377 - val_loss: 0.6114 - val_tp: 51.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 40.0000 - val_accuracy: 0.6957 - val_precision: 0.3091 - val_recall: 0.5604 - val_auc: 0.6784 - val_prc: 0.3703\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9183 - tp: 222.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 176.0000 - accuracy: 0.7110 - precision: 0.3518 - recall: 0.5578 - auc: 0.7107 - prc: 0.4401 - val_loss: 0.5887 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6792 - val_prc: 0.3731\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9175 - tp: 218.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 180.0000 - accuracy: 0.7100 - precision: 0.3488 - recall: 0.5477 - auc: 0.7116 - prc: 0.4417 - val_loss: 0.6053 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6793 - val_prc: 0.3767\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9173 - tp: 221.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 177.0000 - accuracy: 0.7060 - precision: 0.3459 - recall: 0.5553 - auc: 0.7118 - prc: 0.4416 - val_loss: 0.5979 - val_tp: 48.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 43.0000 - val_accuracy: 0.7154 - val_precision: 0.3221 - val_recall: 0.5275 - val_auc: 0.6789 - val_prc: 0.3750\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9163 - tp: 218.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 180.0000 - accuracy: 0.7095 - precision: 0.3482 - recall: 0.5477 - auc: 0.7129 - prc: 0.4426 - val_loss: 0.5972 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6784 - val_prc: 0.3766\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9158 - tp: 215.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 183.0000 - accuracy: 0.7189 - precision: 0.3577 - recall: 0.5402 - auc: 0.7127 - prc: 0.4429 - val_loss: 0.5874 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6792 - val_prc: 0.3789\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9153 - tp: 217.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 181.0000 - accuracy: 0.7041 - precision: 0.3417 - recall: 0.5452 - auc: 0.7129 - prc: 0.4454 - val_loss: 0.6084 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6793 - val_prc: 0.3809\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9150 - tp: 222.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 176.0000 - accuracy: 0.6996 - precision: 0.3394 - recall: 0.5578 - auc: 0.7137 - prc: 0.4456 - val_loss: 0.5877 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6808 - val_prc: 0.3894\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9149 - tp: 207.0000 - fp: 344.0000 - tn: 1282.0000 - fn: 191.0000 - accuracy: 0.7357 - precision: 0.3757 - recall: 0.5201 - auc: 0.7135 - prc: 0.4476 - val_loss: 0.5803 - val_tp: 46.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 45.0000 - val_accuracy: 0.7332 - val_precision: 0.3382 - val_recall: 0.5055 - val_auc: 0.6804 - val_prc: 0.3849\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9135 - tp: 214.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 184.0000 - accuracy: 0.7194 - precision: 0.3579 - recall: 0.5377 - auc: 0.7142 - prc: 0.4460 - val_loss: 0.6006 - val_tp: 48.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 43.0000 - val_accuracy: 0.7036 - val_precision: 0.3097 - val_recall: 0.5275 - val_auc: 0.6791 - val_prc: 0.3826\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9132 - tp: 225.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 173.0000 - accuracy: 0.7031 - precision: 0.3446 - recall: 0.5653 - auc: 0.7149 - prc: 0.4469 - val_loss: 0.5995 - val_tp: 48.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 43.0000 - val_accuracy: 0.7036 - val_precision: 0.3097 - val_recall: 0.5275 - val_auc: 0.6794 - val_prc: 0.3815\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9126 - tp: 214.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 184.0000 - accuracy: 0.7213 - precision: 0.3603 - recall: 0.5377 - auc: 0.7148 - prc: 0.4483 - val_loss: 0.5844 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6810 - val_prc: 0.3898\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9121 - tp: 215.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 183.0000 - accuracy: 0.7233 - precision: 0.3632 - recall: 0.5402 - auc: 0.7153 - prc: 0.4502 - val_loss: 0.5918 - val_tp: 47.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 44.0000 - val_accuracy: 0.7115 - val_precision: 0.3154 - val_recall: 0.5165 - val_auc: 0.6814 - val_prc: 0.3952\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9125 - tp: 224.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 174.0000 - accuracy: 0.7011 - precision: 0.3420 - recall: 0.5628 - auc: 0.7156 - prc: 0.4497 - val_loss: 0.6101 - val_tp: 50.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 41.0000 - val_accuracy: 0.6798 - val_precision: 0.2924 - val_recall: 0.5495 - val_auc: 0.6806 - val_prc: 0.3869\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9127 - tp: 232.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 166.0000 - accuracy: 0.6922 - precision: 0.3367 - recall: 0.5829 - auc: 0.7158 - prc: 0.4489 - val_loss: 0.5995 - val_tp: 48.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 43.0000 - val_accuracy: 0.7055 - val_precision: 0.3117 - val_recall: 0.5275 - val_auc: 0.6809 - val_prc: 0.3861\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9114 - tp: 216.0000 - fp: 368.0000 - tn: 1258.0000 - fn: 182.0000 - accuracy: 0.7283 - precision: 0.3699 - recall: 0.5427 - auc: 0.7154 - prc: 0.4507 - val_loss: 0.5765 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6815 - val_prc: 0.3930\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9107 - tp: 207.0000 - fp: 341.0000 - tn: 1285.0000 - fn: 191.0000 - accuracy: 0.7372 - precision: 0.3777 - recall: 0.5201 - auc: 0.7163 - prc: 0.4526 - val_loss: 0.5840 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6814 - val_prc: 0.3899\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9099 - tp: 214.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 184.0000 - accuracy: 0.7268 - precision: 0.3671 - recall: 0.5377 - auc: 0.7165 - prc: 0.4534 - val_loss: 0.5824 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6817 - val_prc: 0.3920\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9108 - tp: 202.0000 - fp: 332.0000 - tn: 1294.0000 - fn: 196.0000 - accuracy: 0.7391 - precision: 0.3783 - recall: 0.5075 - auc: 0.7159 - prc: 0.4533 - val_loss: 0.5752 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6824 - val_prc: 0.3929\n",
      "Epoch 129/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9093 - tp: 211.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 187.0000 - accuracy: 0.7347 - precision: 0.3761 - recall: 0.5302 - auc: 0.7170 - prc: 0.4542 - val_loss: 0.5843 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6821 - val_prc: 0.3942\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9091 - tp: 217.0000 - fp: 385.0000 - tn: 1241.0000 - fn: 181.0000 - accuracy: 0.7204 - precision: 0.3605 - recall: 0.5452 - auc: 0.7165 - prc: 0.4547 - val_loss: 0.5895 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6835 - val_prc: 0.4020\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9100 - tp: 226.0000 - fp: 429.0000 - tn: 1197.0000 - fn: 172.0000 - accuracy: 0.7031 - precision: 0.3450 - recall: 0.5678 - auc: 0.7160 - prc: 0.4546 - val_loss: 0.5896 - val_tp: 47.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.3133 - val_recall: 0.5165 - val_auc: 0.6835 - val_prc: 0.4037\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9101 - tp: 199.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 199.0000 - accuracy: 0.7441 - precision: 0.3842 - recall: 0.5000 - auc: 0.7158 - prc: 0.4563 - val_loss: 0.5584 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6840 - val_prc: 0.4047\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9075 - tp: 215.0000 - fp: 350.0000 - tn: 1276.0000 - fn: 183.0000 - accuracy: 0.7367 - precision: 0.3805 - recall: 0.5402 - auc: 0.7181 - prc: 0.4585 - val_loss: 0.5985 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6830 - val_prc: 0.3987\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9079 - tp: 218.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 180.0000 - accuracy: 0.7144 - precision: 0.3539 - recall: 0.5477 - auc: 0.7174 - prc: 0.4567 - val_loss: 0.5773 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6846 - val_prc: 0.4055\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9071 - tp: 218.0000 - fp: 385.0000 - tn: 1241.0000 - fn: 180.0000 - accuracy: 0.7208 - precision: 0.3615 - recall: 0.5477 - auc: 0.7180 - prc: 0.4608 - val_loss: 0.5801 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6846 - val_prc: 0.4065\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9064 - tp: 212.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 186.0000 - accuracy: 0.7376 - precision: 0.3806 - recall: 0.5327 - auc: 0.7191 - prc: 0.4630 - val_loss: 0.5672 - val_tp: 45.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 46.0000 - val_accuracy: 0.7431 - val_precision: 0.3488 - val_recall: 0.4945 - val_auc: 0.6854 - val_prc: 0.4079\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9076 - tp: 213.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 185.0000 - accuracy: 0.7381 - precision: 0.3817 - recall: 0.5352 - auc: 0.7171 - prc: 0.4610 - val_loss: 0.5883 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6835 - val_prc: 0.4042\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9064 - tp: 221.0000 - fp: 414.0000 - tn: 1212.0000 - fn: 177.0000 - accuracy: 0.7080 - precision: 0.3480 - recall: 0.5553 - auc: 0.7177 - prc: 0.4602 - val_loss: 0.5873 - val_tp: 46.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 45.0000 - val_accuracy: 0.7115 - val_precision: 0.3129 - val_recall: 0.5055 - val_auc: 0.6837 - val_prc: 0.4037\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9061 - tp: 223.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 175.0000 - accuracy: 0.7075 - precision: 0.3484 - recall: 0.5603 - auc: 0.7185 - prc: 0.4607 - val_loss: 0.5925 - val_tp: 48.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 43.0000 - val_accuracy: 0.7055 - val_precision: 0.3117 - val_recall: 0.5275 - val_auc: 0.6832 - val_prc: 0.4025\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9059 - tp: 223.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 175.0000 - accuracy: 0.7115 - precision: 0.3528 - recall: 0.5603 - auc: 0.7183 - prc: 0.4614 - val_loss: 0.5788 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6849 - val_prc: 0.4072\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9054 - tp: 212.0000 - fp: 356.0000 - tn: 1270.0000 - fn: 186.0000 - accuracy: 0.7322 - precision: 0.3732 - recall: 0.5327 - auc: 0.7190 - prc: 0.4624 - val_loss: 0.5713 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6853 - val_prc: 0.4051\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9051 - tp: 213.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 185.0000 - accuracy: 0.7376 - precision: 0.3810 - recall: 0.5352 - auc: 0.7190 - prc: 0.4627 - val_loss: 0.5800 - val_tp: 45.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 46.0000 - val_accuracy: 0.7213 - val_precision: 0.3214 - val_recall: 0.4945 - val_auc: 0.6846 - val_prc: 0.4032\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9049 - tp: 222.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 176.0000 - accuracy: 0.7134 - precision: 0.3546 - recall: 0.5578 - auc: 0.7193 - prc: 0.4623 - val_loss: 0.5862 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6843 - val_prc: 0.4044\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9043 - tp: 215.0000 - fp: 374.0000 - tn: 1252.0000 - fn: 183.0000 - accuracy: 0.7248 - precision: 0.3650 - recall: 0.5402 - auc: 0.7195 - prc: 0.4639 - val_loss: 0.5716 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6853 - val_prc: 0.4080\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9053 - tp: 205.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 193.0000 - accuracy: 0.7421 - precision: 0.3839 - recall: 0.5151 - auc: 0.7193 - prc: 0.4643 - val_loss: 0.5724 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6850 - val_prc: 0.4099\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9037 - tp: 223.0000 - fp: 393.0000 - tn: 1233.0000 - fn: 175.0000 - accuracy: 0.7194 - precision: 0.3620 - recall: 0.5603 - auc: 0.7200 - prc: 0.4643 - val_loss: 0.6021 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6837 - val_prc: 0.4019\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9050 - tp: 235.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 163.0000 - accuracy: 0.7016 - precision: 0.3476 - recall: 0.5905 - auc: 0.7197 - prc: 0.4645 - val_loss: 0.5973 - val_tp: 49.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 42.0000 - val_accuracy: 0.6877 - val_precision: 0.2970 - val_recall: 0.5385 - val_auc: 0.6851 - val_prc: 0.4101\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9035 - tp: 222.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 176.0000 - accuracy: 0.7120 - precision: 0.3529 - recall: 0.5578 - auc: 0.7199 - prc: 0.4673 - val_loss: 0.5726 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6867 - val_prc: 0.4138\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9044 - tp: 208.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 190.0000 - accuracy: 0.7436 - precision: 0.3873 - recall: 0.5226 - auc: 0.7201 - prc: 0.4667 - val_loss: 0.5727 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6855 - val_prc: 0.4106\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9031 - tp: 220.0000 - fp: 391.0000 - tn: 1235.0000 - fn: 178.0000 - accuracy: 0.7189 - precision: 0.3601 - recall: 0.5528 - auc: 0.7204 - prc: 0.4656 - val_loss: 0.5926 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6841 - val_prc: 0.4065\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9035 - tp: 223.0000 - fp: 412.0000 - tn: 1214.0000 - fn: 175.0000 - accuracy: 0.7100 - precision: 0.3512 - recall: 0.5603 - auc: 0.7198 - prc: 0.4651 - val_loss: 0.5802 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6853 - val_prc: 0.4103\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9030 - tp: 218.0000 - fp: 373.0000 - tn: 1253.0000 - fn: 180.0000 - accuracy: 0.7268 - precision: 0.3689 - recall: 0.5477 - auc: 0.7202 - prc: 0.4680 - val_loss: 0.5814 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6867 - val_prc: 0.4155\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9056 - tp: 242.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 156.0000 - accuracy: 0.6952 - precision: 0.3442 - recall: 0.6080 - auc: 0.7205 - prc: 0.4612 - val_loss: 0.6095 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6846 - val_prc: 0.4061\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9046 - tp: 221.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 177.0000 - accuracy: 0.7288 - precision: 0.3727 - recall: 0.5553 - auc: 0.7190 - prc: 0.4629 - val_loss: 0.5685 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6867 - val_prc: 0.4098\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9018 - tp: 220.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 178.0000 - accuracy: 0.7297 - precision: 0.3735 - recall: 0.5528 - auc: 0.7213 - prc: 0.4694 - val_loss: 0.5886 - val_tp: 46.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 45.0000 - val_accuracy: 0.7075 - val_precision: 0.3087 - val_recall: 0.5055 - val_auc: 0.6854 - val_prc: 0.4112\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9031 - tp: 229.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 169.0000 - accuracy: 0.7075 - precision: 0.3512 - recall: 0.5754 - auc: 0.7207 - prc: 0.4666 - val_loss: 0.5817 - val_tp: 46.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 45.0000 - val_accuracy: 0.7154 - val_precision: 0.3172 - val_recall: 0.5055 - val_auc: 0.6864 - val_prc: 0.4108\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9012 - tp: 221.0000 - fp: 366.0000 - tn: 1260.0000 - fn: 177.0000 - accuracy: 0.7317 - precision: 0.3765 - recall: 0.5553 - auc: 0.7221 - prc: 0.4681 - val_loss: 0.5707 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6862 - val_prc: 0.4029\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9034 - tp: 204.0000 - fp: 304.0000 - tn: 1322.0000 - fn: 194.0000 - accuracy: 0.7540 - precision: 0.4016 - recall: 0.5126 - auc: 0.7212 - prc: 0.4643 - val_loss: 0.5715 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6852 - val_prc: 0.3954\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9024 - tp: 229.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 169.0000 - accuracy: 0.7090 - precision: 0.3529 - recall: 0.5754 - auc: 0.7213 - prc: 0.4655 - val_loss: 0.6087 - val_tp: 51.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 40.0000 - val_accuracy: 0.6838 - val_precision: 0.2982 - val_recall: 0.5604 - val_auc: 0.6866 - val_prc: 0.4081\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9037 - tp: 237.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 161.0000 - accuracy: 0.7001 - precision: 0.3470 - recall: 0.5955 - auc: 0.7204 - prc: 0.4665 - val_loss: 0.5886 - val_tp: 47.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 44.0000 - val_accuracy: 0.6957 - val_precision: 0.2994 - val_recall: 0.5165 - val_auc: 0.6881 - val_prc: 0.4237\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9009 - tp: 226.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 172.0000 - accuracy: 0.7154 - precision: 0.3587 - recall: 0.5678 - auc: 0.7217 - prc: 0.4669 - val_loss: 0.5787 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6866 - val_prc: 0.4022\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9007 - tp: 228.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 170.0000 - accuracy: 0.7278 - precision: 0.3744 - recall: 0.5729 - auc: 0.7212 - prc: 0.4648 - val_loss: 0.5810 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6860 - val_prc: 0.4009\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8993 - tp: 222.0000 - fp: 357.0000 - tn: 1269.0000 - fn: 176.0000 - accuracy: 0.7367 - precision: 0.3834 - recall: 0.5578 - auc: 0.7222 - prc: 0.4697 - val_loss: 0.5676 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6883 - val_prc: 0.4159\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8996 - tp: 222.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 176.0000 - accuracy: 0.7307 - precision: 0.3756 - recall: 0.5578 - auc: 0.7217 - prc: 0.4702 - val_loss: 0.5803 - val_tp: 46.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 45.0000 - val_accuracy: 0.7115 - val_precision: 0.3129 - val_recall: 0.5055 - val_auc: 0.6887 - val_prc: 0.4229\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8993 - tp: 221.0000 - fp: 367.0000 - tn: 1259.0000 - fn: 177.0000 - accuracy: 0.7312 - precision: 0.3759 - recall: 0.5553 - auc: 0.7216 - prc: 0.4713 - val_loss: 0.5728 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6882 - val_prc: 0.4177\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8991 - tp: 222.0000 - fp: 373.0000 - tn: 1253.0000 - fn: 176.0000 - accuracy: 0.7288 - precision: 0.3731 - recall: 0.5578 - auc: 0.7221 - prc: 0.4699 - val_loss: 0.5794 - val_tp: 46.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 45.0000 - val_accuracy: 0.7194 - val_precision: 0.3217 - val_recall: 0.5055 - val_auc: 0.6880 - val_prc: 0.4164\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8985 - tp: 223.0000 - fp: 373.0000 - tn: 1253.0000 - fn: 175.0000 - accuracy: 0.7292 - precision: 0.3742 - recall: 0.5603 - auc: 0.7226 - prc: 0.4720 - val_loss: 0.5784 - val_tp: 46.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 45.0000 - val_accuracy: 0.7174 - val_precision: 0.3194 - val_recall: 0.5055 - val_auc: 0.6885 - val_prc: 0.4214\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8983 - tp: 232.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 166.0000 - accuracy: 0.7169 - precision: 0.3631 - recall: 0.5829 - auc: 0.7225 - prc: 0.4722 - val_loss: 0.5852 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6876 - val_prc: 0.4228\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8983 - tp: 233.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 165.0000 - accuracy: 0.7134 - precision: 0.3596 - recall: 0.5854 - auc: 0.7235 - prc: 0.4720 - val_loss: 0.5694 - val_tp: 46.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 45.0000 - val_accuracy: 0.7332 - val_precision: 0.3382 - val_recall: 0.5055 - val_auc: 0.6881 - val_prc: 0.4181\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9010 - tp: 194.0000 - fp: 274.0000 - tn: 1352.0000 - fn: 204.0000 - accuracy: 0.7638 - precision: 0.4145 - recall: 0.4874 - auc: 0.7226 - prc: 0.4717 - val_loss: 0.5438 - val_tp: 40.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 51.0000 - val_accuracy: 0.7589 - val_precision: 0.3604 - val_recall: 0.4396 - val_auc: 0.6906 - val_prc: 0.4178\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8981 - tp: 206.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 192.0000 - accuracy: 0.7594 - precision: 0.4112 - recall: 0.5176 - auc: 0.7236 - prc: 0.4716 - val_loss: 0.5977 - val_tp: 48.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 43.0000 - val_accuracy: 0.7016 - val_precision: 0.3077 - val_recall: 0.5275 - val_auc: 0.6862 - val_prc: 0.4125\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9042 - tp: 254.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 144.0000 - accuracy: 0.6848 - precision: 0.3396 - recall: 0.6382 - auc: 0.7246 - prc: 0.4682 - val_loss: 0.6085 - val_tp: 49.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 42.0000 - val_accuracy: 0.6858 - val_precision: 0.2952 - val_recall: 0.5385 - val_auc: 0.6866 - val_prc: 0.4185\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8988 - tp: 218.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 180.0000 - accuracy: 0.7436 - precision: 0.3914 - recall: 0.5477 - auc: 0.7227 - prc: 0.4730 - val_loss: 0.5448 - val_tp: 40.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 51.0000 - val_accuracy: 0.7569 - val_precision: 0.3571 - val_recall: 0.4396 - val_auc: 0.6921 - val_prc: 0.4348\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8988 - tp: 211.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 187.0000 - accuracy: 0.7510 - precision: 0.3996 - recall: 0.5302 - auc: 0.7239 - prc: 0.4742 - val_loss: 0.5769 - val_tp: 47.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 44.0000 - val_accuracy: 0.7233 - val_precision: 0.3287 - val_recall: 0.5165 - val_auc: 0.6900 - val_prc: 0.4294\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8971 - tp: 222.0000 - fp: 368.0000 - tn: 1258.0000 - fn: 176.0000 - accuracy: 0.7312 - precision: 0.3763 - recall: 0.5578 - auc: 0.7244 - prc: 0.4741 - val_loss: 0.5684 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6907 - val_prc: 0.4274\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8970 - tp: 212.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 186.0000 - accuracy: 0.7470 - precision: 0.3941 - recall: 0.5327 - auc: 0.7240 - prc: 0.4747 - val_loss: 0.5724 - val_tp: 46.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 45.0000 - val_accuracy: 0.7292 - val_precision: 0.3333 - val_recall: 0.5055 - val_auc: 0.6896 - val_prc: 0.4232\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8975 - tp: 216.0000 - fp: 344.0000 - tn: 1282.0000 - fn: 182.0000 - accuracy: 0.7401 - precision: 0.3857 - recall: 0.5427 - auc: 0.7233 - prc: 0.4727 - val_loss: 0.5888 - val_tp: 47.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 44.0000 - val_accuracy: 0.7095 - val_precision: 0.3133 - val_recall: 0.5165 - val_auc: 0.6871 - val_prc: 0.4176\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8972 - tp: 237.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 161.0000 - accuracy: 0.7120 - precision: 0.3596 - recall: 0.5955 - auc: 0.7252 - prc: 0.4753 - val_loss: 0.5974 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6891 - val_prc: 0.4227\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8958 - tp: 232.0000 - fp: 396.0000 - tn: 1230.0000 - fn: 166.0000 - accuracy: 0.7223 - precision: 0.3694 - recall: 0.5829 - auc: 0.7260 - prc: 0.4757 - val_loss: 0.5712 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6920 - val_prc: 0.4305\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8963 - tp: 227.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 171.0000 - accuracy: 0.7317 - precision: 0.3790 - recall: 0.5704 - auc: 0.7251 - prc: 0.4745 - val_loss: 0.5818 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6892 - val_prc: 0.4209\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8967 - tp: 215.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 183.0000 - accuracy: 0.7465 - precision: 0.3945 - recall: 0.5402 - auc: 0.7241 - prc: 0.4748 - val_loss: 0.5681 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6915 - val_prc: 0.4291\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8966 - tp: 231.0000 - fp: 401.0000 - tn: 1225.0000 - fn: 167.0000 - accuracy: 0.7194 - precision: 0.3655 - recall: 0.5804 - auc: 0.7245 - prc: 0.4762 - val_loss: 0.5866 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6905 - val_prc: 0.4305\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8976 - tp: 214.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 184.0000 - accuracy: 0.7465 - precision: 0.3941 - recall: 0.5377 - auc: 0.7230 - prc: 0.4761 - val_loss: 0.5575 - val_tp: 46.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 45.0000 - val_accuracy: 0.7490 - val_precision: 0.3594 - val_recall: 0.5055 - val_auc: 0.6913 - val_prc: 0.4295\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8949 - tp: 222.0000 - fp: 351.0000 - tn: 1275.0000 - fn: 176.0000 - accuracy: 0.7396 - precision: 0.3874 - recall: 0.5578 - auc: 0.7263 - prc: 0.4756 - val_loss: 0.5994 - val_tp: 48.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 43.0000 - val_accuracy: 0.6917 - val_precision: 0.2981 - val_recall: 0.5275 - val_auc: 0.6879 - val_prc: 0.4249\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8969 - tp: 240.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 158.0000 - accuracy: 0.7075 - precision: 0.3561 - recall: 0.6030 - auc: 0.7256 - prc: 0.4769 - val_loss: 0.5857 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6893 - val_prc: 0.4258\n",
      "Epoch 186/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8958 - tp: 233.0000 - fp: 401.0000 - tn: 1225.0000 - fn: 165.0000 - accuracy: 0.7204 - precision: 0.3675 - recall: 0.5854 - auc: 0.7258 - prc: 0.4760 - val_loss: 0.5761 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 44.0000 - val_accuracy: 0.7253 - val_precision: 0.3310 - val_recall: 0.5165 - val_auc: 0.6909 - val_prc: 0.4281\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8958 - tp: 217.0000 - fp: 331.0000 - tn: 1295.0000 - fn: 181.0000 - accuracy: 0.7470 - precision: 0.3960 - recall: 0.5452 - auc: 0.7258 - prc: 0.4761 - val_loss: 0.5591 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6915 - val_prc: 0.4285\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8959 - tp: 213.0000 - fp: 313.0000 - tn: 1313.0000 - fn: 185.0000 - accuracy: 0.7540 - precision: 0.4049 - recall: 0.5352 - auc: 0.7253 - prc: 0.4769 - val_loss: 0.5729 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6925 - val_prc: 0.4314\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8979 - tp: 234.0000 - fp: 403.0000 - tn: 1223.0000 - fn: 164.0000 - accuracy: 0.7199 - precision: 0.3673 - recall: 0.5879 - auc: 0.7231 - prc: 0.4733 - val_loss: 0.5818 - val_tp: 47.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 44.0000 - val_accuracy: 0.7213 - val_precision: 0.3264 - val_recall: 0.5165 - val_auc: 0.6909 - val_prc: 0.4295\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8953 - tp: 222.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 176.0000 - accuracy: 0.7391 - precision: 0.3868 - recall: 0.5578 - auc: 0.7252 - prc: 0.4767 - val_loss: 0.5733 - val_tp: 46.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 45.0000 - val_accuracy: 0.7233 - val_precision: 0.3262 - val_recall: 0.5055 - val_auc: 0.6918 - val_prc: 0.4299\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8961 - tp: 231.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 167.0000 - accuracy: 0.7144 - precision: 0.3598 - recall: 0.5804 - auc: 0.7251 - prc: 0.4763 - val_loss: 0.5933 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6905 - val_prc: 0.4287\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8954 - tp: 235.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 163.0000 - accuracy: 0.7164 - precision: 0.3638 - recall: 0.5905 - auc: 0.7264 - prc: 0.4765 - val_loss: 0.5820 - val_tp: 47.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 44.0000 - val_accuracy: 0.7194 - val_precision: 0.3241 - val_recall: 0.5165 - val_auc: 0.6914 - val_prc: 0.4306\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8945 - tp: 230.0000 - fp: 381.0000 - tn: 1245.0000 - fn: 168.0000 - accuracy: 0.7288 - precision: 0.3764 - recall: 0.5779 - auc: 0.7263 - prc: 0.4772 - val_loss: 0.5769 - val_tp: 47.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 44.0000 - val_accuracy: 0.7233 - val_precision: 0.3287 - val_recall: 0.5165 - val_auc: 0.6912 - val_prc: 0.4320\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8945 - tp: 233.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 165.0000 - accuracy: 0.7238 - precision: 0.3716 - recall: 0.5854 - auc: 0.7265 - prc: 0.4775 - val_loss: 0.5757 - val_tp: 47.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 44.0000 - val_accuracy: 0.7233 - val_precision: 0.3287 - val_recall: 0.5165 - val_auc: 0.6915 - val_prc: 0.4321\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8968 - tp: 201.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 197.0000 - accuracy: 0.7609 - precision: 0.4119 - recall: 0.5050 - auc: 0.7256 - prc: 0.4752 - val_loss: 0.5486 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6917 - val_prc: 0.4301\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8940 - tp: 221.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 177.0000 - accuracy: 0.7465 - precision: 0.3968 - recall: 0.5553 - auc: 0.7269 - prc: 0.4761 - val_loss: 0.5888 - val_tp: 47.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 44.0000 - val_accuracy: 0.7115 - val_precision: 0.3154 - val_recall: 0.5165 - val_auc: 0.6879 - val_prc: 0.4229\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8954 - tp: 233.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 165.0000 - accuracy: 0.7208 - precision: 0.3681 - recall: 0.5854 - auc: 0.7260 - prc: 0.4747 - val_loss: 0.5806 - val_tp: 47.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 44.0000 - val_accuracy: 0.7194 - val_precision: 0.3241 - val_recall: 0.5165 - val_auc: 0.6864 - val_prc: 0.4112\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8953 - tp: 208.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 190.0000 - accuracy: 0.7540 - precision: 0.4031 - recall: 0.5226 - auc: 0.7266 - prc: 0.4749 - val_loss: 0.5540 - val_tp: 43.0000 - val_fp: 79.0000 - val_tn: 336.0000 - val_fn: 48.0000 - val_accuracy: 0.7490 - val_precision: 0.3525 - val_recall: 0.4725 - val_auc: 0.6891 - val_prc: 0.4228\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8966 - tp: 211.0000 - fp: 317.0000 - tn: 1309.0000 - fn: 187.0000 - accuracy: 0.7510 - precision: 0.3996 - recall: 0.5302 - auc: 0.7261 - prc: 0.4721 - val_loss: 0.5814 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6903 - val_prc: 0.4310\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8937 - tp: 231.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 167.0000 - accuracy: 0.7278 - precision: 0.3756 - recall: 0.5804 - auc: 0.7269 - prc: 0.4780 - val_loss: 0.5703 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6927 - val_prc: 0.4344\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8962 - tp: 209.0000 - fp: 302.0000 - tn: 1324.0000 - fn: 189.0000 - accuracy: 0.7574 - precision: 0.4090 - recall: 0.5251 - auc: 0.7259 - prc: 0.4751 - val_loss: 0.5630 - val_tp: 46.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 45.0000 - val_accuracy: 0.7332 - val_precision: 0.3382 - val_recall: 0.5055 - val_auc: 0.6916 - val_prc: 0.4323\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8970 - tp: 234.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 164.0000 - accuracy: 0.7179 - precision: 0.3651 - recall: 0.5879 - auc: 0.7251 - prc: 0.4743 - val_loss: 0.5923 - val_tp: 47.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 44.0000 - val_accuracy: 0.6996 - val_precision: 0.3032 - val_recall: 0.5165 - val_auc: 0.6899 - val_prc: 0.4306\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8937 - tp: 219.0000 - fp: 348.0000 - tn: 1278.0000 - fn: 179.0000 - accuracy: 0.7396 - precision: 0.3862 - recall: 0.5503 - auc: 0.7273 - prc: 0.4770 - val_loss: 0.5502 - val_tp: 43.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 48.0000 - val_accuracy: 0.7530 - val_precision: 0.3583 - val_recall: 0.4725 - val_auc: 0.6914 - val_prc: 0.4308\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8953 - tp: 200.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 198.0000 - accuracy: 0.7628 - precision: 0.4149 - recall: 0.5025 - auc: 0.7270 - prc: 0.4777 - val_loss: 0.5665 - val_tp: 46.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 45.0000 - val_accuracy: 0.7332 - val_precision: 0.3382 - val_recall: 0.5055 - val_auc: 0.6909 - val_prc: 0.4296\n",
      "Epoch 205/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8945 - tp: 232.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 166.0000 - accuracy: 0.7218 - precision: 0.3688 - recall: 0.5829 - auc: 0.7269 - prc: 0.4764 - val_loss: 0.6003 - val_tp: 49.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 42.0000 - val_accuracy: 0.6917 - val_precision: 0.3006 - val_recall: 0.5385 - val_auc: 0.6908 - val_prc: 0.4319\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8942 - tp: 239.0000 - fp: 429.0000 - tn: 1197.0000 - fn: 159.0000 - accuracy: 0.7095 - precision: 0.3578 - recall: 0.6005 - auc: 0.7277 - prc: 0.4785 - val_loss: 0.5747 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 44.0000 - val_accuracy: 0.7253 - val_precision: 0.3310 - val_recall: 0.5165 - val_auc: 0.6905 - val_prc: 0.4309\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8951 - tp: 207.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 191.0000 - accuracy: 0.7540 - precision: 0.4027 - recall: 0.5201 - auc: 0.7268 - prc: 0.4764 - val_loss: 0.5577 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6919 - val_prc: 0.4329\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8964 - tp: 235.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 163.0000 - accuracy: 0.7283 - precision: 0.3778 - recall: 0.5905 - auc: 0.7251 - prc: 0.4726 - val_loss: 0.5882 - val_tp: 48.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 43.0000 - val_accuracy: 0.7115 - val_precision: 0.3179 - val_recall: 0.5275 - val_auc: 0.6921 - val_prc: 0.4360\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8934 - tp: 229.0000 - fp: 380.0000 - tn: 1246.0000 - fn: 169.0000 - accuracy: 0.7288 - precision: 0.3760 - recall: 0.5754 - auc: 0.7275 - prc: 0.4774 - val_loss: 0.5728 - val_tp: 47.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 44.0000 - val_accuracy: 0.7292 - val_precision: 0.3357 - val_recall: 0.5165 - val_auc: 0.6902 - val_prc: 0.4315\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8931 - tp: 222.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 176.0000 - accuracy: 0.7426 - precision: 0.3915 - recall: 0.5578 - auc: 0.7278 - prc: 0.4779 - val_loss: 0.5675 - val_tp: 47.0000 - val_fp: 92.0000 - val_tn: 323.0000 - val_fn: 44.0000 - val_accuracy: 0.7312 - val_precision: 0.3381 - val_recall: 0.5165 - val_auc: 0.6925 - val_prc: 0.4389\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8941 - tp: 232.0000 - fp: 385.0000 - tn: 1241.0000 - fn: 166.0000 - accuracy: 0.7278 - precision: 0.3760 - recall: 0.5829 - auc: 0.7268 - prc: 0.4772 - val_loss: 0.5748 - val_tp: 47.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 44.0000 - val_accuracy: 0.7233 - val_precision: 0.3287 - val_recall: 0.5165 - val_auc: 0.6918 - val_prc: 0.4383\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8929 - tp: 223.0000 - fp: 364.0000 - tn: 1262.0000 - fn: 175.0000 - accuracy: 0.7337 - precision: 0.3799 - recall: 0.5603 - auc: 0.7276 - prc: 0.4780 - val_loss: 0.5616 - val_tp: 45.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 46.0000 - val_accuracy: 0.7352 - val_precision: 0.3383 - val_recall: 0.4945 - val_auc: 0.6902 - val_prc: 0.4327\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8951 - tp: 204.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 194.0000 - accuracy: 0.7624 - precision: 0.4155 - recall: 0.5126 - auc: 0.7269 - prc: 0.4779 - val_loss: 0.5587 - val_tp: 45.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 46.0000 - val_accuracy: 0.7372 - val_precision: 0.3409 - val_recall: 0.4945 - val_auc: 0.6894 - val_prc: 0.4297\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8923 - tp: 222.0000 - fp: 344.0000 - tn: 1282.0000 - fn: 176.0000 - accuracy: 0.7431 - precision: 0.3922 - recall: 0.5578 - auc: 0.7281 - prc: 0.4787 - val_loss: 0.5813 - val_tp: 47.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 44.0000 - val_accuracy: 0.7213 - val_precision: 0.3264 - val_recall: 0.5165 - val_auc: 0.6888 - val_prc: 0.4287\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8930 - tp: 232.0000 - fp: 379.0000 - tn: 1247.0000 - fn: 166.0000 - accuracy: 0.7307 - precision: 0.3797 - recall: 0.5829 - auc: 0.7275 - prc: 0.4782 - val_loss: 0.5816 - val_tp: 47.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 44.0000 - val_accuracy: 0.7213 - val_precision: 0.3264 - val_recall: 0.5165 - val_auc: 0.6889 - val_prc: 0.4295\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8922 - tp: 229.0000 - fp: 371.0000 - tn: 1255.0000 - fn: 169.0000 - accuracy: 0.7332 - precision: 0.3817 - recall: 0.5754 - auc: 0.7283 - prc: 0.4783 - val_loss: 0.5694 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6878 - val_prc: 0.4236\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8931 - tp: 219.0000 - fp: 332.0000 - tn: 1294.0000 - fn: 179.0000 - accuracy: 0.7475 - precision: 0.3975 - recall: 0.5503 - auc: 0.7278 - prc: 0.4758 - val_loss: 0.5713 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6867 - val_prc: 0.4149\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8923 - tp: 225.0000 - fp: 344.0000 - tn: 1282.0000 - fn: 173.0000 - accuracy: 0.7446 - precision: 0.3954 - recall: 0.5653 - auc: 0.7282 - prc: 0.4776 - val_loss: 0.5714 - val_tp: 47.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 44.0000 - val_accuracy: 0.7292 - val_precision: 0.3357 - val_recall: 0.5165 - val_auc: 0.6890 - val_prc: 0.4290\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8922 - tp: 225.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 173.0000 - accuracy: 0.7441 - precision: 0.3947 - recall: 0.5653 - auc: 0.7286 - prc: 0.4788 - val_loss: 0.5715 - val_tp: 47.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 44.0000 - val_accuracy: 0.7292 - val_precision: 0.3357 - val_recall: 0.5165 - val_auc: 0.6894 - val_prc: 0.4288\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8921 - tp: 226.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 172.0000 - accuracy: 0.7441 - precision: 0.3951 - recall: 0.5678 - auc: 0.7286 - prc: 0.4784 - val_loss: 0.5751 - val_tp: 47.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 44.0000 - val_accuracy: 0.7273 - val_precision: 0.3333 - val_recall: 0.5165 - val_auc: 0.6889 - val_prc: 0.4270\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8922 - tp: 232.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 166.0000 - accuracy: 0.7268 - precision: 0.3748 - recall: 0.5829 - auc: 0.7284 - prc: 0.4787 - val_loss: 0.5793 - val_tp: 47.0000 - val_fp: 97.0000 - val_tn: 318.0000 - val_fn: 44.0000 - val_accuracy: 0.7213 - val_precision: 0.3264 - val_recall: 0.5165 - val_auc: 0.6892 - val_prc: 0.4278\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8925 - tp: 218.0000 - fp: 335.0000 - tn: 1291.0000 - fn: 180.0000 - accuracy: 0.7456 - precision: 0.3942 - recall: 0.5477 - auc: 0.7283 - prc: 0.4777 - val_loss: 0.5690 - val_tp: 47.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 44.0000 - val_accuracy: 0.7352 - val_precision: 0.3431 - val_recall: 0.5165 - val_auc: 0.6899 - val_prc: 0.4286\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8921 - tp: 234.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 164.0000 - accuracy: 0.7273 - precision: 0.3762 - recall: 0.5879 - auc: 0.7288 - prc: 0.4780 - val_loss: 0.5911 - val_tp: 48.0000 - val_fp: 103.0000 - val_tn: 312.0000 - val_fn: 43.0000 - val_accuracy: 0.7115 - val_precision: 0.3179 - val_recall: 0.5275 - val_auc: 0.6881 - val_prc: 0.4255\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8928 - tp: 222.0000 - fp: 352.0000 - tn: 1274.0000 - fn: 176.0000 - accuracy: 0.7391 - precision: 0.3868 - recall: 0.5578 - auc: 0.7278 - prc: 0.4773 - val_loss: 0.5664 - val_tp: 46.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 45.0000 - val_accuracy: 0.7372 - val_precision: 0.3433 - val_recall: 0.5055 - val_auc: 0.6895 - val_prc: 0.4304\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8914 - tp: 228.0000 - fp: 369.0000 - tn: 1257.0000 - fn: 170.0000 - accuracy: 0.7337 - precision: 0.3819 - recall: 0.5729 - auc: 0.7287 - prc: 0.4817 - val_loss: 0.5940 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6894 - val_prc: 0.4302\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8930 - tp: 240.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 158.0000 - accuracy: 0.7120 - precision: 0.3609 - recall: 0.6030 - auc: 0.7287 - prc: 0.4789 - val_loss: 0.5921 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6873 - val_prc: 0.4159\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8923 - tp: 231.0000 - fp: 391.0000 - tn: 1235.0000 - fn: 167.0000 - accuracy: 0.7243 - precision: 0.3714 - recall: 0.5804 - auc: 0.7275 - prc: 0.4787 - val_loss: 0.5741 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6879 - val_prc: 0.4203\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8911 - tp: 224.0000 - fp: 334.0000 - tn: 1292.0000 - fn: 174.0000 - accuracy: 0.7490 - precision: 0.4014 - recall: 0.5628 - auc: 0.7292 - prc: 0.4805 - val_loss: 0.5675 - val_tp: 46.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 45.0000 - val_accuracy: 0.7372 - val_precision: 0.3433 - val_recall: 0.5055 - val_auc: 0.6889 - val_prc: 0.4253\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8922 - tp: 212.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 186.0000 - accuracy: 0.7559 - precision: 0.4077 - recall: 0.5327 - auc: 0.7285 - prc: 0.4798 - val_loss: 0.5687 - val_tp: 46.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 45.0000 - val_accuracy: 0.7372 - val_precision: 0.3433 - val_recall: 0.5055 - val_auc: 0.6909 - val_prc: 0.4304\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8917 - tp: 240.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 158.0000 - accuracy: 0.7115 - precision: 0.3604 - recall: 0.6030 - auc: 0.7295 - prc: 0.4813 - val_loss: 0.5987 - val_tp: 49.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 42.0000 - val_accuracy: 0.7016 - val_precision: 0.3101 - val_recall: 0.5385 - val_auc: 0.6893 - val_prc: 0.4264\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8909 - tp: 223.0000 - fp: 358.0000 - tn: 1268.0000 - fn: 175.0000 - accuracy: 0.7367 - precision: 0.3838 - recall: 0.5603 - auc: 0.7295 - prc: 0.4800 - val_loss: 0.5559 - val_tp: 45.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 46.0000 - val_accuracy: 0.7470 - val_precision: 0.3543 - val_recall: 0.4945 - val_auc: 0.6916 - val_prc: 0.4267\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8959 - tp: 200.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 198.0000 - accuracy: 0.7782 - precision: 0.4435 - recall: 0.5025 - auc: 0.7279 - prc: 0.4785 - val_loss: 0.5599 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6890 - val_prc: 0.4164\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8919 - tp: 230.0000 - fp: 363.0000 - tn: 1263.0000 - fn: 168.0000 - accuracy: 0.7376 - precision: 0.3879 - recall: 0.5779 - auc: 0.7295 - prc: 0.4762 - val_loss: 0.5933 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6882 - val_prc: 0.4144\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8925 - tp: 224.0000 - fp: 339.0000 - tn: 1287.0000 - fn: 174.0000 - accuracy: 0.7465 - precision: 0.3979 - recall: 0.5628 - auc: 0.7283 - prc: 0.4778 - val_loss: 0.5665 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6916 - val_prc: 0.4238\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8932 - tp: 235.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 163.0000 - accuracy: 0.7164 - precision: 0.3638 - recall: 0.5905 - auc: 0.7283 - prc: 0.4775 - val_loss: 0.6046 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6883 - val_prc: 0.4217\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8915 - tp: 226.0000 - fp: 378.0000 - tn: 1248.0000 - fn: 172.0000 - accuracy: 0.7283 - precision: 0.3742 - recall: 0.5678 - auc: 0.7279 - prc: 0.4801 - val_loss: 0.5646 - val_tp: 46.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 45.0000 - val_accuracy: 0.7411 - val_precision: 0.3485 - val_recall: 0.5055 - val_auc: 0.6902 - val_prc: 0.4235\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8910 - tp: 215.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 183.0000 - accuracy: 0.7495 - precision: 0.3989 - recall: 0.5402 - auc: 0.7295 - prc: 0.4810 - val_loss: 0.5722 - val_tp: 47.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 44.0000 - val_accuracy: 0.7273 - val_precision: 0.3333 - val_recall: 0.5165 - val_auc: 0.6900 - val_prc: 0.4228\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8919 - tp: 235.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 163.0000 - accuracy: 0.7288 - precision: 0.3784 - recall: 0.5905 - auc: 0.7285 - prc: 0.4783 - val_loss: 0.5851 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6895 - val_prc: 0.4241\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8906 - tp: 225.0000 - fp: 373.0000 - tn: 1253.0000 - fn: 173.0000 - accuracy: 0.7302 - precision: 0.3763 - recall: 0.5653 - auc: 0.7292 - prc: 0.4809 - val_loss: 0.5768 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6920 - val_prc: 0.4311\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8903 - tp: 230.0000 - fp: 379.0000 - tn: 1247.0000 - fn: 168.0000 - accuracy: 0.7297 - precision: 0.3777 - recall: 0.5779 - auc: 0.7295 - prc: 0.4811 - val_loss: 0.5835 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6892 - val_prc: 0.4242\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8901 - tp: 223.0000 - fp: 346.0000 - tn: 1280.0000 - fn: 175.0000 - accuracy: 0.7426 - precision: 0.3919 - recall: 0.5603 - auc: 0.7293 - prc: 0.4824 - val_loss: 0.5623 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6907 - val_prc: 0.4253\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8902 - tp: 218.0000 - fp: 327.0000 - tn: 1299.0000 - fn: 180.0000 - accuracy: 0.7495 - precision: 0.4000 - recall: 0.5477 - auc: 0.7295 - prc: 0.4807 - val_loss: 0.5775 - val_tp: 48.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 43.0000 - val_accuracy: 0.7273 - val_precision: 0.3357 - val_recall: 0.5275 - val_auc: 0.6889 - val_prc: 0.4232\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8896 - tp: 230.0000 - fp: 372.0000 - tn: 1254.0000 - fn: 168.0000 - accuracy: 0.7332 - precision: 0.3821 - recall: 0.5779 - auc: 0.7302 - prc: 0.4805 - val_loss: 0.5785 - val_tp: 48.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 43.0000 - val_accuracy: 0.7273 - val_precision: 0.3357 - val_recall: 0.5275 - val_auc: 0.6901 - val_prc: 0.4276\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8905 - tp: 235.0000 - fp: 404.0000 - tn: 1222.0000 - fn: 163.0000 - accuracy: 0.7199 - precision: 0.3678 - recall: 0.5905 - auc: 0.7302 - prc: 0.4811 - val_loss: 0.5844 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6894 - val_prc: 0.4234\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8902 - tp: 233.0000 - fp: 393.0000 - tn: 1233.0000 - fn: 165.0000 - accuracy: 0.7243 - precision: 0.3722 - recall: 0.5854 - auc: 0.7306 - prc: 0.4806 - val_loss: 0.5841 - val_tp: 48.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 43.0000 - val_accuracy: 0.7194 - val_precision: 0.3265 - val_recall: 0.5275 - val_auc: 0.6890 - val_prc: 0.4209\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8908 - tp: 240.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 158.0000 - accuracy: 0.7149 - precision: 0.3642 - recall: 0.6030 - auc: 0.7307 - prc: 0.4819 - val_loss: 0.5937 - val_tp: 48.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 43.0000 - val_accuracy: 0.6996 - val_precision: 0.3057 - val_recall: 0.5275 - val_auc: 0.6891 - val_prc: 0.4252\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8910 - tp: 228.0000 - fp: 377.0000 - tn: 1249.0000 - fn: 170.0000 - accuracy: 0.7297 - precision: 0.3769 - recall: 0.5729 - auc: 0.7295 - prc: 0.4785 - val_loss: 0.5645 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6931 - val_prc: 0.4380\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8906 - tp: 219.0000 - fp: 337.0000 - tn: 1289.0000 - fn: 179.0000 - accuracy: 0.7451 - precision: 0.3939 - recall: 0.5503 - auc: 0.7294 - prc: 0.4799 - val_loss: 0.5804 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6877 - val_prc: 0.4173\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8911 - tp: 236.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 162.0000 - accuracy: 0.7174 - precision: 0.3653 - recall: 0.5930 - auc: 0.7293 - prc: 0.4801 - val_loss: 0.5865 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6881 - val_prc: 0.4145\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8900 - tp: 222.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 176.0000 - accuracy: 0.7460 - precision: 0.3964 - recall: 0.5578 - auc: 0.7292 - prc: 0.4816 - val_loss: 0.5599 - val_tp: 45.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 46.0000 - val_accuracy: 0.7391 - val_precision: 0.3435 - val_recall: 0.4945 - val_auc: 0.6893 - val_prc: 0.4228\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8904 - tp: 211.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 187.0000 - accuracy: 0.7559 - precision: 0.4073 - recall: 0.5302 - auc: 0.7296 - prc: 0.4822 - val_loss: 0.5675 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6892 - val_prc: 0.4263\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8909 - tp: 231.0000 - fp: 387.0000 - tn: 1239.0000 - fn: 167.0000 - accuracy: 0.7263 - precision: 0.3738 - recall: 0.5804 - auc: 0.7289 - prc: 0.4801 - val_loss: 0.5813 - val_tp: 48.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 43.0000 - val_accuracy: 0.7174 - val_precision: 0.3243 - val_recall: 0.5275 - val_auc: 0.6891 - val_prc: 0.4280\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8908 - tp: 218.0000 - fp: 338.0000 - tn: 1288.0000 - fn: 180.0000 - accuracy: 0.7441 - precision: 0.3921 - recall: 0.5477 - auc: 0.7295 - prc: 0.4805 - val_loss: 0.5675 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6894 - val_prc: 0.4288\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8911 - tp: 240.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 158.0000 - accuracy: 0.7090 - precision: 0.3577 - recall: 0.6030 - auc: 0.7295 - prc: 0.4825 - val_loss: 0.6176 - val_tp: 50.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 41.0000 - val_accuracy: 0.6700 - val_precision: 0.2841 - val_recall: 0.5495 - val_auc: 0.6864 - val_prc: 0.4205\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8936 - tp: 246.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 152.0000 - accuracy: 0.6966 - precision: 0.3475 - recall: 0.6181 - auc: 0.7293 - prc: 0.4821 - val_loss: 0.5790 - val_tp: 48.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 43.0000 - val_accuracy: 0.7213 - val_precision: 0.3288 - val_recall: 0.5275 - val_auc: 0.6876 - val_prc: 0.4190\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8932 - tp: 206.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 192.0000 - accuracy: 0.7633 - precision: 0.4178 - recall: 0.5176 - auc: 0.7279 - prc: 0.4802 - val_loss: 0.5563 - val_tp: 45.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 46.0000 - val_accuracy: 0.7411 - val_precision: 0.3462 - val_recall: 0.4945 - val_auc: 0.6901 - val_prc: 0.4258\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8921 - tp: 233.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 165.0000 - accuracy: 0.7199 - precision: 0.3669 - recall: 0.5854 - auc: 0.7280 - prc: 0.4790 - val_loss: 0.6087 - val_tp: 49.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 42.0000 - val_accuracy: 0.6858 - val_precision: 0.2952 - val_recall: 0.5385 - val_auc: 0.6852 - val_prc: 0.4094\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8895 - tp: 238.0000 - fp: 400.0000 - tn: 1226.0000 - fn: 160.0000 - accuracy: 0.7233 - precision: 0.3730 - recall: 0.5980 - auc: 0.7311 - prc: 0.4801 - val_loss: 0.5715 - val_tp: 46.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 45.0000 - val_accuracy: 0.7312 - val_precision: 0.3358 - val_recall: 0.5055 - val_auc: 0.6863 - val_prc: 0.4105\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8892 - tp: 227.0000 - fp: 355.0000 - tn: 1271.0000 - fn: 171.0000 - accuracy: 0.7401 - precision: 0.3900 - recall: 0.5704 - auc: 0.7304 - prc: 0.4810 - val_loss: 0.5774 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 44.0000 - val_accuracy: 0.7253 - val_precision: 0.3310 - val_recall: 0.5165 - val_auc: 0.6867 - val_prc: 0.4153\n",
      "Epoch 260/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.0526 - tp: 24.0000 - fp: 39.0000 - tn: 114.0000 - fn: 23.0000 - accuracy: 0.6900 - precision: 0.3810 - recall: 0.5106 - auc: 0.6532 - prc: 0.4538Restoring model weights from the end of the best epoch: 210.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8889 - tp: 221.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 177.0000 - accuracy: 0.7446 - precision: 0.3939 - recall: 0.5553 - auc: 0.7303 - prc: 0.4821 - val_loss: 0.5714 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6882 - val_prc: 0.4198\n",
      "Epoch 260: early stopping\n",
      "3/3 [==============================] - 0s 890us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.4630 - tp: 47.0000 - fp: 88.0000 - tn: 1953.0000 - fn: 442.0000 - accuracy: 0.7905 - precision: 0.3481 - recall: 0.0961 - auc: 0.5019 - prc: 0.2343 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5156 - val_prc: 0.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4472 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4929 - prc: 0.1970 - val_loss: 0.4728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4870 - val_prc: 0.1736\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5320 - prc: 0.2166 - val_loss: 0.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4988 - val_prc: 0.1928\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5636 - prc: 0.2449 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5593 - val_prc: 0.2107\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3873 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5867 - prc: 0.2736 - val_loss: 0.4763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5944 - val_prc: 0.2487\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3596 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6411 - prc: 0.3277 - val_loss: 0.4787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5922 - val_prc: 0.2482\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3309 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6509 - prc: 0.3435 - val_loss: 0.4824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6260 - val_prc: 0.2681\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2982 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6510 - prc: 0.3280 - val_loss: 0.4882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6301 - val_prc: 0.2736\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2591 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6710 - prc: 0.3508 - val_loss: 0.4969 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6358 - val_prc: 0.2774\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2196 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6628 - prc: 0.3379 - val_loss: 0.5104 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6411 - val_prc: 0.2744\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1741 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1625.0000 - fn: 398.0000 - accuracy: 0.8029 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6703 - prc: 0.3496 - val_loss: 0.5316 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6480 - val_prc: 0.2756\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1270 - tp: 5.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 393.0000 - accuracy: 0.8039 - precision: 0.5556 - recall: 0.0126 - auc: 0.6748 - prc: 0.3447 - val_loss: 0.5660 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6490 - val_prc: 0.2734\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0858 - tp: 25.0000 - fp: 25.0000 - tn: 1601.0000 - fn: 373.0000 - accuracy: 0.8034 - precision: 0.5000 - recall: 0.0628 - auc: 0.6800 - prc: 0.3484 - val_loss: 0.6137 - val_tp: 9.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 82.0000 - val_accuracy: 0.7984 - val_precision: 0.3103 - val_recall: 0.0989 - val_auc: 0.6503 - val_prc: 0.2764\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0635 - tp: 128.0000 - fp: 159.0000 - tn: 1467.0000 - fn: 270.0000 - accuracy: 0.7880 - precision: 0.4460 - recall: 0.3216 - auc: 0.6847 - prc: 0.3605 - val_loss: 0.6563 - val_tp: 40.0000 - val_fp: 98.0000 - val_tn: 317.0000 - val_fn: 51.0000 - val_accuracy: 0.7055 - val_precision: 0.2899 - val_recall: 0.4396 - val_auc: 0.6517 - val_prc: 0.2788\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0553 - tp: 232.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 166.0000 - accuracy: 0.6680 - precision: 0.3144 - recall: 0.5829 - auc: 0.6880 - prc: 0.3730 - val_loss: 0.6850 - val_tp: 62.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 29.0000 - val_accuracy: 0.5593 - val_precision: 0.2422 - val_recall: 0.6813 - val_auc: 0.6522 - val_prc: 0.2816\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0547 - tp: 292.0000 - fp: 776.0000 - tn: 850.0000 - fn: 106.0000 - accuracy: 0.5642 - precision: 0.2734 - recall: 0.7337 - auc: 0.6894 - prc: 0.3731 - val_loss: 0.6910 - val_tp: 67.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 24.0000 - val_accuracy: 0.5395 - val_precision: 0.2428 - val_recall: 0.7363 - val_auc: 0.6528 - val_prc: 0.2846\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0538 - tp: 287.0000 - fp: 743.0000 - tn: 883.0000 - fn: 111.0000 - accuracy: 0.5781 - precision: 0.2786 - recall: 0.7211 - auc: 0.6903 - prc: 0.3756 - val_loss: 0.6835 - val_tp: 60.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 31.0000 - val_accuracy: 0.5494 - val_precision: 0.2335 - val_recall: 0.6593 - val_auc: 0.6533 - val_prc: 0.2849\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0529 - tp: 288.0000 - fp: 771.0000 - tn: 855.0000 - fn: 110.0000 - accuracy: 0.5647 - precision: 0.2720 - recall: 0.7236 - auc: 0.6907 - prc: 0.3779 - val_loss: 0.6908 - val_tp: 66.0000 - val_fp: 211.0000 - val_tn: 204.0000 - val_fn: 25.0000 - val_accuracy: 0.5336 - val_precision: 0.2383 - val_recall: 0.7253 - val_auc: 0.6536 - val_prc: 0.2866\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0526 - tp: 296.0000 - fp: 801.0000 - tn: 825.0000 - fn: 102.0000 - accuracy: 0.5539 - precision: 0.2698 - recall: 0.7437 - auc: 0.6910 - prc: 0.3771 - val_loss: 0.6910 - val_tp: 66.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 25.0000 - val_accuracy: 0.5316 - val_precision: 0.2374 - val_recall: 0.7253 - val_auc: 0.6531 - val_prc: 0.2858\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0519 - tp: 295.0000 - fp: 792.0000 - tn: 834.0000 - fn: 103.0000 - accuracy: 0.5578 - precision: 0.2714 - recall: 0.7412 - auc: 0.6916 - prc: 0.3781 - val_loss: 0.6895 - val_tp: 65.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 26.0000 - val_accuracy: 0.5296 - val_precision: 0.2347 - val_recall: 0.7143 - val_auc: 0.6568 - val_prc: 0.2898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0515 - tp: 295.0000 - fp: 781.0000 - tn: 845.0000 - fn: 103.0000 - accuracy: 0.5632 - precision: 0.2742 - recall: 0.7412 - auc: 0.6911 - prc: 0.3792 - val_loss: 0.6891 - val_tp: 65.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 26.0000 - val_accuracy: 0.5296 - val_precision: 0.2347 - val_recall: 0.7143 - val_auc: 0.6532 - val_prc: 0.2879\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0507 - tp: 292.0000 - fp: 774.0000 - tn: 852.0000 - fn: 106.0000 - accuracy: 0.5652 - precision: 0.2739 - recall: 0.7337 - auc: 0.6916 - prc: 0.3798 - val_loss: 0.6864 - val_tp: 62.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 29.0000 - val_accuracy: 0.5356 - val_precision: 0.2313 - val_recall: 0.6813 - val_auc: 0.6574 - val_prc: 0.2919\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0502 - tp: 291.0000 - fp: 765.0000 - tn: 861.0000 - fn: 107.0000 - accuracy: 0.5692 - precision: 0.2756 - recall: 0.7312 - auc: 0.6922 - prc: 0.3802 - val_loss: 0.6847 - val_tp: 61.0000 - val_fp: 199.0000 - val_tn: 216.0000 - val_fn: 30.0000 - val_accuracy: 0.5474 - val_precision: 0.2346 - val_recall: 0.6703 - val_auc: 0.6581 - val_prc: 0.2928\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0496 - tp: 276.0000 - fp: 693.0000 - tn: 933.0000 - fn: 122.0000 - accuracy: 0.5973 - precision: 0.2848 - recall: 0.6935 - auc: 0.6932 - prc: 0.3804 - val_loss: 0.6761 - val_tp: 58.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 33.0000 - val_accuracy: 0.5850 - val_precision: 0.2468 - val_recall: 0.6374 - val_auc: 0.6560 - val_prc: 0.2907\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0491 - tp: 259.0000 - fp: 596.0000 - tn: 1030.0000 - fn: 139.0000 - accuracy: 0.6369 - precision: 0.3029 - recall: 0.6508 - auc: 0.6939 - prc: 0.3827 - val_loss: 0.6725 - val_tp: 57.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 34.0000 - val_accuracy: 0.6008 - val_precision: 0.2533 - val_recall: 0.6264 - val_auc: 0.6592 - val_prc: 0.2936\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0484 - tp: 278.0000 - fp: 687.0000 - tn: 939.0000 - fn: 120.0000 - accuracy: 0.6013 - precision: 0.2881 - recall: 0.6985 - auc: 0.6934 - prc: 0.3814 - val_loss: 0.6855 - val_tp: 62.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 29.0000 - val_accuracy: 0.5435 - val_precision: 0.2348 - val_recall: 0.6813 - val_auc: 0.6595 - val_prc: 0.2949\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0477 - tp: 280.0000 - fp: 709.0000 - tn: 917.0000 - fn: 118.0000 - accuracy: 0.5914 - precision: 0.2831 - recall: 0.7035 - auc: 0.6944 - prc: 0.3832 - val_loss: 0.6766 - val_tp: 58.0000 - val_fp: 178.0000 - val_tn: 237.0000 - val_fn: 33.0000 - val_accuracy: 0.5830 - val_precision: 0.2458 - val_recall: 0.6374 - val_auc: 0.6581 - val_prc: 0.2935\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0473 - tp: 265.0000 - fp: 634.0000 - tn: 992.0000 - fn: 133.0000 - accuracy: 0.6210 - precision: 0.2948 - recall: 0.6658 - auc: 0.6938 - prc: 0.3835 - val_loss: 0.6783 - val_tp: 58.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 33.0000 - val_accuracy: 0.5711 - val_precision: 0.2397 - val_recall: 0.6374 - val_auc: 0.6593 - val_prc: 0.2951\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0463 - tp: 278.0000 - fp: 695.0000 - tn: 931.0000 - fn: 120.0000 - accuracy: 0.5973 - precision: 0.2857 - recall: 0.6985 - auc: 0.6944 - prc: 0.3846 - val_loss: 0.6834 - val_tp: 61.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 30.0000 - val_accuracy: 0.5534 - val_precision: 0.2374 - val_recall: 0.6703 - val_auc: 0.6615 - val_prc: 0.2976\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0460 - tp: 289.0000 - fp: 751.0000 - tn: 875.0000 - fn: 109.0000 - accuracy: 0.5751 - precision: 0.2779 - recall: 0.7261 - auc: 0.6951 - prc: 0.3858 - val_loss: 0.6812 - val_tp: 60.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 31.0000 - val_accuracy: 0.5613 - val_precision: 0.2390 - val_recall: 0.6593 - val_auc: 0.6601 - val_prc: 0.2962\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0456 - tp: 261.0000 - fp: 604.0000 - tn: 1022.0000 - fn: 137.0000 - accuracy: 0.6339 - precision: 0.3017 - recall: 0.6558 - auc: 0.6930 - prc: 0.3850 - val_loss: 0.6633 - val_tp: 55.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 36.0000 - val_accuracy: 0.6423 - val_precision: 0.2750 - val_recall: 0.6044 - val_auc: 0.6622 - val_prc: 0.2982\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0450 - tp: 237.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 161.0000 - accuracy: 0.6823 - precision: 0.3296 - recall: 0.5955 - auc: 0.6951 - prc: 0.3875 - val_loss: 0.6614 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6594 - val_prc: 0.2980\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0434 - tp: 261.0000 - fp: 603.0000 - tn: 1023.0000 - fn: 137.0000 - accuracy: 0.6344 - precision: 0.3021 - recall: 0.6558 - auc: 0.6976 - prc: 0.3886 - val_loss: 0.6808 - val_tp: 60.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 31.0000 - val_accuracy: 0.5573 - val_precision: 0.2372 - val_recall: 0.6593 - val_auc: 0.6621 - val_prc: 0.2997\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0433 - tp: 289.0000 - fp: 747.0000 - tn: 879.0000 - fn: 109.0000 - accuracy: 0.5771 - precision: 0.2790 - recall: 0.7261 - auc: 0.6947 - prc: 0.3885 - val_loss: 0.6830 - val_tp: 61.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 30.0000 - val_accuracy: 0.5455 - val_precision: 0.2337 - val_recall: 0.6703 - val_auc: 0.6623 - val_prc: 0.2998\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0425 - tp: 272.0000 - fp: 657.0000 - tn: 969.0000 - fn: 126.0000 - accuracy: 0.6131 - precision: 0.2928 - recall: 0.6834 - auc: 0.6955 - prc: 0.3901 - val_loss: 0.6674 - val_tp: 57.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 34.0000 - val_accuracy: 0.6126 - val_precision: 0.2603 - val_recall: 0.6264 - val_auc: 0.6619 - val_prc: 0.3004\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0426 - tp: 247.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 151.0000 - accuracy: 0.6655 - precision: 0.3195 - recall: 0.6206 - auc: 0.6956 - prc: 0.3890 - val_loss: 0.6610 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6615 - val_prc: 0.3010\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0415 - tp: 251.0000 - fp: 563.0000 - tn: 1063.0000 - fn: 147.0000 - accuracy: 0.6492 - precision: 0.3084 - recall: 0.6307 - auc: 0.6969 - prc: 0.3909 - val_loss: 0.6694 - val_tp: 57.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 34.0000 - val_accuracy: 0.6008 - val_precision: 0.2533 - val_recall: 0.6264 - val_auc: 0.6627 - val_prc: 0.3016\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0406 - tp: 270.0000 - fp: 652.0000 - tn: 974.0000 - fn: 128.0000 - accuracy: 0.6146 - precision: 0.2928 - recall: 0.6784 - auc: 0.6965 - prc: 0.3921 - val_loss: 0.6788 - val_tp: 60.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 31.0000 - val_accuracy: 0.5593 - val_precision: 0.2381 - val_recall: 0.6593 - val_auc: 0.6624 - val_prc: 0.3019\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0401 - tp: 275.0000 - fp: 709.0000 - tn: 917.0000 - fn: 123.0000 - accuracy: 0.5889 - precision: 0.2795 - recall: 0.6910 - auc: 0.6963 - prc: 0.3918 - val_loss: 0.6822 - val_tp: 62.0000 - val_fp: 201.0000 - val_tn: 214.0000 - val_fn: 29.0000 - val_accuracy: 0.5455 - val_precision: 0.2357 - val_recall: 0.6813 - val_auc: 0.6631 - val_prc: 0.3025\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0398 - tp: 289.0000 - fp: 766.0000 - tn: 860.0000 - fn: 109.0000 - accuracy: 0.5677 - precision: 0.2739 - recall: 0.7261 - auc: 0.6966 - prc: 0.3943 - val_loss: 0.6868 - val_tp: 63.0000 - val_fp: 207.0000 - val_tn: 208.0000 - val_fn: 28.0000 - val_accuracy: 0.5356 - val_precision: 0.2333 - val_recall: 0.6923 - val_auc: 0.6634 - val_prc: 0.3030\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0392 - tp: 276.0000 - fp: 689.0000 - tn: 937.0000 - fn: 122.0000 - accuracy: 0.5993 - precision: 0.2860 - recall: 0.6935 - auc: 0.6962 - prc: 0.3918 - val_loss: 0.6700 - val_tp: 57.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 34.0000 - val_accuracy: 0.5909 - val_precision: 0.2478 - val_recall: 0.6264 - val_auc: 0.6639 - val_prc: 0.3039\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0379 - tp: 269.0000 - fp: 642.0000 - tn: 984.0000 - fn: 129.0000 - accuracy: 0.6191 - precision: 0.2953 - recall: 0.6759 - auc: 0.6975 - prc: 0.3937 - val_loss: 0.6751 - val_tp: 60.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 31.0000 - val_accuracy: 0.5731 - val_precision: 0.2449 - val_recall: 0.6593 - val_auc: 0.6632 - val_prc: 0.3050\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0377 - tp: 275.0000 - fp: 713.0000 - tn: 913.0000 - fn: 123.0000 - accuracy: 0.5870 - precision: 0.2783 - recall: 0.6910 - auc: 0.6966 - prc: 0.3930 - val_loss: 0.6800 - val_tp: 61.0000 - val_fp: 195.0000 - val_tn: 220.0000 - val_fn: 30.0000 - val_accuracy: 0.5553 - val_precision: 0.2383 - val_recall: 0.6703 - val_auc: 0.6645 - val_prc: 0.3046\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0367 - tp: 285.0000 - fp: 741.0000 - tn: 885.0000 - fn: 113.0000 - accuracy: 0.5781 - precision: 0.2778 - recall: 0.7161 - auc: 0.6983 - prc: 0.3950 - val_loss: 0.6887 - val_tp: 64.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 27.0000 - val_accuracy: 0.5316 - val_precision: 0.2336 - val_recall: 0.7033 - val_auc: 0.6646 - val_prc: 0.3058\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0364 - tp: 293.0000 - fp: 790.0000 - tn: 836.0000 - fn: 105.0000 - accuracy: 0.5578 - precision: 0.2705 - recall: 0.7362 - auc: 0.6974 - prc: 0.3960 - val_loss: 0.6798 - val_tp: 62.0000 - val_fp: 195.0000 - val_tn: 220.0000 - val_fn: 29.0000 - val_accuracy: 0.5573 - val_precision: 0.2412 - val_recall: 0.6813 - val_auc: 0.6648 - val_prc: 0.3059\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0348 - tp: 269.0000 - fp: 646.0000 - tn: 980.0000 - fn: 129.0000 - accuracy: 0.6171 - precision: 0.2940 - recall: 0.6759 - auc: 0.6991 - prc: 0.3985 - val_loss: 0.6654 - val_tp: 57.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 34.0000 - val_accuracy: 0.6146 - val_precision: 0.2615 - val_recall: 0.6264 - val_auc: 0.6641 - val_prc: 0.3061\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0344 - tp: 273.0000 - fp: 669.0000 - tn: 957.0000 - fn: 125.0000 - accuracy: 0.6077 - precision: 0.2898 - recall: 0.6859 - auc: 0.6990 - prc: 0.3967 - val_loss: 0.6797 - val_tp: 62.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 29.0000 - val_accuracy: 0.5553 - val_precision: 0.2403 - val_recall: 0.6813 - val_auc: 0.6652 - val_prc: 0.3075\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0342 - tp: 283.0000 - fp: 743.0000 - tn: 883.0000 - fn: 115.0000 - accuracy: 0.5761 - precision: 0.2758 - recall: 0.7111 - auc: 0.6976 - prc: 0.3962 - val_loss: 0.6761 - val_tp: 60.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 31.0000 - val_accuracy: 0.5652 - val_precision: 0.2410 - val_recall: 0.6593 - val_auc: 0.6661 - val_prc: 0.3089\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0328 - tp: 264.0000 - fp: 624.0000 - tn: 1002.0000 - fn: 134.0000 - accuracy: 0.6255 - precision: 0.2973 - recall: 0.6633 - auc: 0.6985 - prc: 0.3990 - val_loss: 0.6608 - val_tp: 55.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 36.0000 - val_accuracy: 0.6304 - val_precision: 0.2670 - val_recall: 0.6044 - val_auc: 0.6651 - val_prc: 0.3103\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0325 - tp: 254.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 144.0000 - accuracy: 0.6542 - precision: 0.3136 - recall: 0.6382 - auc: 0.6987 - prc: 0.4008 - val_loss: 0.6613 - val_tp: 56.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 35.0000 - val_accuracy: 0.6245 - val_precision: 0.2654 - val_recall: 0.6154 - val_auc: 0.6668 - val_prc: 0.3121\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0326 - tp: 272.0000 - fp: 672.0000 - tn: 954.0000 - fn: 126.0000 - accuracy: 0.6057 - precision: 0.2881 - recall: 0.6834 - auc: 0.6953 - prc: 0.3971 - val_loss: 0.6776 - val_tp: 61.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 30.0000 - val_accuracy: 0.5573 - val_precision: 0.2392 - val_recall: 0.6703 - val_auc: 0.6660 - val_prc: 0.3111\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0312 - tp: 267.0000 - fp: 633.0000 - tn: 993.0000 - fn: 131.0000 - accuracy: 0.6225 - precision: 0.2967 - recall: 0.6709 - auc: 0.6975 - prc: 0.4012 - val_loss: 0.6597 - val_tp: 56.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 35.0000 - val_accuracy: 0.6285 - val_precision: 0.2679 - val_recall: 0.6154 - val_auc: 0.6671 - val_prc: 0.3127\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0306 - tp: 245.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 153.0000 - accuracy: 0.6724 - precision: 0.3245 - recall: 0.6156 - auc: 0.6990 - prc: 0.4012 - val_loss: 0.6491 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6672 - val_prc: 0.3139\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0301 - tp: 237.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 161.0000 - accuracy: 0.6971 - precision: 0.3440 - recall: 0.5955 - auc: 0.6987 - prc: 0.4044 - val_loss: 0.6491 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6673 - val_prc: 0.3153\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0289 - tp: 252.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 146.0000 - accuracy: 0.6611 - precision: 0.3182 - recall: 0.6332 - auc: 0.6991 - prc: 0.4021 - val_loss: 0.6637 - val_tp: 57.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 34.0000 - val_accuracy: 0.6067 - val_precision: 0.2568 - val_recall: 0.6264 - val_auc: 0.6682 - val_prc: 0.3134\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0277 - tp: 263.0000 - fp: 597.0000 - tn: 1029.0000 - fn: 135.0000 - accuracy: 0.6383 - precision: 0.3058 - recall: 0.6608 - auc: 0.7000 - prc: 0.4046 - val_loss: 0.6648 - val_tp: 57.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 34.0000 - val_accuracy: 0.6028 - val_precision: 0.2545 - val_recall: 0.6264 - val_auc: 0.6673 - val_prc: 0.3136\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0271 - tp: 265.0000 - fp: 615.0000 - tn: 1011.0000 - fn: 133.0000 - accuracy: 0.6304 - precision: 0.3011 - recall: 0.6658 - auc: 0.6992 - prc: 0.4050 - val_loss: 0.6630 - val_tp: 57.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 34.0000 - val_accuracy: 0.6028 - val_precision: 0.2545 - val_recall: 0.6264 - val_auc: 0.6679 - val_prc: 0.3159\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0261 - tp: 268.0000 - fp: 643.0000 - tn: 983.0000 - fn: 130.0000 - accuracy: 0.6181 - precision: 0.2942 - recall: 0.6734 - auc: 0.7008 - prc: 0.4072 - val_loss: 0.6671 - val_tp: 59.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 32.0000 - val_accuracy: 0.5909 - val_precision: 0.2521 - val_recall: 0.6484 - val_auc: 0.6683 - val_prc: 0.3179\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0259 - tp: 257.0000 - fp: 565.0000 - tn: 1061.0000 - fn: 141.0000 - accuracy: 0.6512 - precision: 0.3127 - recall: 0.6457 - auc: 0.6990 - prc: 0.4051 - val_loss: 0.6508 - val_tp: 54.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 37.0000 - val_accuracy: 0.6443 - val_precision: 0.2741 - val_recall: 0.5934 - val_auc: 0.6686 - val_prc: 0.3199\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0249 - tp: 255.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 143.0000 - accuracy: 0.6571 - precision: 0.3164 - recall: 0.6407 - auc: 0.6999 - prc: 0.4088 - val_loss: 0.6638 - val_tp: 58.0000 - val_fp: 169.0000 - val_tn: 246.0000 - val_fn: 33.0000 - val_accuracy: 0.6008 - val_precision: 0.2555 - val_recall: 0.6374 - val_auc: 0.6675 - val_prc: 0.3171\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0238 - tp: 272.0000 - fp: 670.0000 - tn: 956.0000 - fn: 126.0000 - accuracy: 0.6067 - precision: 0.2887 - recall: 0.6834 - auc: 0.7004 - prc: 0.4069 - val_loss: 0.6760 - val_tp: 62.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 29.0000 - val_accuracy: 0.5613 - val_precision: 0.2431 - val_recall: 0.6813 - val_auc: 0.6680 - val_prc: 0.3161\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0237 - tp: 280.0000 - fp: 713.0000 - tn: 913.0000 - fn: 118.0000 - accuracy: 0.5894 - precision: 0.2820 - recall: 0.7035 - auc: 0.7002 - prc: 0.4072 - val_loss: 0.6702 - val_tp: 60.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 31.0000 - val_accuracy: 0.5830 - val_precision: 0.2500 - val_recall: 0.6593 - val_auc: 0.6684 - val_prc: 0.3175\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0221 - tp: 260.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 138.0000 - accuracy: 0.6403 - precision: 0.3059 - recall: 0.6533 - auc: 0.7006 - prc: 0.4110 - val_loss: 0.6474 - val_tp: 53.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 38.0000 - val_accuracy: 0.6522 - val_precision: 0.2775 - val_recall: 0.5824 - val_auc: 0.6696 - val_prc: 0.3220\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0248 - tp: 227.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 171.0000 - accuracy: 0.7129 - precision: 0.3564 - recall: 0.5704 - auc: 0.6988 - prc: 0.4084 - val_loss: 0.6322 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6697 - val_prc: 0.3254\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0217 - tp: 233.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 165.0000 - accuracy: 0.6937 - precision: 0.3387 - recall: 0.5854 - auc: 0.7014 - prc: 0.4125 - val_loss: 0.6553 - val_tp: 56.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 35.0000 - val_accuracy: 0.6285 - val_precision: 0.2679 - val_recall: 0.6154 - val_auc: 0.6697 - val_prc: 0.3234\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0209 - tp: 274.0000 - fp: 675.0000 - tn: 951.0000 - fn: 124.0000 - accuracy: 0.6052 - precision: 0.2887 - recall: 0.6884 - auc: 0.6998 - prc: 0.4102 - val_loss: 0.6765 - val_tp: 62.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 29.0000 - val_accuracy: 0.5593 - val_precision: 0.2422 - val_recall: 0.6813 - val_auc: 0.6704 - val_prc: 0.3232\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0195 - tp: 269.0000 - fp: 638.0000 - tn: 988.0000 - fn: 129.0000 - accuracy: 0.6210 - precision: 0.2966 - recall: 0.6759 - auc: 0.7003 - prc: 0.4091 - val_loss: 0.6560 - val_tp: 56.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 35.0000 - val_accuracy: 0.6265 - val_precision: 0.2667 - val_recall: 0.6154 - val_auc: 0.6689 - val_prc: 0.3235\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0181 - tp: 264.0000 - fp: 615.0000 - tn: 1011.0000 - fn: 134.0000 - accuracy: 0.6299 - precision: 0.3003 - recall: 0.6633 - auc: 0.7008 - prc: 0.4134 - val_loss: 0.6635 - val_tp: 58.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 33.0000 - val_accuracy: 0.5929 - val_precision: 0.2511 - val_recall: 0.6374 - val_auc: 0.6706 - val_prc: 0.3255\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0170 - tp: 264.0000 - fp: 604.0000 - tn: 1022.0000 - fn: 134.0000 - accuracy: 0.6354 - precision: 0.3041 - recall: 0.6633 - auc: 0.7017 - prc: 0.4147 - val_loss: 0.6515 - val_tp: 55.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 36.0000 - val_accuracy: 0.6304 - val_precision: 0.2670 - val_recall: 0.6044 - val_auc: 0.6710 - val_prc: 0.3269\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0164 - tp: 255.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 143.0000 - accuracy: 0.6581 - precision: 0.3172 - recall: 0.6407 - auc: 0.7014 - prc: 0.4136 - val_loss: 0.6514 - val_tp: 55.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 36.0000 - val_accuracy: 0.6304 - val_precision: 0.2670 - val_recall: 0.6044 - val_auc: 0.6704 - val_prc: 0.3246\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0154 - tp: 260.0000 - fp: 575.0000 - tn: 1051.0000 - fn: 138.0000 - accuracy: 0.6477 - precision: 0.3114 - recall: 0.6533 - auc: 0.7016 - prc: 0.4140 - val_loss: 0.6561 - val_tp: 56.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 35.0000 - val_accuracy: 0.6225 - val_precision: 0.2642 - val_recall: 0.6154 - val_auc: 0.6700 - val_prc: 0.3257\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0143 - tp: 260.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 138.0000 - accuracy: 0.6472 - precision: 0.3110 - recall: 0.6533 - auc: 0.7018 - prc: 0.4141 - val_loss: 0.6530 - val_tp: 55.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 36.0000 - val_accuracy: 0.6285 - val_precision: 0.2657 - val_recall: 0.6044 - val_auc: 0.6718 - val_prc: 0.3252\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0136 - tp: 262.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 136.0000 - accuracy: 0.6413 - precision: 0.3075 - recall: 0.6583 - auc: 0.7021 - prc: 0.4133 - val_loss: 0.6559 - val_tp: 55.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 36.0000 - val_accuracy: 0.6186 - val_precision: 0.2594 - val_recall: 0.6044 - val_auc: 0.6709 - val_prc: 0.3246\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0129 - tp: 257.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 141.0000 - accuracy: 0.6561 - precision: 0.3165 - recall: 0.6457 - auc: 0.7017 - prc: 0.4161 - val_loss: 0.6440 - val_tp: 54.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 37.0000 - val_accuracy: 0.6443 - val_precision: 0.2741 - val_recall: 0.5934 - val_auc: 0.6714 - val_prc: 0.3281\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0119 - tp: 245.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 153.0000 - accuracy: 0.6789 - precision: 0.3302 - recall: 0.6156 - auc: 0.7028 - prc: 0.4167 - val_loss: 0.6389 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6714 - val_prc: 0.3285\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0112 - tp: 254.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 144.0000 - accuracy: 0.6645 - precision: 0.3219 - recall: 0.6382 - auc: 0.7011 - prc: 0.4148 - val_loss: 0.6454 - val_tp: 54.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 37.0000 - val_accuracy: 0.6344 - val_precision: 0.2673 - val_recall: 0.5934 - val_auc: 0.6719 - val_prc: 0.3301\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0111 - tp: 240.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 158.0000 - accuracy: 0.6863 - precision: 0.3347 - recall: 0.6030 - auc: 0.7015 - prc: 0.4157 - val_loss: 0.6351 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6721 - val_prc: 0.3313\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0091 - tp: 257.0000 - fp: 554.0000 - tn: 1072.0000 - fn: 141.0000 - accuracy: 0.6566 - precision: 0.3169 - recall: 0.6457 - auc: 0.7025 - prc: 0.4157 - val_loss: 0.6609 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6725 - val_prc: 0.3296\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0081 - tp: 266.0000 - fp: 615.0000 - tn: 1011.0000 - fn: 132.0000 - accuracy: 0.6309 - precision: 0.3019 - recall: 0.6683 - auc: 0.7040 - prc: 0.4161 - val_loss: 0.6522 - val_tp: 56.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 35.0000 - val_accuracy: 0.6245 - val_precision: 0.2654 - val_recall: 0.6154 - val_auc: 0.6742 - val_prc: 0.3319\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0093 - tp: 234.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 164.0000 - accuracy: 0.6952 - precision: 0.3406 - recall: 0.5879 - auc: 0.7016 - prc: 0.4134 - val_loss: 0.6238 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6740 - val_prc: 0.3344\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0080 - tp: 251.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 147.0000 - accuracy: 0.6754 - precision: 0.3298 - recall: 0.6307 - auc: 0.7006 - prc: 0.4137 - val_loss: 0.6595 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6749 - val_prc: 0.3327\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0052 - tp: 266.0000 - fp: 601.0000 - tn: 1025.0000 - fn: 132.0000 - accuracy: 0.6378 - precision: 0.3068 - recall: 0.6683 - auc: 0.7044 - prc: 0.4182 - val_loss: 0.6567 - val_tp: 58.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 33.0000 - val_accuracy: 0.6225 - val_precision: 0.2685 - val_recall: 0.6374 - val_auc: 0.6748 - val_prc: 0.3335\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0041 - tp: 261.0000 - fp: 565.0000 - tn: 1061.0000 - fn: 137.0000 - accuracy: 0.6532 - precision: 0.3160 - recall: 0.6558 - auc: 0.7050 - prc: 0.4159 - val_loss: 0.6527 - val_tp: 56.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 35.0000 - val_accuracy: 0.6265 - val_precision: 0.2667 - val_recall: 0.6154 - val_auc: 0.6752 - val_prc: 0.3319\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0026 - tp: 255.0000 - fp: 532.0000 - tn: 1094.0000 - fn: 143.0000 - accuracy: 0.6665 - precision: 0.3240 - recall: 0.6407 - auc: 0.7058 - prc: 0.4177 - val_loss: 0.6385 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6758 - val_prc: 0.3361\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0017 - tp: 247.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 151.0000 - accuracy: 0.6680 - precision: 0.3216 - recall: 0.6206 - auc: 0.7060 - prc: 0.4178 - val_loss: 0.6456 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6762 - val_prc: 0.3372\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0029 - tp: 269.0000 - fp: 624.0000 - tn: 1002.0000 - fn: 129.0000 - accuracy: 0.6280 - precision: 0.3012 - recall: 0.6759 - auc: 0.7045 - prc: 0.4177 - val_loss: 0.6664 - val_tp: 58.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 33.0000 - val_accuracy: 0.5929 - val_precision: 0.2511 - val_recall: 0.6374 - val_auc: 0.6767 - val_prc: 0.3357\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0005 - tp: 249.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 149.0000 - accuracy: 0.6630 - precision: 0.3184 - recall: 0.6256 - auc: 0.7058 - prc: 0.4186 - val_loss: 0.6205 - val_tp: 52.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 39.0000 - val_accuracy: 0.6976 - val_precision: 0.3133 - val_recall: 0.5714 - val_auc: 0.6772 - val_prc: 0.3430\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0002 - tp: 224.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 174.0000 - accuracy: 0.7070 - precision: 0.3484 - recall: 0.5628 - auc: 0.7073 - prc: 0.4228 - val_loss: 0.6240 - val_tp: 53.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 38.0000 - val_accuracy: 0.6858 - val_precision: 0.3046 - val_recall: 0.5824 - val_auc: 0.6781 - val_prc: 0.3433\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9983 - tp: 239.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 159.0000 - accuracy: 0.6789 - precision: 0.3274 - recall: 0.6005 - auc: 0.7068 - prc: 0.4229 - val_loss: 0.6386 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6780 - val_prc: 0.3432\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9972 - tp: 242.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 156.0000 - accuracy: 0.6724 - precision: 0.3231 - recall: 0.6080 - auc: 0.7066 - prc: 0.4244 - val_loss: 0.6357 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6779 - val_prc: 0.3446\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9962 - tp: 249.0000 - fp: 532.0000 - tn: 1094.0000 - fn: 149.0000 - accuracy: 0.6635 - precision: 0.3188 - recall: 0.6256 - auc: 0.7077 - prc: 0.4256 - val_loss: 0.6374 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6787 - val_prc: 0.3442\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9954 - tp: 237.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 161.0000 - accuracy: 0.6784 - precision: 0.3260 - recall: 0.5955 - auc: 0.7075 - prc: 0.4270 - val_loss: 0.6322 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6793 - val_prc: 0.3466\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9940 - tp: 255.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 143.0000 - accuracy: 0.6625 - precision: 0.3208 - recall: 0.6407 - auc: 0.7084 - prc: 0.4270 - val_loss: 0.6483 - val_tp: 56.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 35.0000 - val_accuracy: 0.6423 - val_precision: 0.2772 - val_recall: 0.6154 - val_auc: 0.6784 - val_prc: 0.3445\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9937 - tp: 245.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 153.0000 - accuracy: 0.6621 - precision: 0.3157 - recall: 0.6156 - auc: 0.7085 - prc: 0.4247 - val_loss: 0.6339 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6784 - val_prc: 0.3444\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9933 - tp: 234.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 164.0000 - accuracy: 0.6838 - precision: 0.3296 - recall: 0.5879 - auc: 0.7081 - prc: 0.4254 - val_loss: 0.6284 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6781 - val_prc: 0.3462\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9921 - tp: 239.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 159.0000 - accuracy: 0.6838 - precision: 0.3319 - recall: 0.6005 - auc: 0.7090 - prc: 0.4269 - val_loss: 0.6298 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6783 - val_prc: 0.3522\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9914 - tp: 243.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 155.0000 - accuracy: 0.6803 - precision: 0.3306 - recall: 0.6106 - auc: 0.7093 - prc: 0.4261 - val_loss: 0.6220 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6781 - val_prc: 0.3534\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9916 - tp: 228.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 170.0000 - accuracy: 0.6996 - precision: 0.3423 - recall: 0.5729 - auc: 0.7092 - prc: 0.4285 - val_loss: 0.6210 - val_tp: 50.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 41.0000 - val_accuracy: 0.6779 - val_precision: 0.2907 - val_recall: 0.5495 - val_auc: 0.6780 - val_prc: 0.3534\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9905 - tp: 247.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 151.0000 - accuracy: 0.6675 - precision: 0.3212 - recall: 0.6206 - auc: 0.7092 - prc: 0.4268 - val_loss: 0.6441 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6783 - val_prc: 0.3528\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9895 - tp: 254.0000 - fp: 554.0000 - tn: 1072.0000 - fn: 144.0000 - accuracy: 0.6551 - precision: 0.3144 - recall: 0.6382 - auc: 0.7099 - prc: 0.4290 - val_loss: 0.6436 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6782 - val_prc: 0.3549\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9889 - tp: 255.0000 - fp: 557.0000 - tn: 1069.0000 - fn: 143.0000 - accuracy: 0.6542 - precision: 0.3140 - recall: 0.6407 - auc: 0.7100 - prc: 0.4281 - val_loss: 0.6402 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6785 - val_prc: 0.3540\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9880 - tp: 253.0000 - fp: 554.0000 - tn: 1072.0000 - fn: 145.0000 - accuracy: 0.6546 - precision: 0.3135 - recall: 0.6357 - auc: 0.7104 - prc: 0.4279 - val_loss: 0.6307 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6775 - val_prc: 0.3525\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9898 - tp: 223.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 175.0000 - accuracy: 0.7060 - precision: 0.3468 - recall: 0.5603 - auc: 0.7081 - prc: 0.4281 - val_loss: 0.6090 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6787 - val_prc: 0.3578\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9856 - tp: 236.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 162.0000 - accuracy: 0.6853 - precision: 0.3319 - recall: 0.5930 - auc: 0.7117 - prc: 0.4322 - val_loss: 0.6390 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6786 - val_prc: 0.3616\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9858 - tp: 253.0000 - fp: 542.0000 - tn: 1084.0000 - fn: 145.0000 - accuracy: 0.6606 - precision: 0.3182 - recall: 0.6357 - auc: 0.7100 - prc: 0.4334 - val_loss: 0.6386 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6799 - val_prc: 0.3649\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9854 - tp: 253.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 145.0000 - accuracy: 0.6591 - precision: 0.3170 - recall: 0.6357 - auc: 0.7104 - prc: 0.4342 - val_loss: 0.6278 - val_tp: 55.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 36.0000 - val_accuracy: 0.6680 - val_precision: 0.2941 - val_recall: 0.6044 - val_auc: 0.6800 - val_prc: 0.3649\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9842 - tp: 241.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 157.0000 - accuracy: 0.6798 - precision: 0.3292 - recall: 0.6055 - auc: 0.7115 - prc: 0.4353 - val_loss: 0.6133 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6793 - val_prc: 0.3655\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9845 - tp: 225.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 173.0000 - accuracy: 0.7006 - precision: 0.3419 - recall: 0.5653 - auc: 0.7119 - prc: 0.4348 - val_loss: 0.6089 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6799 - val_prc: 0.3662\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9847 - tp: 219.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 179.0000 - accuracy: 0.7041 - precision: 0.3427 - recall: 0.5503 - auc: 0.7120 - prc: 0.4360 - val_loss: 0.6138 - val_tp: 49.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 42.0000 - val_accuracy: 0.6858 - val_precision: 0.2952 - val_recall: 0.5385 - val_auc: 0.6796 - val_prc: 0.3665\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9830 - tp: 237.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 161.0000 - accuracy: 0.6749 - precision: 0.3229 - recall: 0.5955 - auc: 0.7109 - prc: 0.4364 - val_loss: 0.6352 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.6799 - val_prc: 0.3682\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9828 - tp: 254.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 144.0000 - accuracy: 0.6542 - precision: 0.3136 - recall: 0.6382 - auc: 0.7115 - prc: 0.4362 - val_loss: 0.6425 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6799 - val_prc: 0.3693\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9831 - tp: 261.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 137.0000 - accuracy: 0.6537 - precision: 0.3164 - recall: 0.6558 - auc: 0.7117 - prc: 0.4366 - val_loss: 0.6376 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6798 - val_prc: 0.3682\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9811 - tp: 241.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 157.0000 - accuracy: 0.6724 - precision: 0.3226 - recall: 0.6055 - auc: 0.7127 - prc: 0.4378 - val_loss: 0.6218 - val_tp: 54.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 37.0000 - val_accuracy: 0.6719 - val_precision: 0.2951 - val_recall: 0.5934 - val_auc: 0.6795 - val_prc: 0.3680\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9807 - tp: 240.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 158.0000 - accuracy: 0.6793 - precision: 0.3283 - recall: 0.6030 - auc: 0.7125 - prc: 0.4383 - val_loss: 0.6338 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6800 - val_prc: 0.3697\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9812 - tp: 252.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 146.0000 - accuracy: 0.6611 - precision: 0.3182 - recall: 0.6332 - auc: 0.7125 - prc: 0.4358 - val_loss: 0.6348 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6791 - val_prc: 0.3683\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9799 - tp: 243.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 155.0000 - accuracy: 0.6690 - precision: 0.3206 - recall: 0.6106 - auc: 0.7128 - prc: 0.4400 - val_loss: 0.6172 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6799 - val_prc: 0.3701\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9792 - tp: 235.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 163.0000 - accuracy: 0.6873 - precision: 0.3333 - recall: 0.5905 - auc: 0.7138 - prc: 0.4421 - val_loss: 0.6101 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6808 - val_prc: 0.3732\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9793 - tp: 225.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 173.0000 - accuracy: 0.6961 - precision: 0.3373 - recall: 0.5653 - auc: 0.7136 - prc: 0.4436 - val_loss: 0.6130 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6808 - val_prc: 0.3766\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9815 - tp: 248.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 150.0000 - accuracy: 0.6576 - precision: 0.3135 - recall: 0.6231 - auc: 0.7110 - prc: 0.4369 - val_loss: 0.6385 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6808 - val_prc: 0.3758\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9792 - tp: 225.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 173.0000 - accuracy: 0.6873 - precision: 0.3285 - recall: 0.5653 - auc: 0.7119 - prc: 0.4427 - val_loss: 0.5967 - val_tp: 49.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 42.0000 - val_accuracy: 0.7095 - val_precision: 0.3182 - val_recall: 0.5385 - val_auc: 0.6804 - val_prc: 0.3742\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9778 - tp: 228.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 170.0000 - accuracy: 0.6981 - precision: 0.3408 - recall: 0.5729 - auc: 0.7142 - prc: 0.4422 - val_loss: 0.6235 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6807 - val_prc: 0.3771\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9773 - tp: 242.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 156.0000 - accuracy: 0.6700 - precision: 0.3210 - recall: 0.6080 - auc: 0.7139 - prc: 0.4433 - val_loss: 0.6294 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6806 - val_prc: 0.3766\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9787 - tp: 259.0000 - fp: 574.0000 - tn: 1052.0000 - fn: 139.0000 - accuracy: 0.6477 - precision: 0.3109 - recall: 0.6508 - auc: 0.7139 - prc: 0.4419 - val_loss: 0.6423 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6826 - val_prc: 0.3836\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9758 - tp: 244.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 154.0000 - accuracy: 0.6734 - precision: 0.3249 - recall: 0.6131 - auc: 0.7147 - prc: 0.4465 - val_loss: 0.6054 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6825 - val_prc: 0.3848\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9767 - tp: 220.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 178.0000 - accuracy: 0.7045 - precision: 0.3438 - recall: 0.5528 - auc: 0.7156 - prc: 0.4464 - val_loss: 0.6079 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6838 - val_prc: 0.3855\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9782 - tp: 254.0000 - fp: 550.0000 - tn: 1076.0000 - fn: 144.0000 - accuracy: 0.6571 - precision: 0.3159 - recall: 0.6382 - auc: 0.7142 - prc: 0.4398 - val_loss: 0.6478 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6816 - val_prc: 0.3711\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9763 - tp: 233.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 165.0000 - accuracy: 0.6882 - precision: 0.3333 - recall: 0.5854 - auc: 0.7160 - prc: 0.4397 - val_loss: 0.5876 - val_tp: 47.0000 - val_fp: 100.0000 - val_tn: 315.0000 - val_fn: 44.0000 - val_accuracy: 0.7154 - val_precision: 0.3197 - val_recall: 0.5165 - val_auc: 0.6847 - val_prc: 0.3871\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9755 - tp: 227.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 171.0000 - accuracy: 0.7001 - precision: 0.3424 - recall: 0.5704 - auc: 0.7167 - prc: 0.4452 - val_loss: 0.6288 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6816 - val_prc: 0.3767\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9767 - tp: 257.0000 - fp: 551.0000 - tn: 1075.0000 - fn: 141.0000 - accuracy: 0.6581 - precision: 0.3181 - recall: 0.6457 - auc: 0.7158 - prc: 0.4424 - val_loss: 0.6420 - val_tp: 54.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 37.0000 - val_accuracy: 0.6502 - val_precision: 0.2784 - val_recall: 0.5934 - val_auc: 0.6824 - val_prc: 0.3772\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9746 - tp: 239.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 159.0000 - accuracy: 0.6789 - precision: 0.3274 - recall: 0.6005 - auc: 0.7167 - prc: 0.4461 - val_loss: 0.6000 - val_tp: 51.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 40.0000 - val_accuracy: 0.7016 - val_precision: 0.3148 - val_recall: 0.5604 - val_auc: 0.6852 - val_prc: 0.3929\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9764 - tp: 219.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 179.0000 - accuracy: 0.7100 - precision: 0.3493 - recall: 0.5503 - auc: 0.7162 - prc: 0.4498 - val_loss: 0.6033 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6844 - val_prc: 0.3891\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9734 - tp: 230.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 168.0000 - accuracy: 0.6877 - precision: 0.3314 - recall: 0.5779 - auc: 0.7170 - prc: 0.4482 - val_loss: 0.6308 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6834 - val_prc: 0.3860\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9740 - tp: 253.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 145.0000 - accuracy: 0.6611 - precision: 0.3186 - recall: 0.6357 - auc: 0.7168 - prc: 0.4482 - val_loss: 0.6347 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6835 - val_prc: 0.3857\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9734 - tp: 244.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 154.0000 - accuracy: 0.6700 - precision: 0.3219 - recall: 0.6131 - auc: 0.7165 - prc: 0.4491 - val_loss: 0.6151 - val_tp: 52.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 39.0000 - val_accuracy: 0.6680 - val_precision: 0.2873 - val_recall: 0.5714 - val_auc: 0.6842 - val_prc: 0.3940\n",
      "Epoch 135/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9730 - tp: 234.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 164.0000 - accuracy: 0.6818 - precision: 0.3277 - recall: 0.5879 - auc: 0.7164 - prc: 0.4516 - val_loss: 0.6146 - val_tp: 51.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 40.0000 - val_accuracy: 0.6700 - val_precision: 0.2865 - val_recall: 0.5604 - val_auc: 0.6849 - val_prc: 0.3939\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9729 - tp: 239.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 159.0000 - accuracy: 0.6798 - precision: 0.3283 - recall: 0.6005 - auc: 0.7165 - prc: 0.4517 - val_loss: 0.6200 - val_tp: 52.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 39.0000 - val_accuracy: 0.6680 - val_precision: 0.2873 - val_recall: 0.5714 - val_auc: 0.6852 - val_prc: 0.3977\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9734 - tp: 245.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 153.0000 - accuracy: 0.6675 - precision: 0.3203 - recall: 0.6156 - auc: 0.7162 - prc: 0.4508 - val_loss: 0.6317 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6843 - val_prc: 0.3907\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9721 - tp: 245.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 153.0000 - accuracy: 0.6774 - precision: 0.3289 - recall: 0.6156 - auc: 0.7174 - prc: 0.4518 - val_loss: 0.6056 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6850 - val_prc: 0.3939\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9729 - tp: 225.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 173.0000 - accuracy: 0.7006 - precision: 0.3419 - recall: 0.5653 - auc: 0.7170 - prc: 0.4522 - val_loss: 0.6065 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6839 - val_prc: 0.3878\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9720 - tp: 227.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 171.0000 - accuracy: 0.7031 - precision: 0.3455 - recall: 0.5704 - auc: 0.7178 - prc: 0.4525 - val_loss: 0.6070 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6848 - val_prc: 0.3930\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9718 - tp: 240.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 158.0000 - accuracy: 0.6769 - precision: 0.3261 - recall: 0.6030 - auc: 0.7167 - prc: 0.4560 - val_loss: 0.6242 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6851 - val_prc: 0.4028\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9724 - tp: 232.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 166.0000 - accuracy: 0.6873 - precision: 0.3319 - recall: 0.5829 - auc: 0.7156 - prc: 0.4562 - val_loss: 0.5907 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6868 - val_prc: 0.4098\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9731 - tp: 220.0000 - fp: 401.0000 - tn: 1225.0000 - fn: 178.0000 - accuracy: 0.7139 - precision: 0.3543 - recall: 0.5528 - auc: 0.7177 - prc: 0.4610 - val_loss: 0.5948 - val_tp: 51.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 40.0000 - val_accuracy: 0.7016 - val_precision: 0.3148 - val_recall: 0.5604 - val_auc: 0.6868 - val_prc: 0.4110\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9704 - tp: 236.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 162.0000 - accuracy: 0.6843 - precision: 0.3310 - recall: 0.5930 - auc: 0.7180 - prc: 0.4569 - val_loss: 0.6294 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6839 - val_prc: 0.3981\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9713 - tp: 252.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 146.0000 - accuracy: 0.6685 - precision: 0.3243 - recall: 0.6332 - auc: 0.7183 - prc: 0.4517 - val_loss: 0.6281 - val_tp: 52.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 39.0000 - val_accuracy: 0.6621 - val_precision: 0.2826 - val_recall: 0.5714 - val_auc: 0.6835 - val_prc: 0.3840\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9714 - tp: 250.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 148.0000 - accuracy: 0.6729 - precision: 0.3272 - recall: 0.6281 - auc: 0.7185 - prc: 0.4499 - val_loss: 0.6167 - val_tp: 51.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 40.0000 - val_accuracy: 0.6739 - val_precision: 0.2898 - val_recall: 0.5604 - val_auc: 0.6834 - val_prc: 0.3844\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9724 - tp: 226.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 172.0000 - accuracy: 0.7080 - precision: 0.3504 - recall: 0.5678 - auc: 0.7177 - prc: 0.4525 - val_loss: 0.5998 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6861 - val_prc: 0.4048\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9729 - tp: 253.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 145.0000 - accuracy: 0.6635 - precision: 0.3207 - recall: 0.6357 - auc: 0.7165 - prc: 0.4552 - val_loss: 0.6525 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6847 - val_prc: 0.4007\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9727 - tp: 240.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 158.0000 - accuracy: 0.6774 - precision: 0.3265 - recall: 0.6030 - auc: 0.7159 - prc: 0.4543 - val_loss: 0.6002 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6858 - val_prc: 0.4048\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9701 - tp: 223.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 175.0000 - accuracy: 0.7021 - precision: 0.3425 - recall: 0.5603 - auc: 0.7191 - prc: 0.4607 - val_loss: 0.6057 - val_tp: 51.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 40.0000 - val_accuracy: 0.6897 - val_precision: 0.3036 - val_recall: 0.5604 - val_auc: 0.6847 - val_prc: 0.4047\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9693 - tp: 246.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 152.0000 - accuracy: 0.6789 - precision: 0.3306 - recall: 0.6181 - auc: 0.7188 - prc: 0.4582 - val_loss: 0.6252 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6841 - val_prc: 0.3996\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9692 - tp: 237.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 161.0000 - accuracy: 0.6887 - precision: 0.3357 - recall: 0.5955 - auc: 0.7191 - prc: 0.4586 - val_loss: 0.6047 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6849 - val_prc: 0.4026\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9686 - tp: 248.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 150.0000 - accuracy: 0.6803 - precision: 0.3329 - recall: 0.6231 - auc: 0.7194 - prc: 0.4582 - val_loss: 0.6304 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6854 - val_prc: 0.4049\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9688 - tp: 245.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 153.0000 - accuracy: 0.6793 - precision: 0.3306 - recall: 0.6156 - auc: 0.7192 - prc: 0.4596 - val_loss: 0.6170 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6845 - val_prc: 0.4031\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9679 - tp: 250.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 148.0000 - accuracy: 0.6793 - precision: 0.3329 - recall: 0.6281 - auc: 0.7202 - prc: 0.4618 - val_loss: 0.6224 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6851 - val_prc: 0.4075\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9680 - tp: 238.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 160.0000 - accuracy: 0.6843 - precision: 0.3319 - recall: 0.5980 - auc: 0.7195 - prc: 0.4628 - val_loss: 0.6121 - val_tp: 51.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 40.0000 - val_accuracy: 0.6739 - val_precision: 0.2898 - val_recall: 0.5604 - val_auc: 0.6864 - val_prc: 0.4109\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9677 - tp: 233.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 165.0000 - accuracy: 0.6848 - precision: 0.3300 - recall: 0.5854 - auc: 0.7197 - prc: 0.4637 - val_loss: 0.6119 - val_tp: 51.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 40.0000 - val_accuracy: 0.6719 - val_precision: 0.2881 - val_recall: 0.5604 - val_auc: 0.6862 - val_prc: 0.4130\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9668 - tp: 243.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 155.0000 - accuracy: 0.6833 - precision: 0.3333 - recall: 0.6106 - auc: 0.7207 - prc: 0.4658 - val_loss: 0.6275 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6857 - val_prc: 0.4122\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9679 - tp: 249.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 149.0000 - accuracy: 0.6754 - precision: 0.3289 - recall: 0.6256 - auc: 0.7198 - prc: 0.4645 - val_loss: 0.6141 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6871 - val_prc: 0.4156\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9669 - tp: 229.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 169.0000 - accuracy: 0.6912 - precision: 0.3343 - recall: 0.5754 - auc: 0.7207 - prc: 0.4662 - val_loss: 0.5997 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6859 - val_prc: 0.4134\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9675 - tp: 233.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 165.0000 - accuracy: 0.6927 - precision: 0.3377 - recall: 0.5854 - auc: 0.7197 - prc: 0.4647 - val_loss: 0.6104 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6855 - val_prc: 0.4099\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9675 - tp: 235.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 163.0000 - accuracy: 0.6868 - precision: 0.3329 - recall: 0.5905 - auc: 0.7197 - prc: 0.4630 - val_loss: 0.6052 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6853 - val_prc: 0.4106\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9674 - tp: 225.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 173.0000 - accuracy: 0.7011 - precision: 0.3425 - recall: 0.5653 - auc: 0.7203 - prc: 0.4650 - val_loss: 0.5979 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6863 - val_prc: 0.4146\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9667 - tp: 230.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 168.0000 - accuracy: 0.6976 - precision: 0.3412 - recall: 0.5779 - auc: 0.7205 - prc: 0.4652 - val_loss: 0.6010 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6863 - val_prc: 0.4120\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9663 - tp: 226.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 172.0000 - accuracy: 0.6991 - precision: 0.3409 - recall: 0.5678 - auc: 0.7213 - prc: 0.4660 - val_loss: 0.6010 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6861 - val_prc: 0.4125\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9663 - tp: 242.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 156.0000 - accuracy: 0.6833 - precision: 0.3329 - recall: 0.6080 - auc: 0.7203 - prc: 0.4660 - val_loss: 0.6208 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6862 - val_prc: 0.4140\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9648 - tp: 236.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 162.0000 - accuracy: 0.6882 - precision: 0.3348 - recall: 0.5930 - auc: 0.7214 - prc: 0.4672 - val_loss: 0.5953 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6864 - val_prc: 0.4155\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9658 - tp: 227.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 171.0000 - accuracy: 0.6961 - precision: 0.3383 - recall: 0.5704 - auc: 0.7214 - prc: 0.4677 - val_loss: 0.6085 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6865 - val_prc: 0.4167\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9653 - tp: 242.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 156.0000 - accuracy: 0.6798 - precision: 0.3297 - recall: 0.6080 - auc: 0.7210 - prc: 0.4666 - val_loss: 0.6144 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6859 - val_prc: 0.4120\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9654 - tp: 228.0000 - fp: 442.0000 - tn: 1184.0000 - fn: 170.0000 - accuracy: 0.6976 - precision: 0.3403 - recall: 0.5729 - auc: 0.7213 - prc: 0.4665 - val_loss: 0.5918 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6858 - val_prc: 0.4159\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9643 - tp: 235.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 163.0000 - accuracy: 0.6947 - precision: 0.3406 - recall: 0.5905 - auc: 0.7218 - prc: 0.4684 - val_loss: 0.6227 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6855 - val_prc: 0.4133\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9654 - tp: 257.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 141.0000 - accuracy: 0.6744 - precision: 0.3316 - recall: 0.6457 - auc: 0.7215 - prc: 0.4677 - val_loss: 0.6237 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6856 - val_prc: 0.4134\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9642 - tp: 247.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 151.0000 - accuracy: 0.6843 - precision: 0.3361 - recall: 0.6206 - auc: 0.7217 - prc: 0.4684 - val_loss: 0.6035 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6866 - val_prc: 0.4176\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9644 - tp: 225.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 173.0000 - accuracy: 0.6981 - precision: 0.3394 - recall: 0.5653 - auc: 0.7224 - prc: 0.4696 - val_loss: 0.5853 - val_tp: 48.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 43.0000 - val_accuracy: 0.7095 - val_precision: 0.3158 - val_recall: 0.5275 - val_auc: 0.6868 - val_prc: 0.4196\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9674 - tp: 217.0000 - fp: 364.0000 - tn: 1262.0000 - fn: 181.0000 - accuracy: 0.7307 - precision: 0.3735 - recall: 0.5452 - auc: 0.7220 - prc: 0.4696 - val_loss: 0.5917 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6859 - val_prc: 0.4158\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9682 - tp: 253.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 145.0000 - accuracy: 0.6621 - precision: 0.3194 - recall: 0.6357 - auc: 0.7193 - prc: 0.4644 - val_loss: 0.6557 - val_tp: 57.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 34.0000 - val_accuracy: 0.6245 - val_precision: 0.2676 - val_recall: 0.6264 - val_auc: 0.6854 - val_prc: 0.4127\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9650 - tp: 259.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 139.0000 - accuracy: 0.6640 - precision: 0.3237 - recall: 0.6508 - auc: 0.7228 - prc: 0.4678 - val_loss: 0.5989 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6865 - val_prc: 0.4170\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9666 - tp: 218.0000 - fp: 370.0000 - tn: 1256.0000 - fn: 180.0000 - accuracy: 0.7283 - precision: 0.3707 - recall: 0.5477 - auc: 0.7227 - prc: 0.4696 - val_loss: 0.5767 - val_tp: 46.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 45.0000 - val_accuracy: 0.7253 - val_precision: 0.3286 - val_recall: 0.5055 - val_auc: 0.6866 - val_prc: 0.4174\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9655 - tp: 227.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 171.0000 - accuracy: 0.7041 - precision: 0.3466 - recall: 0.5704 - auc: 0.7220 - prc: 0.4669 - val_loss: 0.6128 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6853 - val_prc: 0.4121\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9629 - tp: 247.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 151.0000 - accuracy: 0.6873 - precision: 0.3388 - recall: 0.6206 - auc: 0.7230 - prc: 0.4699 - val_loss: 0.6177 - val_tp: 52.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 39.0000 - val_accuracy: 0.6700 - val_precision: 0.2889 - val_recall: 0.5714 - val_auc: 0.6859 - val_prc: 0.4169\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9636 - tp: 251.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 147.0000 - accuracy: 0.6818 - precision: 0.3356 - recall: 0.6307 - auc: 0.7225 - prc: 0.4691 - val_loss: 0.6139 - val_tp: 51.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 40.0000 - val_accuracy: 0.6739 - val_precision: 0.2898 - val_recall: 0.5604 - val_auc: 0.6864 - val_prc: 0.4179\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9630 - tp: 243.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 155.0000 - accuracy: 0.6892 - precision: 0.3389 - recall: 0.6106 - auc: 0.7238 - prc: 0.4675 - val_loss: 0.6063 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6845 - val_prc: 0.3979\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9634 - tp: 234.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 164.0000 - accuracy: 0.7085 - precision: 0.3545 - recall: 0.5879 - auc: 0.7236 - prc: 0.4674 - val_loss: 0.6045 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6836 - val_prc: 0.3943\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9641 - tp: 242.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 156.0000 - accuracy: 0.6818 - precision: 0.3315 - recall: 0.6080 - auc: 0.7229 - prc: 0.4647 - val_loss: 0.6257 - val_tp: 52.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 39.0000 - val_accuracy: 0.6561 - val_precision: 0.2781 - val_recall: 0.5714 - val_auc: 0.6841 - val_prc: 0.3971\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9638 - tp: 255.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 143.0000 - accuracy: 0.6724 - precision: 0.3290 - recall: 0.6407 - auc: 0.7229 - prc: 0.4678 - val_loss: 0.6258 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6856 - val_prc: 0.4079\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9640 - tp: 261.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 137.0000 - accuracy: 0.6655 - precision: 0.3258 - recall: 0.6558 - auc: 0.7237 - prc: 0.4723 - val_loss: 0.6390 - val_tp: 57.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 34.0000 - val_accuracy: 0.6403 - val_precision: 0.2780 - val_recall: 0.6264 - val_auc: 0.6868 - val_prc: 0.4223\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9648 - tp: 237.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 161.0000 - accuracy: 0.6887 - precision: 0.3357 - recall: 0.5955 - auc: 0.7208 - prc: 0.4678 - val_loss: 0.5891 - val_tp: 49.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 42.0000 - val_accuracy: 0.7016 - val_precision: 0.3101 - val_recall: 0.5385 - val_auc: 0.6887 - val_prc: 0.4294\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9629 - tp: 228.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 170.0000 - accuracy: 0.7045 - precision: 0.3476 - recall: 0.5729 - auc: 0.7236 - prc: 0.4734 - val_loss: 0.5989 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6888 - val_prc: 0.4282\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9615 - tp: 234.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 164.0000 - accuracy: 0.6937 - precision: 0.3391 - recall: 0.5879 - auc: 0.7239 - prc: 0.4734 - val_loss: 0.6079 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6877 - val_prc: 0.4239\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9611 - tp: 243.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 155.0000 - accuracy: 0.6947 - precision: 0.3442 - recall: 0.6106 - auc: 0.7246 - prc: 0.4722 - val_loss: 0.6064 - val_tp: 49.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 42.0000 - val_accuracy: 0.6838 - val_precision: 0.2934 - val_recall: 0.5385 - val_auc: 0.6849 - val_prc: 0.4051\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9627 - tp: 232.0000 - fp: 423.0000 - tn: 1203.0000 - fn: 166.0000 - accuracy: 0.7090 - precision: 0.3542 - recall: 0.5829 - auc: 0.7240 - prc: 0.4714 - val_loss: 0.5989 - val_tp: 49.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 42.0000 - val_accuracy: 0.6937 - val_precision: 0.3025 - val_recall: 0.5385 - val_auc: 0.6856 - val_prc: 0.4083\n",
      "Epoch 192/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9610 - tp: 237.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 161.0000 - accuracy: 0.6971 - precision: 0.3440 - recall: 0.5955 - auc: 0.7250 - prc: 0.4732 - val_loss: 0.6117 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6862 - val_prc: 0.4145\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9607 - tp: 248.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 150.0000 - accuracy: 0.6868 - precision: 0.3388 - recall: 0.6231 - auc: 0.7249 - prc: 0.4729 - val_loss: 0.6128 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6869 - val_prc: 0.4170\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9607 - tp: 238.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 160.0000 - accuracy: 0.7001 - precision: 0.3474 - recall: 0.5980 - auc: 0.7253 - prc: 0.4728 - val_loss: 0.5953 - val_tp: 49.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 42.0000 - val_accuracy: 0.6957 - val_precision: 0.3043 - val_recall: 0.5385 - val_auc: 0.6868 - val_prc: 0.4180\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9605 - tp: 234.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 164.0000 - accuracy: 0.6961 - precision: 0.3416 - recall: 0.5879 - auc: 0.7250 - prc: 0.4736 - val_loss: 0.6122 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6874 - val_prc: 0.4186\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9611 - tp: 257.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 141.0000 - accuracy: 0.6813 - precision: 0.3377 - recall: 0.6457 - auc: 0.7249 - prc: 0.4725 - val_loss: 0.6239 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6873 - val_prc: 0.4199\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9596 - tp: 240.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 158.0000 - accuracy: 0.6942 - precision: 0.3424 - recall: 0.6030 - auc: 0.7260 - prc: 0.4735 - val_loss: 0.5946 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6860 - val_prc: 0.4175\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9602 - tp: 233.0000 - fp: 431.0000 - tn: 1195.0000 - fn: 165.0000 - accuracy: 0.7055 - precision: 0.3509 - recall: 0.5854 - auc: 0.7259 - prc: 0.4741 - val_loss: 0.6050 - val_tp: 50.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 41.0000 - val_accuracy: 0.6858 - val_precision: 0.2976 - val_recall: 0.5495 - val_auc: 0.6854 - val_prc: 0.4121\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9596 - tp: 240.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 158.0000 - accuracy: 0.6917 - precision: 0.3399 - recall: 0.6030 - auc: 0.7258 - prc: 0.4739 - val_loss: 0.6164 - val_tp: 51.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 40.0000 - val_accuracy: 0.6739 - val_precision: 0.2898 - val_recall: 0.5604 - val_auc: 0.6862 - val_prc: 0.4082\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9605 - tp: 248.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 150.0000 - accuracy: 0.6779 - precision: 0.3307 - recall: 0.6231 - auc: 0.7255 - prc: 0.4739 - val_loss: 0.6258 - val_tp: 53.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 38.0000 - val_accuracy: 0.6680 - val_precision: 0.2896 - val_recall: 0.5824 - val_auc: 0.6847 - val_prc: 0.4015\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9610 - tp: 254.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 144.0000 - accuracy: 0.6779 - precision: 0.3333 - recall: 0.6382 - auc: 0.7255 - prc: 0.4720 - val_loss: 0.6115 - val_tp: 50.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 41.0000 - val_accuracy: 0.6719 - val_precision: 0.2857 - val_recall: 0.5495 - val_auc: 0.6866 - val_prc: 0.4087\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9606 - tp: 233.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 165.0000 - accuracy: 0.7060 - precision: 0.3514 - recall: 0.5854 - auc: 0.7255 - prc: 0.4729 - val_loss: 0.5923 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6869 - val_prc: 0.4205\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9599 - tp: 234.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 164.0000 - accuracy: 0.7026 - precision: 0.3482 - recall: 0.5879 - auc: 0.7260 - prc: 0.4749 - val_loss: 0.5990 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6870 - val_prc: 0.4220\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9606 - tp: 226.0000 - fp: 410.0000 - tn: 1216.0000 - fn: 172.0000 - accuracy: 0.7125 - precision: 0.3553 - recall: 0.5678 - auc: 0.7261 - prc: 0.4755 - val_loss: 0.5928 - val_tp: 49.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 42.0000 - val_accuracy: 0.7055 - val_precision: 0.3141 - val_recall: 0.5385 - val_auc: 0.6866 - val_prc: 0.4218\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9590 - tp: 241.0000 - fp: 449.0000 - tn: 1177.0000 - fn: 157.0000 - accuracy: 0.7006 - precision: 0.3493 - recall: 0.6055 - auc: 0.7263 - prc: 0.4751 - val_loss: 0.6142 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6863 - val_prc: 0.4199\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9592 - tp: 254.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 144.0000 - accuracy: 0.6863 - precision: 0.3409 - recall: 0.6382 - auc: 0.7261 - prc: 0.4744 - val_loss: 0.6226 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6862 - val_prc: 0.4178\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9608 - tp: 229.0000 - fp: 409.0000 - tn: 1217.0000 - fn: 169.0000 - accuracy: 0.7144 - precision: 0.3589 - recall: 0.5754 - auc: 0.7255 - prc: 0.4736 - val_loss: 0.5791 - val_tp: 47.0000 - val_fp: 99.0000 - val_tn: 316.0000 - val_fn: 44.0000 - val_accuracy: 0.7174 - val_precision: 0.3219 - val_recall: 0.5165 - val_auc: 0.6869 - val_prc: 0.4203\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9595 - tp: 229.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 169.0000 - accuracy: 0.7149 - precision: 0.3595 - recall: 0.5754 - auc: 0.7270 - prc: 0.4757 - val_loss: 0.6098 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6863 - val_prc: 0.4201\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9582 - tp: 243.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 155.0000 - accuracy: 0.6966 - precision: 0.3462 - recall: 0.6106 - auc: 0.7269 - prc: 0.4750 - val_loss: 0.6024 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6854 - val_prc: 0.4169\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9580 - tp: 238.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 160.0000 - accuracy: 0.7045 - precision: 0.3521 - recall: 0.5980 - auc: 0.7272 - prc: 0.4761 - val_loss: 0.6047 - val_tp: 51.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 40.0000 - val_accuracy: 0.6877 - val_precision: 0.3018 - val_recall: 0.5604 - val_auc: 0.6851 - val_prc: 0.4168\n",
      "Epoch 211/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9581 - tp: 242.0000 - fp: 443.0000 - tn: 1183.0000 - fn: 156.0000 - accuracy: 0.7041 - precision: 0.3533 - recall: 0.6080 - auc: 0.7270 - prc: 0.4752 - val_loss: 0.6137 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6855 - val_prc: 0.4178\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9579 - tp: 251.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 147.0000 - accuracy: 0.6897 - precision: 0.3429 - recall: 0.6307 - auc: 0.7272 - prc: 0.4756 - val_loss: 0.6230 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6864 - val_prc: 0.4199\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9584 - tp: 255.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 143.0000 - accuracy: 0.6798 - precision: 0.3355 - recall: 0.6407 - auc: 0.7270 - prc: 0.4747 - val_loss: 0.6213 - val_tp: 53.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 38.0000 - val_accuracy: 0.6700 - val_precision: 0.2912 - val_recall: 0.5824 - val_auc: 0.6842 - val_prc: 0.4105\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9578 - tp: 242.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 156.0000 - accuracy: 0.6937 - precision: 0.3428 - recall: 0.6080 - auc: 0.7270 - prc: 0.4759 - val_loss: 0.6005 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6851 - val_prc: 0.4165\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9580 - tp: 233.0000 - fp: 418.0000 - tn: 1208.0000 - fn: 165.0000 - accuracy: 0.7120 - precision: 0.3579 - recall: 0.5854 - auc: 0.7279 - prc: 0.4768 - val_loss: 0.5949 - val_tp: 50.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 41.0000 - val_accuracy: 0.7016 - val_precision: 0.3125 - val_recall: 0.5495 - val_auc: 0.6863 - val_prc: 0.4203\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9585 - tp: 245.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 153.0000 - accuracy: 0.7036 - precision: 0.3540 - recall: 0.6156 - auc: 0.7269 - prc: 0.4742 - val_loss: 0.6153 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6865 - val_prc: 0.4216\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9576 - tp: 241.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 157.0000 - accuracy: 0.7001 - precision: 0.3488 - recall: 0.6055 - auc: 0.7275 - prc: 0.4769 - val_loss: 0.5989 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6868 - val_prc: 0.4256\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9577 - tp: 236.0000 - fp: 427.0000 - tn: 1199.0000 - fn: 162.0000 - accuracy: 0.7090 - precision: 0.3560 - recall: 0.5930 - auc: 0.7279 - prc: 0.4779 - val_loss: 0.6003 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6865 - val_prc: 0.4245\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9582 - tp: 232.0000 - fp: 415.0000 - tn: 1211.0000 - fn: 166.0000 - accuracy: 0.7129 - precision: 0.3586 - recall: 0.5829 - auc: 0.7278 - prc: 0.4767 - val_loss: 0.5948 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6860 - val_prc: 0.4229\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9563 - tp: 243.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 155.0000 - accuracy: 0.7001 - precision: 0.3496 - recall: 0.6106 - auc: 0.7287 - prc: 0.4782 - val_loss: 0.6140 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6866 - val_prc: 0.4233\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9565 - tp: 248.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 150.0000 - accuracy: 0.6892 - precision: 0.3411 - recall: 0.6231 - auc: 0.7286 - prc: 0.4775 - val_loss: 0.6026 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6871 - val_prc: 0.4266\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9584 - tp: 227.0000 - fp: 395.0000 - tn: 1231.0000 - fn: 171.0000 - accuracy: 0.7204 - precision: 0.3650 - recall: 0.5704 - auc: 0.7285 - prc: 0.4773 - val_loss: 0.5831 - val_tp: 50.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 41.0000 - val_accuracy: 0.7174 - val_precision: 0.3289 - val_recall: 0.5495 - val_auc: 0.6881 - val_prc: 0.4311\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9576 - tp: 242.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 156.0000 - accuracy: 0.6996 - precision: 0.3487 - recall: 0.6080 - auc: 0.7284 - prc: 0.4734 - val_loss: 0.6234 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6868 - val_prc: 0.4268\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9572 - tp: 255.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 143.0000 - accuracy: 0.6863 - precision: 0.3414 - recall: 0.6407 - auc: 0.7281 - prc: 0.4769 - val_loss: 0.6081 - val_tp: 53.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 38.0000 - val_accuracy: 0.6897 - val_precision: 0.3081 - val_recall: 0.5824 - val_auc: 0.6884 - val_prc: 0.4320\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9564 - tp: 244.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 154.0000 - accuracy: 0.7036 - precision: 0.3536 - recall: 0.6131 - auc: 0.7292 - prc: 0.4768 - val_loss: 0.6017 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6879 - val_prc: 0.4295\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9558 - tp: 245.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 153.0000 - accuracy: 0.7006 - precision: 0.3510 - recall: 0.6156 - auc: 0.7294 - prc: 0.4774 - val_loss: 0.6083 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6869 - val_prc: 0.4272\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9571 - tp: 247.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 151.0000 - accuracy: 0.6897 - precision: 0.3412 - recall: 0.6206 - auc: 0.7283 - prc: 0.4761 - val_loss: 0.6158 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6857 - val_prc: 0.4186\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9556 - tp: 239.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 159.0000 - accuracy: 0.7041 - precision: 0.3520 - recall: 0.6005 - auc: 0.7298 - prc: 0.4784 - val_loss: 0.5923 - val_tp: 50.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 41.0000 - val_accuracy: 0.7055 - val_precision: 0.3165 - val_recall: 0.5495 - val_auc: 0.6857 - val_prc: 0.4196\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9571 - tp: 233.0000 - fp: 416.0000 - tn: 1210.0000 - fn: 165.0000 - accuracy: 0.7129 - precision: 0.3590 - recall: 0.5854 - auc: 0.7290 - prc: 0.4782 - val_loss: 0.6066 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6858 - val_prc: 0.4200\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9559 - tp: 242.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 156.0000 - accuracy: 0.7001 - precision: 0.3492 - recall: 0.6080 - auc: 0.7293 - prc: 0.4786 - val_loss: 0.6027 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6860 - val_prc: 0.4223\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9562 - tp: 246.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 152.0000 - accuracy: 0.6991 - precision: 0.3499 - recall: 0.6181 - auc: 0.7289 - prc: 0.4774 - val_loss: 0.6162 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6859 - val_prc: 0.4199\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9554 - tp: 247.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 151.0000 - accuracy: 0.6971 - precision: 0.3484 - recall: 0.6206 - auc: 0.7295 - prc: 0.4791 - val_loss: 0.6070 - val_tp: 50.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 41.0000 - val_accuracy: 0.6798 - val_precision: 0.2924 - val_recall: 0.5495 - val_auc: 0.6859 - val_prc: 0.4225\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9559 - tp: 245.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 153.0000 - accuracy: 0.7045 - precision: 0.3551 - recall: 0.6156 - auc: 0.7293 - prc: 0.4777 - val_loss: 0.5997 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6884 - val_prc: 0.4301\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9558 - tp: 242.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 156.0000 - accuracy: 0.7050 - precision: 0.3543 - recall: 0.6080 - auc: 0.7295 - prc: 0.4777 - val_loss: 0.6067 - val_tp: 51.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 40.0000 - val_accuracy: 0.6779 - val_precision: 0.2931 - val_recall: 0.5604 - val_auc: 0.6877 - val_prc: 0.4289\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9554 - tp: 244.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 154.0000 - accuracy: 0.7016 - precision: 0.3516 - recall: 0.6131 - auc: 0.7298 - prc: 0.4780 - val_loss: 0.6010 - val_tp: 50.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 41.0000 - val_accuracy: 0.6858 - val_precision: 0.2976 - val_recall: 0.5495 - val_auc: 0.6879 - val_prc: 0.4256\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9559 - tp: 236.0000 - fp: 430.0000 - tn: 1196.0000 - fn: 162.0000 - accuracy: 0.7075 - precision: 0.3544 - recall: 0.5930 - auc: 0.7295 - prc: 0.4768 - val_loss: 0.6021 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6877 - val_prc: 0.4230\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9551 - tp: 246.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 152.0000 - accuracy: 0.7016 - precision: 0.3524 - recall: 0.6181 - auc: 0.7298 - prc: 0.4785 - val_loss: 0.6187 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6867 - val_prc: 0.4213\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9567 - tp: 254.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 144.0000 - accuracy: 0.6759 - precision: 0.3316 - recall: 0.6382 - auc: 0.7295 - prc: 0.4780 - val_loss: 0.6281 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6871 - val_prc: 0.4246\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9582 - tp: 239.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 159.0000 - accuracy: 0.7041 - precision: 0.3520 - recall: 0.6005 - auc: 0.7277 - prc: 0.4719 - val_loss: 0.5870 - val_tp: 50.0000 - val_fp: 104.0000 - val_tn: 311.0000 - val_fn: 41.0000 - val_accuracy: 0.7134 - val_precision: 0.3247 - val_recall: 0.5495 - val_auc: 0.6868 - val_prc: 0.4208\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9561 - tp: 239.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 159.0000 - accuracy: 0.6986 - precision: 0.3464 - recall: 0.6005 - auc: 0.7292 - prc: 0.4781 - val_loss: 0.6282 - val_tp: 53.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 38.0000 - val_accuracy: 0.6522 - val_precision: 0.2775 - val_recall: 0.5824 - val_auc: 0.6857 - val_prc: 0.4196\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9560 - tp: 253.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 145.0000 - accuracy: 0.6863 - precision: 0.3405 - recall: 0.6357 - auc: 0.7294 - prc: 0.4784 - val_loss: 0.6136 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6863 - val_prc: 0.4204\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9551 - tp: 250.0000 - fp: 470.0000 - tn: 1156.0000 - fn: 148.0000 - accuracy: 0.6947 - precision: 0.3472 - recall: 0.6281 - auc: 0.7297 - prc: 0.4784 - val_loss: 0.6172 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6860 - val_prc: 0.4217\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9549 - tp: 248.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 150.0000 - accuracy: 0.6961 - precision: 0.3478 - recall: 0.6231 - auc: 0.7301 - prc: 0.4784 - val_loss: 0.6059 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6860 - val_prc: 0.4204\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9550 - tp: 240.0000 - fp: 450.0000 - tn: 1176.0000 - fn: 158.0000 - accuracy: 0.6996 - precision: 0.3478 - recall: 0.6030 - auc: 0.7302 - prc: 0.4791 - val_loss: 0.6066 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6858 - val_prc: 0.4186\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9545 - tp: 246.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 152.0000 - accuracy: 0.6917 - precision: 0.3426 - recall: 0.6181 - auc: 0.7306 - prc: 0.4795 - val_loss: 0.6274 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6860 - val_prc: 0.4212\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9561 - tp: 256.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 142.0000 - accuracy: 0.6793 - precision: 0.3355 - recall: 0.6432 - auc: 0.7302 - prc: 0.4792 - val_loss: 0.6312 - val_tp: 54.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 37.0000 - val_accuracy: 0.6542 - val_precision: 0.2812 - val_recall: 0.5934 - val_auc: 0.6858 - val_prc: 0.4208\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9561 - tp: 251.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 147.0000 - accuracy: 0.6873 - precision: 0.3406 - recall: 0.6307 - auc: 0.7301 - prc: 0.4775 - val_loss: 0.6190 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6878 - val_prc: 0.4289\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9558 - tp: 255.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 143.0000 - accuracy: 0.6848 - precision: 0.3400 - recall: 0.6407 - auc: 0.7300 - prc: 0.4778 - val_loss: 0.6168 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6882 - val_prc: 0.4312\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9557 - tp: 242.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 156.0000 - accuracy: 0.7031 - precision: 0.3523 - recall: 0.6080 - auc: 0.7294 - prc: 0.4758 - val_loss: 0.5992 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6882 - val_prc: 0.4308\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9548 - tp: 245.0000 - fp: 447.0000 - tn: 1179.0000 - fn: 153.0000 - accuracy: 0.7036 - precision: 0.3540 - recall: 0.6156 - auc: 0.7300 - prc: 0.4774 - val_loss: 0.6067 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6876 - val_prc: 0.4237\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9544 - tp: 251.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 147.0000 - accuracy: 0.6942 - precision: 0.3472 - recall: 0.6307 - auc: 0.7307 - prc: 0.4788 - val_loss: 0.6247 - val_tp: 53.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 38.0000 - val_accuracy: 0.6621 - val_precision: 0.2849 - val_recall: 0.5824 - val_auc: 0.6857 - val_prc: 0.4126\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9548 - tp: 251.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 147.0000 - accuracy: 0.6892 - precision: 0.3424 - recall: 0.6307 - auc: 0.7304 - prc: 0.4785 - val_loss: 0.6137 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6857 - val_prc: 0.4160\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9545 - tp: 243.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 155.0000 - accuracy: 0.6971 - precision: 0.3466 - recall: 0.6106 - auc: 0.7303 - prc: 0.4788 - val_loss: 0.6105 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6855 - val_prc: 0.4173\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9545 - tp: 245.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 153.0000 - accuracy: 0.6996 - precision: 0.3500 - recall: 0.6156 - auc: 0.7306 - prc: 0.4784 - val_loss: 0.5987 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6863 - val_prc: 0.4202\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9556 - tp: 231.0000 - fp: 397.0000 - tn: 1229.0000 - fn: 167.0000 - accuracy: 0.7213 - precision: 0.3678 - recall: 0.5804 - auc: 0.7303 - prc: 0.4795 - val_loss: 0.5912 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6877 - val_prc: 0.4243\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9548 - tp: 237.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 161.0000 - accuracy: 0.7120 - precision: 0.3596 - recall: 0.5955 - auc: 0.7305 - prc: 0.4789 - val_loss: 0.6178 - val_tp: 52.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 39.0000 - val_accuracy: 0.6660 - val_precision: 0.2857 - val_recall: 0.5714 - val_auc: 0.6883 - val_prc: 0.4271\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9544 - tp: 252.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 146.0000 - accuracy: 0.6907 - precision: 0.3443 - recall: 0.6332 - auc: 0.7306 - prc: 0.4781 - val_loss: 0.6233 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6875 - val_prc: 0.4260\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9543 - tp: 252.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 146.0000 - accuracy: 0.6887 - precision: 0.3424 - recall: 0.6332 - auc: 0.7307 - prc: 0.4785 - val_loss: 0.6123 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6878 - val_prc: 0.4259\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9547 - tp: 237.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 161.0000 - accuracy: 0.7060 - precision: 0.3532 - recall: 0.5955 - auc: 0.7308 - prc: 0.4783 - val_loss: 0.5918 - val_tp: 50.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 41.0000 - val_accuracy: 0.7095 - val_precision: 0.3205 - val_recall: 0.5495 - val_auc: 0.6888 - val_prc: 0.4284\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9549 - tp: 245.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 153.0000 - accuracy: 0.6996 - precision: 0.3500 - recall: 0.6156 - auc: 0.7304 - prc: 0.4776 - val_loss: 0.6127 - val_tp: 52.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 39.0000 - val_accuracy: 0.6680 - val_precision: 0.2873 - val_recall: 0.5714 - val_auc: 0.6894 - val_prc: 0.4366\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9547 - tp: 246.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 152.0000 - accuracy: 0.6991 - precision: 0.3499 - recall: 0.6181 - auc: 0.7301 - prc: 0.4772 - val_loss: 0.6004 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6887 - val_prc: 0.4287\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9554 - tp: 244.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 154.0000 - accuracy: 0.6991 - precision: 0.3491 - recall: 0.6131 - auc: 0.7297 - prc: 0.4757 - val_loss: 0.6131 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6874 - val_prc: 0.4227\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9563 - tp: 231.0000 - fp: 419.0000 - tn: 1207.0000 - fn: 167.0000 - accuracy: 0.7105 - precision: 0.3554 - recall: 0.5804 - auc: 0.7291 - prc: 0.4753 - val_loss: 0.5950 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6882 - val_prc: 0.4291\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9544 - tp: 247.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 151.0000 - accuracy: 0.7011 - precision: 0.3524 - recall: 0.6206 - auc: 0.7302 - prc: 0.4791 - val_loss: 0.6210 - val_tp: 52.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 39.0000 - val_accuracy: 0.6542 - val_precision: 0.2766 - val_recall: 0.5714 - val_auc: 0.6883 - val_prc: 0.4239\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9540 - tp: 252.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 146.0000 - accuracy: 0.6912 - precision: 0.3447 - recall: 0.6332 - auc: 0.7309 - prc: 0.4787 - val_loss: 0.6104 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6892 - val_prc: 0.4278\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9552 - tp: 236.0000 - fp: 420.0000 - tn: 1206.0000 - fn: 162.0000 - accuracy: 0.7125 - precision: 0.3598 - recall: 0.5930 - auc: 0.7302 - prc: 0.4771 - val_loss: 0.5938 - val_tp: 50.0000 - val_fp: 112.0000 - val_tn: 303.0000 - val_fn: 41.0000 - val_accuracy: 0.6976 - val_precision: 0.3086 - val_recall: 0.5495 - val_auc: 0.6897 - val_prc: 0.4253\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9540 - tp: 240.0000 - fp: 438.0000 - tn: 1188.0000 - fn: 158.0000 - accuracy: 0.7055 - precision: 0.3540 - recall: 0.6030 - auc: 0.7311 - prc: 0.4793 - val_loss: 0.6110 - val_tp: 50.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 41.0000 - val_accuracy: 0.6739 - val_precision: 0.2874 - val_recall: 0.5495 - val_auc: 0.6900 - val_prc: 0.4219\n",
      "Epoch 268/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9541 - tp: 247.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 151.0000 - accuracy: 0.6986 - precision: 0.3499 - recall: 0.6206 - auc: 0.7308 - prc: 0.4786 - val_loss: 0.6126 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6900 - val_prc: 0.4228\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9539 - tp: 250.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 148.0000 - accuracy: 0.6922 - precision: 0.3448 - recall: 0.6281 - auc: 0.7313 - prc: 0.4775 - val_loss: 0.6122 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6892 - val_prc: 0.4259\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9536 - tp: 238.0000 - fp: 434.0000 - tn: 1192.0000 - fn: 160.0000 - accuracy: 0.7065 - precision: 0.3542 - recall: 0.5980 - auc: 0.7312 - prc: 0.4792 - val_loss: 0.5937 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6876 - val_prc: 0.4222\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9537 - tp: 235.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 163.0000 - accuracy: 0.7080 - precision: 0.3544 - recall: 0.5905 - auc: 0.7316 - prc: 0.4787 - val_loss: 0.6177 - val_tp: 52.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 39.0000 - val_accuracy: 0.6660 - val_precision: 0.2857 - val_recall: 0.5714 - val_auc: 0.6873 - val_prc: 0.4223\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9574 - tp: 259.0000 - fp: 543.0000 - tn: 1083.0000 - fn: 139.0000 - accuracy: 0.6630 - precision: 0.3229 - recall: 0.6508 - auc: 0.7305 - prc: 0.4776 - val_loss: 0.6481 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.6864 - val_prc: 0.4217\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9545 - tp: 254.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 144.0000 - accuracy: 0.6892 - precision: 0.3437 - recall: 0.6382 - auc: 0.7309 - prc: 0.4779 - val_loss: 0.6045 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6870 - val_prc: 0.4207\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9533 - tp: 247.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 151.0000 - accuracy: 0.7011 - precision: 0.3524 - recall: 0.6206 - auc: 0.7313 - prc: 0.4792 - val_loss: 0.6151 - val_tp: 52.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 39.0000 - val_accuracy: 0.6640 - val_precision: 0.2842 - val_recall: 0.5714 - val_auc: 0.6875 - val_prc: 0.4221\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9534 - tp: 250.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 148.0000 - accuracy: 0.6937 - precision: 0.3463 - recall: 0.6281 - auc: 0.7311 - prc: 0.4791 - val_loss: 0.6201 - val_tp: 52.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 39.0000 - val_accuracy: 0.6581 - val_precision: 0.2796 - val_recall: 0.5714 - val_auc: 0.6865 - val_prc: 0.4199\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9530 - tp: 251.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 147.0000 - accuracy: 0.6922 - precision: 0.3453 - recall: 0.6307 - auc: 0.7317 - prc: 0.4797 - val_loss: 0.6151 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6874 - val_prc: 0.4148\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9539 - tp: 246.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 152.0000 - accuracy: 0.6947 - precision: 0.3455 - recall: 0.6181 - auc: 0.7308 - prc: 0.4794 - val_loss: 0.6138 - val_tp: 50.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 41.0000 - val_accuracy: 0.6719 - val_precision: 0.2857 - val_recall: 0.5495 - val_auc: 0.6870 - val_prc: 0.4078\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9548 - tp: 254.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 144.0000 - accuracy: 0.6838 - precision: 0.3387 - recall: 0.6382 - auc: 0.7308 - prc: 0.4780 - val_loss: 0.6269 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6867 - val_prc: 0.4133\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9521 - tp: 238.0000 - fp: 428.0000 - tn: 1198.0000 - fn: 160.0000 - accuracy: 0.7095 - precision: 0.3574 - recall: 0.5980 - auc: 0.7331 - prc: 0.4796 - val_loss: 0.5800 - val_tp: 50.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 41.0000 - val_accuracy: 0.7194 - val_precision: 0.3311 - val_recall: 0.5495 - val_auc: 0.6878 - val_prc: 0.4206\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9562 - tp: 220.0000 - fp: 356.0000 - tn: 1270.0000 - fn: 178.0000 - accuracy: 0.7362 - precision: 0.3819 - recall: 0.5528 - auc: 0.7321 - prc: 0.4802 - val_loss: 0.5941 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6889 - val_prc: 0.4241\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9552 - tp: 254.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 144.0000 - accuracy: 0.6848 - precision: 0.3396 - recall: 0.6382 - auc: 0.7310 - prc: 0.4751 - val_loss: 0.6429 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6893 - val_prc: 0.4292\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9545 - tp: 252.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 146.0000 - accuracy: 0.6882 - precision: 0.3419 - recall: 0.6332 - auc: 0.7307 - prc: 0.4749 - val_loss: 0.6040 - val_tp: 50.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 41.0000 - val_accuracy: 0.6838 - val_precision: 0.2959 - val_recall: 0.5495 - val_auc: 0.6897 - val_prc: 0.4291\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9542 - tp: 252.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 146.0000 - accuracy: 0.6907 - precision: 0.3443 - recall: 0.6332 - auc: 0.7307 - prc: 0.4785 - val_loss: 0.6172 - val_tp: 52.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 39.0000 - val_accuracy: 0.6640 - val_precision: 0.2842 - val_recall: 0.5714 - val_auc: 0.6891 - val_prc: 0.4272\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9531 - tp: 240.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 158.0000 - accuracy: 0.7021 - precision: 0.3504 - recall: 0.6030 - auc: 0.7317 - prc: 0.4794 - val_loss: 0.5960 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6889 - val_prc: 0.4266\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9526 - tp: 248.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 150.0000 - accuracy: 0.6986 - precision: 0.3503 - recall: 0.6231 - auc: 0.7323 - prc: 0.4794 - val_loss: 0.6318 - val_tp: 53.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 38.0000 - val_accuracy: 0.6462 - val_precision: 0.2732 - val_recall: 0.5824 - val_auc: 0.6873 - val_prc: 0.4198\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9533 - tp: 250.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 148.0000 - accuracy: 0.6892 - precision: 0.3420 - recall: 0.6281 - auc: 0.7314 - prc: 0.4794 - val_loss: 0.6102 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6873 - val_prc: 0.4205\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9546 - tp: 253.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 145.0000 - accuracy: 0.6868 - precision: 0.3410 - recall: 0.6357 - auc: 0.7306 - prc: 0.4776 - val_loss: 0.6217 - val_tp: 52.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 39.0000 - val_accuracy: 0.6621 - val_precision: 0.2826 - val_recall: 0.5714 - val_auc: 0.6870 - val_prc: 0.4158\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9526 - tp: 250.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 148.0000 - accuracy: 0.6917 - precision: 0.3444 - recall: 0.6281 - auc: 0.7322 - prc: 0.4805 - val_loss: 0.6082 - val_tp: 50.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 41.0000 - val_accuracy: 0.6818 - val_precision: 0.2941 - val_recall: 0.5495 - val_auc: 0.6869 - val_prc: 0.4141\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9540 - tp: 238.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 160.0000 - accuracy: 0.7115 - precision: 0.3595 - recall: 0.5980 - auc: 0.7316 - prc: 0.4791 - val_loss: 0.5985 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6885 - val_prc: 0.4207\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9540 - tp: 247.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 151.0000 - accuracy: 0.6907 - precision: 0.3421 - recall: 0.6206 - auc: 0.7308 - prc: 0.4780 - val_loss: 0.6334 - val_tp: 53.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 38.0000 - val_accuracy: 0.6403 - val_precision: 0.2690 - val_recall: 0.5824 - val_auc: 0.6876 - val_prc: 0.4224\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9529 - tp: 252.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 146.0000 - accuracy: 0.6863 - precision: 0.3401 - recall: 0.6332 - auc: 0.7322 - prc: 0.4800 - val_loss: 0.6094 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6879 - val_prc: 0.4221\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9528 - tp: 241.0000 - fp: 426.0000 - tn: 1200.0000 - fn: 157.0000 - accuracy: 0.7120 - precision: 0.3613 - recall: 0.6055 - auc: 0.7320 - prc: 0.4810 - val_loss: 0.5926 - val_tp: 50.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 41.0000 - val_accuracy: 0.7036 - val_precision: 0.3145 - val_recall: 0.5495 - val_auc: 0.6882 - val_prc: 0.4203\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9551 - tp: 227.0000 - fp: 386.0000 - tn: 1240.0000 - fn: 171.0000 - accuracy: 0.7248 - precision: 0.3703 - recall: 0.5704 - auc: 0.7314 - prc: 0.4790 - val_loss: 0.6036 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6874 - val_prc: 0.4144\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9545 - tp: 258.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 140.0000 - accuracy: 0.6848 - precision: 0.3413 - recall: 0.6482 - auc: 0.7306 - prc: 0.4801 - val_loss: 0.6383 - val_tp: 53.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 38.0000 - val_accuracy: 0.6403 - val_precision: 0.2690 - val_recall: 0.5824 - val_auc: 0.6867 - val_prc: 0.4081\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9547 - tp: 250.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 148.0000 - accuracy: 0.6942 - precision: 0.3467 - recall: 0.6281 - auc: 0.7301 - prc: 0.4777 - val_loss: 0.6110 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6878 - val_prc: 0.4141\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9547 - tp: 257.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 141.0000 - accuracy: 0.6833 - precision: 0.3395 - recall: 0.6457 - auc: 0.7310 - prc: 0.4796 - val_loss: 0.6381 - val_tp: 54.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 37.0000 - val_accuracy: 0.6423 - val_precision: 0.2727 - val_recall: 0.5934 - val_auc: 0.6868 - val_prc: 0.4079\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9541 - tp: 258.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 140.0000 - accuracy: 0.6803 - precision: 0.3373 - recall: 0.6482 - auc: 0.7315 - prc: 0.4797 - val_loss: 0.6167 - val_tp: 52.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 39.0000 - val_accuracy: 0.6700 - val_precision: 0.2889 - val_recall: 0.5714 - val_auc: 0.6867 - val_prc: 0.4085\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9524 - tp: 251.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 147.0000 - accuracy: 0.6927 - precision: 0.3457 - recall: 0.6307 - auc: 0.7319 - prc: 0.4801 - val_loss: 0.6090 - val_tp: 50.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 41.0000 - val_accuracy: 0.6798 - val_precision: 0.2924 - val_recall: 0.5495 - val_auc: 0.6871 - val_prc: 0.4102\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9525 - tp: 242.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 156.0000 - accuracy: 0.7055 - precision: 0.3548 - recall: 0.6080 - auc: 0.7318 - prc: 0.4804 - val_loss: 0.6056 - val_tp: 50.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 41.0000 - val_accuracy: 0.6818 - val_precision: 0.2941 - val_recall: 0.5495 - val_auc: 0.6866 - val_prc: 0.4156\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9519 - tp: 248.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 150.0000 - accuracy: 0.6986 - precision: 0.3503 - recall: 0.6231 - auc: 0.7327 - prc: 0.4807 - val_loss: 0.6218 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6874 - val_prc: 0.4201\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9533 - tp: 248.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 150.0000 - accuracy: 0.6971 - precision: 0.3488 - recall: 0.6231 - auc: 0.7315 - prc: 0.4787 - val_loss: 0.6150 - val_tp: 52.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 39.0000 - val_accuracy: 0.6700 - val_precision: 0.2889 - val_recall: 0.5714 - val_auc: 0.6873 - val_prc: 0.4209\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9526 - tp: 252.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 146.0000 - accuracy: 0.6902 - precision: 0.3438 - recall: 0.6332 - auc: 0.7321 - prc: 0.4802 - val_loss: 0.6295 - val_tp: 52.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 39.0000 - val_accuracy: 0.6482 - val_precision: 0.2723 - val_recall: 0.5714 - val_auc: 0.6866 - val_prc: 0.4137\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9542 - tp: 253.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 145.0000 - accuracy: 0.6942 - precision: 0.3480 - recall: 0.6357 - auc: 0.7310 - prc: 0.4783 - val_loss: 0.6148 - val_tp: 52.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 39.0000 - val_accuracy: 0.6700 - val_precision: 0.2889 - val_recall: 0.5714 - val_auc: 0.6881 - val_prc: 0.4207\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9523 - tp: 252.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 146.0000 - accuracy: 0.6937 - precision: 0.3471 - recall: 0.6332 - auc: 0.7322 - prc: 0.4804 - val_loss: 0.6185 - val_tp: 52.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 39.0000 - val_accuracy: 0.6640 - val_precision: 0.2842 - val_recall: 0.5714 - val_auc: 0.6885 - val_prc: 0.4193\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9522 - tp: 251.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 147.0000 - accuracy: 0.6942 - precision: 0.3472 - recall: 0.6307 - auc: 0.7324 - prc: 0.4801 - val_loss: 0.6150 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6877 - val_prc: 0.4095\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9521 - tp: 247.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 151.0000 - accuracy: 0.7016 - precision: 0.3529 - recall: 0.6206 - auc: 0.7322 - prc: 0.4798 - val_loss: 0.6004 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6880 - val_prc: 0.4160\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9530 - tp: 241.0000 - fp: 437.0000 - tn: 1189.0000 - fn: 157.0000 - accuracy: 0.7065 - precision: 0.3555 - recall: 0.6055 - auc: 0.7318 - prc: 0.4805 - val_loss: 0.6024 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6863 - val_prc: 0.4101\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9532 - tp: 229.0000 - fp: 394.0000 - tn: 1232.0000 - fn: 169.0000 - accuracy: 0.7218 - precision: 0.3676 - recall: 0.5754 - auc: 0.7324 - prc: 0.4817 - val_loss: 0.5908 - val_tp: 50.0000 - val_fp: 107.0000 - val_tn: 308.0000 - val_fn: 41.0000 - val_accuracy: 0.7075 - val_precision: 0.3185 - val_recall: 0.5495 - val_auc: 0.6867 - val_prc: 0.4087\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9522 - tp: 247.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 151.0000 - accuracy: 0.6976 - precision: 0.3489 - recall: 0.6206 - auc: 0.7320 - prc: 0.4782 - val_loss: 0.6443 - val_tp: 56.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 35.0000 - val_accuracy: 0.6364 - val_precision: 0.2732 - val_recall: 0.6154 - val_auc: 0.6863 - val_prc: 0.4082\n",
      "Epoch 310/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 1.0221 - tp: 29.0000 - fp: 55.0000 - tn: 101.0000 - fn: 15.0000 - accuracy: 0.6500 - precision: 0.3452 - recall: 0.6591 - auc: 0.7182 - prc: 0.4546Restoring model weights from the end of the best epoch: 260.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9539 - tp: 256.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 142.0000 - accuracy: 0.6803 - precision: 0.3364 - recall: 0.6432 - auc: 0.7320 - prc: 0.4799 - val_loss: 0.6155 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6876 - val_prc: 0.4189\n",
      "Epoch 310: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 32ms/step - loss: 1.6242 - tp: 52.0000 - fp: 127.0000 - tn: 1914.0000 - fn: 437.0000 - accuracy: 0.7771 - precision: 0.2905 - recall: 0.1063 - auc: 0.4937 - prc: 0.2317 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5143 - val_prc: 0.1844\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5043 - prc: 0.2017 - val_loss: 0.4728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4906 - val_prc: 0.1746\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5865 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5047 - prc: 0.1992 - val_loss: 0.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5042 - val_prc: 0.1944\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5629 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5654 - prc: 0.2506 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5465 - val_prc: 0.2052\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5363 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5732 - prc: 0.2529 - val_loss: 0.4763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5947 - val_prc: 0.2481\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5038 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6427 - prc: 0.3329 - val_loss: 0.4787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6092 - val_prc: 0.2648\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.4705 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6312 - prc: 0.3185 - val_loss: 0.4824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6265 - val_prc: 0.2676\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6563 - prc: 0.3295 - val_loss: 0.4880 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6372 - val_prc: 0.2803\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3887 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6581 - prc: 0.3276 - val_loss: 0.4967 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6378 - val_prc: 0.2766\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3376 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6563 - prc: 0.3434 - val_loss: 0.5105 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6420 - val_prc: 0.2852\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6799 - prc: 0.3583 - val_loss: 0.5316 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6407 - val_prc: 0.2763\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2269 - tp: 1.0000 - fp: 3.0000 - tn: 1623.0000 - fn: 397.0000 - accuracy: 0.8024 - precision: 0.2500 - recall: 0.0025 - auc: 0.6658 - prc: 0.3318 - val_loss: 0.5641 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 90.0000 - val_accuracy: 0.8182 - val_precision: 0.3333 - val_recall: 0.0110 - val_auc: 0.6465 - val_prc: 0.2735\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1776 - tp: 18.0000 - fp: 15.0000 - tn: 1611.0000 - fn: 380.0000 - accuracy: 0.8048 - precision: 0.5455 - recall: 0.0452 - auc: 0.6747 - prc: 0.3378 - val_loss: 0.6070 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 83.0000 - val_accuracy: 0.8083 - val_precision: 0.3636 - val_recall: 0.0879 - val_auc: 0.6489 - val_prc: 0.2745\n",
      "Epoch 14/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1352 - tp: 128.0000 - fp: 174.0000 - tn: 1452.0000 - fn: 270.0000 - accuracy: 0.7806 - precision: 0.4238 - recall: 0.3216 - auc: 0.6852 - prc: 0.3655 - val_loss: 0.6659 - val_tp: 48.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 43.0000 - val_accuracy: 0.6759 - val_precision: 0.2840 - val_recall: 0.5275 - val_auc: 0.6494 - val_prc: 0.2764\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1195 - tp: 279.0000 - fp: 695.0000 - tn: 931.0000 - fn: 119.0000 - accuracy: 0.5978 - precision: 0.2864 - recall: 0.7010 - auc: 0.6855 - prc: 0.3639 - val_loss: 0.7087 - val_tp: 71.0000 - val_fp: 252.0000 - val_tn: 163.0000 - val_fn: 20.0000 - val_accuracy: 0.4625 - val_precision: 0.2198 - val_recall: 0.7802 - val_auc: 0.6522 - val_prc: 0.2793\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1165 - tp: 343.0000 - fp: 1117.0000 - tn: 509.0000 - fn: 55.0000 - accuracy: 0.4209 - precision: 0.2349 - recall: 0.8618 - auc: 0.6876 - prc: 0.3679 - val_loss: 0.7358 - val_tp: 79.0000 - val_fp: 304.0000 - val_tn: 111.0000 - val_fn: 12.0000 - val_accuracy: 0.3755 - val_precision: 0.2063 - val_recall: 0.8681 - val_auc: 0.6514 - val_prc: 0.2796\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1159 - tp: 356.0000 - fp: 1242.0000 - tn: 384.0000 - fn: 42.0000 - accuracy: 0.3656 - precision: 0.2228 - recall: 0.8945 - auc: 0.6914 - prc: 0.3743 - val_loss: 0.7388 - val_tp: 78.0000 - val_fp: 311.0000 - val_tn: 104.0000 - val_fn: 13.0000 - val_accuracy: 0.3597 - val_precision: 0.2005 - val_recall: 0.8571 - val_auc: 0.6510 - val_prc: 0.2818\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1149 - tp: 353.0000 - fp: 1187.0000 - tn: 439.0000 - fn: 45.0000 - accuracy: 0.3913 - precision: 0.2292 - recall: 0.8869 - auc: 0.6903 - prc: 0.3754 - val_loss: 0.7264 - val_tp: 77.0000 - val_fp: 284.0000 - val_tn: 131.0000 - val_fn: 14.0000 - val_accuracy: 0.4111 - val_precision: 0.2133 - val_recall: 0.8462 - val_auc: 0.6533 - val_prc: 0.2845\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1136 - tp: 344.0000 - fp: 1136.0000 - tn: 490.0000 - fn: 54.0000 - accuracy: 0.4121 - precision: 0.2324 - recall: 0.8643 - auc: 0.6915 - prc: 0.3779 - val_loss: 0.7203 - val_tp: 74.0000 - val_fp: 273.0000 - val_tn: 142.0000 - val_fn: 17.0000 - val_accuracy: 0.4269 - val_precision: 0.2133 - val_recall: 0.8132 - val_auc: 0.6551 - val_prc: 0.2888\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1129 - tp: 326.0000 - fp: 993.0000 - tn: 633.0000 - fn: 72.0000 - accuracy: 0.4738 - precision: 0.2472 - recall: 0.8191 - auc: 0.6915 - prc: 0.3778 - val_loss: 0.7017 - val_tp: 71.0000 - val_fp: 237.0000 - val_tn: 178.0000 - val_fn: 20.0000 - val_accuracy: 0.4921 - val_precision: 0.2305 - val_recall: 0.7802 - val_auc: 0.6548 - val_prc: 0.2886\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1127 - tp: 314.0000 - fp: 956.0000 - tn: 670.0000 - fn: 84.0000 - accuracy: 0.4862 - precision: 0.2472 - recall: 0.7889 - auc: 0.6906 - prc: 0.3770 - val_loss: 0.7103 - val_tp: 71.0000 - val_fp: 249.0000 - val_tn: 166.0000 - val_fn: 20.0000 - val_accuracy: 0.4684 - val_precision: 0.2219 - val_recall: 0.7802 - val_auc: 0.6548 - val_prc: 0.2893\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1118 - tp: 316.0000 - fp: 951.0000 - tn: 675.0000 - fn: 82.0000 - accuracy: 0.4896 - precision: 0.2494 - recall: 0.7940 - auc: 0.6919 - prc: 0.3804 - val_loss: 0.7058 - val_tp: 71.0000 - val_fp: 243.0000 - val_tn: 172.0000 - val_fn: 20.0000 - val_accuracy: 0.4802 - val_precision: 0.2261 - val_recall: 0.7802 - val_auc: 0.6571 - val_prc: 0.2910\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1112 - tp: 313.0000 - fp: 946.0000 - tn: 680.0000 - fn: 85.0000 - accuracy: 0.4906 - precision: 0.2486 - recall: 0.7864 - auc: 0.6928 - prc: 0.3798 - val_loss: 0.7094 - val_tp: 71.0000 - val_fp: 248.0000 - val_tn: 167.0000 - val_fn: 20.0000 - val_accuracy: 0.4704 - val_precision: 0.2226 - val_recall: 0.7802 - val_auc: 0.6583 - val_prc: 0.2940\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1103 - tp: 326.0000 - fp: 1006.0000 - tn: 620.0000 - fn: 72.0000 - accuracy: 0.4674 - precision: 0.2447 - recall: 0.8191 - auc: 0.6930 - prc: 0.3831 - val_loss: 0.7169 - val_tp: 73.0000 - val_fp: 258.0000 - val_tn: 157.0000 - val_fn: 18.0000 - val_accuracy: 0.4545 - val_precision: 0.2205 - val_recall: 0.8022 - val_auc: 0.6572 - val_prc: 0.2914\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1102 - tp: 342.0000 - fp: 1103.0000 - tn: 523.0000 - fn: 56.0000 - accuracy: 0.4274 - precision: 0.2367 - recall: 0.8593 - auc: 0.6923 - prc: 0.3818 - val_loss: 0.7277 - val_tp: 77.0000 - val_fp: 281.0000 - val_tn: 134.0000 - val_fn: 14.0000 - val_accuracy: 0.4170 - val_precision: 0.2151 - val_recall: 0.8462 - val_auc: 0.6565 - val_prc: 0.2924\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1095 - tp: 344.0000 - fp: 1131.0000 - tn: 495.0000 - fn: 54.0000 - accuracy: 0.4145 - precision: 0.2332 - recall: 0.8643 - auc: 0.6936 - prc: 0.3827 - val_loss: 0.7254 - val_tp: 76.0000 - val_fp: 279.0000 - val_tn: 136.0000 - val_fn: 15.0000 - val_accuracy: 0.4190 - val_precision: 0.2141 - val_recall: 0.8352 - val_auc: 0.6592 - val_prc: 0.2945\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1088 - tp: 334.0000 - fp: 1072.0000 - tn: 554.0000 - fn: 64.0000 - accuracy: 0.4387 - precision: 0.2376 - recall: 0.8392 - auc: 0.6933 - prc: 0.3826 - val_loss: 0.7122 - val_tp: 72.0000 - val_fp: 251.0000 - val_tn: 164.0000 - val_fn: 19.0000 - val_accuracy: 0.4664 - val_precision: 0.2229 - val_recall: 0.7912 - val_auc: 0.6589 - val_prc: 0.2948\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1081 - tp: 318.0000 - fp: 966.0000 - tn: 660.0000 - fn: 80.0000 - accuracy: 0.4832 - precision: 0.2477 - recall: 0.7990 - auc: 0.6938 - prc: 0.3849 - val_loss: 0.7064 - val_tp: 71.0000 - val_fp: 244.0000 - val_tn: 171.0000 - val_fn: 20.0000 - val_accuracy: 0.4783 - val_precision: 0.2254 - val_recall: 0.7802 - val_auc: 0.6585 - val_prc: 0.2955\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1076 - tp: 318.0000 - fp: 942.0000 - tn: 684.0000 - fn: 80.0000 - accuracy: 0.4951 - precision: 0.2524 - recall: 0.7990 - auc: 0.6931 - prc: 0.3850 - val_loss: 0.7066 - val_tp: 71.0000 - val_fp: 244.0000 - val_tn: 171.0000 - val_fn: 20.0000 - val_accuracy: 0.4783 - val_precision: 0.2254 - val_recall: 0.7802 - val_auc: 0.6587 - val_prc: 0.2960\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1068 - tp: 323.0000 - fp: 974.0000 - tn: 652.0000 - fn: 75.0000 - accuracy: 0.4817 - precision: 0.2490 - recall: 0.8116 - auc: 0.6949 - prc: 0.3855 - val_loss: 0.7124 - val_tp: 73.0000 - val_fp: 249.0000 - val_tn: 166.0000 - val_fn: 18.0000 - val_accuracy: 0.4723 - val_precision: 0.2267 - val_recall: 0.8022 - val_auc: 0.6594 - val_prc: 0.2958\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1061 - tp: 331.0000 - fp: 1020.0000 - tn: 606.0000 - fn: 67.0000 - accuracy: 0.4629 - precision: 0.2450 - recall: 0.8317 - auc: 0.6952 - prc: 0.3866 - val_loss: 0.7131 - val_tp: 73.0000 - val_fp: 249.0000 - val_tn: 166.0000 - val_fn: 18.0000 - val_accuracy: 0.4723 - val_precision: 0.2267 - val_recall: 0.8022 - val_auc: 0.6602 - val_prc: 0.2973\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1055 - tp: 315.0000 - fp: 945.0000 - tn: 681.0000 - fn: 83.0000 - accuracy: 0.4921 - precision: 0.2500 - recall: 0.7915 - auc: 0.6944 - prc: 0.3875 - val_loss: 0.7029 - val_tp: 70.0000 - val_fp: 236.0000 - val_tn: 179.0000 - val_fn: 21.0000 - val_accuracy: 0.4921 - val_precision: 0.2288 - val_recall: 0.7692 - val_auc: 0.6607 - val_prc: 0.2988\n",
      "Epoch 33/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1057 - tp: 328.0000 - fp: 1006.0000 - tn: 620.0000 - fn: 70.0000 - accuracy: 0.4684 - precision: 0.2459 - recall: 0.8241 - auc: 0.6933 - prc: 0.3869 - val_loss: 0.7193 - val_tp: 73.0000 - val_fp: 259.0000 - val_tn: 156.0000 - val_fn: 18.0000 - val_accuracy: 0.4526 - val_precision: 0.2199 - val_recall: 0.8022 - val_auc: 0.6610 - val_prc: 0.2989\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1044 - tp: 313.0000 - fp: 953.0000 - tn: 673.0000 - fn: 85.0000 - accuracy: 0.4872 - precision: 0.2472 - recall: 0.7864 - auc: 0.6947 - prc: 0.3893 - val_loss: 0.6990 - val_tp: 67.0000 - val_fp: 233.0000 - val_tn: 182.0000 - val_fn: 24.0000 - val_accuracy: 0.4921 - val_precision: 0.2233 - val_recall: 0.7363 - val_auc: 0.6605 - val_prc: 0.2993\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1045 - tp: 324.0000 - fp: 974.0000 - tn: 652.0000 - fn: 74.0000 - accuracy: 0.4822 - precision: 0.2496 - recall: 0.8141 - auc: 0.6935 - prc: 0.3870 - val_loss: 0.7206 - val_tp: 74.0000 - val_fp: 259.0000 - val_tn: 156.0000 - val_fn: 17.0000 - val_accuracy: 0.4545 - val_precision: 0.2222 - val_recall: 0.8132 - val_auc: 0.6618 - val_prc: 0.3016\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1032 - tp: 334.0000 - fp: 1044.0000 - tn: 582.0000 - fn: 64.0000 - accuracy: 0.4526 - precision: 0.2424 - recall: 0.8392 - auc: 0.6957 - prc: 0.3920 - val_loss: 0.7183 - val_tp: 73.0000 - val_fp: 255.0000 - val_tn: 160.0000 - val_fn: 18.0000 - val_accuracy: 0.4605 - val_precision: 0.2226 - val_recall: 0.8022 - val_auc: 0.6613 - val_prc: 0.3019\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1026 - tp: 330.0000 - fp: 1011.0000 - tn: 615.0000 - fn: 68.0000 - accuracy: 0.4669 - precision: 0.2461 - recall: 0.8291 - auc: 0.6964 - prc: 0.3907 - val_loss: 0.7151 - val_tp: 73.0000 - val_fp: 249.0000 - val_tn: 166.0000 - val_fn: 18.0000 - val_accuracy: 0.4723 - val_precision: 0.2267 - val_recall: 0.8022 - val_auc: 0.6621 - val_prc: 0.3020\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1023 - tp: 338.0000 - fp: 1071.0000 - tn: 555.0000 - fn: 60.0000 - accuracy: 0.4412 - precision: 0.2399 - recall: 0.8492 - auc: 0.6952 - prc: 0.3904 - val_loss: 0.7264 - val_tp: 76.0000 - val_fp: 269.0000 - val_tn: 146.0000 - val_fn: 15.0000 - val_accuracy: 0.4387 - val_precision: 0.2203 - val_recall: 0.8352 - val_auc: 0.6630 - val_prc: 0.3039\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1018 - tp: 343.0000 - fp: 1099.0000 - tn: 527.0000 - fn: 55.0000 - accuracy: 0.4298 - precision: 0.2379 - recall: 0.8618 - auc: 0.6965 - prc: 0.3928 - val_loss: 0.7251 - val_tp: 76.0000 - val_fp: 266.0000 - val_tn: 149.0000 - val_fn: 15.0000 - val_accuracy: 0.4447 - val_precision: 0.2222 - val_recall: 0.8352 - val_auc: 0.6637 - val_prc: 0.3047\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1007 - tp: 337.0000 - fp: 1068.0000 - tn: 558.0000 - fn: 61.0000 - accuracy: 0.4422 - precision: 0.2399 - recall: 0.8467 - auc: 0.6966 - prc: 0.3940 - val_loss: 0.7172 - val_tp: 73.0000 - val_fp: 252.0000 - val_tn: 163.0000 - val_fn: 18.0000 - val_accuracy: 0.4664 - val_precision: 0.2246 - val_recall: 0.8022 - val_auc: 0.6628 - val_prc: 0.3036\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1000 - tp: 332.0000 - fp: 1021.0000 - tn: 605.0000 - fn: 66.0000 - accuracy: 0.4629 - precision: 0.2454 - recall: 0.8342 - auc: 0.6967 - prc: 0.3945 - val_loss: 0.7137 - val_tp: 72.0000 - val_fp: 248.0000 - val_tn: 167.0000 - val_fn: 19.0000 - val_accuracy: 0.4723 - val_precision: 0.2250 - val_recall: 0.7912 - val_auc: 0.6645 - val_prc: 0.3050\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0992 - tp: 318.0000 - fp: 963.0000 - tn: 663.0000 - fn: 80.0000 - accuracy: 0.4847 - precision: 0.2482 - recall: 0.7990 - auc: 0.6973 - prc: 0.3947 - val_loss: 0.7073 - val_tp: 69.0000 - val_fp: 242.0000 - val_tn: 173.0000 - val_fn: 22.0000 - val_accuracy: 0.4783 - val_precision: 0.2219 - val_recall: 0.7582 - val_auc: 0.6650 - val_prc: 0.3062\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0985 - tp: 320.0000 - fp: 961.0000 - tn: 665.0000 - fn: 78.0000 - accuracy: 0.4867 - precision: 0.2498 - recall: 0.8040 - auc: 0.6971 - prc: 0.3967 - val_loss: 0.7090 - val_tp: 71.0000 - val_fp: 245.0000 - val_tn: 170.0000 - val_fn: 20.0000 - val_accuracy: 0.4763 - val_precision: 0.2247 - val_recall: 0.7802 - val_auc: 0.6644 - val_prc: 0.3063\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0983 - tp: 321.0000 - fp: 992.0000 - tn: 634.0000 - fn: 77.0000 - accuracy: 0.4718 - precision: 0.2445 - recall: 0.8065 - auc: 0.6960 - prc: 0.3965 - val_loss: 0.7110 - val_tp: 71.0000 - val_fp: 245.0000 - val_tn: 170.0000 - val_fn: 20.0000 - val_accuracy: 0.4763 - val_precision: 0.2247 - val_recall: 0.7802 - val_auc: 0.6626 - val_prc: 0.3053\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0969 - tp: 314.0000 - fp: 940.0000 - tn: 686.0000 - fn: 84.0000 - accuracy: 0.4941 - precision: 0.2504 - recall: 0.7889 - auc: 0.6976 - prc: 0.3972 - val_loss: 0.7006 - val_tp: 66.0000 - val_fp: 236.0000 - val_tn: 179.0000 - val_fn: 25.0000 - val_accuracy: 0.4842 - val_precision: 0.2185 - val_recall: 0.7253 - val_auc: 0.6656 - val_prc: 0.3084\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0966 - tp: 302.0000 - fp: 856.0000 - tn: 770.0000 - fn: 96.0000 - accuracy: 0.5296 - precision: 0.2608 - recall: 0.7588 - auc: 0.6978 - prc: 0.3969 - val_loss: 0.6953 - val_tp: 66.0000 - val_fp: 228.0000 - val_tn: 187.0000 - val_fn: 25.0000 - val_accuracy: 0.5000 - val_precision: 0.2245 - val_recall: 0.7253 - val_auc: 0.6646 - val_prc: 0.3077\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0960 - tp: 301.0000 - fp: 853.0000 - tn: 773.0000 - fn: 97.0000 - accuracy: 0.5306 - precision: 0.2608 - recall: 0.7563 - auc: 0.6980 - prc: 0.4004 - val_loss: 0.6977 - val_tp: 66.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 25.0000 - val_accuracy: 0.4941 - val_precision: 0.2222 - val_recall: 0.7253 - val_auc: 0.6634 - val_prc: 0.3064\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0951 - tp: 303.0000 - fp: 873.0000 - tn: 753.0000 - fn: 95.0000 - accuracy: 0.5217 - precision: 0.2577 - recall: 0.7613 - auc: 0.6986 - prc: 0.4005 - val_loss: 0.7063 - val_tp: 69.0000 - val_fp: 242.0000 - val_tn: 173.0000 - val_fn: 22.0000 - val_accuracy: 0.4783 - val_precision: 0.2219 - val_recall: 0.7582 - val_auc: 0.6660 - val_prc: 0.3095\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0948 - tp: 330.0000 - fp: 999.0000 - tn: 627.0000 - fn: 68.0000 - accuracy: 0.4728 - precision: 0.2483 - recall: 0.8291 - auc: 0.6979 - prc: 0.3995 - val_loss: 0.7218 - val_tp: 72.0000 - val_fp: 253.0000 - val_tn: 162.0000 - val_fn: 19.0000 - val_accuracy: 0.4625 - val_precision: 0.2215 - val_recall: 0.7912 - val_auc: 0.6657 - val_prc: 0.3083\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0942 - tp: 321.0000 - fp: 977.0000 - tn: 649.0000 - fn: 77.0000 - accuracy: 0.4792 - precision: 0.2473 - recall: 0.8065 - auc: 0.6982 - prc: 0.4009 - val_loss: 0.7055 - val_tp: 68.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 23.0000 - val_accuracy: 0.4783 - val_precision: 0.2201 - val_recall: 0.7473 - val_auc: 0.6650 - val_prc: 0.3099\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0932 - tp: 314.0000 - fp: 931.0000 - tn: 695.0000 - fn: 84.0000 - accuracy: 0.4985 - precision: 0.2522 - recall: 0.7889 - auc: 0.6985 - prc: 0.4019 - val_loss: 0.7045 - val_tp: 68.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 23.0000 - val_accuracy: 0.4783 - val_precision: 0.2201 - val_recall: 0.7473 - val_auc: 0.6661 - val_prc: 0.3109\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0923 - tp: 304.0000 - fp: 888.0000 - tn: 738.0000 - fn: 94.0000 - accuracy: 0.5148 - precision: 0.2550 - recall: 0.7638 - auc: 0.6989 - prc: 0.4028 - val_loss: 0.6973 - val_tp: 66.0000 - val_fp: 230.0000 - val_tn: 185.0000 - val_fn: 25.0000 - val_accuracy: 0.4960 - val_precision: 0.2230 - val_recall: 0.7253 - val_auc: 0.6656 - val_prc: 0.3124\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0918 - tp: 299.0000 - fp: 856.0000 - tn: 770.0000 - fn: 99.0000 - accuracy: 0.5282 - precision: 0.2589 - recall: 0.7513 - auc: 0.6990 - prc: 0.4046 - val_loss: 0.6976 - val_tp: 66.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 25.0000 - val_accuracy: 0.4941 - val_precision: 0.2222 - val_recall: 0.7253 - val_auc: 0.6657 - val_prc: 0.3127\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0908 - tp: 304.0000 - fp: 876.0000 - tn: 750.0000 - fn: 94.0000 - accuracy: 0.5208 - precision: 0.2576 - recall: 0.7638 - auc: 0.6995 - prc: 0.4055 - val_loss: 0.7055 - val_tp: 68.0000 - val_fp: 240.0000 - val_tn: 175.0000 - val_fn: 23.0000 - val_accuracy: 0.4802 - val_precision: 0.2208 - val_recall: 0.7473 - val_auc: 0.6646 - val_prc: 0.3126\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0907 - tp: 318.0000 - fp: 962.0000 - tn: 664.0000 - fn: 80.0000 - accuracy: 0.4852 - precision: 0.2484 - recall: 0.7990 - auc: 0.6994 - prc: 0.4051 - val_loss: 0.7148 - val_tp: 71.0000 - val_fp: 247.0000 - val_tn: 168.0000 - val_fn: 20.0000 - val_accuracy: 0.4723 - val_precision: 0.2233 - val_recall: 0.7802 - val_auc: 0.6675 - val_prc: 0.3152\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0895 - tp: 318.0000 - fp: 961.0000 - tn: 665.0000 - fn: 80.0000 - accuracy: 0.4857 - precision: 0.2486 - recall: 0.7990 - auc: 0.6999 - prc: 0.4072 - val_loss: 0.7073 - val_tp: 69.0000 - val_fp: 243.0000 - val_tn: 172.0000 - val_fn: 22.0000 - val_accuracy: 0.4763 - val_precision: 0.2212 - val_recall: 0.7582 - val_auc: 0.6676 - val_prc: 0.3155\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0888 - tp: 299.0000 - fp: 822.0000 - tn: 804.0000 - fn: 99.0000 - accuracy: 0.5450 - precision: 0.2667 - recall: 0.7513 - auc: 0.7001 - prc: 0.4053 - val_loss: 0.6814 - val_tp: 63.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 28.0000 - val_accuracy: 0.5455 - val_precision: 0.2377 - val_recall: 0.6923 - val_auc: 0.6681 - val_prc: 0.3173\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0893 - tp: 275.0000 - fp: 694.0000 - tn: 932.0000 - fn: 123.0000 - accuracy: 0.5963 - precision: 0.2838 - recall: 0.6910 - auc: 0.6989 - prc: 0.4060 - val_loss: 0.6796 - val_tp: 63.0000 - val_fp: 195.0000 - val_tn: 220.0000 - val_fn: 28.0000 - val_accuracy: 0.5593 - val_precision: 0.2442 - val_recall: 0.6923 - val_auc: 0.6667 - val_prc: 0.3143\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0868 - tp: 290.0000 - fp: 781.0000 - tn: 845.0000 - fn: 108.0000 - accuracy: 0.5608 - precision: 0.2708 - recall: 0.7286 - auc: 0.7009 - prc: 0.4074 - val_loss: 0.7007 - val_tp: 66.0000 - val_fp: 231.0000 - val_tn: 184.0000 - val_fn: 25.0000 - val_accuracy: 0.4941 - val_precision: 0.2222 - val_recall: 0.7253 - val_auc: 0.6674 - val_prc: 0.3143\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0866 - tp: 319.0000 - fp: 956.0000 - tn: 670.0000 - fn: 79.0000 - accuracy: 0.4886 - precision: 0.2502 - recall: 0.8015 - auc: 0.7011 - prc: 0.4059 - val_loss: 0.7188 - val_tp: 72.0000 - val_fp: 248.0000 - val_tn: 167.0000 - val_fn: 19.0000 - val_accuracy: 0.4723 - val_precision: 0.2250 - val_recall: 0.7912 - val_auc: 0.6666 - val_prc: 0.3140\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0861 - tp: 307.0000 - fp: 882.0000 - tn: 744.0000 - fn: 91.0000 - accuracy: 0.5193 - precision: 0.2582 - recall: 0.7714 - auc: 0.6987 - prc: 0.4041 - val_loss: 0.6936 - val_tp: 65.0000 - val_fp: 218.0000 - val_tn: 197.0000 - val_fn: 26.0000 - val_accuracy: 0.5178 - val_precision: 0.2297 - val_recall: 0.7143 - val_auc: 0.6670 - val_prc: 0.3146\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0842 - tp: 297.0000 - fp: 846.0000 - tn: 780.0000 - fn: 101.0000 - accuracy: 0.5321 - precision: 0.2598 - recall: 0.7462 - auc: 0.7014 - prc: 0.4090 - val_loss: 0.7045 - val_tp: 66.0000 - val_fp: 237.0000 - val_tn: 178.0000 - val_fn: 25.0000 - val_accuracy: 0.4822 - val_precision: 0.2178 - val_recall: 0.7253 - val_auc: 0.6670 - val_prc: 0.3153\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0842 - tp: 318.0000 - fp: 974.0000 - tn: 652.0000 - fn: 80.0000 - accuracy: 0.4792 - precision: 0.2461 - recall: 0.7990 - auc: 0.7007 - prc: 0.4097 - val_loss: 0.7257 - val_tp: 74.0000 - val_fp: 250.0000 - val_tn: 165.0000 - val_fn: 17.0000 - val_accuracy: 0.4723 - val_precision: 0.2284 - val_recall: 0.8132 - val_auc: 0.6683 - val_prc: 0.3172\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0835 - tp: 321.0000 - fp: 974.0000 - tn: 652.0000 - fn: 77.0000 - accuracy: 0.4807 - precision: 0.2479 - recall: 0.8065 - auc: 0.7014 - prc: 0.4101 - val_loss: 0.7092 - val_tp: 69.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 22.0000 - val_accuracy: 0.4802 - val_precision: 0.2226 - val_recall: 0.7582 - val_auc: 0.6688 - val_prc: 0.3192\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0843 - tp: 288.0000 - fp: 801.0000 - tn: 825.0000 - fn: 110.0000 - accuracy: 0.5499 - precision: 0.2645 - recall: 0.7236 - auc: 0.6960 - prc: 0.4044 - val_loss: 0.6776 - val_tp: 63.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 28.0000 - val_accuracy: 0.5613 - val_precision: 0.2451 - val_recall: 0.6923 - val_auc: 0.6699 - val_prc: 0.3230\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0815 - tp: 283.0000 - fp: 725.0000 - tn: 901.0000 - fn: 115.0000 - accuracy: 0.5850 - precision: 0.2808 - recall: 0.7111 - auc: 0.7013 - prc: 0.4127 - val_loss: 0.6863 - val_tp: 64.0000 - val_fp: 208.0000 - val_tn: 207.0000 - val_fn: 27.0000 - val_accuracy: 0.5356 - val_precision: 0.2353 - val_recall: 0.7033 - val_auc: 0.6680 - val_prc: 0.3214\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0801 - tp: 290.0000 - fp: 780.0000 - tn: 846.0000 - fn: 108.0000 - accuracy: 0.5613 - precision: 0.2710 - recall: 0.7286 - auc: 0.7015 - prc: 0.4135 - val_loss: 0.6875 - val_tp: 64.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 27.0000 - val_accuracy: 0.5336 - val_precision: 0.2344 - val_recall: 0.7033 - val_auc: 0.6690 - val_prc: 0.3233\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0792 - tp: 289.0000 - fp: 791.0000 - tn: 835.0000 - fn: 109.0000 - accuracy: 0.5553 - precision: 0.2676 - recall: 0.7261 - auc: 0.7013 - prc: 0.4129 - val_loss: 0.6932 - val_tp: 65.0000 - val_fp: 214.0000 - val_tn: 201.0000 - val_fn: 26.0000 - val_accuracy: 0.5257 - val_precision: 0.2330 - val_recall: 0.7143 - val_auc: 0.6692 - val_prc: 0.3244\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0786 - tp: 300.0000 - fp: 856.0000 - tn: 770.0000 - fn: 98.0000 - accuracy: 0.5287 - precision: 0.2595 - recall: 0.7538 - auc: 0.7007 - prc: 0.4135 - val_loss: 0.6950 - val_tp: 65.0000 - val_fp: 221.0000 - val_tn: 194.0000 - val_fn: 26.0000 - val_accuracy: 0.5119 - val_precision: 0.2273 - val_recall: 0.7143 - val_auc: 0.6707 - val_prc: 0.3257\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0781 - tp: 284.0000 - fp: 747.0000 - tn: 879.0000 - fn: 114.0000 - accuracy: 0.5746 - precision: 0.2755 - recall: 0.7136 - auc: 0.7016 - prc: 0.4111 - val_loss: 0.6745 - val_tp: 62.0000 - val_fp: 189.0000 - val_tn: 226.0000 - val_fn: 29.0000 - val_accuracy: 0.5692 - val_precision: 0.2470 - val_recall: 0.6813 - val_auc: 0.6703 - val_prc: 0.3273\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0777 - tp: 282.0000 - fp: 741.0000 - tn: 885.0000 - fn: 116.0000 - accuracy: 0.5766 - precision: 0.2757 - recall: 0.7085 - auc: 0.7011 - prc: 0.4132 - val_loss: 0.6884 - val_tp: 64.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 27.0000 - val_accuracy: 0.5336 - val_precision: 0.2344 - val_recall: 0.7033 - val_auc: 0.6713 - val_prc: 0.3280\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0760 - tp: 286.0000 - fp: 776.0000 - tn: 850.0000 - fn: 112.0000 - accuracy: 0.5613 - precision: 0.2693 - recall: 0.7186 - auc: 0.7022 - prc: 0.4166 - val_loss: 0.6904 - val_tp: 64.0000 - val_fp: 213.0000 - val_tn: 202.0000 - val_fn: 27.0000 - val_accuracy: 0.5257 - val_precision: 0.2310 - val_recall: 0.7033 - val_auc: 0.6707 - val_prc: 0.3285\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0752 - tp: 301.0000 - fp: 860.0000 - tn: 766.0000 - fn: 97.0000 - accuracy: 0.5272 - precision: 0.2593 - recall: 0.7563 - auc: 0.7019 - prc: 0.4162 - val_loss: 0.7056 - val_tp: 66.0000 - val_fp: 232.0000 - val_tn: 183.0000 - val_fn: 25.0000 - val_accuracy: 0.4921 - val_precision: 0.2215 - val_recall: 0.7253 - val_auc: 0.6708 - val_prc: 0.3251\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0745 - tp: 296.0000 - fp: 825.0000 - tn: 801.0000 - fn: 102.0000 - accuracy: 0.5420 - precision: 0.2640 - recall: 0.7437 - auc: 0.7021 - prc: 0.4148 - val_loss: 0.6903 - val_tp: 64.0000 - val_fp: 211.0000 - val_tn: 204.0000 - val_fn: 27.0000 - val_accuracy: 0.5296 - val_precision: 0.2327 - val_recall: 0.7033 - val_auc: 0.6717 - val_prc: 0.3251\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0734 - tp: 295.0000 - fp: 824.0000 - tn: 802.0000 - fn: 103.0000 - accuracy: 0.5420 - precision: 0.2636 - recall: 0.7412 - auc: 0.7034 - prc: 0.4140 - val_loss: 0.6982 - val_tp: 65.0000 - val_fp: 224.0000 - val_tn: 191.0000 - val_fn: 26.0000 - val_accuracy: 0.5059 - val_precision: 0.2249 - val_recall: 0.7143 - val_auc: 0.6707 - val_prc: 0.3240\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0736 - tp: 286.0000 - fp: 760.0000 - tn: 866.0000 - fn: 112.0000 - accuracy: 0.5692 - precision: 0.2734 - recall: 0.7186 - auc: 0.7003 - prc: 0.4111 - val_loss: 0.6785 - val_tp: 62.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 29.0000 - val_accuracy: 0.5593 - val_precision: 0.2422 - val_recall: 0.6813 - val_auc: 0.6718 - val_prc: 0.3285\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0729 - tp: 291.0000 - fp: 805.0000 - tn: 821.0000 - fn: 107.0000 - accuracy: 0.5494 - precision: 0.2655 - recall: 0.7312 - auc: 0.7013 - prc: 0.4130 - val_loss: 0.6984 - val_tp: 65.0000 - val_fp: 223.0000 - val_tn: 192.0000 - val_fn: 26.0000 - val_accuracy: 0.5079 - val_precision: 0.2257 - val_recall: 0.7143 - val_auc: 0.6717 - val_prc: 0.3263\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0717 - tp: 289.0000 - fp: 755.0000 - tn: 871.0000 - fn: 109.0000 - accuracy: 0.5731 - precision: 0.2768 - recall: 0.7261 - auc: 0.7023 - prc: 0.4134 - val_loss: 0.6789 - val_tp: 62.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 29.0000 - val_accuracy: 0.5593 - val_precision: 0.2422 - val_recall: 0.6813 - val_auc: 0.6725 - val_prc: 0.3309\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0701 - tp: 285.0000 - fp: 755.0000 - tn: 871.0000 - fn: 113.0000 - accuracy: 0.5711 - precision: 0.2740 - recall: 0.7161 - auc: 0.7031 - prc: 0.4172 - val_loss: 0.6875 - val_tp: 64.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 27.0000 - val_accuracy: 0.5395 - val_precision: 0.2370 - val_recall: 0.7033 - val_auc: 0.6727 - val_prc: 0.3316\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0695 - tp: 283.0000 - fp: 748.0000 - tn: 878.0000 - fn: 115.0000 - accuracy: 0.5736 - precision: 0.2745 - recall: 0.7111 - auc: 0.7036 - prc: 0.4164 - val_loss: 0.6809 - val_tp: 62.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 29.0000 - val_accuracy: 0.5553 - val_precision: 0.2403 - val_recall: 0.6813 - val_auc: 0.6734 - val_prc: 0.3303\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0696 - tp: 295.0000 - fp: 815.0000 - tn: 811.0000 - fn: 103.0000 - accuracy: 0.5464 - precision: 0.2658 - recall: 0.7412 - auc: 0.7025 - prc: 0.4147 - val_loss: 0.7022 - val_tp: 67.0000 - val_fp: 226.0000 - val_tn: 189.0000 - val_fn: 24.0000 - val_accuracy: 0.5059 - val_precision: 0.2287 - val_recall: 0.7363 - val_auc: 0.6745 - val_prc: 0.3333\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0675 - tp: 293.0000 - fp: 811.0000 - tn: 815.0000 - fn: 105.0000 - accuracy: 0.5474 - precision: 0.2654 - recall: 0.7362 - auc: 0.7046 - prc: 0.4187 - val_loss: 0.6832 - val_tp: 62.0000 - val_fp: 199.0000 - val_tn: 216.0000 - val_fn: 29.0000 - val_accuracy: 0.5494 - val_precision: 0.2375 - val_recall: 0.6813 - val_auc: 0.6758 - val_prc: 0.3355\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0678 - tp: 269.0000 - fp: 649.0000 - tn: 977.0000 - fn: 129.0000 - accuracy: 0.6156 - precision: 0.2930 - recall: 0.6759 - auc: 0.7041 - prc: 0.4168 - val_loss: 0.6623 - val_tp: 59.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 32.0000 - val_accuracy: 0.6107 - val_precision: 0.2634 - val_recall: 0.6484 - val_auc: 0.6759 - val_prc: 0.3381\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0656 - tp: 281.0000 - fp: 713.0000 - tn: 913.0000 - fn: 117.0000 - accuracy: 0.5899 - precision: 0.2827 - recall: 0.7060 - auc: 0.7055 - prc: 0.4193 - val_loss: 0.6994 - val_tp: 66.0000 - val_fp: 218.0000 - val_tn: 197.0000 - val_fn: 25.0000 - val_accuracy: 0.5198 - val_precision: 0.2324 - val_recall: 0.7253 - val_auc: 0.6763 - val_prc: 0.3374\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0651 - tp: 293.0000 - fp: 785.0000 - tn: 841.0000 - fn: 105.0000 - accuracy: 0.5603 - precision: 0.2718 - recall: 0.7362 - auc: 0.7049 - prc: 0.4215 - val_loss: 0.6880 - val_tp: 65.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 26.0000 - val_accuracy: 0.5534 - val_precision: 0.2453 - val_recall: 0.7143 - val_auc: 0.6766 - val_prc: 0.3399\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0643 - tp: 294.0000 - fp: 798.0000 - tn: 828.0000 - fn: 104.0000 - accuracy: 0.5543 - precision: 0.2692 - recall: 0.7387 - auc: 0.7060 - prc: 0.4213 - val_loss: 0.6983 - val_tp: 66.0000 - val_fp: 211.0000 - val_tn: 204.0000 - val_fn: 25.0000 - val_accuracy: 0.5336 - val_precision: 0.2383 - val_recall: 0.7253 - val_auc: 0.6765 - val_prc: 0.3389\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0638 - tp: 303.0000 - fp: 834.0000 - tn: 792.0000 - fn: 95.0000 - accuracy: 0.5410 - precision: 0.2665 - recall: 0.7613 - auc: 0.7066 - prc: 0.4200 - val_loss: 0.7031 - val_tp: 66.0000 - val_fp: 215.0000 - val_tn: 200.0000 - val_fn: 25.0000 - val_accuracy: 0.5257 - val_precision: 0.2349 - val_recall: 0.7253 - val_auc: 0.6777 - val_prc: 0.3401\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0611 - tp: 290.0000 - fp: 762.0000 - tn: 864.0000 - fn: 108.0000 - accuracy: 0.5702 - precision: 0.2757 - recall: 0.7286 - auc: 0.7077 - prc: 0.4245 - val_loss: 0.6769 - val_tp: 62.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 29.0000 - val_accuracy: 0.5711 - val_precision: 0.2480 - val_recall: 0.6813 - val_auc: 0.6782 - val_prc: 0.3424\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0612 - tp: 283.0000 - fp: 740.0000 - tn: 886.0000 - fn: 115.0000 - accuracy: 0.5776 - precision: 0.2766 - recall: 0.7111 - auc: 0.7065 - prc: 0.4239 - val_loss: 0.6884 - val_tp: 65.0000 - val_fp: 201.0000 - val_tn: 214.0000 - val_fn: 26.0000 - val_accuracy: 0.5514 - val_precision: 0.2444 - val_recall: 0.7143 - val_auc: 0.6774 - val_prc: 0.3421\n",
      "Epoch 90/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0599 - tp: 286.0000 - fp: 739.0000 - tn: 887.0000 - fn: 112.0000 - accuracy: 0.5795 - precision: 0.2790 - recall: 0.7186 - auc: 0.7072 - prc: 0.4238 - val_loss: 0.6828 - val_tp: 63.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 28.0000 - val_accuracy: 0.5632 - val_precision: 0.2461 - val_recall: 0.6923 - val_auc: 0.6780 - val_prc: 0.3419\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0586 - tp: 281.0000 - fp: 705.0000 - tn: 921.0000 - fn: 117.0000 - accuracy: 0.5939 - precision: 0.2850 - recall: 0.7060 - auc: 0.7078 - prc: 0.4251 - val_loss: 0.6676 - val_tp: 59.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 32.0000 - val_accuracy: 0.5889 - val_precision: 0.2511 - val_recall: 0.6484 - val_auc: 0.6784 - val_prc: 0.3437\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0599 - tp: 261.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 137.0000 - accuracy: 0.6477 - precision: 0.3118 - recall: 0.6558 - auc: 0.7066 - prc: 0.4263 - val_loss: 0.6505 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6782 - val_prc: 0.3452\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0578 - tp: 274.0000 - fp: 634.0000 - tn: 992.0000 - fn: 124.0000 - accuracy: 0.6255 - precision: 0.3018 - recall: 0.6884 - auc: 0.7077 - prc: 0.4256 - val_loss: 0.6794 - val_tp: 61.0000 - val_fp: 187.0000 - val_tn: 228.0000 - val_fn: 30.0000 - val_accuracy: 0.5711 - val_precision: 0.2460 - val_recall: 0.6703 - val_auc: 0.6786 - val_prc: 0.3435\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0577 - tp: 287.0000 - fp: 738.0000 - tn: 888.0000 - fn: 111.0000 - accuracy: 0.5805 - precision: 0.2800 - recall: 0.7211 - auc: 0.7072 - prc: 0.4227 - val_loss: 0.6937 - val_tp: 65.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 26.0000 - val_accuracy: 0.5415 - val_precision: 0.2399 - val_recall: 0.7143 - val_auc: 0.6785 - val_prc: 0.3429\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0569 - tp: 295.0000 - fp: 778.0000 - tn: 848.0000 - fn: 103.0000 - accuracy: 0.5647 - precision: 0.2749 - recall: 0.7412 - auc: 0.7089 - prc: 0.4254 - val_loss: 0.6970 - val_tp: 65.0000 - val_fp: 209.0000 - val_tn: 206.0000 - val_fn: 26.0000 - val_accuracy: 0.5356 - val_precision: 0.2372 - val_recall: 0.7143 - val_auc: 0.6788 - val_prc: 0.3438\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0553 - tp: 286.0000 - fp: 710.0000 - tn: 916.0000 - fn: 112.0000 - accuracy: 0.5939 - precision: 0.2871 - recall: 0.7186 - auc: 0.7082 - prc: 0.4246 - val_loss: 0.6610 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6783 - val_prc: 0.3530\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0545 - tp: 265.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 133.0000 - accuracy: 0.6428 - precision: 0.3099 - recall: 0.6658 - auc: 0.7084 - prc: 0.4281 - val_loss: 0.6575 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6787 - val_prc: 0.3471\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0544 - tp: 261.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 137.0000 - accuracy: 0.6507 - precision: 0.3141 - recall: 0.6558 - auc: 0.7089 - prc: 0.4277 - val_loss: 0.6519 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6798 - val_prc: 0.3541\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0522 - tp: 269.0000 - fp: 607.0000 - tn: 1019.0000 - fn: 129.0000 - accuracy: 0.6364 - precision: 0.3071 - recall: 0.6759 - auc: 0.7095 - prc: 0.4298 - val_loss: 0.6778 - val_tp: 60.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 31.0000 - val_accuracy: 0.5731 - val_precision: 0.2449 - val_recall: 0.6593 - val_auc: 0.6787 - val_prc: 0.3516\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0520 - tp: 287.0000 - fp: 720.0000 - tn: 906.0000 - fn: 111.0000 - accuracy: 0.5894 - precision: 0.2850 - recall: 0.7211 - auc: 0.7090 - prc: 0.4293 - val_loss: 0.6920 - val_tp: 63.0000 - val_fp: 198.0000 - val_tn: 217.0000 - val_fn: 28.0000 - val_accuracy: 0.5534 - val_precision: 0.2414 - val_recall: 0.6923 - val_auc: 0.6788 - val_prc: 0.3530\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0526 - tp: 289.0000 - fp: 743.0000 - tn: 883.0000 - fn: 109.0000 - accuracy: 0.5791 - precision: 0.2800 - recall: 0.7261 - auc: 0.7091 - prc: 0.4281 - val_loss: 0.6839 - val_tp: 61.0000 - val_fp: 188.0000 - val_tn: 227.0000 - val_fn: 30.0000 - val_accuracy: 0.5692 - val_precision: 0.2450 - val_recall: 0.6703 - val_auc: 0.6793 - val_prc: 0.3523\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0508 - tp: 280.0000 - fp: 684.0000 - tn: 942.0000 - fn: 118.0000 - accuracy: 0.6038 - precision: 0.2905 - recall: 0.7035 - auc: 0.7093 - prc: 0.4284 - val_loss: 0.6695 - val_tp: 58.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 33.0000 - val_accuracy: 0.5870 - val_precision: 0.2479 - val_recall: 0.6374 - val_auc: 0.6788 - val_prc: 0.3528\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0503 - tp: 273.0000 - fp: 629.0000 - tn: 997.0000 - fn: 125.0000 - accuracy: 0.6275 - precision: 0.3027 - recall: 0.6859 - auc: 0.7094 - prc: 0.4288 - val_loss: 0.6664 - val_tp: 58.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 33.0000 - val_accuracy: 0.5988 - val_precision: 0.2544 - val_recall: 0.6374 - val_auc: 0.6781 - val_prc: 0.3521\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0496 - tp: 267.0000 - fp: 608.0000 - tn: 1018.0000 - fn: 131.0000 - accuracy: 0.6349 - precision: 0.3051 - recall: 0.6709 - auc: 0.7097 - prc: 0.4288 - val_loss: 0.6556 - val_tp: 58.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 33.0000 - val_accuracy: 0.6364 - val_precision: 0.2775 - val_recall: 0.6374 - val_auc: 0.6790 - val_prc: 0.3558\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0487 - tp: 262.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 136.0000 - accuracy: 0.6462 - precision: 0.3112 - recall: 0.6583 - auc: 0.7105 - prc: 0.4321 - val_loss: 0.6556 - val_tp: 58.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 33.0000 - val_accuracy: 0.6304 - val_precision: 0.2736 - val_recall: 0.6374 - val_auc: 0.6791 - val_prc: 0.3576\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0478 - tp: 268.0000 - fp: 613.0000 - tn: 1013.0000 - fn: 130.0000 - accuracy: 0.6329 - precision: 0.3042 - recall: 0.6734 - auc: 0.7100 - prc: 0.4314 - val_loss: 0.6671 - val_tp: 58.0000 - val_fp: 170.0000 - val_tn: 245.0000 - val_fn: 33.0000 - val_accuracy: 0.5988 - val_precision: 0.2544 - val_recall: 0.6374 - val_auc: 0.6793 - val_prc: 0.3574\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0473 - tp: 266.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 132.0000 - accuracy: 0.6413 - precision: 0.3093 - recall: 0.6683 - auc: 0.7106 - prc: 0.4324 - val_loss: 0.6537 - val_tp: 58.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 33.0000 - val_accuracy: 0.6403 - val_precision: 0.2802 - val_recall: 0.6374 - val_auc: 0.6791 - val_prc: 0.3568\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0461 - tp: 269.0000 - fp: 610.0000 - tn: 1016.0000 - fn: 129.0000 - accuracy: 0.6349 - precision: 0.3060 - recall: 0.6759 - auc: 0.7108 - prc: 0.4332 - val_loss: 0.6733 - val_tp: 59.0000 - val_fp: 177.0000 - val_tn: 238.0000 - val_fn: 32.0000 - val_accuracy: 0.5870 - val_precision: 0.2500 - val_recall: 0.6484 - val_auc: 0.6802 - val_prc: 0.3600\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0467 - tp: 283.0000 - fp: 702.0000 - tn: 924.0000 - fn: 115.0000 - accuracy: 0.5963 - precision: 0.2873 - recall: 0.7111 - auc: 0.7104 - prc: 0.4330 - val_loss: 0.6833 - val_tp: 60.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 31.0000 - val_accuracy: 0.5751 - val_precision: 0.2459 - val_recall: 0.6593 - val_auc: 0.6805 - val_prc: 0.3620\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0458 - tp: 272.0000 - fp: 626.0000 - tn: 1000.0000 - fn: 126.0000 - accuracy: 0.6285 - precision: 0.3029 - recall: 0.6834 - auc: 0.7104 - prc: 0.4332 - val_loss: 0.6506 - val_tp: 58.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 33.0000 - val_accuracy: 0.6423 - val_precision: 0.2816 - val_recall: 0.6374 - val_auc: 0.6804 - val_prc: 0.3670\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0448 - tp: 261.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 137.0000 - accuracy: 0.6507 - precision: 0.3141 - recall: 0.6558 - auc: 0.7113 - prc: 0.4367 - val_loss: 0.6555 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6792 - val_prc: 0.3663\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0443 - tp: 272.0000 - fp: 622.0000 - tn: 1004.0000 - fn: 126.0000 - accuracy: 0.6304 - precision: 0.3043 - recall: 0.6834 - auc: 0.7107 - prc: 0.4356 - val_loss: 0.6668 - val_tp: 58.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 33.0000 - val_accuracy: 0.6047 - val_precision: 0.2578 - val_recall: 0.6374 - val_auc: 0.6806 - val_prc: 0.3677\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0440 - tp: 263.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 135.0000 - accuracy: 0.6398 - precision: 0.3069 - recall: 0.6608 - auc: 0.7112 - prc: 0.4364 - val_loss: 0.6441 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.6805 - val_prc: 0.3691\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0441 - tp: 252.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 146.0000 - accuracy: 0.6586 - precision: 0.3162 - recall: 0.6332 - auc: 0.7114 - prc: 0.4379 - val_loss: 0.6515 - val_tp: 58.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 33.0000 - val_accuracy: 0.6403 - val_precision: 0.2802 - val_recall: 0.6374 - val_auc: 0.6806 - val_prc: 0.3690\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0425 - tp: 265.0000 - fp: 618.0000 - tn: 1008.0000 - fn: 133.0000 - accuracy: 0.6290 - precision: 0.3001 - recall: 0.6658 - auc: 0.7113 - prc: 0.4374 - val_loss: 0.6683 - val_tp: 58.0000 - val_fp: 169.0000 - val_tn: 246.0000 - val_fn: 33.0000 - val_accuracy: 0.6008 - val_precision: 0.2555 - val_recall: 0.6374 - val_auc: 0.6799 - val_prc: 0.3678\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0419 - tp: 273.0000 - fp: 634.0000 - tn: 992.0000 - fn: 125.0000 - accuracy: 0.6250 - precision: 0.3010 - recall: 0.6859 - auc: 0.7119 - prc: 0.4386 - val_loss: 0.6508 - val_tp: 58.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 33.0000 - val_accuracy: 0.6383 - val_precision: 0.2788 - val_recall: 0.6374 - val_auc: 0.6806 - val_prc: 0.3703\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0433 - tp: 245.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 153.0000 - accuracy: 0.6690 - precision: 0.3215 - recall: 0.6156 - auc: 0.7122 - prc: 0.4416 - val_loss: 0.6200 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6819 - val_prc: 0.3790\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0465 - tp: 229.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 169.0000 - accuracy: 0.6966 - precision: 0.3398 - recall: 0.5754 - auc: 0.7124 - prc: 0.4433 - val_loss: 0.6274 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6823 - val_prc: 0.3797\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0405 - tp: 265.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 133.0000 - accuracy: 0.6477 - precision: 0.3136 - recall: 0.6658 - auc: 0.7122 - prc: 0.4432 - val_loss: 0.6798 - val_tp: 60.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 31.0000 - val_accuracy: 0.5830 - val_precision: 0.2500 - val_recall: 0.6593 - val_auc: 0.6807 - val_prc: 0.3769\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0417 - tp: 285.0000 - fp: 685.0000 - tn: 941.0000 - fn: 113.0000 - accuracy: 0.6057 - precision: 0.2938 - recall: 0.7161 - auc: 0.7123 - prc: 0.4407 - val_loss: 0.6773 - val_tp: 60.0000 - val_fp: 179.0000 - val_tn: 236.0000 - val_fn: 31.0000 - val_accuracy: 0.5850 - val_precision: 0.2510 - val_recall: 0.6593 - val_auc: 0.6801 - val_prc: 0.3753\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0394 - tp: 275.0000 - fp: 614.0000 - tn: 1012.0000 - fn: 123.0000 - accuracy: 0.6359 - precision: 0.3093 - recall: 0.6910 - auc: 0.7134 - prc: 0.4416 - val_loss: 0.6505 - val_tp: 58.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 33.0000 - val_accuracy: 0.6344 - val_precision: 0.2762 - val_recall: 0.6374 - val_auc: 0.6815 - val_prc: 0.3794\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0406 - tp: 272.0000 - fp: 632.0000 - tn: 994.0000 - fn: 126.0000 - accuracy: 0.6255 - precision: 0.3009 - recall: 0.6834 - auc: 0.7119 - prc: 0.4411 - val_loss: 0.6702 - val_tp: 58.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 33.0000 - val_accuracy: 0.5968 - val_precision: 0.2533 - val_recall: 0.6374 - val_auc: 0.6806 - val_prc: 0.3766\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0390 - tp: 268.0000 - fp: 609.0000 - tn: 1017.0000 - fn: 130.0000 - accuracy: 0.6349 - precision: 0.3056 - recall: 0.6734 - auc: 0.7130 - prc: 0.4419 - val_loss: 0.6508 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6817 - val_prc: 0.3784\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0388 - tp: 269.0000 - fp: 604.0000 - tn: 1022.0000 - fn: 129.0000 - accuracy: 0.6378 - precision: 0.3081 - recall: 0.6759 - auc: 0.7130 - prc: 0.4417 - val_loss: 0.6625 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6803 - val_prc: 0.3733\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0383 - tp: 260.0000 - fp: 574.0000 - tn: 1052.0000 - fn: 138.0000 - accuracy: 0.6482 - precision: 0.3118 - recall: 0.6533 - auc: 0.7133 - prc: 0.4432 - val_loss: 0.6465 - val_tp: 57.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 34.0000 - val_accuracy: 0.6423 - val_precision: 0.2794 - val_recall: 0.6264 - val_auc: 0.6807 - val_prc: 0.3755\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0371 - tp: 277.0000 - fp: 646.0000 - tn: 980.0000 - fn: 121.0000 - accuracy: 0.6210 - precision: 0.3001 - recall: 0.6960 - auc: 0.7153 - prc: 0.4447 - val_loss: 0.6855 - val_tp: 60.0000 - val_fp: 183.0000 - val_tn: 232.0000 - val_fn: 31.0000 - val_accuracy: 0.5771 - val_precision: 0.2469 - val_recall: 0.6593 - val_auc: 0.6811 - val_prc: 0.3781\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0384 - tp: 268.0000 - fp: 617.0000 - tn: 1009.0000 - fn: 130.0000 - accuracy: 0.6309 - precision: 0.3028 - recall: 0.6734 - auc: 0.7129 - prc: 0.4436 - val_loss: 0.6391 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6824 - val_prc: 0.3876\n",
      "Epoch 128/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0372 - tp: 253.0000 - fp: 539.0000 - tn: 1087.0000 - fn: 145.0000 - accuracy: 0.6621 - precision: 0.3194 - recall: 0.6357 - auc: 0.7152 - prc: 0.4476 - val_loss: 0.6458 - val_tp: 57.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 34.0000 - val_accuracy: 0.6403 - val_precision: 0.2780 - val_recall: 0.6264 - val_auc: 0.6819 - val_prc: 0.3823\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0372 - tp: 269.0000 - fp: 606.0000 - tn: 1020.0000 - fn: 129.0000 - accuracy: 0.6369 - precision: 0.3074 - recall: 0.6759 - auc: 0.7145 - prc: 0.4430 - val_loss: 0.6629 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6806 - val_prc: 0.3787\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0365 - tp: 271.0000 - fp: 621.0000 - tn: 1005.0000 - fn: 127.0000 - accuracy: 0.6304 - precision: 0.3038 - recall: 0.6809 - auc: 0.7145 - prc: 0.4455 - val_loss: 0.6560 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6809 - val_prc: 0.3837\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0351 - tp: 268.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 130.0000 - accuracy: 0.6393 - precision: 0.3088 - recall: 0.6734 - auc: 0.7156 - prc: 0.4493 - val_loss: 0.6636 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6816 - val_prc: 0.3854\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0363 - tp: 277.0000 - fp: 666.0000 - tn: 960.0000 - fn: 121.0000 - accuracy: 0.6112 - precision: 0.2937 - recall: 0.6960 - auc: 0.7153 - prc: 0.4480 - val_loss: 0.6819 - val_tp: 60.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 31.0000 - val_accuracy: 0.5830 - val_precision: 0.2500 - val_recall: 0.6593 - val_auc: 0.6830 - val_prc: 0.3919\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0357 - tp: 272.0000 - fp: 629.0000 - tn: 997.0000 - fn: 126.0000 - accuracy: 0.6270 - precision: 0.3019 - recall: 0.6834 - auc: 0.7149 - prc: 0.4481 - val_loss: 0.6440 - val_tp: 57.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 34.0000 - val_accuracy: 0.6364 - val_precision: 0.2754 - val_recall: 0.6264 - val_auc: 0.6836 - val_prc: 0.3942\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0342 - tp: 263.0000 - fp: 585.0000 - tn: 1041.0000 - fn: 135.0000 - accuracy: 0.6443 - precision: 0.3101 - recall: 0.6608 - auc: 0.7154 - prc: 0.4514 - val_loss: 0.6580 - val_tp: 58.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 33.0000 - val_accuracy: 0.6206 - val_precision: 0.2673 - val_recall: 0.6374 - val_auc: 0.6822 - val_prc: 0.3918\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0346 - tp: 275.0000 - fp: 638.0000 - tn: 988.0000 - fn: 123.0000 - accuracy: 0.6240 - precision: 0.3012 - recall: 0.6910 - auc: 0.7157 - prc: 0.4513 - val_loss: 0.6714 - val_tp: 58.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 33.0000 - val_accuracy: 0.5929 - val_precision: 0.2511 - val_recall: 0.6374 - val_auc: 0.6832 - val_prc: 0.3933\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0347 - tp: 260.0000 - fp: 576.0000 - tn: 1050.0000 - fn: 138.0000 - accuracy: 0.6472 - precision: 0.3110 - recall: 0.6533 - auc: 0.7149 - prc: 0.4519 - val_loss: 0.6347 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.6840 - val_prc: 0.3967\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0339 - tp: 258.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 140.0000 - accuracy: 0.6566 - precision: 0.3173 - recall: 0.6482 - auc: 0.7161 - prc: 0.4513 - val_loss: 0.6501 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6831 - val_prc: 0.3897\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0332 - tp: 259.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 139.0000 - accuracy: 0.6586 - precision: 0.3194 - recall: 0.6508 - auc: 0.7165 - prc: 0.4532 - val_loss: 0.6443 - val_tp: 58.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 33.0000 - val_accuracy: 0.6423 - val_precision: 0.2816 - val_recall: 0.6374 - val_auc: 0.6838 - val_prc: 0.3957\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0323 - tp: 268.0000 - fp: 599.0000 - tn: 1027.0000 - fn: 130.0000 - accuracy: 0.6398 - precision: 0.3091 - recall: 0.6734 - auc: 0.7174 - prc: 0.4507 - val_loss: 0.6670 - val_tp: 58.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 33.0000 - val_accuracy: 0.5968 - val_precision: 0.2533 - val_recall: 0.6374 - val_auc: 0.6831 - val_prc: 0.3853\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0321 - tp: 268.0000 - fp: 595.0000 - tn: 1031.0000 - fn: 130.0000 - accuracy: 0.6418 - precision: 0.3105 - recall: 0.6734 - auc: 0.7175 - prc: 0.4502 - val_loss: 0.6453 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6833 - val_prc: 0.3868\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0318 - tp: 266.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 132.0000 - accuracy: 0.6433 - precision: 0.3107 - recall: 0.6683 - auc: 0.7174 - prc: 0.4541 - val_loss: 0.6522 - val_tp: 58.0000 - val_fp: 157.0000 - val_tn: 258.0000 - val_fn: 33.0000 - val_accuracy: 0.6245 - val_precision: 0.2698 - val_recall: 0.6374 - val_auc: 0.6834 - val_prc: 0.3927\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0310 - tp: 260.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 138.0000 - accuracy: 0.6551 - precision: 0.3171 - recall: 0.6533 - auc: 0.7178 - prc: 0.4554 - val_loss: 0.6390 - val_tp: 56.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 35.0000 - val_accuracy: 0.6601 - val_precision: 0.2902 - val_recall: 0.6154 - val_auc: 0.6838 - val_prc: 0.3906\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0308 - tp: 261.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 137.0000 - accuracy: 0.6596 - precision: 0.3210 - recall: 0.6558 - auc: 0.7182 - prc: 0.4585 - val_loss: 0.6492 - val_tp: 58.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 33.0000 - val_accuracy: 0.6285 - val_precision: 0.2723 - val_recall: 0.6374 - val_auc: 0.6847 - val_prc: 0.4012\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0318 - tp: 276.0000 - fp: 640.0000 - tn: 986.0000 - fn: 122.0000 - accuracy: 0.6235 - precision: 0.3013 - recall: 0.6935 - auc: 0.7173 - prc: 0.4567 - val_loss: 0.6760 - val_tp: 61.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 30.0000 - val_accuracy: 0.5850 - val_precision: 0.2531 - val_recall: 0.6703 - val_auc: 0.6847 - val_prc: 0.3993\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0302 - tp: 270.0000 - fp: 618.0000 - tn: 1008.0000 - fn: 128.0000 - accuracy: 0.6314 - precision: 0.3041 - recall: 0.6784 - auc: 0.7182 - prc: 0.4592 - val_loss: 0.6479 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6855 - val_prc: 0.4038\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0294 - tp: 260.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 138.0000 - accuracy: 0.6591 - precision: 0.3202 - recall: 0.6533 - auc: 0.7186 - prc: 0.4596 - val_loss: 0.6458 - val_tp: 58.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 33.0000 - val_accuracy: 0.6462 - val_precision: 0.2843 - val_recall: 0.6374 - val_auc: 0.6852 - val_prc: 0.3965\n",
      "Epoch 147/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0291 - tp: 268.0000 - fp: 595.0000 - tn: 1031.0000 - fn: 130.0000 - accuracy: 0.6418 - precision: 0.3105 - recall: 0.6734 - auc: 0.7187 - prc: 0.4577 - val_loss: 0.6675 - val_tp: 60.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 31.0000 - val_accuracy: 0.6126 - val_precision: 0.2667 - val_recall: 0.6593 - val_auc: 0.6843 - val_prc: 0.3913\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0275 - tp: 265.0000 - fp: 573.0000 - tn: 1053.0000 - fn: 133.0000 - accuracy: 0.6512 - precision: 0.3162 - recall: 0.6658 - auc: 0.7199 - prc: 0.4572 - val_loss: 0.6351 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6863 - val_prc: 0.4005\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0275 - tp: 259.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 139.0000 - accuracy: 0.6680 - precision: 0.3270 - recall: 0.6508 - auc: 0.7198 - prc: 0.4604 - val_loss: 0.6535 - val_tp: 58.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 33.0000 - val_accuracy: 0.6265 - val_precision: 0.2710 - val_recall: 0.6374 - val_auc: 0.6881 - val_prc: 0.4149\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0281 - tp: 268.0000 - fp: 604.0000 - tn: 1022.0000 - fn: 130.0000 - accuracy: 0.6374 - precision: 0.3073 - recall: 0.6734 - auc: 0.7193 - prc: 0.4622 - val_loss: 0.6614 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6876 - val_prc: 0.4090\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0270 - tp: 269.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 129.0000 - accuracy: 0.6428 - precision: 0.3117 - recall: 0.6759 - auc: 0.7198 - prc: 0.4632 - val_loss: 0.6433 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6874 - val_prc: 0.4104\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0262 - tp: 256.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 142.0000 - accuracy: 0.6675 - precision: 0.3253 - recall: 0.6432 - auc: 0.7203 - prc: 0.4652 - val_loss: 0.6312 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6888 - val_prc: 0.4137\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0272 - tp: 259.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 139.0000 - accuracy: 0.6616 - precision: 0.3217 - recall: 0.6508 - auc: 0.7195 - prc: 0.4638 - val_loss: 0.6439 - val_tp: 57.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 34.0000 - val_accuracy: 0.6423 - val_precision: 0.2794 - val_recall: 0.6264 - val_auc: 0.6883 - val_prc: 0.4161\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0258 - tp: 261.0000 - fp: 548.0000 - tn: 1078.0000 - fn: 137.0000 - accuracy: 0.6616 - precision: 0.3226 - recall: 0.6558 - auc: 0.7205 - prc: 0.4666 - val_loss: 0.6341 - val_tp: 56.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 35.0000 - val_accuracy: 0.6522 - val_precision: 0.2843 - val_recall: 0.6154 - val_auc: 0.6893 - val_prc: 0.4219\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0264 - tp: 247.0000 - fp: 503.0000 - tn: 1123.0000 - fn: 151.0000 - accuracy: 0.6769 - precision: 0.3293 - recall: 0.6206 - auc: 0.7205 - prc: 0.4662 - val_loss: 0.6393 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6874 - val_prc: 0.4191\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0247 - tp: 269.0000 - fp: 592.0000 - tn: 1034.0000 - fn: 129.0000 - accuracy: 0.6438 - precision: 0.3124 - recall: 0.6759 - auc: 0.7211 - prc: 0.4677 - val_loss: 0.6651 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6873 - val_prc: 0.4212\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0237 - tp: 258.0000 - fp: 555.0000 - tn: 1071.0000 - fn: 140.0000 - accuracy: 0.6566 - precision: 0.3173 - recall: 0.6482 - auc: 0.7218 - prc: 0.4695 - val_loss: 0.6188 - val_tp: 52.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 39.0000 - val_accuracy: 0.6621 - val_precision: 0.2826 - val_recall: 0.5714 - val_auc: 0.6881 - val_prc: 0.4222\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0263 - tp: 246.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 152.0000 - accuracy: 0.6774 - precision: 0.3293 - recall: 0.6181 - auc: 0.7200 - prc: 0.4662 - val_loss: 0.6309 - val_tp: 54.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 37.0000 - val_accuracy: 0.6542 - val_precision: 0.2812 - val_recall: 0.5934 - val_auc: 0.6874 - val_prc: 0.4125\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0243 - tp: 255.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 143.0000 - accuracy: 0.6645 - precision: 0.3224 - recall: 0.6407 - auc: 0.7214 - prc: 0.4654 - val_loss: 0.6353 - val_tp: 54.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 37.0000 - val_accuracy: 0.6482 - val_precision: 0.2769 - val_recall: 0.5934 - val_auc: 0.6862 - val_prc: 0.4123\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0245 - tp: 247.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 151.0000 - accuracy: 0.6779 - precision: 0.3302 - recall: 0.6206 - auc: 0.7222 - prc: 0.4674 - val_loss: 0.6236 - val_tp: 52.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 39.0000 - val_accuracy: 0.6621 - val_precision: 0.2826 - val_recall: 0.5714 - val_auc: 0.6878 - val_prc: 0.4176\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0252 - tp: 246.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 152.0000 - accuracy: 0.6848 - precision: 0.3361 - recall: 0.6181 - auc: 0.7215 - prc: 0.4671 - val_loss: 0.6318 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6873 - val_prc: 0.4201\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0252 - tp: 246.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 152.0000 - accuracy: 0.6803 - precision: 0.3320 - recall: 0.6181 - auc: 0.7218 - prc: 0.4685 - val_loss: 0.6355 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6897 - val_prc: 0.4283\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0336 - tp: 281.0000 - fp: 687.0000 - tn: 939.0000 - fn: 117.0000 - accuracy: 0.6028 - precision: 0.2903 - recall: 0.7060 - auc: 0.7176 - prc: 0.4601 - val_loss: 0.6662 - val_tp: 58.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 33.0000 - val_accuracy: 0.6047 - val_precision: 0.2578 - val_recall: 0.6374 - val_auc: 0.6863 - val_prc: 0.4139\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0219 - tp: 246.0000 - fp: 488.0000 - tn: 1138.0000 - fn: 152.0000 - accuracy: 0.6838 - precision: 0.3351 - recall: 0.6181 - auc: 0.7240 - prc: 0.4706 - val_loss: 0.6017 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6875 - val_prc: 0.4145\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0257 - tp: 250.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 148.0000 - accuracy: 0.6729 - precision: 0.3272 - recall: 0.6281 - auc: 0.7212 - prc: 0.4625 - val_loss: 0.6579 - val_tp: 56.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 35.0000 - val_accuracy: 0.6324 - val_precision: 0.2705 - val_recall: 0.6154 - val_auc: 0.6829 - val_prc: 0.3919\n",
      "Epoch 166/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0245 - tp: 253.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 145.0000 - accuracy: 0.6714 - precision: 0.3273 - recall: 0.6357 - auc: 0.7216 - prc: 0.4645 - val_loss: 0.6366 - val_tp: 54.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 37.0000 - val_accuracy: 0.6462 - val_precision: 0.2755 - val_recall: 0.5934 - val_auc: 0.6862 - val_prc: 0.4087\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0235 - tp: 268.0000 - fp: 586.0000 - tn: 1040.0000 - fn: 130.0000 - accuracy: 0.6462 - precision: 0.3138 - recall: 0.6734 - auc: 0.7221 - prc: 0.4670 - val_loss: 0.6637 - val_tp: 57.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 34.0000 - val_accuracy: 0.6126 - val_precision: 0.2603 - val_recall: 0.6264 - val_auc: 0.6867 - val_prc: 0.4177\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0233 - tp: 269.0000 - fp: 606.0000 - tn: 1020.0000 - fn: 129.0000 - accuracy: 0.6369 - precision: 0.3074 - recall: 0.6759 - auc: 0.7227 - prc: 0.4701 - val_loss: 0.6398 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6897 - val_prc: 0.4349\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0259 - tp: 244.0000 - fp: 485.0000 - tn: 1141.0000 - fn: 154.0000 - accuracy: 0.6843 - precision: 0.3347 - recall: 0.6131 - auc: 0.7218 - prc: 0.4694 - val_loss: 0.6096 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6892 - val_prc: 0.4298\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0230 - tp: 253.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 145.0000 - accuracy: 0.6739 - precision: 0.3294 - recall: 0.6357 - auc: 0.7229 - prc: 0.4672 - val_loss: 0.6478 - val_tp: 55.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 36.0000 - val_accuracy: 0.6324 - val_precision: 0.2683 - val_recall: 0.6044 - val_auc: 0.6879 - val_prc: 0.4211\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0236 - tp: 268.0000 - fp: 602.0000 - tn: 1024.0000 - fn: 130.0000 - accuracy: 0.6383 - precision: 0.3080 - recall: 0.6734 - auc: 0.7220 - prc: 0.4701 - val_loss: 0.6491 - val_tp: 56.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 35.0000 - val_accuracy: 0.6304 - val_precision: 0.2692 - val_recall: 0.6154 - val_auc: 0.6880 - val_prc: 0.4223\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0222 - tp: 253.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 145.0000 - accuracy: 0.6650 - precision: 0.3219 - recall: 0.6357 - auc: 0.7230 - prc: 0.4698 - val_loss: 0.6341 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6873 - val_prc: 0.4169\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0216 - tp: 265.0000 - fp: 562.0000 - tn: 1064.0000 - fn: 133.0000 - accuracy: 0.6566 - precision: 0.3204 - recall: 0.6658 - auc: 0.7235 - prc: 0.4705 - val_loss: 0.6570 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6868 - val_prc: 0.4142\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0222 - tp: 261.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 137.0000 - accuracy: 0.6621 - precision: 0.3230 - recall: 0.6558 - auc: 0.7233 - prc: 0.4688 - val_loss: 0.6453 - val_tp: 55.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 36.0000 - val_accuracy: 0.6383 - val_precision: 0.2723 - val_recall: 0.6044 - val_auc: 0.6854 - val_prc: 0.4090\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0223 - tp: 251.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 147.0000 - accuracy: 0.6764 - precision: 0.3307 - recall: 0.6307 - auc: 0.7233 - prc: 0.4701 - val_loss: 0.6302 - val_tp: 53.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 38.0000 - val_accuracy: 0.6561 - val_precision: 0.2804 - val_recall: 0.5824 - val_auc: 0.6864 - val_prc: 0.4140\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0216 - tp: 247.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 151.0000 - accuracy: 0.6803 - precision: 0.3324 - recall: 0.6206 - auc: 0.7245 - prc: 0.4723 - val_loss: 0.6300 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6885 - val_prc: 0.4244\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0209 - tp: 260.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 138.0000 - accuracy: 0.6670 - precision: 0.3266 - recall: 0.6533 - auc: 0.7241 - prc: 0.4725 - val_loss: 0.6479 - val_tp: 56.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 35.0000 - val_accuracy: 0.6324 - val_precision: 0.2705 - val_recall: 0.6154 - val_auc: 0.6883 - val_prc: 0.4239\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0218 - tp: 270.0000 - fp: 600.0000 - tn: 1026.0000 - fn: 128.0000 - accuracy: 0.6403 - precision: 0.3103 - recall: 0.6784 - auc: 0.7237 - prc: 0.4726 - val_loss: 0.6487 - val_tp: 56.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 35.0000 - val_accuracy: 0.6324 - val_precision: 0.2705 - val_recall: 0.6154 - val_auc: 0.6885 - val_prc: 0.4248\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0208 - tp: 261.0000 - fp: 533.0000 - tn: 1093.0000 - fn: 137.0000 - accuracy: 0.6690 - precision: 0.3287 - recall: 0.6558 - auc: 0.7246 - prc: 0.4715 - val_loss: 0.6415 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6888 - val_prc: 0.4255\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0204 - tp: 269.0000 - fp: 587.0000 - tn: 1039.0000 - fn: 129.0000 - accuracy: 0.6462 - precision: 0.3143 - recall: 0.6759 - auc: 0.7251 - prc: 0.4722 - val_loss: 0.6666 - val_tp: 58.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 33.0000 - val_accuracy: 0.6028 - val_precision: 0.2566 - val_recall: 0.6374 - val_auc: 0.6873 - val_prc: 0.4224\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0208 - tp: 267.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 131.0000 - accuracy: 0.6438 - precision: 0.3116 - recall: 0.6709 - auc: 0.7247 - prc: 0.4721 - val_loss: 0.6311 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.6884 - val_prc: 0.4259\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0221 - tp: 247.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 151.0000 - accuracy: 0.6853 - precision: 0.3370 - recall: 0.6206 - auc: 0.7245 - prc: 0.4718 - val_loss: 0.6241 - val_tp: 53.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 38.0000 - val_accuracy: 0.6621 - val_precision: 0.2849 - val_recall: 0.5824 - val_auc: 0.6888 - val_prc: 0.4273\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0200 - tp: 256.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 142.0000 - accuracy: 0.6744 - precision: 0.3312 - recall: 0.6432 - auc: 0.7252 - prc: 0.4720 - val_loss: 0.6442 - val_tp: 55.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 36.0000 - val_accuracy: 0.6364 - val_precision: 0.2709 - val_recall: 0.6044 - val_auc: 0.6875 - val_prc: 0.4191\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0202 - tp: 258.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 140.0000 - accuracy: 0.6729 - precision: 0.3308 - recall: 0.6482 - auc: 0.7244 - prc: 0.4717 - val_loss: 0.6470 - val_tp: 55.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 36.0000 - val_accuracy: 0.6304 - val_precision: 0.2670 - val_recall: 0.6044 - val_auc: 0.6872 - val_prc: 0.4172\n",
      "Epoch 185/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0213 - tp: 270.0000 - fp: 601.0000 - tn: 1025.0000 - fn: 128.0000 - accuracy: 0.6398 - precision: 0.3100 - recall: 0.6784 - auc: 0.7243 - prc: 0.4720 - val_loss: 0.6540 - val_tp: 57.0000 - val_fp: 156.0000 - val_tn: 259.0000 - val_fn: 34.0000 - val_accuracy: 0.6245 - val_precision: 0.2676 - val_recall: 0.6264 - val_auc: 0.6879 - val_prc: 0.4214\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0203 - tp: 259.0000 - fp: 519.0000 - tn: 1107.0000 - fn: 139.0000 - accuracy: 0.6749 - precision: 0.3329 - recall: 0.6508 - auc: 0.7249 - prc: 0.4726 - val_loss: 0.6249 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6889 - val_prc: 0.4251\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0191 - tp: 260.0000 - fp: 549.0000 - tn: 1077.0000 - fn: 138.0000 - accuracy: 0.6606 - precision: 0.3214 - recall: 0.6533 - auc: 0.7257 - prc: 0.4744 - val_loss: 0.6650 - val_tp: 59.0000 - val_fp: 167.0000 - val_tn: 248.0000 - val_fn: 32.0000 - val_accuracy: 0.6067 - val_precision: 0.2611 - val_recall: 0.6484 - val_auc: 0.6881 - val_prc: 0.4239\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0209 - tp: 272.0000 - fp: 613.0000 - tn: 1013.0000 - fn: 126.0000 - accuracy: 0.6349 - precision: 0.3073 - recall: 0.6834 - auc: 0.7249 - prc: 0.4732 - val_loss: 0.6413 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6884 - val_prc: 0.4212\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0190 - tp: 258.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 140.0000 - accuracy: 0.6803 - precision: 0.3373 - recall: 0.6482 - auc: 0.7262 - prc: 0.4742 - val_loss: 0.6200 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6888 - val_prc: 0.4241\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0202 - tp: 258.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 140.0000 - accuracy: 0.6709 - precision: 0.3291 - recall: 0.6482 - auc: 0.7252 - prc: 0.4729 - val_loss: 0.6487 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6899 - val_prc: 0.4296\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0218 - tp: 257.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 141.0000 - accuracy: 0.6793 - precision: 0.3359 - recall: 0.6457 - auc: 0.7236 - prc: 0.4712 - val_loss: 0.6246 - val_tp: 53.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 38.0000 - val_accuracy: 0.6640 - val_precision: 0.2865 - val_recall: 0.5824 - val_auc: 0.6901 - val_prc: 0.4319\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0207 - tp: 269.0000 - fp: 574.0000 - tn: 1052.0000 - fn: 129.0000 - accuracy: 0.6527 - precision: 0.3191 - recall: 0.6759 - auc: 0.7244 - prc: 0.4726 - val_loss: 0.6629 - val_tp: 59.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 32.0000 - val_accuracy: 0.6107 - val_precision: 0.2634 - val_recall: 0.6484 - val_auc: 0.6892 - val_prc: 0.4275\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0191 - tp: 255.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 143.0000 - accuracy: 0.6754 - precision: 0.3316 - recall: 0.6407 - auc: 0.7256 - prc: 0.4734 - val_loss: 0.6083 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6895 - val_prc: 0.4253\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0209 - tp: 239.0000 - fp: 445.0000 - tn: 1181.0000 - fn: 159.0000 - accuracy: 0.7016 - precision: 0.3494 - recall: 0.6005 - auc: 0.7263 - prc: 0.4751 - val_loss: 0.6229 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6884 - val_prc: 0.4221\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0231 - tp: 263.0000 - fp: 577.0000 - tn: 1049.0000 - fn: 135.0000 - accuracy: 0.6482 - precision: 0.3131 - recall: 0.6608 - auc: 0.7221 - prc: 0.4709 - val_loss: 0.6578 - val_tp: 58.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 33.0000 - val_accuracy: 0.6186 - val_precision: 0.2661 - val_recall: 0.6374 - val_auc: 0.6878 - val_prc: 0.4232\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0185 - tp: 256.0000 - fp: 500.0000 - tn: 1126.0000 - fn: 142.0000 - accuracy: 0.6828 - precision: 0.3386 - recall: 0.6432 - auc: 0.7268 - prc: 0.4719 - val_loss: 0.6074 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6898 - val_prc: 0.4326\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0200 - tp: 252.0000 - fp: 487.0000 - tn: 1139.0000 - fn: 146.0000 - accuracy: 0.6873 - precision: 0.3410 - recall: 0.6332 - auc: 0.7261 - prc: 0.4735 - val_loss: 0.6502 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.6890 - val_prc: 0.4270\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0182 - tp: 265.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 133.0000 - accuracy: 0.6472 - precision: 0.3132 - recall: 0.6658 - auc: 0.7265 - prc: 0.4754 - val_loss: 0.6513 - val_tp: 56.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 35.0000 - val_accuracy: 0.6285 - val_precision: 0.2679 - val_recall: 0.6154 - val_auc: 0.6883 - val_prc: 0.4195\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0179 - tp: 262.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 136.0000 - accuracy: 0.6690 - precision: 0.3291 - recall: 0.6583 - auc: 0.7263 - prc: 0.4740 - val_loss: 0.6343 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6881 - val_prc: 0.4188\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0182 - tp: 257.0000 - fp: 493.0000 - tn: 1133.0000 - fn: 141.0000 - accuracy: 0.6868 - precision: 0.3427 - recall: 0.6457 - auc: 0.7265 - prc: 0.4748 - val_loss: 0.6341 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6899 - val_prc: 0.4278\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0198 - tp: 269.0000 - fp: 589.0000 - tn: 1037.0000 - fn: 129.0000 - accuracy: 0.6453 - precision: 0.3135 - recall: 0.6759 - auc: 0.7261 - prc: 0.4714 - val_loss: 0.6649 - val_tp: 58.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 33.0000 - val_accuracy: 0.6087 - val_precision: 0.2601 - val_recall: 0.6374 - val_auc: 0.6888 - val_prc: 0.4247\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0190 - tp: 256.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 142.0000 - accuracy: 0.6779 - precision: 0.3342 - recall: 0.6432 - auc: 0.7263 - prc: 0.4741 - val_loss: 0.6109 - val_tp: 52.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 39.0000 - val_accuracy: 0.6818 - val_precision: 0.2989 - val_recall: 0.5714 - val_auc: 0.6891 - val_prc: 0.4287\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0197 - tp: 245.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 153.0000 - accuracy: 0.6957 - precision: 0.3460 - recall: 0.6156 - auc: 0.7266 - prc: 0.4736 - val_loss: 0.6306 - val_tp: 55.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 36.0000 - val_accuracy: 0.6601 - val_precision: 0.2880 - val_recall: 0.6044 - val_auc: 0.6889 - val_prc: 0.4226\n",
      "Epoch 204/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0184 - tp: 253.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 145.0000 - accuracy: 0.6907 - precision: 0.3447 - recall: 0.6357 - auc: 0.7266 - prc: 0.4758 - val_loss: 0.6200 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6875 - val_prc: 0.4178\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0181 - tp: 258.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 140.0000 - accuracy: 0.6882 - precision: 0.3445 - recall: 0.6482 - auc: 0.7266 - prc: 0.4758 - val_loss: 0.6402 - val_tp: 55.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 36.0000 - val_accuracy: 0.6364 - val_precision: 0.2709 - val_recall: 0.6044 - val_auc: 0.6887 - val_prc: 0.4213\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0168 - tp: 266.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 132.0000 - accuracy: 0.6591 - precision: 0.3228 - recall: 0.6683 - auc: 0.7276 - prc: 0.4759 - val_loss: 0.6577 - val_tp: 59.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 32.0000 - val_accuracy: 0.6225 - val_precision: 0.2706 - val_recall: 0.6484 - val_auc: 0.6892 - val_prc: 0.4229\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0177 - tp: 269.0000 - fp: 590.0000 - tn: 1036.0000 - fn: 129.0000 - accuracy: 0.6448 - precision: 0.3132 - recall: 0.6759 - auc: 0.7273 - prc: 0.4755 - val_loss: 0.6551 - val_tp: 58.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 33.0000 - val_accuracy: 0.6285 - val_precision: 0.2723 - val_recall: 0.6374 - val_auc: 0.6894 - val_prc: 0.4240\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0174 - tp: 267.0000 - fp: 585.0000 - tn: 1041.0000 - fn: 131.0000 - accuracy: 0.6462 - precision: 0.3134 - recall: 0.6709 - auc: 0.7274 - prc: 0.4764 - val_loss: 0.6423 - val_tp: 55.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 36.0000 - val_accuracy: 0.6364 - val_precision: 0.2709 - val_recall: 0.6044 - val_auc: 0.6904 - val_prc: 0.4245\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0186 - tp: 258.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 140.0000 - accuracy: 0.6828 - precision: 0.3395 - recall: 0.6482 - auc: 0.7267 - prc: 0.4756 - val_loss: 0.6283 - val_tp: 55.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 36.0000 - val_accuracy: 0.6621 - val_precision: 0.2895 - val_recall: 0.6044 - val_auc: 0.6894 - val_prc: 0.4258\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0173 - tp: 267.0000 - fp: 564.0000 - tn: 1062.0000 - fn: 131.0000 - accuracy: 0.6566 - precision: 0.3213 - recall: 0.6709 - auc: 0.7269 - prc: 0.4768 - val_loss: 0.6615 - val_tp: 58.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 33.0000 - val_accuracy: 0.6146 - val_precision: 0.2636 - val_recall: 0.6374 - val_auc: 0.6897 - val_prc: 0.4235\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0166 - tp: 261.0000 - fp: 534.0000 - tn: 1092.0000 - fn: 137.0000 - accuracy: 0.6685 - precision: 0.3283 - recall: 0.6558 - auc: 0.7275 - prc: 0.4751 - val_loss: 0.6255 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6902 - val_prc: 0.4278\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0168 - tp: 260.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 138.0000 - accuracy: 0.6670 - precision: 0.3266 - recall: 0.6533 - auc: 0.7275 - prc: 0.4765 - val_loss: 0.6397 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6908 - val_prc: 0.4350\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0175 - tp: 257.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 141.0000 - accuracy: 0.6882 - precision: 0.3440 - recall: 0.6457 - auc: 0.7281 - prc: 0.4771 - val_loss: 0.6194 - val_tp: 53.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 38.0000 - val_accuracy: 0.6719 - val_precision: 0.2928 - val_recall: 0.5824 - val_auc: 0.6896 - val_prc: 0.4277\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0166 - tp: 258.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 140.0000 - accuracy: 0.6784 - precision: 0.3355 - recall: 0.6482 - auc: 0.7284 - prc: 0.4755 - val_loss: 0.6465 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6887 - val_prc: 0.4237\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0162 - tp: 263.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 135.0000 - accuracy: 0.6586 - precision: 0.3211 - recall: 0.6608 - auc: 0.7281 - prc: 0.4759 - val_loss: 0.6511 - val_tp: 56.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 35.0000 - val_accuracy: 0.6324 - val_precision: 0.2705 - val_recall: 0.6154 - val_auc: 0.6896 - val_prc: 0.4208\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0154 - tp: 259.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 139.0000 - accuracy: 0.6739 - precision: 0.3321 - recall: 0.6508 - auc: 0.7284 - prc: 0.4774 - val_loss: 0.6254 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6894 - val_prc: 0.4234\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0160 - tp: 256.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 142.0000 - accuracy: 0.6838 - precision: 0.3395 - recall: 0.6432 - auc: 0.7287 - prc: 0.4767 - val_loss: 0.6363 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6899 - val_prc: 0.4210\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0161 - tp: 262.0000 - fp: 557.0000 - tn: 1069.0000 - fn: 136.0000 - accuracy: 0.6576 - precision: 0.3199 - recall: 0.6583 - auc: 0.7284 - prc: 0.4766 - val_loss: 0.6465 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6894 - val_prc: 0.4234\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0190 - tp: 249.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 149.0000 - accuracy: 0.6907 - precision: 0.3430 - recall: 0.6256 - auc: 0.7272 - prc: 0.4734 - val_loss: 0.6185 - val_tp: 51.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 40.0000 - val_accuracy: 0.6680 - val_precision: 0.2849 - val_recall: 0.5604 - val_auc: 0.6899 - val_prc: 0.4236\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0170 - tp: 261.0000 - fp: 554.0000 - tn: 1072.0000 - fn: 137.0000 - accuracy: 0.6586 - precision: 0.3202 - recall: 0.6558 - auc: 0.7270 - prc: 0.4759 - val_loss: 0.6556 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6883 - val_prc: 0.4203\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0156 - tp: 260.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 138.0000 - accuracy: 0.6803 - precision: 0.3381 - recall: 0.6533 - auc: 0.7284 - prc: 0.4778 - val_loss: 0.6268 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6892 - val_prc: 0.4201\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0149 - tp: 259.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 139.0000 - accuracy: 0.6754 - precision: 0.3333 - recall: 0.6508 - auc: 0.7291 - prc: 0.4779 - val_loss: 0.6525 - val_tp: 57.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 34.0000 - val_accuracy: 0.6304 - val_precision: 0.2714 - val_recall: 0.6264 - val_auc: 0.6897 - val_prc: 0.4209\n",
      "Epoch 223/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0158 - tp: 270.0000 - fp: 583.0000 - tn: 1043.0000 - fn: 128.0000 - accuracy: 0.6487 - precision: 0.3165 - recall: 0.6784 - auc: 0.7287 - prc: 0.4766 - val_loss: 0.6552 - val_tp: 58.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 33.0000 - val_accuracy: 0.6304 - val_precision: 0.2736 - val_recall: 0.6374 - val_auc: 0.6894 - val_prc: 0.4210\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0151 - tp: 263.0000 - fp: 545.0000 - tn: 1081.0000 - fn: 135.0000 - accuracy: 0.6640 - precision: 0.3255 - recall: 0.6608 - auc: 0.7294 - prc: 0.4775 - val_loss: 0.6325 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6893 - val_prc: 0.4216\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0177 - tp: 249.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 149.0000 - accuracy: 0.6917 - precision: 0.3439 - recall: 0.6256 - auc: 0.7284 - prc: 0.4747 - val_loss: 0.6163 - val_tp: 51.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 40.0000 - val_accuracy: 0.6660 - val_precision: 0.2833 - val_recall: 0.5604 - val_auc: 0.6898 - val_prc: 0.4226\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0151 - tp: 256.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 142.0000 - accuracy: 0.6858 - precision: 0.3413 - recall: 0.6432 - auc: 0.7294 - prc: 0.4789 - val_loss: 0.6438 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6903 - val_prc: 0.4245\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0162 - tp: 257.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 141.0000 - accuracy: 0.6828 - precision: 0.3391 - recall: 0.6457 - auc: 0.7282 - prc: 0.4761 - val_loss: 0.6332 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6901 - val_prc: 0.4216\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0143 - tp: 270.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 128.0000 - accuracy: 0.6502 - precision: 0.3176 - recall: 0.6784 - auc: 0.7296 - prc: 0.4797 - val_loss: 0.6775 - val_tp: 61.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 30.0000 - val_accuracy: 0.5988 - val_precision: 0.2607 - val_recall: 0.6703 - val_auc: 0.6898 - val_prc: 0.4233\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0157 - tp: 270.0000 - fp: 596.0000 - tn: 1030.0000 - fn: 128.0000 - accuracy: 0.6423 - precision: 0.3118 - recall: 0.6784 - auc: 0.7290 - prc: 0.4766 - val_loss: 0.6367 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6911 - val_prc: 0.4275\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0157 - tp: 255.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 143.0000 - accuracy: 0.6838 - precision: 0.3391 - recall: 0.6407 - auc: 0.7290 - prc: 0.4772 - val_loss: 0.6331 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6905 - val_prc: 0.4241\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0172 - tp: 268.0000 - fp: 597.0000 - tn: 1029.0000 - fn: 130.0000 - accuracy: 0.6408 - precision: 0.3098 - recall: 0.6734 - auc: 0.7280 - prc: 0.4762 - val_loss: 0.6797 - val_tp: 61.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 30.0000 - val_accuracy: 0.5968 - val_precision: 0.2596 - val_recall: 0.6703 - val_auc: 0.6894 - val_prc: 0.4230\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0163 - tp: 273.0000 - fp: 624.0000 - tn: 1002.0000 - fn: 125.0000 - accuracy: 0.6299 - precision: 0.3043 - recall: 0.6859 - auc: 0.7298 - prc: 0.4783 - val_loss: 0.6394 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6910 - val_prc: 0.4293\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0152 - tp: 255.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 143.0000 - accuracy: 0.6838 - precision: 0.3391 - recall: 0.6407 - auc: 0.7298 - prc: 0.4758 - val_loss: 0.6249 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6917 - val_prc: 0.4277\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0138 - tp: 261.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 137.0000 - accuracy: 0.6784 - precision: 0.3368 - recall: 0.6558 - auc: 0.7305 - prc: 0.4784 - val_loss: 0.6528 - val_tp: 57.0000 - val_fp: 152.0000 - val_tn: 263.0000 - val_fn: 34.0000 - val_accuracy: 0.6324 - val_precision: 0.2727 - val_recall: 0.6264 - val_auc: 0.6901 - val_prc: 0.4209\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0154 - tp: 267.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 131.0000 - accuracy: 0.6482 - precision: 0.3149 - recall: 0.6709 - auc: 0.7291 - prc: 0.4768 - val_loss: 0.6526 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6912 - val_prc: 0.4255\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0163 - tp: 259.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 139.0000 - accuracy: 0.6690 - precision: 0.3278 - recall: 0.6508 - auc: 0.7283 - prc: 0.4749 - val_loss: 0.6404 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6908 - val_prc: 0.4242\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0140 - tp: 260.0000 - fp: 530.0000 - tn: 1096.0000 - fn: 138.0000 - accuracy: 0.6700 - precision: 0.3291 - recall: 0.6533 - auc: 0.7300 - prc: 0.4778 - val_loss: 0.6437 - val_tp: 57.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 34.0000 - val_accuracy: 0.6383 - val_precision: 0.2767 - val_recall: 0.6264 - val_auc: 0.6912 - val_prc: 0.4273\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0145 - tp: 257.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 141.0000 - accuracy: 0.6803 - precision: 0.3368 - recall: 0.6457 - auc: 0.7297 - prc: 0.4785 - val_loss: 0.6254 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6913 - val_prc: 0.4243\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0146 - tp: 258.0000 - fp: 509.0000 - tn: 1117.0000 - fn: 140.0000 - accuracy: 0.6793 - precision: 0.3364 - recall: 0.6482 - auc: 0.7296 - prc: 0.4774 - val_loss: 0.6403 - val_tp: 56.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 35.0000 - val_accuracy: 0.6403 - val_precision: 0.2759 - val_recall: 0.6154 - val_auc: 0.6905 - val_prc: 0.4218\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0141 - tp: 261.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 137.0000 - accuracy: 0.6764 - precision: 0.3350 - recall: 0.6558 - auc: 0.7299 - prc: 0.4771 - val_loss: 0.6416 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6904 - val_prc: 0.4224\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0143 - tp: 262.0000 - fp: 548.0000 - tn: 1078.0000 - fn: 136.0000 - accuracy: 0.6621 - precision: 0.3235 - recall: 0.6583 - auc: 0.7296 - prc: 0.4772 - val_loss: 0.6502 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6903 - val_prc: 0.4227\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0142 - tp: 257.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 141.0000 - accuracy: 0.6769 - precision: 0.3338 - recall: 0.6457 - auc: 0.7300 - prc: 0.4790 - val_loss: 0.6223 - val_tp: 51.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 40.0000 - val_accuracy: 0.6660 - val_precision: 0.2833 - val_recall: 0.5604 - val_auc: 0.6909 - val_prc: 0.4242\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0151 - tp: 258.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 140.0000 - accuracy: 0.6724 - precision: 0.3303 - recall: 0.6482 - auc: 0.7295 - prc: 0.4744 - val_loss: 0.6455 - val_tp: 57.0000 - val_fp: 149.0000 - val_tn: 266.0000 - val_fn: 34.0000 - val_accuracy: 0.6383 - val_precision: 0.2767 - val_recall: 0.6264 - val_auc: 0.6901 - val_prc: 0.4225\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0134 - tp: 262.0000 - fp: 528.0000 - tn: 1098.0000 - fn: 136.0000 - accuracy: 0.6719 - precision: 0.3316 - recall: 0.6583 - auc: 0.7305 - prc: 0.4779 - val_loss: 0.6337 - val_tp: 54.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 37.0000 - val_accuracy: 0.6482 - val_precision: 0.2769 - val_recall: 0.5934 - val_auc: 0.6905 - val_prc: 0.4231\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0150 - tp: 255.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 143.0000 - accuracy: 0.6927 - precision: 0.3474 - recall: 0.6407 - auc: 0.7298 - prc: 0.4771 - val_loss: 0.6327 - val_tp: 54.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 37.0000 - val_accuracy: 0.6502 - val_precision: 0.2784 - val_recall: 0.5934 - val_auc: 0.6918 - val_prc: 0.4256\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0195 - tp: 270.0000 - fp: 627.0000 - tn: 999.0000 - fn: 128.0000 - accuracy: 0.6270 - precision: 0.3010 - recall: 0.6784 - auc: 0.7268 - prc: 0.4750 - val_loss: 0.6750 - val_tp: 60.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 31.0000 - val_accuracy: 0.6008 - val_precision: 0.2597 - val_recall: 0.6593 - val_auc: 0.6905 - val_prc: 0.4244\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0146 - tp: 265.0000 - fp: 575.0000 - tn: 1051.0000 - fn: 133.0000 - accuracy: 0.6502 - precision: 0.3155 - recall: 0.6658 - auc: 0.7304 - prc: 0.4744 - val_loss: 0.6397 - val_tp: 57.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 34.0000 - val_accuracy: 0.6443 - val_precision: 0.2808 - val_recall: 0.6264 - val_auc: 0.6924 - val_prc: 0.4310\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0135 - tp: 264.0000 - fp: 546.0000 - tn: 1080.0000 - fn: 134.0000 - accuracy: 0.6640 - precision: 0.3259 - recall: 0.6633 - auc: 0.7303 - prc: 0.4781 - val_loss: 0.6502 - val_tp: 57.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 34.0000 - val_accuracy: 0.6364 - val_precision: 0.2754 - val_recall: 0.6264 - val_auc: 0.6912 - val_prc: 0.4274\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0170 - tp: 259.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 139.0000 - accuracy: 0.6739 - precision: 0.3321 - recall: 0.6508 - auc: 0.7273 - prc: 0.4760 - val_loss: 0.6215 - val_tp: 51.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 40.0000 - val_accuracy: 0.6680 - val_precision: 0.2849 - val_recall: 0.5604 - val_auc: 0.6906 - val_prc: 0.4234\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0150 - tp: 261.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 137.0000 - accuracy: 0.6700 - precision: 0.3295 - recall: 0.6558 - auc: 0.7293 - prc: 0.4752 - val_loss: 0.6568 - val_tp: 58.0000 - val_fp: 153.0000 - val_tn: 262.0000 - val_fn: 33.0000 - val_accuracy: 0.6324 - val_precision: 0.2749 - val_recall: 0.6374 - val_auc: 0.6891 - val_prc: 0.4179\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0138 - tp: 265.0000 - fp: 570.0000 - tn: 1056.0000 - fn: 133.0000 - accuracy: 0.6527 - precision: 0.3174 - recall: 0.6658 - auc: 0.7305 - prc: 0.4781 - val_loss: 0.6363 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6910 - val_prc: 0.4257\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0136 - tp: 256.0000 - fp: 492.0000 - tn: 1134.0000 - fn: 142.0000 - accuracy: 0.6868 - precision: 0.3422 - recall: 0.6432 - auc: 0.7306 - prc: 0.4787 - val_loss: 0.6197 - val_tp: 51.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 40.0000 - val_accuracy: 0.6700 - val_precision: 0.2865 - val_recall: 0.5604 - val_auc: 0.6911 - val_prc: 0.4239\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0152 - tp: 253.0000 - fp: 466.0000 - tn: 1160.0000 - fn: 145.0000 - accuracy: 0.6981 - precision: 0.3519 - recall: 0.6357 - auc: 0.7305 - prc: 0.4778 - val_loss: 0.6283 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6905 - val_prc: 0.4217\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0136 - tp: 261.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 137.0000 - accuracy: 0.6754 - precision: 0.3342 - recall: 0.6558 - auc: 0.7302 - prc: 0.4778 - val_loss: 0.6417 - val_tp: 55.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 36.0000 - val_accuracy: 0.6462 - val_precision: 0.2778 - val_recall: 0.6044 - val_auc: 0.6909 - val_prc: 0.4242\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0141 - tp: 257.0000 - fp: 483.0000 - tn: 1143.0000 - fn: 141.0000 - accuracy: 0.6917 - precision: 0.3473 - recall: 0.6457 - auc: 0.7305 - prc: 0.4768 - val_loss: 0.6227 - val_tp: 51.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 40.0000 - val_accuracy: 0.6680 - val_precision: 0.2849 - val_recall: 0.5604 - val_auc: 0.6908 - val_prc: 0.4238\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0130 - tp: 256.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 142.0000 - accuracy: 0.6858 - precision: 0.3413 - recall: 0.6432 - auc: 0.7306 - prc: 0.4776 - val_loss: 0.6520 - val_tp: 58.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 33.0000 - val_accuracy: 0.6364 - val_precision: 0.2775 - val_recall: 0.6374 - val_auc: 0.6896 - val_prc: 0.4119\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0153 - tp: 270.0000 - fp: 625.0000 - tn: 1001.0000 - fn: 128.0000 - accuracy: 0.6280 - precision: 0.3017 - recall: 0.6784 - auc: 0.7307 - prc: 0.4777 - val_loss: 0.6771 - val_tp: 60.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 31.0000 - val_accuracy: 0.5988 - val_precision: 0.2586 - val_recall: 0.6593 - val_auc: 0.6904 - val_prc: 0.4218\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0122 - tp: 268.0000 - fp: 565.0000 - tn: 1061.0000 - fn: 130.0000 - accuracy: 0.6566 - precision: 0.3217 - recall: 0.6734 - auc: 0.7318 - prc: 0.4767 - val_loss: 0.6265 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6915 - val_prc: 0.4241\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0137 - tp: 258.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 140.0000 - accuracy: 0.6779 - precision: 0.3351 - recall: 0.6482 - auc: 0.7297 - prc: 0.4784 - val_loss: 0.6385 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6927 - val_prc: 0.4250\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0129 - tp: 262.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 136.0000 - accuracy: 0.6754 - precision: 0.3346 - recall: 0.6583 - auc: 0.7306 - prc: 0.4777 - val_loss: 0.6336 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6911 - val_prc: 0.4219\n",
      "Epoch 261/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0128 - tp: 261.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 137.0000 - accuracy: 0.6749 - precision: 0.3338 - recall: 0.6558 - auc: 0.7306 - prc: 0.4776 - val_loss: 0.6400 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6915 - val_prc: 0.4191\n",
      "Epoch 262/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.9655 - tp: 30.0000 - fp: 54.0000 - tn: 105.0000 - fn: 11.0000 - accuracy: 0.6750 - precision: 0.3571 - recall: 0.7317 - auc: 0.7796 - prc: 0.5391Restoring model weights from the end of the best epoch: 212.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0125 - tp: 258.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 140.0000 - accuracy: 0.6813 - precision: 0.3381 - recall: 0.6482 - auc: 0.7311 - prc: 0.4784 - val_loss: 0.6325 - val_tp: 53.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 38.0000 - val_accuracy: 0.6542 - val_precision: 0.2789 - val_recall: 0.5824 - val_auc: 0.6906 - val_prc: 0.4117\n",
      "Epoch 262: early stopping\n",
      "3/3 [==============================] - 0s 905us/step\n",
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 0.9283 - tp: 53.0000 - fp: 137.0000 - tn: 1904.0000 - fn: 436.0000 - accuracy: 0.7735 - precision: 0.2789 - recall: 0.1084 - auc: 0.4725 - prc: 0.2236 - val_loss: 0.4722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5203 - val_prc: 0.1863\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9180 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5017 - prc: 0.1993 - val_loss: 0.4727 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4806 - val_prc: 0.1726\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5193 - prc: 0.2126 - val_loss: 0.4735 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5065 - val_prc: 0.1946\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8935 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5592 - prc: 0.2630 - val_loss: 0.4746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5663 - val_prc: 0.2112\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8786 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6006 - prc: 0.2812 - val_loss: 0.4764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5836 - val_prc: 0.2415\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8612 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6347 - prc: 0.3071 - val_loss: 0.4789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6125 - val_prc: 0.2698\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8422 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6465 - prc: 0.3157 - val_loss: 0.4827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6256 - val_prc: 0.2840\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8208 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6578 - prc: 0.3383 - val_loss: 0.4884 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6289 - val_prc: 0.2776\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7978 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6623 - prc: 0.3361 - val_loss: 0.4969 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6356 - val_prc: 0.2778\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7715 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6676 - prc: 0.3485 - val_loss: 0.5101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6470 - val_prc: 0.2836\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7434 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6615 - prc: 0.3347 - val_loss: 0.5307 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6404 - val_prc: 0.2748\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7161 - tp: 1.0000 - fp: 2.0000 - tn: 1624.0000 - fn: 397.0000 - accuracy: 0.8029 - precision: 0.3333 - recall: 0.0025 - auc: 0.6776 - prc: 0.3633 - val_loss: 0.5561 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6430 - val_prc: 0.2793\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6936 - tp: 10.0000 - fp: 9.0000 - tn: 1617.0000 - fn: 388.0000 - accuracy: 0.8039 - precision: 0.5263 - recall: 0.0251 - auc: 0.6732 - prc: 0.3483 - val_loss: 0.5913 - val_tp: 2.0000 - val_fp: 8.0000 - val_tn: 407.0000 - val_fn: 89.0000 - val_accuracy: 0.8083 - val_precision: 0.2000 - val_recall: 0.0220 - val_auc: 0.6463 - val_prc: 0.2806\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6775 - tp: 50.0000 - fp: 40.0000 - tn: 1586.0000 - fn: 348.0000 - accuracy: 0.8083 - precision: 0.5556 - recall: 0.1256 - auc: 0.6791 - prc: 0.3578 - val_loss: 0.6293 - val_tp: 16.0000 - val_fp: 35.0000 - val_tn: 380.0000 - val_fn: 75.0000 - val_accuracy: 0.7826 - val_precision: 0.3137 - val_recall: 0.1758 - val_auc: 0.6477 - val_prc: 0.2787\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6677 - tp: 160.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 238.0000 - accuracy: 0.7624 - precision: 0.3970 - recall: 0.4020 - auc: 0.6867 - prc: 0.3713 - val_loss: 0.6642 - val_tp: 47.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 44.0000 - val_accuracy: 0.6739 - val_precision: 0.2798 - val_recall: 0.5165 - val_auc: 0.6488 - val_prc: 0.2784\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6642 - tp: 268.0000 - fp: 612.0000 - tn: 1014.0000 - fn: 130.0000 - accuracy: 0.6334 - precision: 0.3045 - recall: 0.6734 - auc: 0.6883 - prc: 0.3679 - val_loss: 0.6935 - val_tp: 68.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 23.0000 - val_accuracy: 0.5395 - val_precision: 0.2446 - val_recall: 0.7473 - val_auc: 0.6531 - val_prc: 0.2798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6641 - tp: 315.0000 - fp: 919.0000 - tn: 707.0000 - fn: 83.0000 - accuracy: 0.5049 - precision: 0.2553 - recall: 0.7915 - auc: 0.6880 - prc: 0.3683 - val_loss: 0.7041 - val_tp: 70.0000 - val_fp: 241.0000 - val_tn: 174.0000 - val_fn: 21.0000 - val_accuracy: 0.4822 - val_precision: 0.2251 - val_recall: 0.7692 - val_auc: 0.6533 - val_prc: 0.2821\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6633 - tp: 304.0000 - fp: 865.0000 - tn: 761.0000 - fn: 94.0000 - accuracy: 0.5262 - precision: 0.2601 - recall: 0.7638 - auc: 0.6900 - prc: 0.3735 - val_loss: 0.6912 - val_tp: 67.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 24.0000 - val_accuracy: 0.5375 - val_precision: 0.2419 - val_recall: 0.7363 - val_auc: 0.6552 - val_prc: 0.2869\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6625 - tp: 295.0000 - fp: 795.0000 - tn: 831.0000 - fn: 103.0000 - accuracy: 0.5563 - precision: 0.2706 - recall: 0.7412 - auc: 0.6908 - prc: 0.3765 - val_loss: 0.6892 - val_tp: 65.0000 - val_fp: 212.0000 - val_tn: 203.0000 - val_fn: 26.0000 - val_accuracy: 0.5296 - val_precision: 0.2347 - val_recall: 0.7143 - val_auc: 0.6550 - val_prc: 0.2863\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6619 - tp: 280.0000 - fp: 708.0000 - tn: 918.0000 - fn: 118.0000 - accuracy: 0.5919 - precision: 0.2834 - recall: 0.7035 - auc: 0.6925 - prc: 0.3794 - val_loss: 0.6763 - val_tp: 58.0000 - val_fp: 176.0000 - val_tn: 239.0000 - val_fn: 33.0000 - val_accuracy: 0.5870 - val_precision: 0.2479 - val_recall: 0.6374 - val_auc: 0.6559 - val_prc: 0.2893\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - tp: 258.0000 - fp: 591.0000 - tn: 1035.0000 - fn: 140.0000 - accuracy: 0.6388 - precision: 0.3039 - recall: 0.6482 - auc: 0.6922 - prc: 0.3801 - val_loss: 0.6754 - val_tp: 57.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 34.0000 - val_accuracy: 0.5870 - val_precision: 0.2457 - val_recall: 0.6264 - val_auc: 0.6560 - val_prc: 0.2896\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6614 - tp: 288.0000 - fp: 769.0000 - tn: 857.0000 - fn: 110.0000 - accuracy: 0.5657 - precision: 0.2725 - recall: 0.7236 - auc: 0.6898 - prc: 0.3774 - val_loss: 0.6934 - val_tp: 67.0000 - val_fp: 221.0000 - val_tn: 194.0000 - val_fn: 24.0000 - val_accuracy: 0.5158 - val_precision: 0.2326 - val_recall: 0.7363 - val_auc: 0.6592 - val_prc: 0.2928\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6606 - tp: 299.0000 - fp: 818.0000 - tn: 808.0000 - fn: 99.0000 - accuracy: 0.5469 - precision: 0.2677 - recall: 0.7513 - auc: 0.6934 - prc: 0.3816 - val_loss: 0.6881 - val_tp: 63.0000 - val_fp: 210.0000 - val_tn: 205.0000 - val_fn: 28.0000 - val_accuracy: 0.5296 - val_precision: 0.2308 - val_recall: 0.6923 - val_auc: 0.6564 - val_prc: 0.2912\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6602 - tp: 286.0000 - fp: 740.0000 - tn: 886.0000 - fn: 112.0000 - accuracy: 0.5791 - precision: 0.2788 - recall: 0.7186 - auc: 0.6922 - prc: 0.3815 - val_loss: 0.6840 - val_tp: 61.0000 - val_fp: 199.0000 - val_tn: 216.0000 - val_fn: 30.0000 - val_accuracy: 0.5474 - val_precision: 0.2346 - val_recall: 0.6703 - val_auc: 0.6583 - val_prc: 0.2933\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6598 - tp: 276.0000 - fp: 698.0000 - tn: 928.0000 - fn: 122.0000 - accuracy: 0.5949 - precision: 0.2834 - recall: 0.6935 - auc: 0.6933 - prc: 0.3823 - val_loss: 0.6834 - val_tp: 61.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 30.0000 - val_accuracy: 0.5514 - val_precision: 0.2364 - val_recall: 0.6703 - val_auc: 0.6579 - val_prc: 0.2941\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6592 - tp: 295.0000 - fp: 794.0000 - tn: 832.0000 - fn: 103.0000 - accuracy: 0.5568 - precision: 0.2709 - recall: 0.7412 - auc: 0.6942 - prc: 0.3842 - val_loss: 0.6937 - val_tp: 67.0000 - val_fp: 220.0000 - val_tn: 195.0000 - val_fn: 24.0000 - val_accuracy: 0.5178 - val_precision: 0.2334 - val_recall: 0.7363 - val_auc: 0.6600 - val_prc: 0.2962\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6588 - tp: 302.0000 - fp: 865.0000 - tn: 761.0000 - fn: 96.0000 - accuracy: 0.5252 - precision: 0.2588 - recall: 0.7588 - auc: 0.6958 - prc: 0.3854 - val_loss: 0.6973 - val_tp: 68.0000 - val_fp: 229.0000 - val_tn: 186.0000 - val_fn: 23.0000 - val_accuracy: 0.5020 - val_precision: 0.2290 - val_recall: 0.7473 - val_auc: 0.6595 - val_prc: 0.2956\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6585 - tp: 300.0000 - fp: 839.0000 - tn: 787.0000 - fn: 98.0000 - accuracy: 0.5371 - precision: 0.2634 - recall: 0.7538 - auc: 0.6951 - prc: 0.3849 - val_loss: 0.6850 - val_tp: 61.0000 - val_fp: 202.0000 - val_tn: 213.0000 - val_fn: 30.0000 - val_accuracy: 0.5415 - val_precision: 0.2319 - val_recall: 0.6703 - val_auc: 0.6601 - val_prc: 0.2972\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6578 - tp: 275.0000 - fp: 699.0000 - tn: 927.0000 - fn: 123.0000 - accuracy: 0.5939 - precision: 0.2823 - recall: 0.6910 - auc: 0.6960 - prc: 0.3859 - val_loss: 0.6723 - val_tp: 57.0000 - val_fp: 172.0000 - val_tn: 243.0000 - val_fn: 34.0000 - val_accuracy: 0.5929 - val_precision: 0.2489 - val_recall: 0.6264 - val_auc: 0.6601 - val_prc: 0.2957\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6576 - tp: 261.0000 - fp: 601.0000 - tn: 1025.0000 - fn: 137.0000 - accuracy: 0.6354 - precision: 0.3028 - recall: 0.6558 - auc: 0.6958 - prc: 0.3880 - val_loss: 0.6730 - val_tp: 57.0000 - val_fp: 175.0000 - val_tn: 240.0000 - val_fn: 34.0000 - val_accuracy: 0.5870 - val_precision: 0.2457 - val_recall: 0.6264 - val_auc: 0.6600 - val_prc: 0.2966\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6571 - tp: 261.0000 - fp: 603.0000 - tn: 1023.0000 - fn: 137.0000 - accuracy: 0.6344 - precision: 0.3021 - recall: 0.6558 - auc: 0.6960 - prc: 0.3888 - val_loss: 0.6726 - val_tp: 57.0000 - val_fp: 174.0000 - val_tn: 241.0000 - val_fn: 34.0000 - val_accuracy: 0.5889 - val_precision: 0.2468 - val_recall: 0.6264 - val_auc: 0.6603 - val_prc: 0.2982\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6569 - tp: 277.0000 - fp: 716.0000 - tn: 910.0000 - fn: 121.0000 - accuracy: 0.5865 - precision: 0.2790 - recall: 0.6960 - auc: 0.6953 - prc: 0.3878 - val_loss: 0.6880 - val_tp: 63.0000 - val_fp: 208.0000 - val_tn: 207.0000 - val_fn: 28.0000 - val_accuracy: 0.5336 - val_precision: 0.2325 - val_recall: 0.6923 - val_auc: 0.6623 - val_prc: 0.3001\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6560 - tp: 293.0000 - fp: 773.0000 - tn: 853.0000 - fn: 105.0000 - accuracy: 0.5662 - precision: 0.2749 - recall: 0.7362 - auc: 0.6966 - prc: 0.3904 - val_loss: 0.6864 - val_tp: 63.0000 - val_fp: 205.0000 - val_tn: 210.0000 - val_fn: 28.0000 - val_accuracy: 0.5395 - val_precision: 0.2351 - val_recall: 0.6923 - val_auc: 0.6612 - val_prc: 0.3001\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6554 - tp: 281.0000 - fp: 722.0000 - tn: 904.0000 - fn: 117.0000 - accuracy: 0.5855 - precision: 0.2802 - recall: 0.7060 - auc: 0.6971 - prc: 0.3917 - val_loss: 0.6786 - val_tp: 60.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 31.0000 - val_accuracy: 0.5593 - val_precision: 0.2381 - val_recall: 0.6593 - val_auc: 0.6618 - val_prc: 0.3016\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6550 - tp: 281.0000 - fp: 723.0000 - tn: 903.0000 - fn: 117.0000 - accuracy: 0.5850 - precision: 0.2799 - recall: 0.7060 - auc: 0.6976 - prc: 0.3926 - val_loss: 0.6792 - val_tp: 60.0000 - val_fp: 193.0000 - val_tn: 222.0000 - val_fn: 31.0000 - val_accuracy: 0.5573 - val_precision: 0.2372 - val_recall: 0.6593 - val_auc: 0.6636 - val_prc: 0.3033\n",
      "Epoch 36/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6553 - tp: 260.0000 - fp: 596.0000 - tn: 1030.0000 - fn: 138.0000 - accuracy: 0.6374 - precision: 0.3037 - recall: 0.6533 - auc: 0.6955 - prc: 0.3885 - val_loss: 0.6673 - val_tp: 57.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 34.0000 - val_accuracy: 0.6126 - val_precision: 0.2603 - val_recall: 0.6264 - val_auc: 0.6623 - val_prc: 0.3031\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6546 - tp: 271.0000 - fp: 703.0000 - tn: 923.0000 - fn: 127.0000 - accuracy: 0.5899 - precision: 0.2782 - recall: 0.6809 - auc: 0.6937 - prc: 0.3900 - val_loss: 0.6842 - val_tp: 62.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 29.0000 - val_accuracy: 0.5415 - val_precision: 0.2340 - val_recall: 0.6813 - val_auc: 0.6630 - val_prc: 0.3032\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6535 - tp: 285.0000 - fp: 746.0000 - tn: 880.0000 - fn: 113.0000 - accuracy: 0.5756 - precision: 0.2764 - recall: 0.7161 - auc: 0.6976 - prc: 0.3938 - val_loss: 0.6849 - val_tp: 63.0000 - val_fp: 204.0000 - val_tn: 211.0000 - val_fn: 28.0000 - val_accuracy: 0.5415 - val_precision: 0.2360 - val_recall: 0.6923 - val_auc: 0.6626 - val_prc: 0.3045\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6530 - tp: 285.0000 - fp: 755.0000 - tn: 871.0000 - fn: 113.0000 - accuracy: 0.5711 - precision: 0.2740 - recall: 0.7161 - auc: 0.6979 - prc: 0.3953 - val_loss: 0.6820 - val_tp: 62.0000 - val_fp: 200.0000 - val_tn: 215.0000 - val_fn: 29.0000 - val_accuracy: 0.5474 - val_precision: 0.2366 - val_recall: 0.6813 - val_auc: 0.6638 - val_prc: 0.3053\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6526 - tp: 281.0000 - fp: 730.0000 - tn: 896.0000 - fn: 117.0000 - accuracy: 0.5815 - precision: 0.2779 - recall: 0.7060 - auc: 0.6985 - prc: 0.3953 - val_loss: 0.6776 - val_tp: 60.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 31.0000 - val_accuracy: 0.5593 - val_precision: 0.2381 - val_recall: 0.6593 - val_auc: 0.6648 - val_prc: 0.3058\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6520 - tp: 277.0000 - fp: 699.0000 - tn: 927.0000 - fn: 121.0000 - accuracy: 0.5949 - precision: 0.2838 - recall: 0.6960 - auc: 0.6987 - prc: 0.3965 - val_loss: 0.6782 - val_tp: 60.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 31.0000 - val_accuracy: 0.5593 - val_precision: 0.2381 - val_recall: 0.6593 - val_auc: 0.6644 - val_prc: 0.3058\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6516 - tp: 276.0000 - fp: 687.0000 - tn: 939.0000 - fn: 122.0000 - accuracy: 0.6003 - precision: 0.2866 - recall: 0.6935 - auc: 0.6986 - prc: 0.3969 - val_loss: 0.6780 - val_tp: 60.0000 - val_fp: 192.0000 - val_tn: 223.0000 - val_fn: 31.0000 - val_accuracy: 0.5593 - val_precision: 0.2381 - val_recall: 0.6593 - val_auc: 0.6656 - val_prc: 0.3082\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6509 - tp: 282.0000 - fp: 731.0000 - tn: 895.0000 - fn: 116.0000 - accuracy: 0.5815 - precision: 0.2784 - recall: 0.7085 - auc: 0.6991 - prc: 0.3977 - val_loss: 0.6846 - val_tp: 64.0000 - val_fp: 206.0000 - val_tn: 209.0000 - val_fn: 27.0000 - val_accuracy: 0.5395 - val_precision: 0.2370 - val_recall: 0.7033 - val_auc: 0.6659 - val_prc: 0.3075\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6503 - tp: 280.0000 - fp: 732.0000 - tn: 894.0000 - fn: 118.0000 - accuracy: 0.5800 - precision: 0.2767 - recall: 0.7035 - auc: 0.7001 - prc: 0.3991 - val_loss: 0.6760 - val_tp: 60.0000 - val_fp: 191.0000 - val_tn: 224.0000 - val_fn: 31.0000 - val_accuracy: 0.5613 - val_precision: 0.2390 - val_recall: 0.6593 - val_auc: 0.6652 - val_prc: 0.3085\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6498 - tp: 272.0000 - fp: 645.0000 - tn: 981.0000 - fn: 126.0000 - accuracy: 0.6191 - precision: 0.2966 - recall: 0.6834 - auc: 0.6995 - prc: 0.3993 - val_loss: 0.6695 - val_tp: 59.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 32.0000 - val_accuracy: 0.5810 - val_precision: 0.2469 - val_recall: 0.6484 - val_auc: 0.6652 - val_prc: 0.3100\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6492 - tp: 276.0000 - fp: 686.0000 - tn: 940.0000 - fn: 122.0000 - accuracy: 0.6008 - precision: 0.2869 - recall: 0.6935 - auc: 0.7001 - prc: 0.4002 - val_loss: 0.6799 - val_tp: 61.0000 - val_fp: 195.0000 - val_tn: 220.0000 - val_fn: 30.0000 - val_accuracy: 0.5553 - val_precision: 0.2383 - val_recall: 0.6703 - val_auc: 0.6651 - val_prc: 0.3097\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6488 - tp: 273.0000 - fp: 650.0000 - tn: 976.0000 - fn: 125.0000 - accuracy: 0.6171 - precision: 0.2958 - recall: 0.6859 - auc: 0.6997 - prc: 0.4020 - val_loss: 0.6662 - val_tp: 59.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 32.0000 - val_accuracy: 0.6107 - val_precision: 0.2634 - val_recall: 0.6484 - val_auc: 0.6653 - val_prc: 0.3098\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6482 - tp: 265.0000 - fp: 615.0000 - tn: 1011.0000 - fn: 133.0000 - accuracy: 0.6304 - precision: 0.3011 - recall: 0.6658 - auc: 0.7009 - prc: 0.4038 - val_loss: 0.6700 - val_tp: 59.0000 - val_fp: 180.0000 - val_tn: 235.0000 - val_fn: 32.0000 - val_accuracy: 0.5810 - val_precision: 0.2469 - val_recall: 0.6484 - val_auc: 0.6661 - val_prc: 0.3106\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6478 - tp: 276.0000 - fp: 692.0000 - tn: 934.0000 - fn: 122.0000 - accuracy: 0.5978 - precision: 0.2851 - recall: 0.6935 - auc: 0.7011 - prc: 0.4027 - val_loss: 0.6781 - val_tp: 61.0000 - val_fp: 195.0000 - val_tn: 220.0000 - val_fn: 30.0000 - val_accuracy: 0.5553 - val_precision: 0.2383 - val_recall: 0.6703 - val_auc: 0.6672 - val_prc: 0.3122\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6470 - tp: 277.0000 - fp: 669.0000 - tn: 957.0000 - fn: 121.0000 - accuracy: 0.6097 - precision: 0.2928 - recall: 0.6960 - auc: 0.7008 - prc: 0.4036 - val_loss: 0.6674 - val_tp: 59.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 32.0000 - val_accuracy: 0.5988 - val_precision: 0.2565 - val_recall: 0.6484 - val_auc: 0.6665 - val_prc: 0.3129\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6466 - tp: 267.0000 - fp: 631.0000 - tn: 995.0000 - fn: 131.0000 - accuracy: 0.6235 - precision: 0.2973 - recall: 0.6709 - auc: 0.7007 - prc: 0.4046 - val_loss: 0.6711 - val_tp: 60.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 31.0000 - val_accuracy: 0.5731 - val_precision: 0.2449 - val_recall: 0.6593 - val_auc: 0.6679 - val_prc: 0.3144\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6460 - tp: 270.0000 - fp: 642.0000 - tn: 984.0000 - fn: 128.0000 - accuracy: 0.6196 - precision: 0.2961 - recall: 0.6784 - auc: 0.7007 - prc: 0.4069 - val_loss: 0.6681 - val_tp: 59.0000 - val_fp: 173.0000 - val_tn: 242.0000 - val_fn: 32.0000 - val_accuracy: 0.5949 - val_precision: 0.2543 - val_recall: 0.6484 - val_auc: 0.6675 - val_prc: 0.3165\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6455 - tp: 265.0000 - fp: 620.0000 - tn: 1006.0000 - fn: 133.0000 - accuracy: 0.6280 - precision: 0.2994 - recall: 0.6658 - auc: 0.7012 - prc: 0.4076 - val_loss: 0.6676 - val_tp: 59.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 32.0000 - val_accuracy: 0.5988 - val_precision: 0.2565 - val_recall: 0.6484 - val_auc: 0.6675 - val_prc: 0.3159\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6450 - tp: 278.0000 - fp: 720.0000 - tn: 906.0000 - fn: 120.0000 - accuracy: 0.5850 - precision: 0.2786 - recall: 0.6985 - auc: 0.7001 - prc: 0.4070 - val_loss: 0.6841 - val_tp: 64.0000 - val_fp: 203.0000 - val_tn: 212.0000 - val_fn: 27.0000 - val_accuracy: 0.5455 - val_precision: 0.2397 - val_recall: 0.7033 - val_auc: 0.6677 - val_prc: 0.3154\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6442 - tp: 281.0000 - fp: 735.0000 - tn: 891.0000 - fn: 117.0000 - accuracy: 0.5791 - precision: 0.2766 - recall: 0.7060 - auc: 0.7016 - prc: 0.4098 - val_loss: 0.6766 - val_tp: 62.0000 - val_fp: 194.0000 - val_tn: 221.0000 - val_fn: 29.0000 - val_accuracy: 0.5593 - val_precision: 0.2422 - val_recall: 0.6813 - val_auc: 0.6684 - val_prc: 0.3168\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6434 - tp: 280.0000 - fp: 704.0000 - tn: 922.0000 - fn: 118.0000 - accuracy: 0.5939 - precision: 0.2846 - recall: 0.7035 - auc: 0.7022 - prc: 0.4109 - val_loss: 0.6778 - val_tp: 62.0000 - val_fp: 196.0000 - val_tn: 219.0000 - val_fn: 29.0000 - val_accuracy: 0.5553 - val_precision: 0.2403 - val_recall: 0.6813 - val_auc: 0.6692 - val_prc: 0.3189\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6428 - tp: 277.0000 - fp: 671.0000 - tn: 955.0000 - fn: 121.0000 - accuracy: 0.6087 - precision: 0.2922 - recall: 0.6960 - auc: 0.7019 - prc: 0.4110 - val_loss: 0.6663 - val_tp: 59.0000 - val_fp: 171.0000 - val_tn: 244.0000 - val_fn: 32.0000 - val_accuracy: 0.5988 - val_precision: 0.2565 - val_recall: 0.6484 - val_auc: 0.6681 - val_prc: 0.3191\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6422 - tp: 264.0000 - fp: 596.0000 - tn: 1030.0000 - fn: 134.0000 - accuracy: 0.6393 - precision: 0.3070 - recall: 0.6633 - auc: 0.7022 - prc: 0.4110 - val_loss: 0.6611 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6689 - val_prc: 0.3199\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6414 - tp: 276.0000 - fp: 665.0000 - tn: 961.0000 - fn: 122.0000 - accuracy: 0.6112 - precision: 0.2933 - recall: 0.6935 - auc: 0.7035 - prc: 0.4119 - val_loss: 0.6811 - val_tp: 62.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 29.0000 - val_accuracy: 0.5534 - val_precision: 0.2394 - val_recall: 0.6813 - val_auc: 0.6693 - val_prc: 0.3194\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6411 - tp: 280.0000 - fp: 721.0000 - tn: 905.0000 - fn: 118.0000 - accuracy: 0.5855 - precision: 0.2797 - recall: 0.7035 - auc: 0.7023 - prc: 0.4133 - val_loss: 0.6718 - val_tp: 62.0000 - val_fp: 185.0000 - val_tn: 230.0000 - val_fn: 29.0000 - val_accuracy: 0.5771 - val_precision: 0.2510 - val_recall: 0.6813 - val_auc: 0.6693 - val_prc: 0.3215\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6404 - tp: 265.0000 - fp: 605.0000 - tn: 1021.0000 - fn: 133.0000 - accuracy: 0.6354 - precision: 0.3046 - recall: 0.6658 - auc: 0.7026 - prc: 0.4145 - val_loss: 0.6546 - val_tp: 57.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 34.0000 - val_accuracy: 0.6344 - val_precision: 0.2740 - val_recall: 0.6264 - val_auc: 0.6698 - val_prc: 0.3233\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6401 - tp: 262.0000 - fp: 558.0000 - tn: 1068.0000 - fn: 136.0000 - accuracy: 0.6571 - precision: 0.3195 - recall: 0.6583 - auc: 0.7021 - prc: 0.4133 - val_loss: 0.6500 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6723 - val_prc: 0.3258\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6403 - tp: 241.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 157.0000 - accuracy: 0.6882 - precision: 0.3371 - recall: 0.6055 - auc: 0.7025 - prc: 0.4136 - val_loss: 0.6417 - val_tp: 53.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 38.0000 - val_accuracy: 0.6700 - val_precision: 0.2912 - val_recall: 0.5824 - val_auc: 0.6698 - val_prc: 0.3243\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6393 - tp: 241.0000 - fp: 474.0000 - tn: 1152.0000 - fn: 157.0000 - accuracy: 0.6882 - precision: 0.3371 - recall: 0.6055 - auc: 0.7042 - prc: 0.4166 - val_loss: 0.6476 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6712 - val_prc: 0.3261\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6380 - tp: 261.0000 - fp: 550.0000 - tn: 1076.0000 - fn: 137.0000 - accuracy: 0.6606 - precision: 0.3218 - recall: 0.6558 - auc: 0.7045 - prc: 0.4168 - val_loss: 0.6572 - val_tp: 58.0000 - val_fp: 161.0000 - val_tn: 254.0000 - val_fn: 33.0000 - val_accuracy: 0.6166 - val_precision: 0.2648 - val_recall: 0.6374 - val_auc: 0.6723 - val_prc: 0.3278\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6376 - tp: 259.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 139.0000 - accuracy: 0.6625 - precision: 0.3225 - recall: 0.6508 - auc: 0.7038 - prc: 0.4187 - val_loss: 0.6467 - val_tp: 54.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 37.0000 - val_accuracy: 0.6482 - val_precision: 0.2769 - val_recall: 0.5934 - val_auc: 0.6720 - val_prc: 0.3296\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6371 - tp: 258.0000 - fp: 531.0000 - tn: 1095.0000 - fn: 140.0000 - accuracy: 0.6685 - precision: 0.3270 - recall: 0.6482 - auc: 0.7045 - prc: 0.4192 - val_loss: 0.6595 - val_tp: 58.0000 - val_fp: 164.0000 - val_tn: 251.0000 - val_fn: 33.0000 - val_accuracy: 0.6107 - val_precision: 0.2613 - val_recall: 0.6374 - val_auc: 0.6719 - val_prc: 0.3273\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6369 - tp: 280.0000 - fp: 694.0000 - tn: 932.0000 - fn: 118.0000 - accuracy: 0.5988 - precision: 0.2875 - recall: 0.7035 - auc: 0.7039 - prc: 0.4177 - val_loss: 0.6844 - val_tp: 63.0000 - val_fp: 197.0000 - val_tn: 218.0000 - val_fn: 28.0000 - val_accuracy: 0.5553 - val_precision: 0.2423 - val_recall: 0.6923 - val_auc: 0.6725 - val_prc: 0.3277\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6361 - tp: 277.0000 - fp: 675.0000 - tn: 951.0000 - fn: 121.0000 - accuracy: 0.6067 - precision: 0.2910 - recall: 0.6960 - auc: 0.7033 - prc: 0.4195 - val_loss: 0.6539 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6717 - val_prc: 0.3311\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6356 - tp: 249.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 149.0000 - accuracy: 0.6739 - precision: 0.3276 - recall: 0.6256 - auc: 0.7045 - prc: 0.4194 - val_loss: 0.6423 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6726 - val_prc: 0.3310\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6345 - tp: 268.0000 - fp: 594.0000 - tn: 1032.0000 - fn: 130.0000 - accuracy: 0.6423 - precision: 0.3109 - recall: 0.6734 - auc: 0.7050 - prc: 0.4197 - val_loss: 0.6710 - val_tp: 61.0000 - val_fp: 184.0000 - val_tn: 231.0000 - val_fn: 30.0000 - val_accuracy: 0.5771 - val_precision: 0.2490 - val_recall: 0.6703 - val_auc: 0.6731 - val_prc: 0.3334\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6347 - tp: 276.0000 - fp: 697.0000 - tn: 929.0000 - fn: 122.0000 - accuracy: 0.5954 - precision: 0.2837 - recall: 0.6935 - auc: 0.7042 - prc: 0.4199 - val_loss: 0.6700 - val_tp: 60.0000 - val_fp: 181.0000 - val_tn: 234.0000 - val_fn: 31.0000 - val_accuracy: 0.5810 - val_precision: 0.2490 - val_recall: 0.6593 - val_auc: 0.6727 - val_prc: 0.3308\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6334 - tp: 266.0000 - fp: 609.0000 - tn: 1017.0000 - fn: 132.0000 - accuracy: 0.6339 - precision: 0.3040 - recall: 0.6683 - auc: 0.7053 - prc: 0.4213 - val_loss: 0.6483 - val_tp: 55.0000 - val_fp: 147.0000 - val_tn: 268.0000 - val_fn: 36.0000 - val_accuracy: 0.6383 - val_precision: 0.2723 - val_recall: 0.6044 - val_auc: 0.6728 - val_prc: 0.3321\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6334 - tp: 251.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 147.0000 - accuracy: 0.6719 - precision: 0.3268 - recall: 0.6307 - auc: 0.7048 - prc: 0.4233 - val_loss: 0.6472 - val_tp: 55.0000 - val_fp: 145.0000 - val_tn: 270.0000 - val_fn: 36.0000 - val_accuracy: 0.6423 - val_precision: 0.2750 - val_recall: 0.6044 - val_auc: 0.6735 - val_prc: 0.3356\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6327 - tp: 265.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 133.0000 - accuracy: 0.6477 - precision: 0.3136 - recall: 0.6658 - auc: 0.7045 - prc: 0.4229 - val_loss: 0.6651 - val_tp: 60.0000 - val_fp: 168.0000 - val_tn: 247.0000 - val_fn: 31.0000 - val_accuracy: 0.6067 - val_precision: 0.2632 - val_recall: 0.6593 - val_auc: 0.6750 - val_prc: 0.3369\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6321 - tp: 270.0000 - fp: 621.0000 - tn: 1005.0000 - fn: 128.0000 - accuracy: 0.6299 - precision: 0.3030 - recall: 0.6784 - auc: 0.7054 - prc: 0.4236 - val_loss: 0.6579 - val_tp: 59.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 32.0000 - val_accuracy: 0.6166 - val_precision: 0.2670 - val_recall: 0.6484 - val_auc: 0.6750 - val_prc: 0.3379\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6314 - tp: 263.0000 - fp: 573.0000 - tn: 1053.0000 - fn: 135.0000 - accuracy: 0.6502 - precision: 0.3146 - recall: 0.6608 - auc: 0.7059 - prc: 0.4249 - val_loss: 0.6543 - val_tp: 58.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 33.0000 - val_accuracy: 0.6285 - val_precision: 0.2723 - val_recall: 0.6374 - val_auc: 0.6741 - val_prc: 0.3351\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6311 - tp: 263.0000 - fp: 588.0000 - tn: 1038.0000 - fn: 135.0000 - accuracy: 0.6428 - precision: 0.3090 - recall: 0.6608 - auc: 0.7054 - prc: 0.4222 - val_loss: 0.6579 - val_tp: 59.0000 - val_fp: 160.0000 - val_tn: 255.0000 - val_fn: 32.0000 - val_accuracy: 0.6206 - val_precision: 0.2694 - val_recall: 0.6484 - val_auc: 0.6744 - val_prc: 0.3337\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6305 - tp: 256.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 142.0000 - accuracy: 0.6596 - precision: 0.3188 - recall: 0.6432 - auc: 0.7068 - prc: 0.4226 - val_loss: 0.6391 - val_tp: 53.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 38.0000 - val_accuracy: 0.6621 - val_precision: 0.2849 - val_recall: 0.5824 - val_auc: 0.6757 - val_prc: 0.3365\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6301 - tp: 245.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 153.0000 - accuracy: 0.6754 - precision: 0.3271 - recall: 0.6156 - auc: 0.7066 - prc: 0.4243 - val_loss: 0.6403 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.6755 - val_prc: 0.3375\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6294 - tp: 246.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 152.0000 - accuracy: 0.6744 - precision: 0.3267 - recall: 0.6181 - auc: 0.7074 - prc: 0.4258 - val_loss: 0.6438 - val_tp: 56.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 35.0000 - val_accuracy: 0.6482 - val_precision: 0.2814 - val_recall: 0.6154 - val_auc: 0.6750 - val_prc: 0.3384\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6285 - tp: 268.0000 - fp: 583.0000 - tn: 1043.0000 - fn: 130.0000 - accuracy: 0.6477 - precision: 0.3149 - recall: 0.6734 - auc: 0.7073 - prc: 0.4250 - val_loss: 0.6625 - val_tp: 59.0000 - val_fp: 165.0000 - val_tn: 250.0000 - val_fn: 32.0000 - val_accuracy: 0.6107 - val_precision: 0.2634 - val_recall: 0.6484 - val_auc: 0.6757 - val_prc: 0.3393\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6284 - tp: 267.0000 - fp: 589.0000 - tn: 1037.0000 - fn: 131.0000 - accuracy: 0.6443 - precision: 0.3119 - recall: 0.6709 - auc: 0.7059 - prc: 0.4244 - val_loss: 0.6474 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6767 - val_prc: 0.3419\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6279 - tp: 246.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 152.0000 - accuracy: 0.6695 - precision: 0.3224 - recall: 0.6181 - auc: 0.7070 - prc: 0.4265 - val_loss: 0.6385 - val_tp: 55.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 36.0000 - val_accuracy: 0.6601 - val_precision: 0.2880 - val_recall: 0.6044 - val_auc: 0.6760 - val_prc: 0.3415\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6269 - tp: 257.0000 - fp: 552.0000 - tn: 1074.0000 - fn: 141.0000 - accuracy: 0.6576 - precision: 0.3177 - recall: 0.6457 - auc: 0.7077 - prc: 0.4263 - val_loss: 0.6566 - val_tp: 57.0000 - val_fp: 155.0000 - val_tn: 260.0000 - val_fn: 34.0000 - val_accuracy: 0.6265 - val_precision: 0.2689 - val_recall: 0.6264 - val_auc: 0.6773 - val_prc: 0.3424\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6269 - tp: 266.0000 - fp: 602.0000 - tn: 1024.0000 - fn: 132.0000 - accuracy: 0.6374 - precision: 0.3065 - recall: 0.6683 - auc: 0.7074 - prc: 0.4263 - val_loss: 0.6488 - val_tp: 56.0000 - val_fp: 150.0000 - val_tn: 265.0000 - val_fn: 35.0000 - val_accuracy: 0.6344 - val_precision: 0.2718 - val_recall: 0.6154 - val_auc: 0.6775 - val_prc: 0.3440\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6260 - tp: 260.0000 - fp: 556.0000 - tn: 1070.0000 - fn: 138.0000 - accuracy: 0.6571 - precision: 0.3186 - recall: 0.6533 - auc: 0.7076 - prc: 0.4280 - val_loss: 0.6411 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6773 - val_prc: 0.3466\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6253 - tp: 249.0000 - fp: 526.0000 - tn: 1100.0000 - fn: 149.0000 - accuracy: 0.6665 - precision: 0.3213 - recall: 0.6256 - auc: 0.7081 - prc: 0.4297 - val_loss: 0.6343 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6776 - val_prc: 0.3472\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6247 - tp: 247.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 151.0000 - accuracy: 0.6670 - precision: 0.3208 - recall: 0.6206 - auc: 0.7087 - prc: 0.4283 - val_loss: 0.6426 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6770 - val_prc: 0.3462\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6248 - tp: 257.0000 - fp: 560.0000 - tn: 1066.0000 - fn: 141.0000 - accuracy: 0.6537 - precision: 0.3146 - recall: 0.6457 - auc: 0.7080 - prc: 0.4264 - val_loss: 0.6458 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6774 - val_prc: 0.3479\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6235 - tp: 248.0000 - fp: 520.0000 - tn: 1106.0000 - fn: 150.0000 - accuracy: 0.6690 - precision: 0.3229 - recall: 0.6231 - auc: 0.7095 - prc: 0.4317 - val_loss: 0.6320 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6777 - val_prc: 0.3483\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6233 - tp: 243.0000 - fp: 506.0000 - tn: 1120.0000 - fn: 155.0000 - accuracy: 0.6734 - precision: 0.3244 - recall: 0.6106 - auc: 0.7093 - prc: 0.4318 - val_loss: 0.6406 - val_tp: 55.0000 - val_fp: 141.0000 - val_tn: 274.0000 - val_fn: 36.0000 - val_accuracy: 0.6502 - val_precision: 0.2806 - val_recall: 0.6044 - val_auc: 0.6782 - val_prc: 0.3511\n",
      "Epoch 93/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6234 - tp: 270.0000 - fp: 602.0000 - tn: 1024.0000 - fn: 128.0000 - accuracy: 0.6393 - precision: 0.3096 - recall: 0.6784 - auc: 0.7097 - prc: 0.4300 - val_loss: 0.6640 - val_tp: 60.0000 - val_fp: 162.0000 - val_tn: 253.0000 - val_fn: 31.0000 - val_accuracy: 0.6186 - val_precision: 0.2703 - val_recall: 0.6593 - val_auc: 0.6776 - val_prc: 0.3477\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6227 - tp: 261.0000 - fp: 584.0000 - tn: 1042.0000 - fn: 137.0000 - accuracy: 0.6438 - precision: 0.3089 - recall: 0.6558 - auc: 0.7098 - prc: 0.4312 - val_loss: 0.6369 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6785 - val_prc: 0.3515\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6221 - tp: 243.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 155.0000 - accuracy: 0.6779 - precision: 0.3284 - recall: 0.6106 - auc: 0.7104 - prc: 0.4312 - val_loss: 0.6266 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6789 - val_prc: 0.3614\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6217 - tp: 241.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 157.0000 - accuracy: 0.6769 - precision: 0.3266 - recall: 0.6055 - auc: 0.7100 - prc: 0.4354 - val_loss: 0.6404 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6793 - val_prc: 0.3603\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6226 - tp: 265.0000 - fp: 607.0000 - tn: 1019.0000 - fn: 133.0000 - accuracy: 0.6344 - precision: 0.3039 - recall: 0.6658 - auc: 0.7075 - prc: 0.4327 - val_loss: 0.6565 - val_tp: 57.0000 - val_fp: 158.0000 - val_tn: 257.0000 - val_fn: 34.0000 - val_accuracy: 0.6206 - val_precision: 0.2651 - val_recall: 0.6264 - val_auc: 0.6783 - val_prc: 0.3619\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6203 - tp: 249.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 149.0000 - accuracy: 0.6660 - precision: 0.3209 - recall: 0.6256 - auc: 0.7103 - prc: 0.4381 - val_loss: 0.6193 - val_tp: 53.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 38.0000 - val_accuracy: 0.6798 - val_precision: 0.2994 - val_recall: 0.5824 - val_auc: 0.6784 - val_prc: 0.3637\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6219 - tp: 225.0000 - fp: 432.0000 - tn: 1194.0000 - fn: 173.0000 - accuracy: 0.7011 - precision: 0.3425 - recall: 0.5653 - auc: 0.7098 - prc: 0.4366 - val_loss: 0.6171 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6789 - val_prc: 0.3676\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6206 - tp: 234.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 164.0000 - accuracy: 0.6912 - precision: 0.3367 - recall: 0.5879 - auc: 0.7103 - prc: 0.4384 - val_loss: 0.6247 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6792 - val_prc: 0.3702\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6197 - tp: 242.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 156.0000 - accuracy: 0.6779 - precision: 0.3279 - recall: 0.6080 - auc: 0.7108 - prc: 0.4387 - val_loss: 0.6312 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6792 - val_prc: 0.3667\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6199 - tp: 237.0000 - fp: 475.0000 - tn: 1151.0000 - fn: 161.0000 - accuracy: 0.6858 - precision: 0.3329 - recall: 0.5955 - auc: 0.7104 - prc: 0.4376 - val_loss: 0.6243 - val_tp: 54.0000 - val_fp: 132.0000 - val_tn: 283.0000 - val_fn: 37.0000 - val_accuracy: 0.6660 - val_precision: 0.2903 - val_recall: 0.5934 - val_auc: 0.6795 - val_prc: 0.3680\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6190 - tp: 251.0000 - fp: 544.0000 - tn: 1082.0000 - fn: 147.0000 - accuracy: 0.6586 - precision: 0.3157 - recall: 0.6307 - auc: 0.7102 - prc: 0.4391 - val_loss: 0.6516 - val_tp: 57.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 34.0000 - val_accuracy: 0.6285 - val_precision: 0.2701 - val_recall: 0.6264 - val_auc: 0.6789 - val_prc: 0.3681\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6190 - tp: 258.0000 - fp: 571.0000 - tn: 1055.0000 - fn: 140.0000 - accuracy: 0.6487 - precision: 0.3112 - recall: 0.6482 - auc: 0.7107 - prc: 0.4397 - val_loss: 0.6435 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6799 - val_prc: 0.3731\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6183 - tp: 248.0000 - fp: 540.0000 - tn: 1086.0000 - fn: 150.0000 - accuracy: 0.6591 - precision: 0.3147 - recall: 0.6231 - auc: 0.7108 - prc: 0.4407 - val_loss: 0.6340 - val_tp: 54.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 37.0000 - val_accuracy: 0.6502 - val_precision: 0.2784 - val_recall: 0.5934 - val_auc: 0.6801 - val_prc: 0.3750\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6178 - tp: 249.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 149.0000 - accuracy: 0.6616 - precision: 0.3172 - recall: 0.6256 - auc: 0.7116 - prc: 0.4414 - val_loss: 0.6387 - val_tp: 54.0000 - val_fp: 143.0000 - val_tn: 272.0000 - val_fn: 37.0000 - val_accuracy: 0.6443 - val_precision: 0.2741 - val_recall: 0.5934 - val_auc: 0.6788 - val_prc: 0.3728\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6174 - tp: 248.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 150.0000 - accuracy: 0.6675 - precision: 0.3217 - recall: 0.6231 - auc: 0.7115 - prc: 0.4407 - val_loss: 0.6319 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6799 - val_prc: 0.3721\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6174 - tp: 243.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 155.0000 - accuracy: 0.6690 - precision: 0.3206 - recall: 0.6106 - auc: 0.7115 - prc: 0.4383 - val_loss: 0.6296 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6785 - val_prc: 0.3683\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6170 - tp: 244.0000 - fp: 508.0000 - tn: 1118.0000 - fn: 154.0000 - accuracy: 0.6729 - precision: 0.3245 - recall: 0.6131 - auc: 0.7125 - prc: 0.4381 - val_loss: 0.6307 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6786 - val_prc: 0.3666\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6169 - tp: 233.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 165.0000 - accuracy: 0.6887 - precision: 0.3338 - recall: 0.5854 - auc: 0.7135 - prc: 0.4385 - val_loss: 0.6146 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6796 - val_prc: 0.3705\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6162 - tp: 244.0000 - fp: 497.0000 - tn: 1129.0000 - fn: 154.0000 - accuracy: 0.6784 - precision: 0.3293 - recall: 0.6131 - auc: 0.7142 - prc: 0.4394 - val_loss: 0.6377 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6795 - val_prc: 0.3732\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6166 - tp: 240.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 158.0000 - accuracy: 0.6887 - precision: 0.3371 - recall: 0.6030 - auc: 0.7129 - prc: 0.4426 - val_loss: 0.6117 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6796 - val_prc: 0.3738\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6172 - tp: 222.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 176.0000 - accuracy: 0.7070 - precision: 0.3474 - recall: 0.5578 - auc: 0.7131 - prc: 0.4411 - val_loss: 0.6123 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6791 - val_prc: 0.3703\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6157 - tp: 243.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 155.0000 - accuracy: 0.6774 - precision: 0.3279 - recall: 0.6106 - auc: 0.7140 - prc: 0.4409 - val_loss: 0.6397 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6787 - val_prc: 0.3714\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6151 - tp: 246.0000 - fp: 512.0000 - tn: 1114.0000 - fn: 152.0000 - accuracy: 0.6719 - precision: 0.3245 - recall: 0.6181 - auc: 0.7142 - prc: 0.4417 - val_loss: 0.6197 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6804 - val_prc: 0.3758\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6149 - tp: 235.0000 - fp: 467.0000 - tn: 1159.0000 - fn: 163.0000 - accuracy: 0.6887 - precision: 0.3348 - recall: 0.5905 - auc: 0.7145 - prc: 0.4450 - val_loss: 0.6194 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6807 - val_prc: 0.3770\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6180 - tp: 258.0000 - fp: 581.0000 - tn: 1045.0000 - fn: 140.0000 - accuracy: 0.6438 - precision: 0.3075 - recall: 0.6482 - auc: 0.7105 - prc: 0.4377 - val_loss: 0.6576 - val_tp: 57.0000 - val_fp: 159.0000 - val_tn: 256.0000 - val_fn: 34.0000 - val_accuracy: 0.6186 - val_precision: 0.2639 - val_recall: 0.6264 - val_auc: 0.6795 - val_prc: 0.3731\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6142 - tp: 244.0000 - fp: 507.0000 - tn: 1119.0000 - fn: 154.0000 - accuracy: 0.6734 - precision: 0.3249 - recall: 0.6131 - auc: 0.7144 - prc: 0.4455 - val_loss: 0.5989 - val_tp: 48.0000 - val_fp: 106.0000 - val_tn: 309.0000 - val_fn: 43.0000 - val_accuracy: 0.7055 - val_precision: 0.3117 - val_recall: 0.5275 - val_auc: 0.6816 - val_prc: 0.3804\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6151 - tp: 219.0000 - fp: 411.0000 - tn: 1215.0000 - fn: 179.0000 - accuracy: 0.7085 - precision: 0.3476 - recall: 0.5503 - auc: 0.7158 - prc: 0.4475 - val_loss: 0.6185 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6807 - val_prc: 0.3808\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6136 - tp: 248.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 150.0000 - accuracy: 0.6665 - precision: 0.3208 - recall: 0.6231 - auc: 0.7154 - prc: 0.4467 - val_loss: 0.6404 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6806 - val_prc: 0.3809\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6135 - tp: 247.0000 - fp: 523.0000 - tn: 1103.0000 - fn: 151.0000 - accuracy: 0.6670 - precision: 0.3208 - recall: 0.6206 - auc: 0.7152 - prc: 0.4480 - val_loss: 0.6222 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6810 - val_prc: 0.3865\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6135 - tp: 239.0000 - fp: 473.0000 - tn: 1153.0000 - fn: 159.0000 - accuracy: 0.6877 - precision: 0.3357 - recall: 0.6005 - auc: 0.7151 - prc: 0.4492 - val_loss: 0.6174 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6818 - val_prc: 0.3856\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6135 - tp: 233.0000 - fp: 457.0000 - tn: 1169.0000 - fn: 165.0000 - accuracy: 0.6927 - precision: 0.3377 - recall: 0.5854 - auc: 0.7152 - prc: 0.4520 - val_loss: 0.6182 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6813 - val_prc: 0.3882\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6129 - tp: 249.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 149.0000 - accuracy: 0.6705 - precision: 0.3246 - recall: 0.6256 - auc: 0.7150 - prc: 0.4505 - val_loss: 0.6329 - val_tp: 55.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 36.0000 - val_accuracy: 0.6601 - val_precision: 0.2880 - val_recall: 0.6044 - val_auc: 0.6812 - val_prc: 0.3883\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6128 - tp: 249.0000 - fp: 527.0000 - tn: 1099.0000 - fn: 149.0000 - accuracy: 0.6660 - precision: 0.3209 - recall: 0.6256 - auc: 0.7155 - prc: 0.4497 - val_loss: 0.6247 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6799 - val_prc: 0.3786\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6123 - tp: 241.0000 - fp: 477.0000 - tn: 1149.0000 - fn: 157.0000 - accuracy: 0.6868 - precision: 0.3357 - recall: 0.6055 - auc: 0.7166 - prc: 0.4496 - val_loss: 0.6156 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6807 - val_prc: 0.3841\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6119 - tp: 237.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 161.0000 - accuracy: 0.6912 - precision: 0.3381 - recall: 0.5955 - auc: 0.7170 - prc: 0.4523 - val_loss: 0.6200 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6810 - val_prc: 0.3893\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6132 - tp: 256.0000 - fp: 553.0000 - tn: 1073.0000 - fn: 142.0000 - accuracy: 0.6566 - precision: 0.3164 - recall: 0.6432 - auc: 0.7151 - prc: 0.4509 - val_loss: 0.6373 - val_tp: 56.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 35.0000 - val_accuracy: 0.6542 - val_precision: 0.2857 - val_recall: 0.6154 - val_auc: 0.6814 - val_prc: 0.3910\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6120 - tp: 242.0000 - fp: 481.0000 - tn: 1145.0000 - fn: 156.0000 - accuracy: 0.6853 - precision: 0.3347 - recall: 0.6080 - auc: 0.7166 - prc: 0.4510 - val_loss: 0.6068 - val_tp: 52.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 39.0000 - val_accuracy: 0.6838 - val_precision: 0.3006 - val_recall: 0.5714 - val_auc: 0.6823 - val_prc: 0.3967\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6116 - tp: 242.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 156.0000 - accuracy: 0.6813 - precision: 0.3311 - recall: 0.6080 - auc: 0.7169 - prc: 0.4535 - val_loss: 0.6359 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6811 - val_prc: 0.3888\n",
      "Epoch 131/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6116 - tp: 252.0000 - fp: 541.0000 - tn: 1085.0000 - fn: 146.0000 - accuracy: 0.6606 - precision: 0.3178 - recall: 0.6332 - auc: 0.7172 - prc: 0.4531 - val_loss: 0.6319 - val_tp: 54.0000 - val_fp: 136.0000 - val_tn: 279.0000 - val_fn: 37.0000 - val_accuracy: 0.6581 - val_precision: 0.2842 - val_recall: 0.5934 - val_auc: 0.6812 - val_prc: 0.3923\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6115 - tp: 240.0000 - fp: 469.0000 - tn: 1157.0000 - fn: 158.0000 - accuracy: 0.6902 - precision: 0.3385 - recall: 0.6030 - auc: 0.7170 - prc: 0.4518 - val_loss: 0.6110 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6818 - val_prc: 0.3965\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6107 - tp: 240.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 158.0000 - accuracy: 0.6853 - precision: 0.3338 - recall: 0.6030 - auc: 0.7184 - prc: 0.4544 - val_loss: 0.6313 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6821 - val_prc: 0.3917\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6107 - tp: 253.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 145.0000 - accuracy: 0.6729 - precision: 0.3286 - recall: 0.6357 - auc: 0.7184 - prc: 0.4534 - val_loss: 0.6274 - val_tp: 53.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 38.0000 - val_accuracy: 0.6739 - val_precision: 0.2944 - val_recall: 0.5824 - val_auc: 0.6814 - val_prc: 0.3896\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6119 - tp: 259.0000 - fp: 565.0000 - tn: 1061.0000 - fn: 139.0000 - accuracy: 0.6522 - precision: 0.3143 - recall: 0.6508 - auc: 0.7180 - prc: 0.4531 - val_loss: 0.6515 - val_tp: 56.0000 - val_fp: 151.0000 - val_tn: 264.0000 - val_fn: 35.0000 - val_accuracy: 0.6324 - val_precision: 0.2705 - val_recall: 0.6154 - val_auc: 0.6811 - val_prc: 0.3897\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6106 - tp: 255.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 143.0000 - accuracy: 0.6650 - precision: 0.3228 - recall: 0.6407 - auc: 0.7184 - prc: 0.4550 - val_loss: 0.6156 - val_tp: 53.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 38.0000 - val_accuracy: 0.6838 - val_precision: 0.3029 - val_recall: 0.5824 - val_auc: 0.6825 - val_prc: 0.3963\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6112 - tp: 223.0000 - fp: 424.0000 - tn: 1202.0000 - fn: 175.0000 - accuracy: 0.7041 - precision: 0.3447 - recall: 0.5603 - auc: 0.7183 - prc: 0.4578 - val_loss: 0.5982 - val_tp: 49.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 42.0000 - val_accuracy: 0.7036 - val_precision: 0.3121 - val_recall: 0.5385 - val_auc: 0.6836 - val_prc: 0.4012\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6103 - tp: 238.0000 - fp: 464.0000 - tn: 1162.0000 - fn: 160.0000 - accuracy: 0.6917 - precision: 0.3390 - recall: 0.5980 - auc: 0.7186 - prc: 0.4564 - val_loss: 0.6271 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6827 - val_prc: 0.4000\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6097 - tp: 251.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 147.0000 - accuracy: 0.6695 - precision: 0.3247 - recall: 0.6307 - auc: 0.7191 - prc: 0.4601 - val_loss: 0.6230 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6823 - val_prc: 0.4028\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6100 - tp: 234.0000 - fp: 446.0000 - tn: 1180.0000 - fn: 164.0000 - accuracy: 0.6986 - precision: 0.3441 - recall: 0.5879 - auc: 0.7194 - prc: 0.4610 - val_loss: 0.6051 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6829 - val_prc: 0.4024\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6097 - tp: 252.0000 - fp: 510.0000 - tn: 1116.0000 - fn: 146.0000 - accuracy: 0.6759 - precision: 0.3307 - recall: 0.6332 - auc: 0.7188 - prc: 0.4562 - val_loss: 0.6460 - val_tp: 55.0000 - val_fp: 144.0000 - val_tn: 271.0000 - val_fn: 36.0000 - val_accuracy: 0.6443 - val_precision: 0.2764 - val_recall: 0.6044 - val_auc: 0.6807 - val_prc: 0.3887\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6097 - tp: 257.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 141.0000 - accuracy: 0.6601 - precision: 0.3197 - recall: 0.6457 - auc: 0.7199 - prc: 0.4570 - val_loss: 0.6234 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6819 - val_prc: 0.3955\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6092 - tp: 232.0000 - fp: 441.0000 - tn: 1185.0000 - fn: 166.0000 - accuracy: 0.7001 - precision: 0.3447 - recall: 0.5829 - auc: 0.7200 - prc: 0.4592 - val_loss: 0.6028 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6826 - val_prc: 0.4028\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6092 - tp: 244.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 154.0000 - accuracy: 0.6877 - precision: 0.3380 - recall: 0.6131 - auc: 0.7198 - prc: 0.4595 - val_loss: 0.6322 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6811 - val_prc: 0.3936\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6089 - tp: 251.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 147.0000 - accuracy: 0.6719 - precision: 0.3268 - recall: 0.6307 - auc: 0.7203 - prc: 0.4619 - val_loss: 0.6212 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6830 - val_prc: 0.4044\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6086 - tp: 247.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 151.0000 - accuracy: 0.6838 - precision: 0.3356 - recall: 0.6206 - auc: 0.7204 - prc: 0.4637 - val_loss: 0.6243 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6825 - val_prc: 0.4058\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6084 - tp: 246.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 152.0000 - accuracy: 0.6789 - precision: 0.3306 - recall: 0.6181 - auc: 0.7201 - prc: 0.4645 - val_loss: 0.6272 - val_tp: 54.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 37.0000 - val_accuracy: 0.6680 - val_precision: 0.2919 - val_recall: 0.5934 - val_auc: 0.6818 - val_prc: 0.4025\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6092 - tp: 257.0000 - fp: 548.0000 - tn: 1078.0000 - fn: 141.0000 - accuracy: 0.6596 - precision: 0.3193 - recall: 0.6457 - auc: 0.7197 - prc: 0.4645 - val_loss: 0.6462 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6829 - val_prc: 0.4100\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6095 - tp: 264.0000 - fp: 580.0000 - tn: 1046.0000 - fn: 134.0000 - accuracy: 0.6472 - precision: 0.3128 - recall: 0.6633 - auc: 0.7208 - prc: 0.4667 - val_loss: 0.6431 - val_tp: 55.0000 - val_fp: 146.0000 - val_tn: 269.0000 - val_fn: 36.0000 - val_accuracy: 0.6403 - val_precision: 0.2736 - val_recall: 0.6044 - val_auc: 0.6833 - val_prc: 0.4097\n",
      "Epoch 150/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6086 - tp: 243.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 155.0000 - accuracy: 0.6793 - precision: 0.3297 - recall: 0.6106 - auc: 0.7198 - prc: 0.4667 - val_loss: 0.6015 - val_tp: 51.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 40.0000 - val_accuracy: 0.6937 - val_precision: 0.3072 - val_recall: 0.5604 - val_auc: 0.6859 - val_prc: 0.4164\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6084 - tp: 235.0000 - fp: 444.0000 - tn: 1182.0000 - fn: 163.0000 - accuracy: 0.7001 - precision: 0.3461 - recall: 0.5905 - auc: 0.7207 - prc: 0.4677 - val_loss: 0.6138 - val_tp: 52.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 39.0000 - val_accuracy: 0.6779 - val_precision: 0.2955 - val_recall: 0.5714 - val_auc: 0.6843 - val_prc: 0.4102\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6078 - tp: 240.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 158.0000 - accuracy: 0.6892 - precision: 0.3376 - recall: 0.6030 - auc: 0.7210 - prc: 0.4671 - val_loss: 0.6204 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6850 - val_prc: 0.4126\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6079 - tp: 249.0000 - fp: 521.0000 - tn: 1105.0000 - fn: 149.0000 - accuracy: 0.6690 - precision: 0.3234 - recall: 0.6256 - auc: 0.7207 - prc: 0.4680 - val_loss: 0.6356 - val_tp: 55.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 36.0000 - val_accuracy: 0.6542 - val_precision: 0.2835 - val_recall: 0.6044 - val_auc: 0.6850 - val_prc: 0.4136\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6082 - tp: 251.0000 - fp: 522.0000 - tn: 1104.0000 - fn: 147.0000 - accuracy: 0.6695 - precision: 0.3247 - recall: 0.6307 - auc: 0.7206 - prc: 0.4659 - val_loss: 0.6255 - val_tp: 54.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 37.0000 - val_accuracy: 0.6700 - val_precision: 0.2935 - val_recall: 0.5934 - val_auc: 0.6843 - val_prc: 0.4120\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6075 - tp: 245.0000 - fp: 495.0000 - tn: 1131.0000 - fn: 153.0000 - accuracy: 0.6798 - precision: 0.3311 - recall: 0.6156 - auc: 0.7209 - prc: 0.4673 - val_loss: 0.6187 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6840 - val_prc: 0.4088\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6071 - tp: 245.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 153.0000 - accuracy: 0.6882 - precision: 0.3389 - recall: 0.6156 - auc: 0.7218 - prc: 0.4678 - val_loss: 0.6156 - val_tp: 53.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 38.0000 - val_accuracy: 0.6818 - val_precision: 0.3011 - val_recall: 0.5824 - val_auc: 0.6841 - val_prc: 0.4111\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6071 - tp: 244.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 154.0000 - accuracy: 0.6887 - precision: 0.3389 - recall: 0.6131 - auc: 0.7217 - prc: 0.4693 - val_loss: 0.6166 - val_tp: 54.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 37.0000 - val_accuracy: 0.6798 - val_precision: 0.3017 - val_recall: 0.5934 - val_auc: 0.6853 - val_prc: 0.4162\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6090 - tp: 252.0000 - fp: 535.0000 - tn: 1091.0000 - fn: 146.0000 - accuracy: 0.6635 - precision: 0.3202 - recall: 0.6332 - auc: 0.7189 - prc: 0.4665 - val_loss: 0.6357 - val_tp: 54.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 37.0000 - val_accuracy: 0.6522 - val_precision: 0.2798 - val_recall: 0.5934 - val_auc: 0.6843 - val_prc: 0.4117\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6067 - tp: 248.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 150.0000 - accuracy: 0.6798 - precision: 0.3324 - recall: 0.6231 - auc: 0.7217 - prc: 0.4695 - val_loss: 0.6068 - val_tp: 52.0000 - val_fp: 118.0000 - val_tn: 297.0000 - val_fn: 39.0000 - val_accuracy: 0.6897 - val_precision: 0.3059 - val_recall: 0.5714 - val_auc: 0.6852 - val_prc: 0.4164\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6069 - tp: 236.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 162.0000 - accuracy: 0.6937 - precision: 0.3401 - recall: 0.5930 - auc: 0.7218 - prc: 0.4702 - val_loss: 0.6168 - val_tp: 53.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 38.0000 - val_accuracy: 0.6759 - val_precision: 0.2961 - val_recall: 0.5824 - val_auc: 0.6856 - val_prc: 0.4168\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6068 - tp: 250.0000 - fp: 515.0000 - tn: 1111.0000 - fn: 148.0000 - accuracy: 0.6724 - precision: 0.3268 - recall: 0.6281 - auc: 0.7220 - prc: 0.4701 - val_loss: 0.6317 - val_tp: 54.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 37.0000 - val_accuracy: 0.6542 - val_precision: 0.2812 - val_recall: 0.5934 - val_auc: 0.6864 - val_prc: 0.4208\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6063 - tp: 250.0000 - fp: 505.0000 - tn: 1121.0000 - fn: 148.0000 - accuracy: 0.6774 - precision: 0.3311 - recall: 0.6281 - auc: 0.7227 - prc: 0.4716 - val_loss: 0.6038 - val_tp: 51.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 40.0000 - val_accuracy: 0.6917 - val_precision: 0.3054 - val_recall: 0.5604 - val_auc: 0.6872 - val_prc: 0.4228\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6075 - tp: 224.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 174.0000 - accuracy: 0.7154 - precision: 0.3578 - recall: 0.5628 - auc: 0.7229 - prc: 0.4738 - val_loss: 0.5910 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6872 - val_prc: 0.4216\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6064 - tp: 241.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 157.0000 - accuracy: 0.6976 - precision: 0.3463 - recall: 0.6055 - auc: 0.7222 - prc: 0.4708 - val_loss: 0.6286 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6848 - val_prc: 0.4127\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6065 - tp: 257.0000 - fp: 536.0000 - tn: 1090.0000 - fn: 141.0000 - accuracy: 0.6655 - precision: 0.3241 - recall: 0.6457 - auc: 0.7223 - prc: 0.4702 - val_loss: 0.6293 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6846 - val_prc: 0.4161\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6057 - tp: 253.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 145.0000 - accuracy: 0.6823 - precision: 0.3369 - recall: 0.6357 - auc: 0.7231 - prc: 0.4722 - val_loss: 0.6119 - val_tp: 53.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 38.0000 - val_accuracy: 0.6858 - val_precision: 0.3046 - val_recall: 0.5824 - val_auc: 0.6856 - val_prc: 0.4185\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6055 - tp: 243.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 155.0000 - accuracy: 0.6873 - precision: 0.3370 - recall: 0.6106 - auc: 0.7231 - prc: 0.4723 - val_loss: 0.6192 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6862 - val_prc: 0.4204\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6056 - tp: 253.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 145.0000 - accuracy: 0.6690 - precision: 0.3252 - recall: 0.6357 - auc: 0.7231 - prc: 0.4732 - val_loss: 0.6343 - val_tp: 55.0000 - val_fp: 138.0000 - val_tn: 277.0000 - val_fn: 36.0000 - val_accuracy: 0.6561 - val_precision: 0.2850 - val_recall: 0.6044 - val_auc: 0.6861 - val_prc: 0.4216\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6059 - tp: 256.0000 - fp: 538.0000 - tn: 1088.0000 - fn: 142.0000 - accuracy: 0.6640 - precision: 0.3224 - recall: 0.6432 - auc: 0.7235 - prc: 0.4737 - val_loss: 0.6199 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6869 - val_prc: 0.4237\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6063 - tp: 233.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 165.0000 - accuracy: 0.7085 - precision: 0.3541 - recall: 0.5854 - auc: 0.7228 - prc: 0.4731 - val_loss: 0.5936 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6868 - val_prc: 0.4245\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6074 - tp: 252.0000 - fp: 517.0000 - tn: 1109.0000 - fn: 146.0000 - accuracy: 0.6724 - precision: 0.3277 - recall: 0.6332 - auc: 0.7205 - prc: 0.4671 - val_loss: 0.6510 - val_tp: 55.0000 - val_fp: 154.0000 - val_tn: 261.0000 - val_fn: 36.0000 - val_accuracy: 0.6245 - val_precision: 0.2632 - val_recall: 0.6044 - val_auc: 0.6831 - val_prc: 0.4132\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6055 - tp: 253.0000 - fp: 502.0000 - tn: 1124.0000 - fn: 145.0000 - accuracy: 0.6803 - precision: 0.3351 - recall: 0.6357 - auc: 0.7232 - prc: 0.4699 - val_loss: 0.6063 - val_tp: 50.0000 - val_fp: 116.0000 - val_tn: 299.0000 - val_fn: 41.0000 - val_accuracy: 0.6897 - val_precision: 0.3012 - val_recall: 0.5495 - val_auc: 0.6840 - val_prc: 0.4125\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6054 - tp: 241.0000 - fp: 465.0000 - tn: 1161.0000 - fn: 157.0000 - accuracy: 0.6927 - precision: 0.3414 - recall: 0.6055 - auc: 0.7237 - prc: 0.4695 - val_loss: 0.6222 - val_tp: 53.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 38.0000 - val_accuracy: 0.6779 - val_precision: 0.2978 - val_recall: 0.5824 - val_auc: 0.6816 - val_prc: 0.3956\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6051 - tp: 254.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 144.0000 - accuracy: 0.6863 - precision: 0.3409 - recall: 0.6382 - auc: 0.7239 - prc: 0.4704 - val_loss: 0.6217 - val_tp: 54.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 37.0000 - val_accuracy: 0.6759 - val_precision: 0.2983 - val_recall: 0.5934 - val_auc: 0.6837 - val_prc: 0.4090\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6048 - tp: 242.0000 - fp: 461.0000 - tn: 1165.0000 - fn: 156.0000 - accuracy: 0.6952 - precision: 0.3442 - recall: 0.6080 - auc: 0.7242 - prc: 0.4729 - val_loss: 0.5953 - val_tp: 49.0000 - val_fp: 109.0000 - val_tn: 306.0000 - val_fn: 42.0000 - val_accuracy: 0.7016 - val_precision: 0.3101 - val_recall: 0.5385 - val_auc: 0.6866 - val_prc: 0.4239\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6073 - tp: 223.0000 - fp: 385.0000 - tn: 1241.0000 - fn: 175.0000 - accuracy: 0.7233 - precision: 0.3668 - recall: 0.5603 - auc: 0.7229 - prc: 0.4743 - val_loss: 0.5954 - val_tp: 49.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 42.0000 - val_accuracy: 0.6996 - val_precision: 0.3082 - val_recall: 0.5385 - val_auc: 0.6869 - val_prc: 0.4237\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6049 - tp: 237.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 161.0000 - accuracy: 0.6917 - precision: 0.3386 - recall: 0.5955 - auc: 0.7237 - prc: 0.4743 - val_loss: 0.6184 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6865 - val_prc: 0.4229\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6044 - tp: 246.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 152.0000 - accuracy: 0.6858 - precision: 0.3370 - recall: 0.6181 - auc: 0.7243 - prc: 0.4758 - val_loss: 0.6191 - val_tp: 54.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 37.0000 - val_accuracy: 0.6779 - val_precision: 0.3000 - val_recall: 0.5934 - val_auc: 0.6863 - val_prc: 0.4234\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6046 - tp: 255.0000 - fp: 513.0000 - tn: 1113.0000 - fn: 143.0000 - accuracy: 0.6759 - precision: 0.3320 - recall: 0.6407 - auc: 0.7244 - prc: 0.4756 - val_loss: 0.6279 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6858 - val_prc: 0.4217\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6050 - tp: 239.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 159.0000 - accuracy: 0.6971 - precision: 0.3449 - recall: 0.6005 - auc: 0.7235 - prc: 0.4757 - val_loss: 0.5991 - val_tp: 50.0000 - val_fp: 113.0000 - val_tn: 302.0000 - val_fn: 41.0000 - val_accuracy: 0.6957 - val_precision: 0.3067 - val_recall: 0.5495 - val_auc: 0.6875 - val_prc: 0.4256\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6043 - tp: 250.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 148.0000 - accuracy: 0.6818 - precision: 0.3351 - recall: 0.6281 - auc: 0.7245 - prc: 0.4761 - val_loss: 0.6311 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6860 - val_prc: 0.4236\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6042 - tp: 245.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 153.0000 - accuracy: 0.6892 - precision: 0.3398 - recall: 0.6156 - auc: 0.7246 - prc: 0.4763 - val_loss: 0.5985 - val_tp: 50.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 41.0000 - val_accuracy: 0.6996 - val_precision: 0.3106 - val_recall: 0.5495 - val_auc: 0.6878 - val_prc: 0.4279\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6043 - tp: 234.0000 - fp: 440.0000 - tn: 1186.0000 - fn: 164.0000 - accuracy: 0.7016 - precision: 0.3472 - recall: 0.5879 - auc: 0.7251 - prc: 0.4769 - val_loss: 0.6009 - val_tp: 50.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 41.0000 - val_accuracy: 0.6917 - val_precision: 0.3030 - val_recall: 0.5495 - val_auc: 0.6890 - val_prc: 0.4306\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6052 - tp: 245.0000 - fp: 494.0000 - tn: 1132.0000 - fn: 153.0000 - accuracy: 0.6803 - precision: 0.3315 - recall: 0.6156 - auc: 0.7231 - prc: 0.4740 - val_loss: 0.6199 - val_tp: 52.0000 - val_fp: 128.0000 - val_tn: 287.0000 - val_fn: 39.0000 - val_accuracy: 0.6700 - val_precision: 0.2889 - val_recall: 0.5714 - val_auc: 0.6863 - val_prc: 0.4205\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6052 - tp: 228.0000 - fp: 398.0000 - tn: 1228.0000 - fn: 170.0000 - accuracy: 0.7194 - precision: 0.3642 - recall: 0.5729 - auc: 0.7243 - prc: 0.4763 - val_loss: 0.5758 - val_tp: 46.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 45.0000 - val_accuracy: 0.7273 - val_precision: 0.3309 - val_recall: 0.5055 - val_auc: 0.6882 - val_prc: 0.4232\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6060 - tp: 224.0000 - fp: 393.0000 - tn: 1233.0000 - fn: 174.0000 - accuracy: 0.7199 - precision: 0.3630 - recall: 0.5628 - auc: 0.7246 - prc: 0.4752 - val_loss: 0.6042 - val_tp: 50.0000 - val_fp: 114.0000 - val_tn: 301.0000 - val_fn: 41.0000 - val_accuracy: 0.6937 - val_precision: 0.3049 - val_recall: 0.5495 - val_auc: 0.6875 - val_prc: 0.4228\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6034 - tp: 236.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 162.0000 - accuracy: 0.6986 - precision: 0.3450 - recall: 0.5930 - auc: 0.7255 - prc: 0.4775 - val_loss: 0.6142 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6879 - val_prc: 0.4239\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6038 - tp: 252.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 146.0000 - accuracy: 0.6858 - precision: 0.3396 - recall: 0.6332 - auc: 0.7249 - prc: 0.4756 - val_loss: 0.6161 - val_tp: 51.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 40.0000 - val_accuracy: 0.6779 - val_precision: 0.2931 - val_recall: 0.5604 - val_auc: 0.6867 - val_prc: 0.4207\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6055 - tp: 228.0000 - fp: 402.0000 - tn: 1224.0000 - fn: 170.0000 - accuracy: 0.7174 - precision: 0.3619 - recall: 0.5729 - auc: 0.7237 - prc: 0.4765 - val_loss: 0.5939 - val_tp: 48.0000 - val_fp: 105.0000 - val_tn: 310.0000 - val_fn: 43.0000 - val_accuracy: 0.7075 - val_precision: 0.3137 - val_recall: 0.5275 - val_auc: 0.6876 - val_prc: 0.4236\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6027 - tp: 243.0000 - fp: 463.0000 - tn: 1163.0000 - fn: 155.0000 - accuracy: 0.6947 - precision: 0.3442 - recall: 0.6106 - auc: 0.7265 - prc: 0.4791 - val_loss: 0.6307 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6869 - val_prc: 0.4222\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6055 - tp: 263.0000 - fp: 567.0000 - tn: 1059.0000 - fn: 135.0000 - accuracy: 0.6532 - precision: 0.3169 - recall: 0.6608 - auc: 0.7249 - prc: 0.4763 - val_loss: 0.6418 - val_tp: 56.0000 - val_fp: 148.0000 - val_tn: 267.0000 - val_fn: 35.0000 - val_accuracy: 0.6383 - val_precision: 0.2745 - val_recall: 0.6154 - val_auc: 0.6869 - val_prc: 0.4238\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6029 - tp: 246.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 152.0000 - accuracy: 0.6868 - precision: 0.3379 - recall: 0.6181 - auc: 0.7272 - prc: 0.4779 - val_loss: 0.5937 - val_tp: 48.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 43.0000 - val_accuracy: 0.6957 - val_precision: 0.3019 - val_recall: 0.5275 - val_auc: 0.6894 - val_prc: 0.4307\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6039 - tp: 233.0000 - fp: 408.0000 - tn: 1218.0000 - fn: 165.0000 - accuracy: 0.7169 - precision: 0.3635 - recall: 0.5854 - auc: 0.7262 - prc: 0.4779 - val_loss: 0.6022 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6894 - val_prc: 0.4291\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6028 - tp: 241.0000 - fp: 454.0000 - tn: 1172.0000 - fn: 157.0000 - accuracy: 0.6981 - precision: 0.3468 - recall: 0.6055 - auc: 0.7266 - prc: 0.4784 - val_loss: 0.6189 - val_tp: 52.0000 - val_fp: 130.0000 - val_tn: 285.0000 - val_fn: 39.0000 - val_accuracy: 0.6660 - val_precision: 0.2857 - val_recall: 0.5714 - val_auc: 0.6879 - val_prc: 0.4224\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6028 - tp: 258.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 140.0000 - accuracy: 0.6769 - precision: 0.3342 - recall: 0.6482 - auc: 0.7267 - prc: 0.4782 - val_loss: 0.6323 - val_tp: 55.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 36.0000 - val_accuracy: 0.6640 - val_precision: 0.2910 - val_recall: 0.6044 - val_auc: 0.6869 - val_prc: 0.4199\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6030 - tp: 246.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 152.0000 - accuracy: 0.6882 - precision: 0.3393 - recall: 0.6181 - auc: 0.7263 - prc: 0.4763 - val_loss: 0.6158 - val_tp: 51.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 40.0000 - val_accuracy: 0.6798 - val_precision: 0.2948 - val_recall: 0.5604 - val_auc: 0.6870 - val_prc: 0.4192\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6038 - tp: 257.0000 - fp: 529.0000 - tn: 1097.0000 - fn: 141.0000 - accuracy: 0.6690 - precision: 0.3270 - recall: 0.6457 - auc: 0.7256 - prc: 0.4766 - val_loss: 0.6419 - val_tp: 55.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 36.0000 - val_accuracy: 0.6482 - val_precision: 0.2792 - val_recall: 0.6044 - val_auc: 0.6848 - val_prc: 0.4138\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6030 - tp: 251.0000 - fp: 490.0000 - tn: 1136.0000 - fn: 147.0000 - accuracy: 0.6853 - precision: 0.3387 - recall: 0.6307 - auc: 0.7262 - prc: 0.4775 - val_loss: 0.6202 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6836 - val_prc: 0.3952\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6028 - tp: 251.0000 - fp: 501.0000 - tn: 1125.0000 - fn: 147.0000 - accuracy: 0.6798 - precision: 0.3338 - recall: 0.6307 - auc: 0.7269 - prc: 0.4763 - val_loss: 0.6370 - val_tp: 55.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 36.0000 - val_accuracy: 0.6581 - val_precision: 0.2865 - val_recall: 0.6044 - val_auc: 0.6851 - val_prc: 0.4101\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6037 - tp: 263.0000 - fp: 553.0000 - tn: 1073.0000 - fn: 135.0000 - accuracy: 0.6601 - precision: 0.3223 - recall: 0.6608 - auc: 0.7267 - prc: 0.4782 - val_loss: 0.6292 - val_tp: 54.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 37.0000 - val_accuracy: 0.6621 - val_precision: 0.2872 - val_recall: 0.5934 - val_auc: 0.6871 - val_prc: 0.4195\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6018 - tp: 245.0000 - fp: 456.0000 - tn: 1170.0000 - fn: 153.0000 - accuracy: 0.6991 - precision: 0.3495 - recall: 0.6156 - auc: 0.7279 - prc: 0.4803 - val_loss: 0.5927 - val_tp: 47.0000 - val_fp: 108.0000 - val_tn: 307.0000 - val_fn: 44.0000 - val_accuracy: 0.6996 - val_precision: 0.3032 - val_recall: 0.5165 - val_auc: 0.6884 - val_prc: 0.4243\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6039 - tp: 225.0000 - fp: 384.0000 - tn: 1242.0000 - fn: 173.0000 - accuracy: 0.7248 - precision: 0.3695 - recall: 0.5653 - auc: 0.7274 - prc: 0.4786 - val_loss: 0.5996 - val_tp: 49.0000 - val_fp: 115.0000 - val_tn: 300.0000 - val_fn: 42.0000 - val_accuracy: 0.6897 - val_precision: 0.2988 - val_recall: 0.5385 - val_auc: 0.6879 - val_prc: 0.4238\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6025 - tp: 248.0000 - fp: 480.0000 - tn: 1146.0000 - fn: 150.0000 - accuracy: 0.6887 - precision: 0.3407 - recall: 0.6231 - auc: 0.7271 - prc: 0.4785 - val_loss: 0.6358 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6850 - val_prc: 0.4098\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6023 - tp: 251.0000 - fp: 498.0000 - tn: 1128.0000 - fn: 147.0000 - accuracy: 0.6813 - precision: 0.3351 - recall: 0.6307 - auc: 0.7275 - prc: 0.4788 - val_loss: 0.6147 - val_tp: 50.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 41.0000 - val_accuracy: 0.6759 - val_precision: 0.2890 - val_recall: 0.5495 - val_auc: 0.6863 - val_prc: 0.4125\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6032 - tp: 232.0000 - fp: 407.0000 - tn: 1219.0000 - fn: 166.0000 - accuracy: 0.7169 - precision: 0.3631 - recall: 0.5829 - auc: 0.7276 - prc: 0.4762 - val_loss: 0.5940 - val_tp: 48.0000 - val_fp: 110.0000 - val_tn: 305.0000 - val_fn: 43.0000 - val_accuracy: 0.6976 - val_precision: 0.3038 - val_recall: 0.5275 - val_auc: 0.6889 - val_prc: 0.4230\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6018 - tp: 239.0000 - fp: 436.0000 - tn: 1190.0000 - fn: 159.0000 - accuracy: 0.7060 - precision: 0.3541 - recall: 0.6005 - auc: 0.7283 - prc: 0.4801 - val_loss: 0.6192 - val_tp: 52.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 39.0000 - val_accuracy: 0.6680 - val_precision: 0.2873 - val_recall: 0.5714 - val_auc: 0.6880 - val_prc: 0.4263\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6016 - tp: 252.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 146.0000 - accuracy: 0.6877 - precision: 0.3415 - recall: 0.6332 - auc: 0.7285 - prc: 0.4801 - val_loss: 0.6175 - val_tp: 52.0000 - val_fp: 127.0000 - val_tn: 288.0000 - val_fn: 39.0000 - val_accuracy: 0.6719 - val_precision: 0.2905 - val_recall: 0.5714 - val_auc: 0.6876 - val_prc: 0.4264\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6016 - tp: 254.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 144.0000 - accuracy: 0.6873 - precision: 0.3419 - recall: 0.6382 - auc: 0.7280 - prc: 0.4801 - val_loss: 0.6254 - val_tp: 52.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 39.0000 - val_accuracy: 0.6640 - val_precision: 0.2842 - val_recall: 0.5714 - val_auc: 0.6870 - val_prc: 0.4210\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6019 - tp: 259.0000 - fp: 518.0000 - tn: 1108.0000 - fn: 139.0000 - accuracy: 0.6754 - precision: 0.3333 - recall: 0.6508 - auc: 0.7285 - prc: 0.4796 - val_loss: 0.6365 - val_tp: 55.0000 - val_fp: 140.0000 - val_tn: 275.0000 - val_fn: 36.0000 - val_accuracy: 0.6522 - val_precision: 0.2821 - val_recall: 0.6044 - val_auc: 0.6875 - val_prc: 0.4250\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6029 - tp: 265.0000 - fp: 547.0000 - tn: 1079.0000 - fn: 133.0000 - accuracy: 0.6640 - precision: 0.3264 - recall: 0.6658 - auc: 0.7283 - prc: 0.4791 - val_loss: 0.6319 - val_tp: 54.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 37.0000 - val_accuracy: 0.6601 - val_precision: 0.2857 - val_recall: 0.5934 - val_auc: 0.6870 - val_prc: 0.4249\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6009 - tp: 248.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 150.0000 - accuracy: 0.6927 - precision: 0.3444 - recall: 0.6231 - auc: 0.7290 - prc: 0.4815 - val_loss: 0.6080 - val_tp: 51.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 40.0000 - val_accuracy: 0.6818 - val_precision: 0.2965 - val_recall: 0.5604 - val_auc: 0.6873 - val_prc: 0.4240\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - tp: 251.0000 - fp: 484.0000 - tn: 1142.0000 - fn: 147.0000 - accuracy: 0.6882 - precision: 0.3415 - recall: 0.6307 - auc: 0.7288 - prc: 0.4805 - val_loss: 0.6297 - val_tp: 54.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 37.0000 - val_accuracy: 0.6640 - val_precision: 0.2888 - val_recall: 0.5934 - val_auc: 0.6874 - val_prc: 0.4245\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6015 - tp: 250.0000 - fp: 486.0000 - tn: 1140.0000 - fn: 148.0000 - accuracy: 0.6868 - precision: 0.3397 - recall: 0.6281 - auc: 0.7281 - prc: 0.4804 - val_loss: 0.6114 - val_tp: 52.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 39.0000 - val_accuracy: 0.6818 - val_precision: 0.2989 - val_recall: 0.5714 - val_auc: 0.6879 - val_prc: 0.4254\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6023 - tp: 236.0000 - fp: 425.0000 - tn: 1201.0000 - fn: 162.0000 - accuracy: 0.7100 - precision: 0.3570 - recall: 0.5930 - auc: 0.7275 - prc: 0.4792 - val_loss: 0.6037 - val_tp: 51.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 40.0000 - val_accuracy: 0.6858 - val_precision: 0.3000 - val_recall: 0.5604 - val_auc: 0.6893 - val_prc: 0.4276\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6014 - tp: 247.0000 - fp: 460.0000 - tn: 1166.0000 - fn: 151.0000 - accuracy: 0.6981 - precision: 0.3494 - recall: 0.6206 - auc: 0.7288 - prc: 0.4800 - val_loss: 0.6165 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6882 - val_prc: 0.4265\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6011 - tp: 243.0000 - fp: 453.0000 - tn: 1173.0000 - fn: 155.0000 - accuracy: 0.6996 - precision: 0.3491 - recall: 0.6106 - auc: 0.7293 - prc: 0.4802 - val_loss: 0.6130 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6875 - val_prc: 0.4253\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6011 - tp: 253.0000 - fp: 491.0000 - tn: 1135.0000 - fn: 145.0000 - accuracy: 0.6858 - precision: 0.3401 - recall: 0.6357 - auc: 0.7290 - prc: 0.4807 - val_loss: 0.6314 - val_tp: 54.0000 - val_fp: 137.0000 - val_tn: 278.0000 - val_fn: 37.0000 - val_accuracy: 0.6561 - val_precision: 0.2827 - val_recall: 0.5934 - val_auc: 0.6877 - val_prc: 0.4250\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - tp: 253.0000 - fp: 496.0000 - tn: 1130.0000 - fn: 145.0000 - accuracy: 0.6833 - precision: 0.3378 - recall: 0.6357 - auc: 0.7290 - prc: 0.4798 - val_loss: 0.6190 - val_tp: 52.0000 - val_fp: 126.0000 - val_tn: 289.0000 - val_fn: 39.0000 - val_accuracy: 0.6739 - val_precision: 0.2921 - val_recall: 0.5714 - val_auc: 0.6890 - val_prc: 0.4267\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6007 - tp: 250.0000 - fp: 476.0000 - tn: 1150.0000 - fn: 148.0000 - accuracy: 0.6917 - precision: 0.3444 - recall: 0.6281 - auc: 0.7294 - prc: 0.4817 - val_loss: 0.6145 - val_tp: 52.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 39.0000 - val_accuracy: 0.6858 - val_precision: 0.3023 - val_recall: 0.5714 - val_auc: 0.6886 - val_prc: 0.4242\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6005 - tp: 248.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 150.0000 - accuracy: 0.6991 - precision: 0.3508 - recall: 0.6231 - auc: 0.7294 - prc: 0.4807 - val_loss: 0.6109 - val_tp: 52.0000 - val_fp: 119.0000 - val_tn: 296.0000 - val_fn: 39.0000 - val_accuracy: 0.6877 - val_precision: 0.3041 - val_recall: 0.5714 - val_auc: 0.6881 - val_prc: 0.4238\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6014 - tp: 241.0000 - fp: 433.0000 - tn: 1193.0000 - fn: 157.0000 - accuracy: 0.7085 - precision: 0.3576 - recall: 0.6055 - auc: 0.7287 - prc: 0.4804 - val_loss: 0.6048 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6882 - val_prc: 0.4247\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6010 - tp: 248.0000 - fp: 471.0000 - tn: 1155.0000 - fn: 150.0000 - accuracy: 0.6932 - precision: 0.3449 - recall: 0.6231 - auc: 0.7291 - prc: 0.4802 - val_loss: 0.6248 - val_tp: 53.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 38.0000 - val_accuracy: 0.6660 - val_precision: 0.2880 - val_recall: 0.5824 - val_auc: 0.6879 - val_prc: 0.4263\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6011 - tp: 257.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 141.0000 - accuracy: 0.6779 - precision: 0.3346 - recall: 0.6457 - auc: 0.7290 - prc: 0.4811 - val_loss: 0.6306 - val_tp: 53.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 38.0000 - val_accuracy: 0.6601 - val_precision: 0.2834 - val_recall: 0.5824 - val_auc: 0.6858 - val_prc: 0.4152\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - tp: 257.0000 - fp: 511.0000 - tn: 1115.0000 - fn: 141.0000 - accuracy: 0.6779 - precision: 0.3346 - recall: 0.6457 - auc: 0.7289 - prc: 0.4801 - val_loss: 0.6276 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6854 - val_prc: 0.4170\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6015 - tp: 245.0000 - fp: 452.0000 - tn: 1174.0000 - fn: 153.0000 - accuracy: 0.7011 - precision: 0.3515 - recall: 0.6156 - auc: 0.7281 - prc: 0.4790 - val_loss: 0.6086 - val_tp: 50.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 41.0000 - val_accuracy: 0.6798 - val_precision: 0.2924 - val_recall: 0.5495 - val_auc: 0.6868 - val_prc: 0.4209\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6006 - tp: 251.0000 - fp: 479.0000 - tn: 1147.0000 - fn: 147.0000 - accuracy: 0.6907 - precision: 0.3438 - recall: 0.6307 - auc: 0.7296 - prc: 0.4804 - val_loss: 0.6300 - val_tp: 53.0000 - val_fp: 135.0000 - val_tn: 280.0000 - val_fn: 38.0000 - val_accuracy: 0.6581 - val_precision: 0.2819 - val_recall: 0.5824 - val_auc: 0.6863 - val_prc: 0.4155\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - tp: 245.0000 - fp: 459.0000 - tn: 1167.0000 - fn: 153.0000 - accuracy: 0.6976 - precision: 0.3480 - recall: 0.6156 - auc: 0.7288 - prc: 0.4792 - val_loss: 0.6205 - val_tp: 52.0000 - val_fp: 123.0000 - val_tn: 292.0000 - val_fn: 39.0000 - val_accuracy: 0.6798 - val_precision: 0.2971 - val_recall: 0.5714 - val_auc: 0.6851 - val_prc: 0.4047\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6009 - tp: 256.0000 - fp: 514.0000 - tn: 1112.0000 - fn: 142.0000 - accuracy: 0.6759 - precision: 0.3325 - recall: 0.6432 - auc: 0.7297 - prc: 0.4809 - val_loss: 0.6351 - val_tp: 53.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 38.0000 - val_accuracy: 0.6502 - val_precision: 0.2760 - val_recall: 0.5824 - val_auc: 0.6858 - val_prc: 0.4138\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6004 - tp: 249.0000 - fp: 482.0000 - tn: 1144.0000 - fn: 149.0000 - accuracy: 0.6882 - precision: 0.3406 - recall: 0.6256 - auc: 0.7294 - prc: 0.4828 - val_loss: 0.6168 - val_tp: 52.0000 - val_fp: 125.0000 - val_tn: 290.0000 - val_fn: 39.0000 - val_accuracy: 0.6759 - val_precision: 0.2938 - val_recall: 0.5714 - val_auc: 0.6872 - val_prc: 0.4173\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6006 - tp: 255.0000 - fp: 504.0000 - tn: 1122.0000 - fn: 143.0000 - accuracy: 0.6803 - precision: 0.3360 - recall: 0.6407 - auc: 0.7298 - prc: 0.4817 - val_loss: 0.6340 - val_tp: 53.0000 - val_fp: 139.0000 - val_tn: 276.0000 - val_fn: 38.0000 - val_accuracy: 0.6502 - val_precision: 0.2760 - val_recall: 0.5824 - val_auc: 0.6877 - val_prc: 0.4209\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6006 - tp: 249.0000 - fp: 472.0000 - tn: 1154.0000 - fn: 149.0000 - accuracy: 0.6932 - precision: 0.3454 - recall: 0.6256 - auc: 0.7291 - prc: 0.4807 - val_loss: 0.6058 - val_tp: 50.0000 - val_fp: 122.0000 - val_tn: 293.0000 - val_fn: 41.0000 - val_accuracy: 0.6779 - val_precision: 0.2907 - val_recall: 0.5495 - val_auc: 0.6876 - val_prc: 0.4199\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6005 - tp: 246.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 152.0000 - accuracy: 0.7036 - precision: 0.3545 - recall: 0.6181 - auc: 0.7294 - prc: 0.4815 - val_loss: 0.6167 - val_tp: 51.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 40.0000 - val_accuracy: 0.6759 - val_precision: 0.2914 - val_recall: 0.5604 - val_auc: 0.6863 - val_prc: 0.4141\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6002 - tp: 246.0000 - fp: 451.0000 - tn: 1175.0000 - fn: 152.0000 - accuracy: 0.7021 - precision: 0.3529 - recall: 0.6181 - auc: 0.7302 - prc: 0.4817 - val_loss: 0.6074 - val_tp: 50.0000 - val_fp: 120.0000 - val_tn: 295.0000 - val_fn: 41.0000 - val_accuracy: 0.6818 - val_precision: 0.2941 - val_recall: 0.5495 - val_auc: 0.6875 - val_prc: 0.4149\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6002 - tp: 240.0000 - fp: 422.0000 - tn: 1204.0000 - fn: 158.0000 - accuracy: 0.7134 - precision: 0.3625 - recall: 0.6030 - auc: 0.7302 - prc: 0.4825 - val_loss: 0.6065 - val_tp: 50.0000 - val_fp: 121.0000 - val_tn: 294.0000 - val_fn: 41.0000 - val_accuracy: 0.6798 - val_precision: 0.2924 - val_recall: 0.5495 - val_auc: 0.6887 - val_prc: 0.4221\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5999 - tp: 246.0000 - fp: 448.0000 - tn: 1178.0000 - fn: 152.0000 - accuracy: 0.7036 - precision: 0.3545 - recall: 0.6181 - auc: 0.7309 - prc: 0.4810 - val_loss: 0.6205 - val_tp: 52.0000 - val_fp: 131.0000 - val_tn: 284.0000 - val_fn: 39.0000 - val_accuracy: 0.6640 - val_precision: 0.2842 - val_recall: 0.5714 - val_auc: 0.6896 - val_prc: 0.4289\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6003 - tp: 257.0000 - fp: 525.0000 - tn: 1101.0000 - fn: 141.0000 - accuracy: 0.6709 - precision: 0.3286 - recall: 0.6457 - auc: 0.7307 - prc: 0.4818 - val_loss: 0.6353 - val_tp: 53.0000 - val_fp: 142.0000 - val_tn: 273.0000 - val_fn: 38.0000 - val_accuracy: 0.6443 - val_precision: 0.2718 - val_recall: 0.5824 - val_auc: 0.6876 - val_prc: 0.4216\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5999 - tp: 253.0000 - fp: 489.0000 - tn: 1137.0000 - fn: 145.0000 - accuracy: 0.6868 - precision: 0.3410 - recall: 0.6357 - auc: 0.7309 - prc: 0.4822 - val_loss: 0.6109 - val_tp: 50.0000 - val_fp: 117.0000 - val_tn: 298.0000 - val_fn: 41.0000 - val_accuracy: 0.6877 - val_precision: 0.2994 - val_recall: 0.5495 - val_auc: 0.6873 - val_prc: 0.4147\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6004 - tp: 239.0000 - fp: 417.0000 - tn: 1209.0000 - fn: 159.0000 - accuracy: 0.7154 - precision: 0.3643 - recall: 0.6005 - auc: 0.7307 - prc: 0.4807 - val_loss: 0.6021 - val_tp: 49.0000 - val_fp: 111.0000 - val_tn: 304.0000 - val_fn: 42.0000 - val_accuracy: 0.6976 - val_precision: 0.3063 - val_recall: 0.5385 - val_auc: 0.6878 - val_prc: 0.4159\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5997 - tp: 246.0000 - fp: 458.0000 - tn: 1168.0000 - fn: 152.0000 - accuracy: 0.6986 - precision: 0.3494 - recall: 0.6181 - auc: 0.7309 - prc: 0.4815 - val_loss: 0.6212 - val_tp: 52.0000 - val_fp: 133.0000 - val_tn: 282.0000 - val_fn: 39.0000 - val_accuracy: 0.6601 - val_precision: 0.2811 - val_recall: 0.5714 - val_auc: 0.6876 - val_prc: 0.4171\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5996 - tp: 248.0000 - fp: 462.0000 - tn: 1164.0000 - fn: 150.0000 - accuracy: 0.6976 - precision: 0.3493 - recall: 0.6231 - auc: 0.7311 - prc: 0.4820 - val_loss: 0.6129 - val_tp: 50.0000 - val_fp: 124.0000 - val_tn: 291.0000 - val_fn: 41.0000 - val_accuracy: 0.6739 - val_precision: 0.2874 - val_recall: 0.5495 - val_auc: 0.6878 - val_prc: 0.4195\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5995 - tp: 246.0000 - fp: 455.0000 - tn: 1171.0000 - fn: 152.0000 - accuracy: 0.7001 - precision: 0.3509 - recall: 0.6181 - auc: 0.7314 - prc: 0.4818 - val_loss: 0.6183 - val_tp: 51.0000 - val_fp: 129.0000 - val_tn: 286.0000 - val_fn: 40.0000 - val_accuracy: 0.6660 - val_precision: 0.2833 - val_recall: 0.5604 - val_auc: 0.6881 - val_prc: 0.4216\n",
      "Epoch 242/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.5644 - tp: 21.0000 - fp: 38.0000 - tn: 127.0000 - fn: 14.0000 - accuracy: 0.7400 - precision: 0.3559 - recall: 0.6000 - auc: 0.7521 - prc: 0.4563Restoring model weights from the end of the best epoch: 192.\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5994 - tp: 252.0000 - fp: 478.0000 - tn: 1148.0000 - fn: 146.0000 - accuracy: 0.6917 - precision: 0.3452 - recall: 0.6332 - auc: 0.7309 - prc: 0.4820 - val_loss: 0.6251 - val_tp: 52.0000 - val_fp: 134.0000 - val_tn: 281.0000 - val_fn: 39.0000 - val_accuracy: 0.6581 - val_precision: 0.2796 - val_recall: 0.5714 - val_auc: 0.6869 - val_prc: 0.4146\n",
      "Epoch 242: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "# Create a dictionary mapping the class indices to their respective weights\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "class_weights_values = [{0: 1, 1: 1+i/2} for i in range(1, 8)]  # list of class_weights dictionary\n",
    "class_weights_values.append(class_weights_dict)\n",
    "\n",
    "# Hyperparameter tuning for class weight\n",
    "coordinates = [[0,0]]\n",
    "for i in range(len(class_weights_values)):\n",
    "    class_weight = class_weights_values[i]\n",
    "    model = make_model(input_shape=X_train.shape[-1])\n",
    "    model.load_weights(initial_weights)\n",
    "    baseline_history = model.fit(X_train,\n",
    "                                y_train,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                callbacks=[early_stopping],\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                class_weight=class_weight)\n",
    "    y_pred = (model.predict(X_val, batch_size=BATCH_SIZE) > 0.5).astype(int)\n",
    "    c_mat = confusion_matrix(y_val, y_pred)\n",
    "    # save the values of sensitivity and 1-specificity for ROC curve\n",
    "    sensitivity = c_mat[1,1]/np.sum(c_mat[1,:])\n",
    "    specificity = c_mat[0,0]/np.sum(c_mat[0,:])\n",
    "    coordinates.append([1-specificity,sensitivity])\n",
    "coordinates.append([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87f5b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot roc curve\n",
    "coordinates_np = np.array(sorted(coordinates, key=lambda x: x[0]))  # first column: FP, second column: TP\n",
    "plt.plot(coordinates_np[:,0], coordinates_np[:,1], linewidth=2, marker='o')\n",
    "diag = np.linspace(0,1,20)\n",
    "plt.plot(diag, diag)\n",
    "plt.xlabel('False positives')\n",
    "plt.ylabel('True positives')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.grid(True)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3336bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 3.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use youden index to find the best class weight\n",
    "youden_np = (coordinates_np[:,1]-coordinates_np[:,0])\n",
    "optimal = coordinates_np[youden_np.argmax(), :]\n",
    "best_class_weight_idx = coordinates.index([optimal[0], optimal[1]])\n",
    "\n",
    "# -1 is needed because coordinates list began with [0,0]\n",
    "best_class_weight = class_weights_values[best_class_weight_idx-1]\n",
    "best_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0fe4187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 1s 30ms/step - loss: 1.1417 - tp: 52.0000 - fp: 134.0000 - tn: 1907.0000 - fn: 437.0000 - accuracy: 0.7743 - precision: 0.2796 - recall: 0.1063 - auc: 0.4842 - prc: 0.2288 - val_loss: 0.4721 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5298 - val_prc: 0.1895\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1321 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4872 - prc: 0.1927 - val_loss: 0.4726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4676 - val_prc: 0.1697\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1206 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5338 - prc: 0.2387 - val_loss: 0.4733 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4905 - val_prc: 0.1909\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1083 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5519 - prc: 0.2328 - val_loss: 0.4743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5924 - val_prc: 0.2762\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6072 - prc: 0.2770 - val_loss: 0.4758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5787 - val_prc: 0.2505\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0771 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6180 - prc: 0.3014 - val_loss: 0.4779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6186 - val_prc: 0.2720\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0591 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6444 - prc: 0.3226 - val_loss: 0.4810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6130 - val_prc: 0.2631\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0399 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6506 - prc: 0.3316 - val_loss: 0.4857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6343 - val_prc: 0.2821\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0190 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6481 - prc: 0.3217 - val_loss: 0.4924 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6343 - val_prc: 0.2786\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9966 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6566 - prc: 0.3496 - val_loss: 0.5024 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6375 - val_prc: 0.2808\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9727 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6686 - prc: 0.3424 - val_loss: 0.5173 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6466 - val_prc: 0.2864\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9505 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1626.0000 - fn: 398.0000 - accuracy: 0.8034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6749 - prc: 0.3666 - val_loss: 0.5358 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 415.0000 - val_fn: 91.0000 - val_accuracy: 0.8202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_prc: 0.2805\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9336 - tp: 2.0000 - fp: 4.0000 - tn: 1622.0000 - fn: 396.0000 - accuracy: 0.8024 - precision: 0.3333 - recall: 0.0050 - auc: 0.6790 - prc: 0.3596 - val_loss: 0.5599 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 91.0000 - val_accuracy: 0.8162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6458 - val_prc: 0.2816\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9236 - tp: 6.0000 - fp: 8.0000 - tn: 1618.0000 - fn: 392.0000 - accuracy: 0.8024 - precision: 0.4286 - recall: 0.0151 - auc: 0.6806 - prc: 0.3678 - val_loss: 0.5805 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 413.0000 - val_fn: 89.0000 - val_accuracy: 0.8202 - val_precision: 0.5000 - val_recall: 0.0220 - val_auc: 0.6473 - val_prc: 0.2832\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9189 - tp: 22.0000 - fp: 14.0000 - tn: 1612.0000 - fn: 376.0000 - accuracy: 0.8073 - precision: 0.6111 - recall: 0.0553 - auc: 0.6853 - prc: 0.3756 - val_loss: 0.5935 - val_tp: 4.0000 - val_fp: 9.0000 - val_tn: 406.0000 - val_fn: 87.0000 - val_accuracy: 0.8103 - val_precision: 0.3077 - val_recall: 0.0440 - val_auc: 0.6506 - val_prc: 0.2865\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9175 - tp: 37.0000 - fp: 29.0000 - tn: 1597.0000 - fn: 361.0000 - accuracy: 0.8073 - precision: 0.5606 - recall: 0.0930 - auc: 0.6866 - prc: 0.3752 - val_loss: 0.5985 - val_tp: 7.0000 - val_fp: 10.0000 - val_tn: 405.0000 - val_fn: 84.0000 - val_accuracy: 0.8142 - val_precision: 0.4118 - val_recall: 0.0769 - val_auc: 0.6491 - val_prc: 0.2884\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9165 - tp: 49.0000 - fp: 38.0000 - tn: 1588.0000 - fn: 349.0000 - accuracy: 0.8088 - precision: 0.5632 - recall: 0.1231 - auc: 0.6872 - prc: 0.3773 - val_loss: 0.6055 - val_tp: 10.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 81.0000 - val_accuracy: 0.8123 - val_precision: 0.4167 - val_recall: 0.1099 - val_auc: 0.6483 - val_prc: 0.2845\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9163 - tp: 69.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 329.0000 - accuracy: 0.8098 - precision: 0.5520 - recall: 0.1734 - auc: 0.6866 - prc: 0.3746 - val_loss: 0.6102 - val_tp: 11.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 80.0000 - val_accuracy: 0.8103 - val_precision: 0.4074 - val_recall: 0.1209 - val_auc: 0.6508 - val_prc: 0.2864\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9155 - tp: 78.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 320.0000 - accuracy: 0.8083 - precision: 0.5342 - recall: 0.1960 - auc: 0.6890 - prc: 0.3791 - val_loss: 0.6146 - val_tp: 13.0000 - val_fp: 20.0000 - val_tn: 395.0000 - val_fn: 78.0000 - val_accuracy: 0.8063 - val_precision: 0.3939 - val_recall: 0.1429 - val_auc: 0.6526 - val_prc: 0.2917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9150 - tp: 79.0000 - fp: 73.0000 - tn: 1553.0000 - fn: 319.0000 - accuracy: 0.8063 - precision: 0.5197 - recall: 0.1985 - auc: 0.6881 - prc: 0.3794 - val_loss: 0.6094 - val_tp: 12.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 79.0000 - val_accuracy: 0.8103 - val_precision: 0.4138 - val_recall: 0.1319 - val_auc: 0.6558 - val_prc: 0.2944\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9142 - tp: 68.0000 - fp: 61.0000 - tn: 1565.0000 - fn: 330.0000 - accuracy: 0.8068 - precision: 0.5271 - recall: 0.1709 - auc: 0.6881 - prc: 0.3797 - val_loss: 0.6039 - val_tp: 11.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 80.0000 - val_accuracy: 0.8103 - val_precision: 0.4074 - val_recall: 0.1209 - val_auc: 0.6504 - val_prc: 0.2882\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9139 - tp: 55.0000 - fp: 50.0000 - tn: 1576.0000 - fn: 343.0000 - accuracy: 0.8058 - precision: 0.5238 - recall: 0.1382 - auc: 0.6844 - prc: 0.3758 - val_loss: 0.5988 - val_tp: 10.0000 - val_fp: 14.0000 - val_tn: 401.0000 - val_fn: 81.0000 - val_accuracy: 0.8123 - val_precision: 0.4167 - val_recall: 0.1099 - val_auc: 0.6505 - val_prc: 0.2897\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9127 - tp: 66.0000 - fp: 57.0000 - tn: 1569.0000 - fn: 332.0000 - accuracy: 0.8078 - precision: 0.5366 - recall: 0.1658 - auc: 0.6879 - prc: 0.3777 - val_loss: 0.6052 - val_tp: 12.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 79.0000 - val_accuracy: 0.8063 - val_precision: 0.3871 - val_recall: 0.1319 - val_auc: 0.6550 - val_prc: 0.2909\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9114 - tp: 73.0000 - fp: 62.0000 - tn: 1564.0000 - fn: 325.0000 - accuracy: 0.8088 - precision: 0.5407 - recall: 0.1834 - auc: 0.6913 - prc: 0.3792 - val_loss: 0.6011 - val_tp: 11.0000 - val_fp: 17.0000 - val_tn: 398.0000 - val_fn: 80.0000 - val_accuracy: 0.8083 - val_precision: 0.3929 - val_recall: 0.1209 - val_auc: 0.6548 - val_prc: 0.2910\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9103 - tp: 69.0000 - fp: 59.0000 - tn: 1567.0000 - fn: 329.0000 - accuracy: 0.8083 - precision: 0.5391 - recall: 0.1734 - auc: 0.6924 - prc: 0.3821 - val_loss: 0.5987 - val_tp: 10.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 81.0000 - val_accuracy: 0.8083 - val_precision: 0.3846 - val_recall: 0.1099 - val_auc: 0.6567 - val_prc: 0.2922\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9095 - tp: 70.0000 - fp: 56.0000 - tn: 1570.0000 - fn: 328.0000 - accuracy: 0.8103 - precision: 0.5556 - recall: 0.1759 - auc: 0.6937 - prc: 0.3834 - val_loss: 0.5979 - val_tp: 10.0000 - val_fp: 16.0000 - val_tn: 399.0000 - val_fn: 81.0000 - val_accuracy: 0.8083 - val_precision: 0.3846 - val_recall: 0.1099 - val_auc: 0.6578 - val_prc: 0.2945\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9087 - tp: 77.0000 - fp: 69.0000 - tn: 1557.0000 - fn: 321.0000 - accuracy: 0.8073 - precision: 0.5274 - recall: 0.1935 - auc: 0.6933 - prc: 0.3842 - val_loss: 0.6005 - val_tp: 12.0000 - val_fp: 19.0000 - val_tn: 396.0000 - val_fn: 79.0000 - val_accuracy: 0.8063 - val_precision: 0.3871 - val_recall: 0.1319 - val_auc: 0.6607 - val_prc: 0.2965\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9075 - tp: 77.0000 - fp: 68.0000 - tn: 1558.0000 - fn: 321.0000 - accuracy: 0.8078 - precision: 0.5310 - recall: 0.1935 - auc: 0.6948 - prc: 0.3869 - val_loss: 0.5956 - val_tp: 11.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 80.0000 - val_accuracy: 0.8063 - val_precision: 0.3793 - val_recall: 0.1209 - val_auc: 0.6619 - val_prc: 0.2987\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9068 - tp: 91.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 307.0000 - accuracy: 0.8088 - precision: 0.5322 - recall: 0.2286 - auc: 0.6919 - prc: 0.3857 - val_loss: 0.6047 - val_tp: 16.0000 - val_fp: 29.0000 - val_tn: 386.0000 - val_fn: 75.0000 - val_accuracy: 0.7945 - val_precision: 0.3556 - val_recall: 0.1758 - val_auc: 0.6607 - val_prc: 0.2986\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9049 - tp: 91.0000 - fp: 80.0000 - tn: 1546.0000 - fn: 307.0000 - accuracy: 0.8088 - precision: 0.5322 - recall: 0.2286 - auc: 0.6938 - prc: 0.3929 - val_loss: 0.5918 - val_tp: 13.0000 - val_fp: 18.0000 - val_tn: 397.0000 - val_fn: 78.0000 - val_accuracy: 0.8103 - val_precision: 0.4194 - val_recall: 0.1429 - val_auc: 0.6587 - val_prc: 0.3002\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9034 - tp: 87.0000 - fp: 79.0000 - tn: 1547.0000 - fn: 311.0000 - accuracy: 0.8073 - precision: 0.5241 - recall: 0.2186 - auc: 0.6928 - prc: 0.3964 - val_loss: 0.5942 - val_tp: 17.0000 - val_fp: 24.0000 - val_tn: 391.0000 - val_fn: 74.0000 - val_accuracy: 0.8063 - val_precision: 0.4146 - val_recall: 0.1868 - val_auc: 0.6602 - val_prc: 0.3092\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9013 - tp: 110.0000 - fp: 118.0000 - tn: 1508.0000 - fn: 288.0000 - accuracy: 0.7994 - precision: 0.4825 - recall: 0.2764 - auc: 0.6904 - prc: 0.3930 - val_loss: 0.5977 - val_tp: 25.0000 - val_fp: 37.0000 - val_tn: 378.0000 - val_fn: 66.0000 - val_accuracy: 0.7964 - val_precision: 0.4032 - val_recall: 0.2747 - val_auc: 0.6611 - val_prc: 0.3111\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8995 - tp: 106.0000 - fp: 113.0000 - tn: 1513.0000 - fn: 292.0000 - accuracy: 0.7999 - precision: 0.4840 - recall: 0.2663 - auc: 0.6893 - prc: 0.3918 - val_loss: 0.5883 - val_tp: 21.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 70.0000 - val_accuracy: 0.8004 - val_precision: 0.4038 - val_recall: 0.2308 - val_auc: 0.6607 - val_prc: 0.3119\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8983 - tp: 100.0000 - fp: 101.0000 - tn: 1525.0000 - fn: 298.0000 - accuracy: 0.8029 - precision: 0.4975 - recall: 0.2513 - auc: 0.6883 - prc: 0.3921 - val_loss: 0.5875 - val_tp: 21.0000 - val_fp: 31.0000 - val_tn: 384.0000 - val_fn: 70.0000 - val_accuracy: 0.8004 - val_precision: 0.4038 - val_recall: 0.2308 - val_auc: 0.6617 - val_prc: 0.3145\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8968 - tp: 107.0000 - fp: 115.0000 - tn: 1511.0000 - fn: 291.0000 - accuracy: 0.7994 - precision: 0.4820 - recall: 0.2688 - auc: 0.6893 - prc: 0.3925 - val_loss: 0.5890 - val_tp: 23.0000 - val_fp: 33.0000 - val_tn: 382.0000 - val_fn: 68.0000 - val_accuracy: 0.8004 - val_precision: 0.4107 - val_recall: 0.2527 - val_auc: 0.6624 - val_prc: 0.3154\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8953 - tp: 131.0000 - fp: 168.0000 - tn: 1458.0000 - fn: 267.0000 - accuracy: 0.7851 - precision: 0.4381 - recall: 0.3291 - auc: 0.6902 - prc: 0.3941 - val_loss: 0.5946 - val_tp: 28.0000 - val_fp: 45.0000 - val_tn: 370.0000 - val_fn: 63.0000 - val_accuracy: 0.7866 - val_precision: 0.3836 - val_recall: 0.3077 - val_auc: 0.6629 - val_prc: 0.3153\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8943 - tp: 121.0000 - fp: 131.0000 - tn: 1495.0000 - fn: 277.0000 - accuracy: 0.7984 - precision: 0.4802 - recall: 0.3040 - auc: 0.6900 - prc: 0.3969 - val_loss: 0.5788 - val_tp: 21.0000 - val_fp: 30.0000 - val_tn: 385.0000 - val_fn: 70.0000 - val_accuracy: 0.8024 - val_precision: 0.4118 - val_recall: 0.2308 - val_auc: 0.6618 - val_prc: 0.3174\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8931 - tp: 115.0000 - fp: 142.0000 - tn: 1484.0000 - fn: 283.0000 - accuracy: 0.7900 - precision: 0.4475 - recall: 0.2889 - auc: 0.6903 - prc: 0.3956 - val_loss: 0.5911 - val_tp: 28.0000 - val_fp: 44.0000 - val_tn: 371.0000 - val_fn: 63.0000 - val_accuracy: 0.7885 - val_precision: 0.3889 - val_recall: 0.3077 - val_auc: 0.6634 - val_prc: 0.3188\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8915 - tp: 139.0000 - fp: 189.0000 - tn: 1437.0000 - fn: 259.0000 - accuracy: 0.7787 - precision: 0.4238 - recall: 0.3492 - auc: 0.6914 - prc: 0.3976 - val_loss: 0.5951 - val_tp: 31.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 60.0000 - val_accuracy: 0.7747 - val_precision: 0.3647 - val_recall: 0.3407 - val_auc: 0.6648 - val_prc: 0.3198\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8904 - tp: 154.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 244.0000 - accuracy: 0.7732 - precision: 0.4173 - recall: 0.3869 - auc: 0.6919 - prc: 0.3972 - val_loss: 0.5951 - val_tp: 32.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 59.0000 - val_accuracy: 0.7688 - val_precision: 0.3556 - val_recall: 0.3516 - val_auc: 0.6646 - val_prc: 0.3197\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8890 - tp: 155.0000 - fp: 216.0000 - tn: 1410.0000 - fn: 243.0000 - accuracy: 0.7732 - precision: 0.4178 - recall: 0.3894 - auc: 0.6935 - prc: 0.3978 - val_loss: 0.5886 - val_tp: 30.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 61.0000 - val_accuracy: 0.7767 - val_precision: 0.3659 - val_recall: 0.3297 - val_auc: 0.6655 - val_prc: 0.3207\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8882 - tp: 122.0000 - fp: 158.0000 - tn: 1468.0000 - fn: 276.0000 - accuracy: 0.7856 - precision: 0.4357 - recall: 0.3065 - auc: 0.6917 - prc: 0.3964 - val_loss: 0.5792 - val_tp: 27.0000 - val_fp: 40.0000 - val_tn: 375.0000 - val_fn: 64.0000 - val_accuracy: 0.7945 - val_precision: 0.4030 - val_recall: 0.2967 - val_auc: 0.6652 - val_prc: 0.3209\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8864 - tp: 157.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 241.0000 - accuracy: 0.7722 - precision: 0.4164 - recall: 0.3945 - auc: 0.6920 - prc: 0.3983 - val_loss: 0.5975 - val_tp: 37.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 54.0000 - val_accuracy: 0.7549 - val_precision: 0.3458 - val_recall: 0.4066 - val_auc: 0.6671 - val_prc: 0.3197\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8850 - tp: 157.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 241.0000 - accuracy: 0.7712 - precision: 0.4142 - recall: 0.3945 - auc: 0.6941 - prc: 0.3998 - val_loss: 0.5821 - val_tp: 30.0000 - val_fp: 52.0000 - val_tn: 363.0000 - val_fn: 61.0000 - val_accuracy: 0.7767 - val_precision: 0.3659 - val_recall: 0.3297 - val_auc: 0.6675 - val_prc: 0.3225\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8846 - tp: 124.0000 - fp: 149.0000 - tn: 1477.0000 - fn: 274.0000 - accuracy: 0.7910 - precision: 0.4542 - recall: 0.3116 - auc: 0.6923 - prc: 0.3982 - val_loss: 0.5747 - val_tp: 29.0000 - val_fp: 42.0000 - val_tn: 373.0000 - val_fn: 62.0000 - val_accuracy: 0.7945 - val_precision: 0.4085 - val_recall: 0.3187 - val_auc: 0.6672 - val_prc: 0.3233\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8832 - tp: 163.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 235.0000 - accuracy: 0.7638 - precision: 0.4015 - recall: 0.4095 - auc: 0.6926 - prc: 0.3948 - val_loss: 0.6023 - val_tp: 40.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 51.0000 - val_accuracy: 0.7253 - val_precision: 0.3125 - val_recall: 0.4396 - val_auc: 0.6682 - val_prc: 0.3197\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8813 - tp: 182.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 216.0000 - accuracy: 0.7569 - precision: 0.3974 - recall: 0.4573 - auc: 0.6966 - prc: 0.4033 - val_loss: 0.5870 - val_tp: 33.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 58.0000 - val_accuracy: 0.7589 - val_precision: 0.3402 - val_recall: 0.3626 - val_auc: 0.6699 - val_prc: 0.3250\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8793 - tp: 154.0000 - fp: 206.0000 - tn: 1420.0000 - fn: 244.0000 - accuracy: 0.7777 - precision: 0.4278 - recall: 0.3869 - auc: 0.6963 - prc: 0.4030 - val_loss: 0.5717 - val_tp: 29.0000 - val_fp: 47.0000 - val_tn: 368.0000 - val_fn: 62.0000 - val_accuracy: 0.7846 - val_precision: 0.3816 - val_recall: 0.3187 - val_auc: 0.6705 - val_prc: 0.3296\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8773 - tp: 151.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 247.0000 - accuracy: 0.7727 - precision: 0.4148 - recall: 0.3794 - auc: 0.6982 - prc: 0.4059 - val_loss: 0.5825 - val_tp: 34.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 57.0000 - val_accuracy: 0.7648 - val_precision: 0.3542 - val_recall: 0.3736 - val_auc: 0.6711 - val_prc: 0.3270\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8757 - tp: 170.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 228.0000 - accuracy: 0.7688 - precision: 0.4146 - recall: 0.4271 - auc: 0.6989 - prc: 0.4063 - val_loss: 0.5798 - val_tp: 33.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 58.0000 - val_accuracy: 0.7628 - val_precision: 0.3474 - val_recall: 0.3626 - val_auc: 0.6715 - val_prc: 0.3256\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8744 - tp: 152.0000 - fp: 212.0000 - tn: 1414.0000 - fn: 246.0000 - accuracy: 0.7737 - precision: 0.4176 - recall: 0.3819 - auc: 0.6985 - prc: 0.4072 - val_loss: 0.5755 - val_tp: 31.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 60.0000 - val_accuracy: 0.7668 - val_precision: 0.3483 - val_recall: 0.3407 - val_auc: 0.6724 - val_prc: 0.3329\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8748 - tp: 183.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 215.0000 - accuracy: 0.7505 - precision: 0.3869 - recall: 0.4598 - auc: 0.6967 - prc: 0.4050 - val_loss: 0.5923 - val_tp: 43.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 48.0000 - val_accuracy: 0.7352 - val_precision: 0.3333 - val_recall: 0.4725 - val_auc: 0.6733 - val_prc: 0.3368\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8716 - tp: 181.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 217.0000 - accuracy: 0.7604 - precision: 0.4031 - recall: 0.4548 - auc: 0.7008 - prc: 0.4136 - val_loss: 0.5715 - val_tp: 31.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 60.0000 - val_accuracy: 0.7628 - val_precision: 0.3407 - val_recall: 0.3407 - val_auc: 0.6734 - val_prc: 0.3413\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8708 - tp: 149.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 249.0000 - accuracy: 0.7712 - precision: 0.4105 - recall: 0.3744 - auc: 0.7001 - prc: 0.4111 - val_loss: 0.5707 - val_tp: 31.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 60.0000 - val_accuracy: 0.7648 - val_precision: 0.3444 - val_recall: 0.3407 - val_auc: 0.6740 - val_prc: 0.3384\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8700 - tp: 185.0000 - fp: 290.0000 - tn: 1336.0000 - fn: 213.0000 - accuracy: 0.7515 - precision: 0.3895 - recall: 0.4648 - auc: 0.7003 - prc: 0.4097 - val_loss: 0.5893 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6751 - val_prc: 0.3382\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8690 - tp: 172.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 226.0000 - accuracy: 0.7698 - precision: 0.4175 - recall: 0.4322 - auc: 0.6994 - prc: 0.4073 - val_loss: 0.5580 - val_tp: 31.0000 - val_fp: 50.0000 - val_tn: 365.0000 - val_fn: 60.0000 - val_accuracy: 0.7826 - val_precision: 0.3827 - val_recall: 0.3407 - val_auc: 0.6742 - val_prc: 0.3414\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8682 - tp: 142.0000 - fp: 171.0000 - tn: 1455.0000 - fn: 256.0000 - accuracy: 0.7890 - precision: 0.4537 - recall: 0.3568 - auc: 0.7016 - prc: 0.4146 - val_loss: 0.5635 - val_tp: 31.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 60.0000 - val_accuracy: 0.7648 - val_precision: 0.3444 - val_recall: 0.3407 - val_auc: 0.6753 - val_prc: 0.3419\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8654 - tp: 185.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 213.0000 - accuracy: 0.7510 - precision: 0.3887 - recall: 0.4648 - auc: 0.7029 - prc: 0.4151 - val_loss: 0.5926 - val_tp: 45.0000 - val_fp: 94.0000 - val_tn: 321.0000 - val_fn: 46.0000 - val_accuracy: 0.7233 - val_precision: 0.3237 - val_recall: 0.4945 - val_auc: 0.6764 - val_prc: 0.3399\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8650 - tp: 188.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 210.0000 - accuracy: 0.7490 - precision: 0.3868 - recall: 0.4724 - auc: 0.7023 - prc: 0.4151 - val_loss: 0.5653 - val_tp: 33.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 58.0000 - val_accuracy: 0.7589 - val_precision: 0.3402 - val_recall: 0.3626 - val_auc: 0.6762 - val_prc: 0.3419\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8640 - tp: 163.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 235.0000 - accuracy: 0.7722 - precision: 0.4190 - recall: 0.4095 - auc: 0.7028 - prc: 0.4146 - val_loss: 0.5638 - val_tp: 34.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 57.0000 - val_accuracy: 0.7628 - val_precision: 0.3505 - val_recall: 0.3736 - val_auc: 0.6770 - val_prc: 0.3450\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8629 - tp: 180.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 218.0000 - accuracy: 0.7599 - precision: 0.4018 - recall: 0.4523 - auc: 0.7026 - prc: 0.4150 - val_loss: 0.5699 - val_tp: 39.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 52.0000 - val_accuracy: 0.7609 - val_precision: 0.3611 - val_recall: 0.4286 - val_auc: 0.6778 - val_prc: 0.3455\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8617 - tp: 172.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 226.0000 - accuracy: 0.7663 - precision: 0.4105 - recall: 0.4322 - auc: 0.7027 - prc: 0.4166 - val_loss: 0.5626 - val_tp: 35.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 56.0000 - val_accuracy: 0.7628 - val_precision: 0.3535 - val_recall: 0.3846 - val_auc: 0.6772 - val_prc: 0.3500\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8606 - tp: 180.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 218.0000 - accuracy: 0.7589 - precision: 0.4000 - recall: 0.4523 - auc: 0.7034 - prc: 0.4178 - val_loss: 0.5669 - val_tp: 39.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 52.0000 - val_accuracy: 0.7609 - val_precision: 0.3611 - val_recall: 0.4286 - val_auc: 0.6777 - val_prc: 0.3508\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8600 - tp: 171.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 227.0000 - accuracy: 0.7688 - precision: 0.4150 - recall: 0.4296 - auc: 0.7037 - prc: 0.4191 - val_loss: 0.5557 - val_tp: 34.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 57.0000 - val_accuracy: 0.7648 - val_precision: 0.3542 - val_recall: 0.3736 - val_auc: 0.6793 - val_prc: 0.3593\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8587 - tp: 166.0000 - fp: 232.0000 - tn: 1394.0000 - fn: 232.0000 - accuracy: 0.7708 - precision: 0.4171 - recall: 0.4171 - auc: 0.7045 - prc: 0.4221 - val_loss: 0.5581 - val_tp: 35.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 56.0000 - val_accuracy: 0.7648 - val_precision: 0.3571 - val_recall: 0.3846 - val_auc: 0.6785 - val_prc: 0.3583\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8584 - tp: 164.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 234.0000 - accuracy: 0.7747 - precision: 0.4249 - recall: 0.4121 - auc: 0.7034 - prc: 0.4212 - val_loss: 0.5603 - val_tp: 38.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 53.0000 - val_accuracy: 0.7589 - val_precision: 0.3551 - val_recall: 0.4176 - val_auc: 0.6794 - val_prc: 0.3587\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8565 - tp: 197.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 201.0000 - accuracy: 0.7446 - precision: 0.3840 - recall: 0.4950 - auc: 0.7056 - prc: 0.4229 - val_loss: 0.5816 - val_tp: 45.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 46.0000 - val_accuracy: 0.7312 - val_precision: 0.3333 - val_recall: 0.4945 - val_auc: 0.6787 - val_prc: 0.3462\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8569 - tp: 179.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 219.0000 - accuracy: 0.7520 - precision: 0.3874 - recall: 0.4497 - auc: 0.7041 - prc: 0.4179 - val_loss: 0.5448 - val_tp: 33.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 58.0000 - val_accuracy: 0.7708 - val_precision: 0.3626 - val_recall: 0.3626 - val_auc: 0.6795 - val_prc: 0.3563\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8559 - tp: 160.0000 - fp: 214.0000 - tn: 1412.0000 - fn: 238.0000 - accuracy: 0.7767 - precision: 0.4278 - recall: 0.4020 - auc: 0.7058 - prc: 0.4248 - val_loss: 0.5507 - val_tp: 35.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 56.0000 - val_accuracy: 0.7727 - val_precision: 0.3723 - val_recall: 0.3846 - val_auc: 0.6800 - val_prc: 0.3593\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8543 - tp: 178.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 220.0000 - accuracy: 0.7564 - precision: 0.3947 - recall: 0.4472 - auc: 0.7051 - prc: 0.4254 - val_loss: 0.5655 - val_tp: 41.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 50.0000 - val_accuracy: 0.7549 - val_precision: 0.3565 - val_recall: 0.4505 - val_auc: 0.6793 - val_prc: 0.3584\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8563 - tp: 172.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 226.0000 - accuracy: 0.7663 - precision: 0.4105 - recall: 0.4322 - auc: 0.7032 - prc: 0.4201 - val_loss: 0.5422 - val_tp: 35.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 56.0000 - val_accuracy: 0.7767 - val_precision: 0.3804 - val_recall: 0.3846 - val_auc: 0.6804 - val_prc: 0.3666\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8536 - tp: 170.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 228.0000 - accuracy: 0.7648 - precision: 0.4067 - recall: 0.4271 - auc: 0.7052 - prc: 0.4286 - val_loss: 0.5607 - val_tp: 40.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 51.0000 - val_accuracy: 0.7530 - val_precision: 0.3509 - val_recall: 0.4396 - val_auc: 0.6801 - val_prc: 0.3578\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8535 - tp: 166.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 232.0000 - accuracy: 0.7653 - precision: 0.4059 - recall: 0.4171 - auc: 0.7049 - prc: 0.4275 - val_loss: 0.5418 - val_tp: 35.0000 - val_fp: 57.0000 - val_tn: 358.0000 - val_fn: 56.0000 - val_accuracy: 0.7767 - val_precision: 0.3804 - val_recall: 0.3846 - val_auc: 0.6812 - val_prc: 0.3717\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8525 - tp: 173.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 225.0000 - accuracy: 0.7604 - precision: 0.3995 - recall: 0.4347 - auc: 0.7047 - prc: 0.4307 - val_loss: 0.5598 - val_tp: 40.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 51.0000 - val_accuracy: 0.7530 - val_precision: 0.3509 - val_recall: 0.4396 - val_auc: 0.6808 - val_prc: 0.3661\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8514 - tp: 173.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 225.0000 - accuracy: 0.7594 - precision: 0.3977 - recall: 0.4347 - auc: 0.7058 - prc: 0.4298 - val_loss: 0.5475 - val_tp: 36.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 55.0000 - val_accuracy: 0.7628 - val_precision: 0.3564 - val_recall: 0.3956 - val_auc: 0.6805 - val_prc: 0.3614\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8505 - tp: 175.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 223.0000 - accuracy: 0.7619 - precision: 0.4032 - recall: 0.4397 - auc: 0.7066 - prc: 0.4320 - val_loss: 0.5560 - val_tp: 40.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 51.0000 - val_accuracy: 0.7530 - val_precision: 0.3509 - val_recall: 0.4396 - val_auc: 0.6816 - val_prc: 0.3677\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8512 - tp: 201.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 197.0000 - accuracy: 0.7367 - precision: 0.3743 - recall: 0.5050 - auc: 0.7061 - prc: 0.4301 - val_loss: 0.5686 - val_tp: 44.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 47.0000 - val_accuracy: 0.7352 - val_precision: 0.3359 - val_recall: 0.4835 - val_auc: 0.6809 - val_prc: 0.3689\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8496 - tp: 196.0000 - fp: 315.0000 - tn: 1311.0000 - fn: 202.0000 - accuracy: 0.7446 - precision: 0.3836 - recall: 0.4925 - auc: 0.7068 - prc: 0.4336 - val_loss: 0.5481 - val_tp: 38.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 53.0000 - val_accuracy: 0.7589 - val_precision: 0.3551 - val_recall: 0.4176 - val_auc: 0.6819 - val_prc: 0.3765\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8499 - tp: 166.0000 - fp: 238.0000 - tn: 1388.0000 - fn: 232.0000 - accuracy: 0.7678 - precision: 0.4109 - recall: 0.4171 - auc: 0.7075 - prc: 0.4340 - val_loss: 0.5418 - val_tp: 36.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 55.0000 - val_accuracy: 0.7688 - val_precision: 0.3673 - val_recall: 0.3956 - val_auc: 0.6824 - val_prc: 0.3695\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8495 - tp: 179.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 219.0000 - accuracy: 0.7589 - precision: 0.3996 - recall: 0.4497 - auc: 0.7068 - prc: 0.4318 - val_loss: 0.5572 - val_tp: 41.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 50.0000 - val_accuracy: 0.7530 - val_precision: 0.3534 - val_recall: 0.4505 - val_auc: 0.6814 - val_prc: 0.3703\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8480 - tp: 184.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 214.0000 - accuracy: 0.7530 - precision: 0.3915 - recall: 0.4623 - auc: 0.7080 - prc: 0.4352 - val_loss: 0.5507 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6828 - val_prc: 0.3737\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8480 - tp: 175.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 223.0000 - accuracy: 0.7604 - precision: 0.4005 - recall: 0.4397 - auc: 0.7073 - prc: 0.4364 - val_loss: 0.5466 - val_tp: 40.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 51.0000 - val_accuracy: 0.7648 - val_precision: 0.3704 - val_recall: 0.4396 - val_auc: 0.6826 - val_prc: 0.3766\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8478 - tp: 172.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 226.0000 - accuracy: 0.7663 - precision: 0.4105 - recall: 0.4322 - auc: 0.7079 - prc: 0.4368 - val_loss: 0.5428 - val_tp: 38.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 53.0000 - val_accuracy: 0.7628 - val_precision: 0.3619 - val_recall: 0.4176 - val_auc: 0.6824 - val_prc: 0.3769\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8470 - tp: 174.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 224.0000 - accuracy: 0.7614 - precision: 0.4018 - recall: 0.4372 - auc: 0.7081 - prc: 0.4378 - val_loss: 0.5531 - val_tp: 41.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 50.0000 - val_accuracy: 0.7530 - val_precision: 0.3534 - val_recall: 0.4505 - val_auc: 0.6832 - val_prc: 0.3784\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8464 - tp: 185.0000 - fp: 284.0000 - tn: 1342.0000 - fn: 213.0000 - accuracy: 0.7544 - precision: 0.3945 - recall: 0.4648 - auc: 0.7082 - prc: 0.4387 - val_loss: 0.5561 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6825 - val_prc: 0.3780\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8469 - tp: 182.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 216.0000 - accuracy: 0.7614 - precision: 0.4053 - recall: 0.4573 - auc: 0.7069 - prc: 0.4385 - val_loss: 0.5458 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6823 - val_prc: 0.3853\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8468 - tp: 194.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 204.0000 - accuracy: 0.7460 - precision: 0.3849 - recall: 0.4874 - auc: 0.7073 - prc: 0.4373 - val_loss: 0.5535 - val_tp: 42.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 49.0000 - val_accuracy: 0.7569 - val_precision: 0.3621 - val_recall: 0.4615 - val_auc: 0.6826 - val_prc: 0.3839\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8462 - tp: 169.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 229.0000 - accuracy: 0.7673 - precision: 0.4112 - recall: 0.4246 - auc: 0.7073 - prc: 0.4424 - val_loss: 0.5287 - val_tp: 34.0000 - val_fp: 55.0000 - val_tn: 360.0000 - val_fn: 57.0000 - val_accuracy: 0.7787 - val_precision: 0.3820 - val_recall: 0.3736 - val_auc: 0.6829 - val_prc: 0.3916\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8472 - tp: 170.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 228.0000 - accuracy: 0.7688 - precision: 0.4146 - recall: 0.4271 - auc: 0.7064 - prc: 0.4404 - val_loss: 0.5507 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6823 - val_prc: 0.3886\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8451 - tp: 196.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 202.0000 - accuracy: 0.7525 - precision: 0.3960 - recall: 0.4925 - auc: 0.7086 - prc: 0.4420 - val_loss: 0.5502 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6818 - val_prc: 0.3911\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8449 - tp: 180.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 218.0000 - accuracy: 0.7594 - precision: 0.4009 - recall: 0.4523 - auc: 0.7083 - prc: 0.4435 - val_loss: 0.5458 - val_tp: 40.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 51.0000 - val_accuracy: 0.7628 - val_precision: 0.3670 - val_recall: 0.4396 - val_auc: 0.6816 - val_prc: 0.3889\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8445 - tp: 179.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 219.0000 - accuracy: 0.7594 - precision: 0.4004 - recall: 0.4497 - auc: 0.7090 - prc: 0.4425 - val_loss: 0.5500 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6827 - val_prc: 0.3837\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8441 - tp: 188.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 210.0000 - accuracy: 0.7589 - precision: 0.4034 - recall: 0.4724 - auc: 0.7091 - prc: 0.4413 - val_loss: 0.5520 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6830 - val_prc: 0.3834\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8437 - tp: 187.0000 - fp: 274.0000 - tn: 1352.0000 - fn: 211.0000 - accuracy: 0.7604 - precision: 0.4056 - recall: 0.4698 - auc: 0.7090 - prc: 0.4442 - val_loss: 0.5443 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6831 - val_prc: 0.3895\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8435 - tp: 181.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 217.0000 - accuracy: 0.7579 - precision: 0.3987 - recall: 0.4548 - auc: 0.7092 - prc: 0.4444 - val_loss: 0.5462 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6829 - val_prc: 0.3901\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8429 - tp: 182.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 216.0000 - accuracy: 0.7584 - precision: 0.4000 - recall: 0.4573 - auc: 0.7094 - prc: 0.4439 - val_loss: 0.5434 - val_tp: 41.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 50.0000 - val_accuracy: 0.7628 - val_precision: 0.3694 - val_recall: 0.4505 - val_auc: 0.6833 - val_prc: 0.3870\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8428 - tp: 177.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 221.0000 - accuracy: 0.7624 - precision: 0.4050 - recall: 0.4447 - auc: 0.7099 - prc: 0.4435 - val_loss: 0.5443 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6825 - val_prc: 0.3838\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8426 - tp: 181.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 217.0000 - accuracy: 0.7633 - precision: 0.4086 - recall: 0.4548 - auc: 0.7099 - prc: 0.4430 - val_loss: 0.5577 - val_tp: 44.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 47.0000 - val_accuracy: 0.7490 - val_precision: 0.3548 - val_recall: 0.4835 - val_auc: 0.6822 - val_prc: 0.3864\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8464 - tp: 216.0000 - fp: 392.0000 - tn: 1234.0000 - fn: 182.0000 - accuracy: 0.7164 - precision: 0.3553 - recall: 0.5427 - auc: 0.7100 - prc: 0.4426 - val_loss: 0.5710 - val_tp: 45.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 46.0000 - val_accuracy: 0.7253 - val_precision: 0.3261 - val_recall: 0.4945 - val_auc: 0.6830 - val_prc: 0.3880\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8434 - tp: 181.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 217.0000 - accuracy: 0.7614 - precision: 0.4049 - recall: 0.4548 - auc: 0.7086 - prc: 0.4448 - val_loss: 0.5195 - val_tp: 34.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 57.0000 - val_accuracy: 0.7866 - val_precision: 0.4000 - val_recall: 0.3736 - val_auc: 0.6838 - val_prc: 0.3933\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8432 - tp: 172.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 226.0000 - accuracy: 0.7792 - precision: 0.4377 - recall: 0.4322 - auc: 0.7112 - prc: 0.4486 - val_loss: 0.5497 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6829 - val_prc: 0.3920\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8424 - tp: 205.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 193.0000 - accuracy: 0.7367 - precision: 0.3761 - recall: 0.5151 - auc: 0.7106 - prc: 0.4461 - val_loss: 0.5609 - val_tp: 44.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 47.0000 - val_accuracy: 0.7411 - val_precision: 0.3438 - val_recall: 0.4835 - val_auc: 0.6826 - val_prc: 0.3923\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8446 - tp: 180.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 218.0000 - accuracy: 0.7628 - precision: 0.4072 - recall: 0.4523 - auc: 0.7075 - prc: 0.4403 - val_loss: 0.5348 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6823 - val_prc: 0.3924\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8413 - tp: 195.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 203.0000 - accuracy: 0.7490 - precision: 0.3900 - recall: 0.4899 - auc: 0.7109 - prc: 0.4464 - val_loss: 0.5578 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6834 - val_prc: 0.3968\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8433 - tp: 179.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 219.0000 - accuracy: 0.7633 - precision: 0.4077 - recall: 0.4497 - auc: 0.7086 - prc: 0.4459 - val_loss: 0.5278 - val_tp: 37.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 54.0000 - val_accuracy: 0.7747 - val_precision: 0.3814 - val_recall: 0.4066 - val_auc: 0.6841 - val_prc: 0.4034\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8410 - tp: 176.0000 - fp: 244.0000 - tn: 1382.0000 - fn: 222.0000 - accuracy: 0.7698 - precision: 0.4190 - recall: 0.4422 - auc: 0.7115 - prc: 0.4511 - val_loss: 0.5449 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6848 - val_prc: 0.3967\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8405 - tp: 187.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 211.0000 - accuracy: 0.7559 - precision: 0.3979 - recall: 0.4698 - auc: 0.7112 - prc: 0.4493 - val_loss: 0.5410 - val_tp: 42.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 49.0000 - val_accuracy: 0.7727 - val_precision: 0.3889 - val_recall: 0.4615 - val_auc: 0.6841 - val_prc: 0.3926\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8412 - tp: 173.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 225.0000 - accuracy: 0.7688 - precision: 0.4159 - recall: 0.4347 - auc: 0.7119 - prc: 0.4478 - val_loss: 0.5352 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6826 - val_prc: 0.3884\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8422 - tp: 193.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 205.0000 - accuracy: 0.7505 - precision: 0.3915 - recall: 0.4849 - auc: 0.7095 - prc: 0.4448 - val_loss: 0.5671 - val_tp: 44.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 47.0000 - val_accuracy: 0.7312 - val_precision: 0.3308 - val_recall: 0.4835 - val_auc: 0.6821 - val_prc: 0.3856\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8406 - tp: 191.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 207.0000 - accuracy: 0.7480 - precision: 0.3866 - recall: 0.4799 - auc: 0.7107 - prc: 0.4458 - val_loss: 0.5412 - val_tp: 42.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 49.0000 - val_accuracy: 0.7708 - val_precision: 0.3853 - val_recall: 0.4615 - val_auc: 0.6825 - val_prc: 0.3894\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8394 - tp: 195.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 203.0000 - accuracy: 0.7589 - precision: 0.4062 - recall: 0.4899 - auc: 0.7125 - prc: 0.4495 - val_loss: 0.5577 - val_tp: 44.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 47.0000 - val_accuracy: 0.7431 - val_precision: 0.3465 - val_recall: 0.4835 - val_auc: 0.6833 - val_prc: 0.3934\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8400 - tp: 195.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 203.0000 - accuracy: 0.7544 - precision: 0.3988 - recall: 0.4899 - auc: 0.7119 - prc: 0.4508 - val_loss: 0.5490 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6840 - val_prc: 0.3987\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8404 - tp: 208.0000 - fp: 336.0000 - tn: 1290.0000 - fn: 190.0000 - accuracy: 0.7401 - precision: 0.3824 - recall: 0.5226 - auc: 0.7118 - prc: 0.4512 - val_loss: 0.5554 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6840 - val_prc: 0.3990\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8398 - tp: 182.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 216.0000 - accuracy: 0.7609 - precision: 0.4044 - recall: 0.4573 - auc: 0.7118 - prc: 0.4518 - val_loss: 0.5309 - val_tp: 38.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 53.0000 - val_accuracy: 0.7688 - val_precision: 0.3725 - val_recall: 0.4176 - val_auc: 0.6848 - val_prc: 0.4038\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8390 - tp: 176.0000 - fp: 251.0000 - tn: 1375.0000 - fn: 222.0000 - accuracy: 0.7663 - precision: 0.4122 - recall: 0.4422 - auc: 0.7127 - prc: 0.4538 - val_loss: 0.5503 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6822 - val_prc: 0.3958\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8390 - tp: 211.0000 - fp: 333.0000 - tn: 1293.0000 - fn: 187.0000 - accuracy: 0.7431 - precision: 0.3879 - recall: 0.5302 - auc: 0.7135 - prc: 0.4533 - val_loss: 0.5696 - val_tp: 46.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 45.0000 - val_accuracy: 0.7213 - val_precision: 0.3239 - val_recall: 0.5055 - val_auc: 0.6829 - val_prc: 0.3956\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8400 - tp: 209.0000 - fp: 337.0000 - tn: 1289.0000 - fn: 189.0000 - accuracy: 0.7401 - precision: 0.3828 - recall: 0.5251 - auc: 0.7125 - prc: 0.4515 - val_loss: 0.5551 - val_tp: 43.0000 - val_fp: 81.0000 - val_tn: 334.0000 - val_fn: 48.0000 - val_accuracy: 0.7451 - val_precision: 0.3468 - val_recall: 0.4725 - val_auc: 0.6842 - val_prc: 0.3965\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8395 - tp: 208.0000 - fp: 326.0000 - tn: 1300.0000 - fn: 190.0000 - accuracy: 0.7451 - precision: 0.3895 - recall: 0.5226 - auc: 0.7123 - prc: 0.4536 - val_loss: 0.5510 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6844 - val_prc: 0.3989\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8382 - tp: 187.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 211.0000 - accuracy: 0.7594 - precision: 0.4039 - recall: 0.4698 - auc: 0.7127 - prc: 0.4558 - val_loss: 0.5399 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6842 - val_prc: 0.4050\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8389 - tp: 201.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 197.0000 - accuracy: 0.7574 - precision: 0.4061 - recall: 0.5050 - auc: 0.7123 - prc: 0.4535 - val_loss: 0.5489 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6847 - val_prc: 0.4036\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8374 - tp: 183.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 215.0000 - accuracy: 0.7653 - precision: 0.4131 - recall: 0.4598 - auc: 0.7137 - prc: 0.4556 - val_loss: 0.5289 - val_tp: 38.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 53.0000 - val_accuracy: 0.7787 - val_precision: 0.3918 - val_recall: 0.4176 - val_auc: 0.6847 - val_prc: 0.4046\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8384 - tp: 177.0000 - fp: 248.0000 - tn: 1378.0000 - fn: 221.0000 - accuracy: 0.7683 - precision: 0.4165 - recall: 0.4447 - auc: 0.7129 - prc: 0.4571 - val_loss: 0.5426 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6849 - val_prc: 0.4078\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8375 - tp: 192.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 206.0000 - accuracy: 0.7554 - precision: 0.3992 - recall: 0.4824 - auc: 0.7130 - prc: 0.4575 - val_loss: 0.5481 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6840 - val_prc: 0.4098\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8373 - tp: 193.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 205.0000 - accuracy: 0.7544 - precision: 0.3979 - recall: 0.4849 - auc: 0.7128 - prc: 0.4581 - val_loss: 0.5490 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6848 - val_prc: 0.4101\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8376 - tp: 202.0000 - fp: 299.0000 - tn: 1327.0000 - fn: 196.0000 - accuracy: 0.7554 - precision: 0.4032 - recall: 0.5075 - auc: 0.7135 - prc: 0.4577 - val_loss: 0.5461 - val_tp: 42.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 49.0000 - val_accuracy: 0.7589 - val_precision: 0.3652 - val_recall: 0.4615 - val_auc: 0.6845 - val_prc: 0.4123\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8374 - tp: 181.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 217.0000 - accuracy: 0.7673 - precision: 0.4161 - recall: 0.4548 - auc: 0.7132 - prc: 0.4604 - val_loss: 0.5288 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6867 - val_prc: 0.4146\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8379 - tp: 174.0000 - fp: 235.0000 - tn: 1391.0000 - fn: 224.0000 - accuracy: 0.7732 - precision: 0.4254 - recall: 0.4372 - auc: 0.7135 - prc: 0.4607 - val_loss: 0.5296 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6863 - val_prc: 0.4150\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8406 - tp: 169.0000 - fp: 215.0000 - tn: 1411.0000 - fn: 229.0000 - accuracy: 0.7806 - precision: 0.4401 - recall: 0.4246 - auc: 0.7120 - prc: 0.4597 - val_loss: 0.5377 - val_tp: 41.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 50.0000 - val_accuracy: 0.7688 - val_precision: 0.3796 - val_recall: 0.4505 - val_auc: 0.6850 - val_prc: 0.4147\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8374 - tp: 206.0000 - fp: 330.0000 - tn: 1296.0000 - fn: 192.0000 - accuracy: 0.7421 - precision: 0.3843 - recall: 0.5176 - auc: 0.7141 - prc: 0.4596 - val_loss: 0.5630 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6846 - val_prc: 0.4088\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8369 - tp: 195.0000 - fp: 287.0000 - tn: 1339.0000 - fn: 203.0000 - accuracy: 0.7579 - precision: 0.4046 - recall: 0.4899 - auc: 0.7138 - prc: 0.4588 - val_loss: 0.5320 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6858 - val_prc: 0.4126\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8375 - tp: 175.0000 - fp: 234.0000 - tn: 1392.0000 - fn: 223.0000 - accuracy: 0.7742 - precision: 0.4279 - recall: 0.4397 - auc: 0.7143 - prc: 0.4626 - val_loss: 0.5285 - val_tp: 38.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 53.0000 - val_accuracy: 0.7708 - val_precision: 0.3762 - val_recall: 0.4176 - val_auc: 0.6863 - val_prc: 0.4128\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8368 - tp: 179.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 219.0000 - accuracy: 0.7673 - precision: 0.4153 - recall: 0.4497 - auc: 0.7140 - prc: 0.4622 - val_loss: 0.5410 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6843 - val_prc: 0.4110\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8361 - tp: 191.0000 - fp: 273.0000 - tn: 1353.0000 - fn: 207.0000 - accuracy: 0.7628 - precision: 0.4116 - recall: 0.4799 - auc: 0.7140 - prc: 0.4602 - val_loss: 0.5405 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6849 - val_prc: 0.4110\n",
      "Epoch 134/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8361 - tp: 181.0000 - fp: 257.0000 - tn: 1369.0000 - fn: 217.0000 - accuracy: 0.7658 - precision: 0.4132 - recall: 0.4548 - auc: 0.7143 - prc: 0.4631 - val_loss: 0.5298 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6868 - val_prc: 0.4146\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8364 - tp: 181.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 217.0000 - accuracy: 0.7727 - precision: 0.4269 - recall: 0.4548 - auc: 0.7150 - prc: 0.4635 - val_loss: 0.5426 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6852 - val_prc: 0.4137\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8357 - tp: 205.0000 - fp: 307.0000 - tn: 1319.0000 - fn: 193.0000 - accuracy: 0.7530 - precision: 0.4004 - recall: 0.5151 - auc: 0.7151 - prc: 0.4609 - val_loss: 0.5534 - val_tp: 43.0000 - val_fp: 80.0000 - val_tn: 335.0000 - val_fn: 48.0000 - val_accuracy: 0.7470 - val_precision: 0.3496 - val_recall: 0.4725 - val_auc: 0.6828 - val_prc: 0.4045\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8373 - tp: 179.0000 - fp: 244.0000 - tn: 1382.0000 - fn: 219.0000 - accuracy: 0.7712 - precision: 0.4232 - recall: 0.4497 - auc: 0.7128 - prc: 0.4631 - val_loss: 0.5236 - val_tp: 38.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 53.0000 - val_accuracy: 0.7846 - val_precision: 0.4043 - val_recall: 0.4176 - val_auc: 0.6856 - val_prc: 0.4118\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8351 - tp: 187.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 211.0000 - accuracy: 0.7693 - precision: 0.4221 - recall: 0.4698 - auc: 0.7151 - prc: 0.4657 - val_loss: 0.5572 - val_tp: 45.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 46.0000 - val_accuracy: 0.7372 - val_precision: 0.3409 - val_recall: 0.4945 - val_auc: 0.6850 - val_prc: 0.4160\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8368 - tp: 217.0000 - fp: 354.0000 - tn: 1272.0000 - fn: 181.0000 - accuracy: 0.7357 - precision: 0.3800 - recall: 0.5452 - auc: 0.7153 - prc: 0.4658 - val_loss: 0.5574 - val_tp: 45.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 46.0000 - val_accuracy: 0.7332 - val_precision: 0.3358 - val_recall: 0.4945 - val_auc: 0.6871 - val_prc: 0.4205\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8362 - tp: 187.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 211.0000 - accuracy: 0.7624 - precision: 0.4092 - recall: 0.4698 - auc: 0.7139 - prc: 0.4620 - val_loss: 0.5312 - val_tp: 39.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 52.0000 - val_accuracy: 0.7688 - val_precision: 0.3750 - val_recall: 0.4286 - val_auc: 0.6868 - val_prc: 0.4169\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8348 - tp: 188.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 210.0000 - accuracy: 0.7638 - precision: 0.4123 - recall: 0.4724 - auc: 0.7148 - prc: 0.4652 - val_loss: 0.5476 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6849 - val_prc: 0.4134\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8347 - tp: 194.0000 - fp: 270.0000 - tn: 1356.0000 - fn: 204.0000 - accuracy: 0.7658 - precision: 0.4181 - recall: 0.4874 - auc: 0.7154 - prc: 0.4647 - val_loss: 0.5472 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6857 - val_prc: 0.4175\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8359 - tp: 212.0000 - fp: 340.0000 - tn: 1286.0000 - fn: 186.0000 - accuracy: 0.7401 - precision: 0.3841 - recall: 0.5327 - auc: 0.7155 - prc: 0.4651 - val_loss: 0.5593 - val_tp: 46.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 45.0000 - val_accuracy: 0.7352 - val_precision: 0.3407 - val_recall: 0.5055 - val_auc: 0.6861 - val_prc: 0.4190\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8350 - tp: 193.0000 - fp: 277.0000 - tn: 1349.0000 - fn: 205.0000 - accuracy: 0.7619 - precision: 0.4106 - recall: 0.4849 - auc: 0.7150 - prc: 0.4670 - val_loss: 0.5289 - val_tp: 39.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 52.0000 - val_accuracy: 0.7708 - val_precision: 0.3786 - val_recall: 0.4286 - val_auc: 0.6881 - val_prc: 0.4245\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8352 - tp: 180.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 218.0000 - accuracy: 0.7732 - precision: 0.4276 - recall: 0.4523 - auc: 0.7161 - prc: 0.4672 - val_loss: 0.5345 - val_tp: 40.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 51.0000 - val_accuracy: 0.7648 - val_precision: 0.3704 - val_recall: 0.4396 - val_auc: 0.6874 - val_prc: 0.4212\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8344 - tp: 189.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 209.0000 - accuracy: 0.7712 - precision: 0.4266 - recall: 0.4749 - auc: 0.7161 - prc: 0.4675 - val_loss: 0.5405 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6862 - val_prc: 0.4178\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8345 - tp: 189.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 209.0000 - accuracy: 0.7712 - precision: 0.4266 - recall: 0.4749 - auc: 0.7154 - prc: 0.4657 - val_loss: 0.5405 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6862 - val_prc: 0.4183\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8344 - tp: 187.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 211.0000 - accuracy: 0.7708 - precision: 0.4250 - recall: 0.4698 - auc: 0.7158 - prc: 0.4660 - val_loss: 0.5391 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6867 - val_prc: 0.4194\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8340 - tp: 199.0000 - fp: 280.0000 - tn: 1346.0000 - fn: 199.0000 - accuracy: 0.7633 - precision: 0.4154 - recall: 0.5000 - auc: 0.7163 - prc: 0.4663 - val_loss: 0.5459 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6860 - val_prc: 0.4188\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8335 - tp: 205.0000 - fp: 300.0000 - tn: 1326.0000 - fn: 193.0000 - accuracy: 0.7564 - precision: 0.4059 - recall: 0.5151 - auc: 0.7170 - prc: 0.4668 - val_loss: 0.5459 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6857 - val_prc: 0.4158\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8351 - tp: 178.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 220.0000 - accuracy: 0.7762 - precision: 0.4331 - recall: 0.4472 - auc: 0.7149 - prc: 0.4651 - val_loss: 0.5232 - val_tp: 39.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 52.0000 - val_accuracy: 0.7826 - val_precision: 0.4021 - val_recall: 0.4286 - val_auc: 0.6872 - val_prc: 0.4205\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8356 - tp: 199.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 199.0000 - accuracy: 0.7574 - precision: 0.4053 - recall: 0.5000 - auc: 0.7140 - prc: 0.4630 - val_loss: 0.5593 - val_tp: 46.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 45.0000 - val_accuracy: 0.7431 - val_precision: 0.3511 - val_recall: 0.5055 - val_auc: 0.6843 - val_prc: 0.4136\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8331 - tp: 211.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 187.0000 - accuracy: 0.7505 - precision: 0.3989 - recall: 0.5302 - auc: 0.7177 - prc: 0.4669 - val_loss: 0.5376 - val_tp: 40.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 51.0000 - val_accuracy: 0.7609 - val_precision: 0.3636 - val_recall: 0.4396 - val_auc: 0.6865 - val_prc: 0.4195\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8345 - tp: 171.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 227.0000 - accuracy: 0.7772 - precision: 0.4329 - recall: 0.4296 - auc: 0.7172 - prc: 0.4687 - val_loss: 0.5145 - val_tp: 38.0000 - val_fp: 51.0000 - val_tn: 364.0000 - val_fn: 53.0000 - val_accuracy: 0.7945 - val_precision: 0.4270 - val_recall: 0.4176 - val_auc: 0.6880 - val_prc: 0.4226\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8349 - tp: 171.0000 - fp: 209.0000 - tn: 1417.0000 - fn: 227.0000 - accuracy: 0.7846 - precision: 0.4500 - recall: 0.4296 - auc: 0.7178 - prc: 0.4692 - val_loss: 0.5455 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6860 - val_prc: 0.4191\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8328 - tp: 209.0000 - fp: 308.0000 - tn: 1318.0000 - fn: 189.0000 - accuracy: 0.7544 - precision: 0.4043 - recall: 0.5251 - auc: 0.7183 - prc: 0.4679 - val_loss: 0.5569 - val_tp: 46.0000 - val_fp: 83.0000 - val_tn: 332.0000 - val_fn: 45.0000 - val_accuracy: 0.7470 - val_precision: 0.3566 - val_recall: 0.5055 - val_auc: 0.6841 - val_prc: 0.4148\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8330 - tp: 211.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 187.0000 - accuracy: 0.7505 - precision: 0.3989 - recall: 0.5302 - auc: 0.7180 - prc: 0.4679 - val_loss: 0.5446 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6866 - val_prc: 0.4229\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8348 - tp: 179.0000 - fp: 235.0000 - tn: 1391.0000 - fn: 219.0000 - accuracy: 0.7757 - precision: 0.4324 - recall: 0.4497 - auc: 0.7165 - prc: 0.4659 - val_loss: 0.5249 - val_tp: 39.0000 - val_fp: 59.0000 - val_tn: 356.0000 - val_fn: 52.0000 - val_accuracy: 0.7806 - val_precision: 0.3980 - val_recall: 0.4286 - val_auc: 0.6892 - val_prc: 0.4261\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8346 - tp: 201.0000 - fp: 311.0000 - tn: 1315.0000 - fn: 197.0000 - accuracy: 0.7490 - precision: 0.3926 - recall: 0.5050 - auc: 0.7159 - prc: 0.4660 - val_loss: 0.5675 - val_tp: 47.0000 - val_fp: 95.0000 - val_tn: 320.0000 - val_fn: 44.0000 - val_accuracy: 0.7253 - val_precision: 0.3310 - val_recall: 0.5165 - val_auc: 0.6852 - val_prc: 0.4208\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8341 - tp: 217.0000 - fp: 362.0000 - tn: 1264.0000 - fn: 181.0000 - accuracy: 0.7317 - precision: 0.3748 - recall: 0.5452 - auc: 0.7180 - prc: 0.4680 - val_loss: 0.5594 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6853 - val_prc: 0.4223\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8328 - tp: 212.0000 - fp: 320.0000 - tn: 1306.0000 - fn: 186.0000 - accuracy: 0.7500 - precision: 0.3985 - recall: 0.5327 - auc: 0.7183 - prc: 0.4686 - val_loss: 0.5553 - val_tp: 46.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 45.0000 - val_accuracy: 0.7451 - val_precision: 0.3538 - val_recall: 0.5055 - val_auc: 0.6853 - val_prc: 0.4228\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8347 - tp: 219.0000 - fp: 365.0000 - tn: 1261.0000 - fn: 179.0000 - accuracy: 0.7312 - precision: 0.3750 - recall: 0.5503 - auc: 0.7180 - prc: 0.4658 - val_loss: 0.5537 - val_tp: 45.0000 - val_fp: 82.0000 - val_tn: 333.0000 - val_fn: 46.0000 - val_accuracy: 0.7470 - val_precision: 0.3543 - val_recall: 0.4945 - val_auc: 0.6854 - val_prc: 0.4187\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8334 - tp: 178.0000 - fp: 240.0000 - tn: 1386.0000 - fn: 220.0000 - accuracy: 0.7727 - precision: 0.4258 - recall: 0.4472 - auc: 0.7178 - prc: 0.4672 - val_loss: 0.5232 - val_tp: 39.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 52.0000 - val_accuracy: 0.7866 - val_precision: 0.4105 - val_recall: 0.4286 - val_auc: 0.6871 - val_prc: 0.4208\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8317 - tp: 191.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 207.0000 - accuracy: 0.7693 - precision: 0.4235 - recall: 0.4799 - auc: 0.7185 - prc: 0.4698 - val_loss: 0.5599 - val_tp: 47.0000 - val_fp: 89.0000 - val_tn: 326.0000 - val_fn: 44.0000 - val_accuracy: 0.7372 - val_precision: 0.3456 - val_recall: 0.5165 - val_auc: 0.6846 - val_prc: 0.4221\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8336 - tp: 217.0000 - fp: 367.0000 - tn: 1259.0000 - fn: 181.0000 - accuracy: 0.7292 - precision: 0.3716 - recall: 0.5452 - auc: 0.7186 - prc: 0.4691 - val_loss: 0.5563 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6870 - val_prc: 0.4257\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8316 - tp: 203.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 195.0000 - accuracy: 0.7609 - precision: 0.4126 - recall: 0.5101 - auc: 0.7187 - prc: 0.4691 - val_loss: 0.5385 - val_tp: 42.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 49.0000 - val_accuracy: 0.7609 - val_precision: 0.3684 - val_recall: 0.4615 - val_auc: 0.6874 - val_prc: 0.4210\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8310 - tp: 197.0000 - fp: 263.0000 - tn: 1363.0000 - fn: 201.0000 - accuracy: 0.7708 - precision: 0.4283 - recall: 0.4950 - auc: 0.7189 - prc: 0.4694 - val_loss: 0.5446 - val_tp: 43.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 48.0000 - val_accuracy: 0.7589 - val_precision: 0.3675 - val_recall: 0.4725 - val_auc: 0.6854 - val_prc: 0.4128\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8315 - tp: 203.0000 - fp: 297.0000 - tn: 1329.0000 - fn: 195.0000 - accuracy: 0.7569 - precision: 0.4060 - recall: 0.5101 - auc: 0.7191 - prc: 0.4672 - val_loss: 0.5595 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6837 - val_prc: 0.4108\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8332 - tp: 219.0000 - fp: 371.0000 - tn: 1255.0000 - fn: 179.0000 - accuracy: 0.7283 - precision: 0.3712 - recall: 0.5503 - auc: 0.7202 - prc: 0.4678 - val_loss: 0.5645 - val_tp: 47.0000 - val_fp: 91.0000 - val_tn: 324.0000 - val_fn: 44.0000 - val_accuracy: 0.7332 - val_precision: 0.3406 - val_recall: 0.5165 - val_auc: 0.6842 - val_prc: 0.4144\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8331 - tp: 191.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 207.0000 - accuracy: 0.7712 - precision: 0.4273 - recall: 0.4799 - auc: 0.7177 - prc: 0.4618 - val_loss: 0.5235 - val_tp: 39.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 52.0000 - val_accuracy: 0.7866 - val_precision: 0.4105 - val_recall: 0.4286 - val_auc: 0.6881 - val_prc: 0.4244\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8311 - tp: 208.0000 - fp: 310.0000 - tn: 1316.0000 - fn: 190.0000 - accuracy: 0.7530 - precision: 0.4015 - recall: 0.5226 - auc: 0.7194 - prc: 0.4680 - val_loss: 0.5653 - val_tp: 47.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 44.0000 - val_accuracy: 0.7292 - val_precision: 0.3357 - val_recall: 0.5165 - val_auc: 0.6862 - val_prc: 0.4237\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8317 - tp: 211.0000 - fp: 316.0000 - tn: 1310.0000 - fn: 187.0000 - accuracy: 0.7515 - precision: 0.4004 - recall: 0.5302 - auc: 0.7186 - prc: 0.4686 - val_loss: 0.5365 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6898 - val_prc: 0.4318\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8306 - tp: 198.0000 - fp: 269.0000 - tn: 1357.0000 - fn: 200.0000 - accuracy: 0.7683 - precision: 0.4240 - recall: 0.4975 - auc: 0.7192 - prc: 0.4701 - val_loss: 0.5394 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6892 - val_prc: 0.4280\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8305 - tp: 193.0000 - fp: 252.0000 - tn: 1374.0000 - fn: 205.0000 - accuracy: 0.7742 - precision: 0.4337 - recall: 0.4849 - auc: 0.7191 - prc: 0.4708 - val_loss: 0.5375 - val_tp: 42.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 49.0000 - val_accuracy: 0.7688 - val_precision: 0.3818 - val_recall: 0.4615 - val_auc: 0.6886 - val_prc: 0.4269\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8297 - tp: 204.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 194.0000 - accuracy: 0.7643 - precision: 0.4189 - recall: 0.5126 - auc: 0.7207 - prc: 0.4702 - val_loss: 0.5549 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6868 - val_prc: 0.4253\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8310 - tp: 206.0000 - fp: 301.0000 - tn: 1325.0000 - fn: 192.0000 - accuracy: 0.7564 - precision: 0.4063 - recall: 0.5176 - auc: 0.7199 - prc: 0.4685 - val_loss: 0.5404 - val_tp: 43.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 48.0000 - val_accuracy: 0.7668 - val_precision: 0.3805 - val_recall: 0.4725 - val_auc: 0.6890 - val_prc: 0.4310\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8304 - tp: 202.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 196.0000 - accuracy: 0.7624 - precision: 0.4148 - recall: 0.5075 - auc: 0.7201 - prc: 0.4689 - val_loss: 0.5382 - val_tp: 42.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 49.0000 - val_accuracy: 0.7688 - val_precision: 0.3818 - val_recall: 0.4615 - val_auc: 0.6881 - val_prc: 0.4259\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8296 - tp: 188.0000 - fp: 238.0000 - tn: 1388.0000 - fn: 210.0000 - accuracy: 0.7787 - precision: 0.4413 - recall: 0.4724 - auc: 0.7204 - prc: 0.4729 - val_loss: 0.5190 - val_tp: 39.0000 - val_fp: 56.0000 - val_tn: 359.0000 - val_fn: 52.0000 - val_accuracy: 0.7866 - val_precision: 0.4105 - val_recall: 0.4286 - val_auc: 0.6895 - val_prc: 0.4264\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8306 - tp: 184.0000 - fp: 223.0000 - tn: 1403.0000 - fn: 214.0000 - accuracy: 0.7841 - precision: 0.4521 - recall: 0.4623 - auc: 0.7212 - prc: 0.4720 - val_loss: 0.5458 - val_tp: 43.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 48.0000 - val_accuracy: 0.7609 - val_precision: 0.3707 - val_recall: 0.4725 - val_auc: 0.6863 - val_prc: 0.4200\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8295 - tp: 206.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 192.0000 - accuracy: 0.7589 - precision: 0.4104 - recall: 0.5176 - auc: 0.7214 - prc: 0.4692 - val_loss: 0.5503 - val_tp: 43.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 48.0000 - val_accuracy: 0.7549 - val_precision: 0.3613 - val_recall: 0.4725 - val_auc: 0.6842 - val_prc: 0.4133\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8289 - tp: 201.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 197.0000 - accuracy: 0.7663 - precision: 0.4214 - recall: 0.5050 - auc: 0.7221 - prc: 0.4702 - val_loss: 0.5339 - val_tp: 41.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 50.0000 - val_accuracy: 0.7708 - val_precision: 0.3832 - val_recall: 0.4505 - val_auc: 0.6870 - val_prc: 0.4163\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8303 - tp: 182.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 216.0000 - accuracy: 0.7841 - precision: 0.4516 - recall: 0.4573 - auc: 0.7207 - prc: 0.4719 - val_loss: 0.5383 - val_tp: 42.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 49.0000 - val_accuracy: 0.7688 - val_precision: 0.3818 - val_recall: 0.4615 - val_auc: 0.6880 - val_prc: 0.4244\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8314 - tp: 221.0000 - fp: 360.0000 - tn: 1266.0000 - fn: 177.0000 - accuracy: 0.7347 - precision: 0.3804 - recall: 0.5553 - auc: 0.7222 - prc: 0.4672 - val_loss: 0.5841 - val_tp: 48.0000 - val_fp: 102.0000 - val_tn: 313.0000 - val_fn: 43.0000 - val_accuracy: 0.7134 - val_precision: 0.3200 - val_recall: 0.5275 - val_auc: 0.6844 - val_prc: 0.4137\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8319 - tp: 218.0000 - fp: 337.0000 - tn: 1289.0000 - fn: 180.0000 - accuracy: 0.7446 - precision: 0.3928 - recall: 0.5477 - auc: 0.7192 - prc: 0.4702 - val_loss: 0.5367 - val_tp: 41.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 50.0000 - val_accuracy: 0.7668 - val_precision: 0.3761 - val_recall: 0.4505 - val_auc: 0.6873 - val_prc: 0.4227\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8283 - tp: 195.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 203.0000 - accuracy: 0.7722 - precision: 0.4305 - recall: 0.4899 - auc: 0.7219 - prc: 0.4729 - val_loss: 0.5383 - val_tp: 41.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 50.0000 - val_accuracy: 0.7648 - val_precision: 0.3727 - val_recall: 0.4505 - val_auc: 0.6867 - val_prc: 0.4241\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8286 - tp: 190.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 208.0000 - accuracy: 0.7722 - precision: 0.4289 - recall: 0.4774 - auc: 0.7221 - prc: 0.4727 - val_loss: 0.5395 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6870 - val_prc: 0.4203\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8282 - tp: 197.0000 - fp: 265.0000 - tn: 1361.0000 - fn: 201.0000 - accuracy: 0.7698 - precision: 0.4264 - recall: 0.4950 - auc: 0.7219 - prc: 0.4728 - val_loss: 0.5400 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6874 - val_prc: 0.4249\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8281 - tp: 197.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 201.0000 - accuracy: 0.7693 - precision: 0.4255 - recall: 0.4950 - auc: 0.7222 - prc: 0.4729 - val_loss: 0.5361 - val_tp: 41.0000 - val_fp: 68.0000 - val_tn: 347.0000 - val_fn: 50.0000 - val_accuracy: 0.7668 - val_precision: 0.3761 - val_recall: 0.4505 - val_auc: 0.6877 - val_prc: 0.4250\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8288 - tp: 185.0000 - fp: 220.0000 - tn: 1406.0000 - fn: 213.0000 - accuracy: 0.7861 - precision: 0.4568 - recall: 0.4648 - auc: 0.7232 - prc: 0.4727 - val_loss: 0.5237 - val_tp: 41.0000 - val_fp: 58.0000 - val_tn: 357.0000 - val_fn: 50.0000 - val_accuracy: 0.7866 - val_precision: 0.4141 - val_recall: 0.4505 - val_auc: 0.6892 - val_prc: 0.4324\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8285 - tp: 191.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 207.0000 - accuracy: 0.7757 - precision: 0.4361 - recall: 0.4799 - auc: 0.7227 - prc: 0.4720 - val_loss: 0.5479 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.6867 - val_prc: 0.4324\n",
      "Epoch 191/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8279 - tp: 201.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 197.0000 - accuracy: 0.7663 - precision: 0.4214 - recall: 0.5050 - auc: 0.7233 - prc: 0.4734 - val_loss: 0.5388 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6887 - val_prc: 0.4336\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8275 - tp: 197.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 201.0000 - accuracy: 0.7727 - precision: 0.4320 - recall: 0.4950 - auc: 0.7227 - prc: 0.4745 - val_loss: 0.5404 - val_tp: 42.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 49.0000 - val_accuracy: 0.7668 - val_precision: 0.3784 - val_recall: 0.4615 - val_auc: 0.6857 - val_prc: 0.4183\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8291 - tp: 207.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 191.0000 - accuracy: 0.7643 - precision: 0.4199 - recall: 0.5201 - auc: 0.7213 - prc: 0.4711 - val_loss: 0.5450 - val_tp: 43.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 48.0000 - val_accuracy: 0.7668 - val_precision: 0.3805 - val_recall: 0.4725 - val_auc: 0.6839 - val_prc: 0.4144\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8287 - tp: 183.0000 - fp: 230.0000 - tn: 1396.0000 - fn: 215.0000 - accuracy: 0.7801 - precision: 0.4431 - recall: 0.4598 - auc: 0.7235 - prc: 0.4714 - val_loss: 0.5276 - val_tp: 41.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 50.0000 - val_accuracy: 0.7826 - val_precision: 0.4059 - val_recall: 0.4505 - val_auc: 0.6857 - val_prc: 0.4165\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8284 - tp: 199.0000 - fp: 266.0000 - tn: 1360.0000 - fn: 199.0000 - accuracy: 0.7703 - precision: 0.4280 - recall: 0.5000 - auc: 0.7226 - prc: 0.4706 - val_loss: 0.5618 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6838 - val_prc: 0.4161\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8296 - tp: 213.0000 - fp: 329.0000 - tn: 1297.0000 - fn: 185.0000 - accuracy: 0.7460 - precision: 0.3930 - recall: 0.5352 - auc: 0.7219 - prc: 0.4708 - val_loss: 0.5485 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6846 - val_prc: 0.4180\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8273 - tp: 201.0000 - fp: 272.0000 - tn: 1354.0000 - fn: 197.0000 - accuracy: 0.7683 - precision: 0.4249 - recall: 0.5050 - auc: 0.7229 - prc: 0.4736 - val_loss: 0.5448 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6850 - val_prc: 0.4181\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8278 - tp: 207.0000 - fp: 282.0000 - tn: 1344.0000 - fn: 191.0000 - accuracy: 0.7663 - precision: 0.4233 - recall: 0.5201 - auc: 0.7215 - prc: 0.4725 - val_loss: 0.5458 - val_tp: 43.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 48.0000 - val_accuracy: 0.7648 - val_precision: 0.3772 - val_recall: 0.4725 - val_auc: 0.6854 - val_prc: 0.4180\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8286 - tp: 188.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 210.0000 - accuracy: 0.7762 - precision: 0.4362 - recall: 0.4724 - auc: 0.7220 - prc: 0.4724 - val_loss: 0.5314 - val_tp: 41.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 50.0000 - val_accuracy: 0.7747 - val_precision: 0.3905 - val_recall: 0.4505 - val_auc: 0.6874 - val_prc: 0.4247\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8279 - tp: 190.0000 - fp: 233.0000 - tn: 1393.0000 - fn: 208.0000 - accuracy: 0.7821 - precision: 0.4492 - recall: 0.4774 - auc: 0.7235 - prc: 0.4726 - val_loss: 0.5367 - val_tp: 42.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 49.0000 - val_accuracy: 0.7708 - val_precision: 0.3853 - val_recall: 0.4615 - val_auc: 0.6853 - val_prc: 0.4192\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8274 - tp: 199.0000 - fp: 259.0000 - tn: 1367.0000 - fn: 199.0000 - accuracy: 0.7737 - precision: 0.4345 - recall: 0.5000 - auc: 0.7227 - prc: 0.4732 - val_loss: 0.5317 - val_tp: 41.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 50.0000 - val_accuracy: 0.7747 - val_precision: 0.3905 - val_recall: 0.4505 - val_auc: 0.6878 - val_prc: 0.4271\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8280 - tp: 186.0000 - fp: 224.0000 - tn: 1402.0000 - fn: 212.0000 - accuracy: 0.7846 - precision: 0.4537 - recall: 0.4673 - auc: 0.7239 - prc: 0.4733 - val_loss: 0.5295 - val_tp: 41.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 50.0000 - val_accuracy: 0.7787 - val_precision: 0.3981 - val_recall: 0.4505 - val_auc: 0.6893 - val_prc: 0.4336\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8284 - tp: 208.0000 - fp: 292.0000 - tn: 1334.0000 - fn: 190.0000 - accuracy: 0.7619 - precision: 0.4160 - recall: 0.5226 - auc: 0.7222 - prc: 0.4705 - val_loss: 0.5536 - val_tp: 47.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 44.0000 - val_accuracy: 0.7470 - val_precision: 0.3588 - val_recall: 0.5165 - val_auc: 0.6874 - val_prc: 0.4334\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8266 - tp: 204.0000 - fp: 291.0000 - tn: 1335.0000 - fn: 194.0000 - accuracy: 0.7604 - precision: 0.4121 - recall: 0.5126 - auc: 0.7237 - prc: 0.4732 - val_loss: 0.5320 - val_tp: 41.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 50.0000 - val_accuracy: 0.7688 - val_precision: 0.3796 - val_recall: 0.4505 - val_auc: 0.6899 - val_prc: 0.4361\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8273 - tp: 189.0000 - fp: 228.0000 - tn: 1398.0000 - fn: 209.0000 - accuracy: 0.7841 - precision: 0.4532 - recall: 0.4749 - auc: 0.7242 - prc: 0.4744 - val_loss: 0.5289 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6888 - val_prc: 0.4312\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8269 - tp: 196.0000 - fp: 249.0000 - tn: 1377.0000 - fn: 202.0000 - accuracy: 0.7772 - precision: 0.4404 - recall: 0.4925 - auc: 0.7244 - prc: 0.4726 - val_loss: 0.5477 - val_tp: 43.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 48.0000 - val_accuracy: 0.7569 - val_precision: 0.3644 - val_recall: 0.4725 - val_auc: 0.6856 - val_prc: 0.4218\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8266 - tp: 208.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 190.0000 - accuracy: 0.7599 - precision: 0.4127 - recall: 0.5226 - auc: 0.7240 - prc: 0.4735 - val_loss: 0.5401 - val_tp: 42.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 49.0000 - val_accuracy: 0.7648 - val_precision: 0.3750 - val_recall: 0.4615 - val_auc: 0.6861 - val_prc: 0.4221\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8262 - tp: 193.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 205.0000 - accuracy: 0.7787 - precision: 0.4427 - recall: 0.4849 - auc: 0.7246 - prc: 0.4736 - val_loss: 0.5288 - val_tp: 41.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 50.0000 - val_accuracy: 0.7767 - val_precision: 0.3942 - val_recall: 0.4505 - val_auc: 0.6884 - val_prc: 0.4308\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8266 - tp: 197.0000 - fp: 253.0000 - tn: 1373.0000 - fn: 201.0000 - accuracy: 0.7757 - precision: 0.4378 - recall: 0.4950 - auc: 0.7244 - prc: 0.4744 - val_loss: 0.5405 - val_tp: 43.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 48.0000 - val_accuracy: 0.7688 - val_precision: 0.3839 - val_recall: 0.4725 - val_auc: 0.6874 - val_prc: 0.4287\n",
      "Epoch 210/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8271 - tp: 207.0000 - fp: 298.0000 - tn: 1328.0000 - fn: 191.0000 - accuracy: 0.7584 - precision: 0.4099 - recall: 0.5201 - auc: 0.7242 - prc: 0.4732 - val_loss: 0.5444 - val_tp: 44.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 47.0000 - val_accuracy: 0.7609 - val_precision: 0.3729 - val_recall: 0.4835 - val_auc: 0.6881 - val_prc: 0.4307\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8266 - tp: 201.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 197.0000 - accuracy: 0.7767 - precision: 0.4408 - recall: 0.5050 - auc: 0.7246 - prc: 0.4735 - val_loss: 0.5397 - val_tp: 43.0000 - val_fp: 72.0000 - val_tn: 343.0000 - val_fn: 48.0000 - val_accuracy: 0.7628 - val_precision: 0.3739 - val_recall: 0.4725 - val_auc: 0.6891 - val_prc: 0.4370\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8296 - tp: 218.0000 - fp: 364.0000 - tn: 1262.0000 - fn: 180.0000 - accuracy: 0.7312 - precision: 0.3746 - recall: 0.5477 - auc: 0.7221 - prc: 0.4720 - val_loss: 0.5640 - val_tp: 48.0000 - val_fp: 93.0000 - val_tn: 322.0000 - val_fn: 43.0000 - val_accuracy: 0.7312 - val_precision: 0.3404 - val_recall: 0.5275 - val_auc: 0.6877 - val_prc: 0.4344\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8277 - tp: 197.0000 - fp: 264.0000 - tn: 1362.0000 - fn: 201.0000 - accuracy: 0.7703 - precision: 0.4273 - recall: 0.4950 - auc: 0.7222 - prc: 0.4725 - val_loss: 0.5151 - val_tp: 40.0000 - val_fp: 54.0000 - val_tn: 361.0000 - val_fn: 51.0000 - val_accuracy: 0.7925 - val_precision: 0.4255 - val_recall: 0.4396 - val_auc: 0.6900 - val_prc: 0.4365\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8277 - tp: 196.0000 - fp: 254.0000 - tn: 1372.0000 - fn: 202.0000 - accuracy: 0.7747 - precision: 0.4356 - recall: 0.4925 - auc: 0.7238 - prc: 0.4729 - val_loss: 0.5482 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.6877 - val_prc: 0.4333\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8257 - tp: 200.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 198.0000 - accuracy: 0.7727 - precision: 0.4329 - recall: 0.5025 - auc: 0.7251 - prc: 0.4741 - val_loss: 0.5323 - val_tp: 41.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 50.0000 - val_accuracy: 0.7688 - val_precision: 0.3796 - val_recall: 0.4505 - val_auc: 0.6881 - val_prc: 0.4307\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8261 - tp: 193.0000 - fp: 235.0000 - tn: 1391.0000 - fn: 205.0000 - accuracy: 0.7826 - precision: 0.4509 - recall: 0.4849 - auc: 0.7255 - prc: 0.4749 - val_loss: 0.5415 - val_tp: 42.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 49.0000 - val_accuracy: 0.7648 - val_precision: 0.3750 - val_recall: 0.4615 - val_auc: 0.6860 - val_prc: 0.4218\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8258 - tp: 204.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 194.0000 - accuracy: 0.7663 - precision: 0.4224 - recall: 0.5126 - auc: 0.7250 - prc: 0.4746 - val_loss: 0.5485 - val_tp: 45.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 46.0000 - val_accuracy: 0.7589 - val_precision: 0.3719 - val_recall: 0.4945 - val_auc: 0.6869 - val_prc: 0.4223\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8260 - tp: 203.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 195.0000 - accuracy: 0.7673 - precision: 0.4238 - recall: 0.5101 - auc: 0.7252 - prc: 0.4741 - val_loss: 0.5418 - val_tp: 42.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 49.0000 - val_accuracy: 0.7628 - val_precision: 0.3717 - val_recall: 0.4615 - val_auc: 0.6858 - val_prc: 0.4224\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8256 - tp: 200.0000 - fp: 255.0000 - tn: 1371.0000 - fn: 198.0000 - accuracy: 0.7762 - precision: 0.4396 - recall: 0.5025 - auc: 0.7254 - prc: 0.4748 - val_loss: 0.5317 - val_tp: 42.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 49.0000 - val_accuracy: 0.7727 - val_precision: 0.3889 - val_recall: 0.4615 - val_auc: 0.6881 - val_prc: 0.4301\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8257 - tp: 201.0000 - fp: 276.0000 - tn: 1350.0000 - fn: 197.0000 - accuracy: 0.7663 - precision: 0.4214 - recall: 0.5050 - auc: 0.7247 - prc: 0.4755 - val_loss: 0.5460 - val_tp: 45.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 46.0000 - val_accuracy: 0.7628 - val_precision: 0.3782 - val_recall: 0.4945 - val_auc: 0.6874 - val_prc: 0.4295\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8261 - tp: 200.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 198.0000 - accuracy: 0.7831 - precision: 0.4535 - recall: 0.5025 - auc: 0.7248 - prc: 0.4749 - val_loss: 0.5330 - val_tp: 42.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 49.0000 - val_accuracy: 0.7708 - val_precision: 0.3853 - val_recall: 0.4615 - val_auc: 0.6878 - val_prc: 0.4276\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - tp: 200.0000 - fp: 267.0000 - tn: 1359.0000 - fn: 198.0000 - accuracy: 0.7703 - precision: 0.4283 - recall: 0.5025 - auc: 0.7251 - prc: 0.4760 - val_loss: 0.5489 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6881 - val_prc: 0.4313\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8254 - tp: 207.0000 - fp: 294.0000 - tn: 1332.0000 - fn: 191.0000 - accuracy: 0.7604 - precision: 0.4132 - recall: 0.5201 - auc: 0.7251 - prc: 0.4750 - val_loss: 0.5492 - val_tp: 46.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 45.0000 - val_accuracy: 0.7569 - val_precision: 0.3710 - val_recall: 0.5055 - val_auc: 0.6881 - val_prc: 0.4334\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8256 - tp: 210.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 188.0000 - accuracy: 0.7564 - precision: 0.4078 - recall: 0.5276 - auc: 0.7246 - prc: 0.4757 - val_loss: 0.5480 - val_tp: 46.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 45.0000 - val_accuracy: 0.7589 - val_precision: 0.3740 - val_recall: 0.5055 - val_auc: 0.6879 - val_prc: 0.4321\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8251 - tp: 201.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 197.0000 - accuracy: 0.7742 - precision: 0.4360 - recall: 0.5050 - auc: 0.7254 - prc: 0.4760 - val_loss: 0.5307 - val_tp: 42.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 49.0000 - val_accuracy: 0.7747 - val_precision: 0.3925 - val_recall: 0.4615 - val_auc: 0.6906 - val_prc: 0.4358\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8257 - tp: 196.0000 - fp: 241.0000 - tn: 1385.0000 - fn: 202.0000 - accuracy: 0.7811 - precision: 0.4485 - recall: 0.4925 - auc: 0.7259 - prc: 0.4752 - val_loss: 0.5270 - val_tp: 41.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 50.0000 - val_accuracy: 0.7806 - val_precision: 0.4020 - val_recall: 0.4505 - val_auc: 0.6899 - val_prc: 0.4399\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8263 - tp: 188.0000 - fp: 227.0000 - tn: 1399.0000 - fn: 210.0000 - accuracy: 0.7841 - precision: 0.4530 - recall: 0.4724 - auc: 0.7260 - prc: 0.4750 - val_loss: 0.5445 - val_tp: 46.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 45.0000 - val_accuracy: 0.7648 - val_precision: 0.3833 - val_recall: 0.5055 - val_auc: 0.6885 - val_prc: 0.4342\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8325 - tp: 221.0000 - fp: 388.0000 - tn: 1238.0000 - fn: 177.0000 - accuracy: 0.7208 - precision: 0.3629 - recall: 0.5553 - auc: 0.7224 - prc: 0.4674 - val_loss: 0.5661 - val_tp: 48.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 43.0000 - val_accuracy: 0.7253 - val_precision: 0.3333 - val_recall: 0.5275 - val_auc: 0.6886 - val_prc: 0.4319\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8273 - tp: 197.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 201.0000 - accuracy: 0.7722 - precision: 0.4311 - recall: 0.4950 - auc: 0.7236 - prc: 0.4736 - val_loss: 0.5234 - val_tp: 41.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 50.0000 - val_accuracy: 0.7806 - val_precision: 0.4020 - val_recall: 0.4505 - val_auc: 0.6885 - val_prc: 0.4353\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8259 - tp: 211.0000 - fp: 295.0000 - tn: 1331.0000 - fn: 187.0000 - accuracy: 0.7619 - precision: 0.4170 - recall: 0.5302 - auc: 0.7248 - prc: 0.4742 - val_loss: 0.5653 - val_tp: 48.0000 - val_fp: 96.0000 - val_tn: 319.0000 - val_fn: 43.0000 - val_accuracy: 0.7253 - val_precision: 0.3333 - val_recall: 0.5275 - val_auc: 0.6884 - val_prc: 0.4330\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8262 - tp: 220.0000 - fp: 341.0000 - tn: 1285.0000 - fn: 178.0000 - accuracy: 0.7436 - precision: 0.3922 - recall: 0.5528 - auc: 0.7261 - prc: 0.4753 - val_loss: 0.5424 - val_tp: 46.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 45.0000 - val_accuracy: 0.7668 - val_precision: 0.3866 - val_recall: 0.5055 - val_auc: 0.6882 - val_prc: 0.4353\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8251 - tp: 198.0000 - fp: 247.0000 - tn: 1379.0000 - fn: 200.0000 - accuracy: 0.7792 - precision: 0.4449 - recall: 0.4975 - auc: 0.7252 - prc: 0.4757 - val_loss: 0.5327 - val_tp: 44.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 47.0000 - val_accuracy: 0.7787 - val_precision: 0.4037 - val_recall: 0.4835 - val_auc: 0.6897 - val_prc: 0.4345\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8273 - tp: 212.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 186.0000 - accuracy: 0.7540 - precision: 0.4046 - recall: 0.5327 - auc: 0.7237 - prc: 0.4736 - val_loss: 0.5534 - val_tp: 47.0000 - val_fp: 86.0000 - val_tn: 329.0000 - val_fn: 44.0000 - val_accuracy: 0.7431 - val_precision: 0.3534 - val_recall: 0.5165 - val_auc: 0.6887 - val_prc: 0.4334\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8250 - tp: 196.0000 - fp: 256.0000 - tn: 1370.0000 - fn: 202.0000 - accuracy: 0.7737 - precision: 0.4336 - recall: 0.4925 - auc: 0.7260 - prc: 0.4747 - val_loss: 0.5245 - val_tp: 41.0000 - val_fp: 61.0000 - val_tn: 354.0000 - val_fn: 50.0000 - val_accuracy: 0.7806 - val_precision: 0.4020 - val_recall: 0.4505 - val_auc: 0.6887 - val_prc: 0.4312\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8261 - tp: 182.0000 - fp: 213.0000 - tn: 1413.0000 - fn: 216.0000 - accuracy: 0.7880 - precision: 0.4608 - recall: 0.4573 - auc: 0.7263 - prc: 0.4759 - val_loss: 0.5354 - val_tp: 42.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 49.0000 - val_accuracy: 0.7708 - val_precision: 0.3853 - val_recall: 0.4615 - val_auc: 0.6884 - val_prc: 0.4311\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8245 - tp: 207.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 191.0000 - accuracy: 0.7643 - precision: 0.4199 - recall: 0.5201 - auc: 0.7267 - prc: 0.4745 - val_loss: 0.5552 - val_tp: 47.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 44.0000 - val_accuracy: 0.7451 - val_precision: 0.3561 - val_recall: 0.5165 - val_auc: 0.6879 - val_prc: 0.4321\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8254 - tp: 217.0000 - fp: 318.0000 - tn: 1308.0000 - fn: 181.0000 - accuracy: 0.7535 - precision: 0.4056 - recall: 0.5452 - auc: 0.7259 - prc: 0.4739 - val_loss: 0.5402 - val_tp: 44.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 47.0000 - val_accuracy: 0.7668 - val_precision: 0.3826 - val_recall: 0.4835 - val_auc: 0.6893 - val_prc: 0.4313\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8244 - tp: 199.0000 - fp: 246.0000 - tn: 1380.0000 - fn: 199.0000 - accuracy: 0.7801 - precision: 0.4472 - recall: 0.5000 - auc: 0.7270 - prc: 0.4758 - val_loss: 0.5300 - val_tp: 42.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 49.0000 - val_accuracy: 0.7806 - val_precision: 0.4038 - val_recall: 0.4615 - val_auc: 0.6890 - val_prc: 0.4329\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - tp: 196.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 202.0000 - accuracy: 0.7806 - precision: 0.4475 - recall: 0.4925 - auc: 0.7261 - prc: 0.4732 - val_loss: 0.5405 - val_tp: 44.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 47.0000 - val_accuracy: 0.7668 - val_precision: 0.3826 - val_recall: 0.4835 - val_auc: 0.6886 - val_prc: 0.4297\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8244 - tp: 198.0000 - fp: 243.0000 - tn: 1383.0000 - fn: 200.0000 - accuracy: 0.7811 - precision: 0.4490 - recall: 0.4975 - auc: 0.7265 - prc: 0.4763 - val_loss: 0.5346 - val_tp: 42.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 49.0000 - val_accuracy: 0.7727 - val_precision: 0.3889 - val_recall: 0.4615 - val_auc: 0.6883 - val_prc: 0.4308\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8249 - tp: 207.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 191.0000 - accuracy: 0.7643 - precision: 0.4199 - recall: 0.5201 - auc: 0.7262 - prc: 0.4740 - val_loss: 0.5554 - val_tp: 47.0000 - val_fp: 87.0000 - val_tn: 328.0000 - val_fn: 44.0000 - val_accuracy: 0.7411 - val_precision: 0.3507 - val_recall: 0.5165 - val_auc: 0.6868 - val_prc: 0.4254\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8249 - tp: 211.0000 - fp: 305.0000 - tn: 1321.0000 - fn: 187.0000 - accuracy: 0.7569 - precision: 0.4089 - recall: 0.5302 - auc: 0.7265 - prc: 0.4749 - val_loss: 0.5355 - val_tp: 42.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 49.0000 - val_accuracy: 0.7747 - val_precision: 0.3925 - val_recall: 0.4615 - val_auc: 0.6870 - val_prc: 0.4258\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8272 - tp: 178.0000 - fp: 208.0000 - tn: 1418.0000 - fn: 220.0000 - accuracy: 0.7885 - precision: 0.4611 - recall: 0.4472 - auc: 0.7274 - prc: 0.4730 - val_loss: 0.5312 - val_tp: 42.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 49.0000 - val_accuracy: 0.7787 - val_precision: 0.4000 - val_recall: 0.4615 - val_auc: 0.6883 - val_prc: 0.4301\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8282 - tp: 221.0000 - fp: 345.0000 - tn: 1281.0000 - fn: 177.0000 - accuracy: 0.7421 - precision: 0.3905 - recall: 0.5553 - auc: 0.7243 - prc: 0.4738 - val_loss: 0.5742 - val_tp: 48.0000 - val_fp: 101.0000 - val_tn: 314.0000 - val_fn: 43.0000 - val_accuracy: 0.7154 - val_precision: 0.3221 - val_recall: 0.5275 - val_auc: 0.6871 - val_prc: 0.4262\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8254 - tp: 205.0000 - fp: 279.0000 - tn: 1347.0000 - fn: 193.0000 - accuracy: 0.7668 - precision: 0.4236 - recall: 0.5151 - auc: 0.7247 - prc: 0.4759 - val_loss: 0.5219 - val_tp: 41.0000 - val_fp: 60.0000 - val_tn: 355.0000 - val_fn: 50.0000 - val_accuracy: 0.7826 - val_precision: 0.4059 - val_recall: 0.4505 - val_auc: 0.6886 - val_prc: 0.4351\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8254 - tp: 186.0000 - fp: 221.0000 - tn: 1405.0000 - fn: 212.0000 - accuracy: 0.7861 - precision: 0.4570 - recall: 0.4673 - auc: 0.7278 - prc: 0.4756 - val_loss: 0.5418 - val_tp: 45.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 46.0000 - val_accuracy: 0.7688 - val_precision: 0.3879 - val_recall: 0.4945 - val_auc: 0.6896 - val_prc: 0.4322\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8245 - tp: 215.0000 - fp: 319.0000 - tn: 1307.0000 - fn: 183.0000 - accuracy: 0.7520 - precision: 0.4026 - recall: 0.5402 - auc: 0.7270 - prc: 0.4766 - val_loss: 0.5584 - val_tp: 47.0000 - val_fp: 90.0000 - val_tn: 325.0000 - val_fn: 44.0000 - val_accuracy: 0.7352 - val_precision: 0.3431 - val_recall: 0.5165 - val_auc: 0.6884 - val_prc: 0.4296\n",
      "Epoch 248/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8253 - tp: 218.0000 - fp: 324.0000 - tn: 1302.0000 - fn: 180.0000 - accuracy: 0.7510 - precision: 0.4022 - recall: 0.5477 - auc: 0.7269 - prc: 0.4744 - val_loss: 0.5453 - val_tp: 46.0000 - val_fp: 74.0000 - val_tn: 341.0000 - val_fn: 45.0000 - val_accuracy: 0.7648 - val_precision: 0.3833 - val_recall: 0.5055 - val_auc: 0.6894 - val_prc: 0.4310\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8240 - tp: 203.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 195.0000 - accuracy: 0.7663 - precision: 0.4220 - recall: 0.5101 - auc: 0.7272 - prc: 0.4765 - val_loss: 0.5384 - val_tp: 44.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 47.0000 - val_accuracy: 0.7688 - val_precision: 0.3860 - val_recall: 0.4835 - val_auc: 0.6884 - val_prc: 0.4321\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8239 - tp: 200.0000 - fp: 249.0000 - tn: 1377.0000 - fn: 198.0000 - accuracy: 0.7792 - precision: 0.4454 - recall: 0.5025 - auc: 0.7273 - prc: 0.4767 - val_loss: 0.5389 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6882 - val_prc: 0.4323\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8238 - tp: 210.0000 - fp: 296.0000 - tn: 1330.0000 - fn: 188.0000 - accuracy: 0.7609 - precision: 0.4150 - recall: 0.5276 - auc: 0.7271 - prc: 0.4776 - val_loss: 0.5556 - val_tp: 47.0000 - val_fp: 88.0000 - val_tn: 327.0000 - val_fn: 44.0000 - val_accuracy: 0.7391 - val_precision: 0.3481 - val_recall: 0.5165 - val_auc: 0.6891 - val_prc: 0.4301\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8243 - tp: 205.0000 - fp: 289.0000 - tn: 1337.0000 - fn: 193.0000 - accuracy: 0.7619 - precision: 0.4150 - recall: 0.5151 - auc: 0.7264 - prc: 0.4764 - val_loss: 0.5384 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6878 - val_prc: 0.4303\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8241 - tp: 195.0000 - fp: 231.0000 - tn: 1395.0000 - fn: 203.0000 - accuracy: 0.7856 - precision: 0.4577 - recall: 0.4899 - auc: 0.7277 - prc: 0.4773 - val_loss: 0.5262 - val_tp: 41.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 50.0000 - val_accuracy: 0.7787 - val_precision: 0.3981 - val_recall: 0.4505 - val_auc: 0.6882 - val_prc: 0.4321\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8254 - tp: 194.0000 - fp: 222.0000 - tn: 1404.0000 - fn: 204.0000 - accuracy: 0.7895 - precision: 0.4663 - recall: 0.4874 - auc: 0.7271 - prc: 0.4772 - val_loss: 0.5415 - val_tp: 45.0000 - val_fp: 71.0000 - val_tn: 344.0000 - val_fn: 46.0000 - val_accuracy: 0.7688 - val_precision: 0.3879 - val_recall: 0.4945 - val_auc: 0.6886 - val_prc: 0.4294\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8243 - tp: 210.0000 - fp: 312.0000 - tn: 1314.0000 - fn: 188.0000 - accuracy: 0.7530 - precision: 0.4023 - recall: 0.5276 - auc: 0.7268 - prc: 0.4756 - val_loss: 0.5499 - val_tp: 47.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 44.0000 - val_accuracy: 0.7589 - val_precision: 0.3760 - val_recall: 0.5165 - val_auc: 0.6885 - val_prc: 0.4293\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8249 - tp: 200.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 198.0000 - accuracy: 0.7826 - precision: 0.4525 - recall: 0.5025 - auc: 0.7268 - prc: 0.4748 - val_loss: 0.5315 - val_tp: 42.0000 - val_fp: 62.0000 - val_tn: 353.0000 - val_fn: 49.0000 - val_accuracy: 0.7806 - val_precision: 0.4038 - val_recall: 0.4615 - val_auc: 0.6894 - val_prc: 0.4327\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8236 - tp: 201.0000 - fp: 275.0000 - tn: 1351.0000 - fn: 197.0000 - accuracy: 0.7668 - precision: 0.4223 - recall: 0.5050 - auc: 0.7267 - prc: 0.4772 - val_loss: 0.5536 - val_tp: 47.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 44.0000 - val_accuracy: 0.7470 - val_precision: 0.3588 - val_recall: 0.5165 - val_auc: 0.6878 - val_prc: 0.4311\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8249 - tp: 201.0000 - fp: 268.0000 - tn: 1358.0000 - fn: 197.0000 - accuracy: 0.7703 - precision: 0.4286 - recall: 0.5050 - auc: 0.7263 - prc: 0.4737 - val_loss: 0.5352 - val_tp: 42.0000 - val_fp: 63.0000 - val_tn: 352.0000 - val_fn: 49.0000 - val_accuracy: 0.7787 - val_precision: 0.4000 - val_recall: 0.4615 - val_auc: 0.6887 - val_prc: 0.4308\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8236 - tp: 200.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 198.0000 - accuracy: 0.7737 - precision: 0.4348 - recall: 0.5025 - auc: 0.7279 - prc: 0.4759 - val_loss: 0.5417 - val_tp: 45.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 46.0000 - val_accuracy: 0.7648 - val_precision: 0.3814 - val_recall: 0.4945 - val_auc: 0.6883 - val_prc: 0.4311\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8240 - tp: 196.0000 - fp: 239.0000 - tn: 1387.0000 - fn: 202.0000 - accuracy: 0.7821 - precision: 0.4506 - recall: 0.4925 - auc: 0.7276 - prc: 0.4763 - val_loss: 0.5357 - val_tp: 44.0000 - val_fp: 64.0000 - val_tn: 351.0000 - val_fn: 47.0000 - val_accuracy: 0.7806 - val_precision: 0.4074 - val_recall: 0.4835 - val_auc: 0.6890 - val_prc: 0.4318\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8241 - tp: 202.0000 - fp: 281.0000 - tn: 1345.0000 - fn: 196.0000 - accuracy: 0.7643 - precision: 0.4182 - recall: 0.5075 - auc: 0.7271 - prc: 0.4754 - val_loss: 0.5497 - val_tp: 47.0000 - val_fp: 78.0000 - val_tn: 337.0000 - val_fn: 44.0000 - val_accuracy: 0.7589 - val_precision: 0.3760 - val_recall: 0.5165 - val_auc: 0.6881 - val_prc: 0.4314\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8249 - tp: 199.0000 - fp: 245.0000 - tn: 1381.0000 - fn: 199.0000 - accuracy: 0.7806 - precision: 0.4482 - recall: 0.5000 - auc: 0.7262 - prc: 0.4752 - val_loss: 0.5361 - val_tp: 44.0000 - val_fp: 67.0000 - val_tn: 348.0000 - val_fn: 47.0000 - val_accuracy: 0.7747 - val_precision: 0.3964 - val_recall: 0.4835 - val_auc: 0.6898 - val_prc: 0.4360\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8234 - tp: 207.0000 - fp: 285.0000 - tn: 1341.0000 - fn: 191.0000 - accuracy: 0.7648 - precision: 0.4207 - recall: 0.5201 - auc: 0.7279 - prc: 0.4768 - val_loss: 0.5512 - val_tp: 47.0000 - val_fp: 85.0000 - val_tn: 330.0000 - val_fn: 44.0000 - val_accuracy: 0.7451 - val_precision: 0.3561 - val_recall: 0.5165 - val_auc: 0.6897 - val_prc: 0.4343\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8241 - tp: 209.0000 - fp: 306.0000 - tn: 1320.0000 - fn: 189.0000 - accuracy: 0.7554 - precision: 0.4058 - recall: 0.5251 - auc: 0.7272 - prc: 0.4762 - val_loss: 0.5431 - val_tp: 46.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 45.0000 - val_accuracy: 0.7628 - val_precision: 0.3802 - val_recall: 0.5055 - val_auc: 0.6897 - val_prc: 0.4375\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8234 - tp: 206.0000 - fp: 293.0000 - tn: 1333.0000 - fn: 192.0000 - accuracy: 0.7604 - precision: 0.4128 - recall: 0.5176 - auc: 0.7276 - prc: 0.4769 - val_loss: 0.5462 - val_tp: 47.0000 - val_fp: 75.0000 - val_tn: 340.0000 - val_fn: 44.0000 - val_accuracy: 0.7648 - val_precision: 0.3852 - val_recall: 0.5165 - val_auc: 0.6898 - val_prc: 0.4354\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8232 - tp: 201.0000 - fp: 264.0000 - tn: 1362.0000 - fn: 197.0000 - accuracy: 0.7722 - precision: 0.4323 - recall: 0.5050 - auc: 0.7277 - prc: 0.4773 - val_loss: 0.5361 - val_tp: 44.0000 - val_fp: 65.0000 - val_tn: 350.0000 - val_fn: 47.0000 - val_accuracy: 0.7787 - val_precision: 0.4037 - val_recall: 0.4835 - val_auc: 0.6891 - val_prc: 0.4331\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8233 - tp: 202.0000 - fp: 262.0000 - tn: 1364.0000 - fn: 196.0000 - accuracy: 0.7737 - precision: 0.4353 - recall: 0.5075 - auc: 0.7278 - prc: 0.4780 - val_loss: 0.5427 - val_tp: 46.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 45.0000 - val_accuracy: 0.7668 - val_precision: 0.3866 - val_recall: 0.5055 - val_auc: 0.6902 - val_prc: 0.4337\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8240 - tp: 196.0000 - fp: 242.0000 - tn: 1384.0000 - fn: 202.0000 - accuracy: 0.7806 - precision: 0.4475 - recall: 0.4925 - auc: 0.7274 - prc: 0.4763 - val_loss: 0.5364 - val_tp: 44.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 47.0000 - val_accuracy: 0.7767 - val_precision: 0.4000 - val_recall: 0.4835 - val_auc: 0.6898 - val_prc: 0.4335\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8234 - tp: 205.0000 - fp: 286.0000 - tn: 1340.0000 - fn: 193.0000 - accuracy: 0.7633 - precision: 0.4175 - recall: 0.5151 - auc: 0.7279 - prc: 0.4762 - val_loss: 0.5453 - val_tp: 47.0000 - val_fp: 77.0000 - val_tn: 338.0000 - val_fn: 44.0000 - val_accuracy: 0.7609 - val_precision: 0.3790 - val_recall: 0.5165 - val_auc: 0.6915 - val_prc: 0.4377\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8234 - tp: 209.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 189.0000 - accuracy: 0.7569 - precision: 0.4082 - recall: 0.5251 - auc: 0.7280 - prc: 0.4764 - val_loss: 0.5437 - val_tp: 47.0000 - val_fp: 73.0000 - val_tn: 342.0000 - val_fn: 44.0000 - val_accuracy: 0.7688 - val_precision: 0.3917 - val_recall: 0.5165 - val_auc: 0.6910 - val_prc: 0.4348\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8234 - tp: 200.0000 - fp: 258.0000 - tn: 1368.0000 - fn: 198.0000 - accuracy: 0.7747 - precision: 0.4367 - recall: 0.5025 - auc: 0.7279 - prc: 0.4769 - val_loss: 0.5366 - val_tp: 44.0000 - val_fp: 70.0000 - val_tn: 345.0000 - val_fn: 47.0000 - val_accuracy: 0.7688 - val_precision: 0.3860 - val_recall: 0.4835 - val_auc: 0.6909 - val_prc: 0.4336\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8228 - tp: 204.0000 - fp: 278.0000 - tn: 1348.0000 - fn: 194.0000 - accuracy: 0.7668 - precision: 0.4232 - recall: 0.5126 - auc: 0.7284 - prc: 0.4761 - val_loss: 0.5481 - val_tp: 46.0000 - val_fp: 76.0000 - val_tn: 339.0000 - val_fn: 45.0000 - val_accuracy: 0.7609 - val_precision: 0.3770 - val_recall: 0.5055 - val_auc: 0.6881 - val_prc: 0.4313\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8230 - tp: 200.0000 - fp: 260.0000 - tn: 1366.0000 - fn: 198.0000 - accuracy: 0.7737 - precision: 0.4348 - recall: 0.5025 - auc: 0.7276 - prc: 0.4770 - val_loss: 0.5375 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6892 - val_prc: 0.4321\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8233 - tp: 211.0000 - fp: 303.0000 - tn: 1323.0000 - fn: 187.0000 - accuracy: 0.7579 - precision: 0.4105 - recall: 0.5302 - auc: 0.7277 - prc: 0.4765 - val_loss: 0.5526 - val_tp: 47.0000 - val_fp: 84.0000 - val_tn: 331.0000 - val_fn: 44.0000 - val_accuracy: 0.7470 - val_precision: 0.3588 - val_recall: 0.5165 - val_auc: 0.6878 - val_prc: 0.4307\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8229 - tp: 204.0000 - fp: 283.0000 - tn: 1343.0000 - fn: 194.0000 - accuracy: 0.7643 - precision: 0.4189 - recall: 0.5126 - auc: 0.7282 - prc: 0.4774 - val_loss: 0.5367 - val_tp: 44.0000 - val_fp: 69.0000 - val_tn: 346.0000 - val_fn: 47.0000 - val_accuracy: 0.7708 - val_precision: 0.3894 - val_recall: 0.4835 - val_auc: 0.6891 - val_prc: 0.4321\n",
      "Epoch 276/500\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.9008 - tp: 24.0000 - fp: 20.0000 - tn: 131.0000 - fn: 25.0000 - accuracy: 0.7750 - precision: 0.5455 - recall: 0.4898 - auc: 0.7219 - prc: 0.5929Restoring model weights from the end of the best epoch: 226.\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8246 - tp: 186.0000 - fp: 226.0000 - tn: 1400.0000 - fn: 212.0000 - accuracy: 0.7836 - precision: 0.4515 - recall: 0.4673 - auc: 0.7273 - prc: 0.4763 - val_loss: 0.5369 - val_tp: 44.0000 - val_fp: 66.0000 - val_tn: 349.0000 - val_fn: 47.0000 - val_accuracy: 0.7767 - val_precision: 0.4000 - val_recall: 0.4835 - val_auc: 0.6879 - val_prc: 0.4313\n",
      "Epoch 276: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train a NN model based on the best class weight found\n",
    "weighted_model = make_model(input_shape=X_train.shape[-1])\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=best_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6296186c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(weighted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61bfc491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 794us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predictions_weighted = weighted_model.predict(X_train, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(X_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad1ba2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.5294618010520935\n",
      "tp :  68.0\n",
      "fp :  89.0\n",
      "tn :  417.0\n",
      "fn :  59.0\n",
      "accuracy :  0.7661927342414856\n",
      "precision :  0.4331210255622864\n",
      "recall :  0.5354330539703369\n",
      "auc :  0.7209315299987793\n",
      "prc :  0.4883788526058197\n",
      "\n",
      "Legitimate Transactions Detected (True Negatives):  417\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  89\n",
      "Fraudulent Transactions Missed (False Negatives):  59\n",
      "Fraudulent Transactions Detected (True Positives):  68\n",
      "Total Fraudulent Transactions:  127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performance report\n",
    "weighted_results = weighted_model.evaluate(X_test, y_test,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "  print(name, ': ', value)\n",
    "print()\n",
    "\n",
    "plot_cm(y_test, test_predictions_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b0fc57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7840909090909091\n",
      "Testing Accuracy: 0.7661927330173776\n",
      "AUC: 0.7216550994366812\n",
      "Present F1 score: 0.47887323943661975\n",
      "Absent F1 score: 0.8492871690427699\n",
      "Sensitivity: 0.5354330708661418\n",
      "Speicificity: 0.8241106719367589\n"
     ]
    }
   ],
   "source": [
    "# detailed report of model performance\n",
    "train_pred = (train_predictions_weighted > 0.5).astype('int')\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, train_pred)}\")\n",
    "test_pred = (test_predictions_weighted > 0.5).astype('int')\n",
    "print(f\"Testing Accuracy: {accuracy_score(y_test, test_pred)}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, test_predictions_weighted)}\")\n",
    "print(f\"Present F1 score: {f1_score(y_test, test_pred)}\")\n",
    "print(f\"Absent F1 score: {f1_score(y_test, test_pred,pos_label=0)}\")\n",
    "print(f\"Sensitivity: {recall_score(y_test, test_pred)}\")\n",
    "print(f\"Speicificity: {recall_score(y_test, test_pred,pos_label=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0853efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
